// ALGLIB++
// Based on ALGLIB: Copyright (c) Sergey Bochkanov (ALGLIB project).
// Revisions Copyright (c) Lydia Marie Williamson, Mark Hopkins Consulting
// Source License:
//	This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License
//	as published by the Free Software Foundation (www.fsf.org);
//	either version 2 of the License, or (at your option) any later version.
//
//	This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;
//	without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
//	See the GNU General Public License for more details.
//
//	A copy of the GNU General Public License is available at http://www.fsf.org/licensing/licenses
#define InAlgLib
#include "Optimization.h"

// === OPTGUARDAPI Package ===
// Depends on: (AlgLibInternal) APSERV
namespace alglib_impl {
// This subroutine initializes "internal" OptGuard report,  i.e. one intended
// for internal use by optimizers.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void optguardinitinternal(optguardreport *rep, ae_int_t n, ae_int_t k) {
   rep->nonc0suspected = false;
   rep->nonc0test0positive = false;
   rep->nonc0lipschitzc = 0.0;
   rep->nonc0fidx = -1;
   rep->nonc1suspected = false;
   rep->nonc1test0positive = false;
   rep->nonc1test1positive = false;
   rep->nonc1lipschitzc = 0.0;
   rep->nonc1fidx = -1;
   rep->badgradsuspected = false;
   rep->badgradfidx = -1;
   rep->badgradvidx = -1;
}

// This subroutine exports report to user-readable representation (all arrays
// are forced to have exactly same size as needed; unused arrays are  set  to
// zero length).
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void optguardexportreport(optguardreport *srcrep, ae_int_t n, ae_int_t k, bool badgradhasxj, optguardreport *dstrep) {
   ae_int_t i;
   ae_int_t j;
   dstrep->nonc0suspected = srcrep->nonc0suspected;
   dstrep->nonc0test0positive = srcrep->nonc0test0positive;
   if (srcrep->nonc0suspected) {
      dstrep->nonc0lipschitzc = srcrep->nonc0lipschitzc;
      dstrep->nonc0fidx = srcrep->nonc0fidx;
   } else {
      dstrep->nonc0lipschitzc = 0.0;
      dstrep->nonc0fidx = -1;
   }
   dstrep->nonc1suspected = srcrep->nonc1suspected;
   dstrep->nonc1test0positive = srcrep->nonc1test0positive;
   dstrep->nonc1test1positive = srcrep->nonc1test1positive;
   if (srcrep->nonc1suspected) {
      dstrep->nonc1lipschitzc = srcrep->nonc1lipschitzc;
      dstrep->nonc1fidx = srcrep->nonc1fidx;
   } else {
      dstrep->nonc1lipschitzc = 0.0;
      dstrep->nonc1fidx = -1;
   }
   dstrep->badgradsuspected = srcrep->badgradsuspected;
   if (srcrep->badgradsuspected) {
      dstrep->badgradfidx = srcrep->badgradfidx;
      dstrep->badgradvidx = srcrep->badgradvidx;
   } else {
      dstrep->badgradfidx = -1;
      dstrep->badgradvidx = -1;
   }
   if (badgradhasxj) {
      ae_vector_set_length(&dstrep->badgradxbase, n);
      for (j = 0; j < n; j++) {
         dstrep->badgradxbase.xR[j] = srcrep->badgradxbase.xR[j];
      }
      ae_matrix_set_length(&dstrep->badgraduser, k, n);
      ae_matrix_set_length(&dstrep->badgradnum, k, n);
      for (i = 0; i < k; i++) {
         for (j = 0; j < n; j++) {
            dstrep->badgraduser.xyR[i][j] = srcrep->badgraduser.xyR[i][j];
            dstrep->badgradnum.xyR[i][j] = srcrep->badgradnum.xyR[i][j];
         }
      }
   } else {
      ae_vector_set_length(&dstrep->badgradxbase, 0);
      ae_matrix_set_length(&dstrep->badgraduser, 0, 0);
      ae_matrix_set_length(&dstrep->badgradnum, 0, 0);
   }
}

// This subroutine exports report to user-readable representation (all arrays
// are forced to have exactly same size as needed; unused arrays are  set  to
// zero length).
//
// NOTE: we assume that SrcRep contains scaled X0[] and  D[],  i.e.  explicit
//       variable scaling was applied. We need to rescale them during export,
//       that's why we need S[] parameter.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorexportc1test0report(optguardnonc1test0report *srcrep, RVector *s, optguardnonc1test0report *dstrep) {
   ae_int_t i;
   dstrep->positive = srcrep->positive;
   if (srcrep->positive) {
      dstrep->stpidxa = srcrep->stpidxa;
      dstrep->stpidxb = srcrep->stpidxb;
      dstrep->inneriter = srcrep->inneriter;
      dstrep->outeriter = srcrep->outeriter;
      dstrep->fidx = srcrep->fidx;
      dstrep->cnt = srcrep->cnt;
      dstrep->n = srcrep->n;
      ae_vector_set_length(&dstrep->x0, srcrep->n);
      ae_vector_set_length(&dstrep->d, srcrep->n);
      for (i = 0; i < srcrep->n; i++) {
         dstrep->x0.xR[i] = srcrep->x0.xR[i] * s->xR[i];
         dstrep->d.xR[i] = srcrep->d.xR[i] * s->xR[i];
      }
      ae_vector_set_length(&dstrep->stp, srcrep->cnt);
      ae_vector_set_length(&dstrep->f, srcrep->cnt);
      for (i = 0; i < srcrep->cnt; i++) {
         dstrep->stp.xR[i] = srcrep->stp.xR[i];
         dstrep->f.xR[i] = srcrep->f.xR[i];
      }
   } else {
      dstrep->stpidxa = -1;
      dstrep->stpidxb = -1;
      dstrep->inneriter = -1;
      dstrep->outeriter = -1;
      dstrep->fidx = -1;
      dstrep->cnt = 0;
      dstrep->n = 0;
      ae_vector_set_length(&dstrep->x0, 0);
      ae_vector_set_length(&dstrep->d, 0);
      ae_vector_set_length(&dstrep->stp, 0);
      ae_vector_set_length(&dstrep->f, 0);
   }
}

// This subroutine exports report to user-readable representation (all arrays
// are forced to have exactly same size as needed; unused arrays are  set  to
// zero length).
//
// NOTE: we assume that SrcRep contains scaled X0[], D[] and G[], i.e. explicit
//       variable scaling was applied. We need to rescale them during export,
//       that's why we need S[] parameter.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorexportc1test1report(optguardnonc1test1report *srcrep, RVector *s, optguardnonc1test1report *dstrep) {
   ae_int_t i;
   dstrep->positive = srcrep->positive;
   if (srcrep->positive) {
      ae_assert(srcrep->vidx >= 0 && srcrep->vidx < srcrep->n, "SmoothnessMonitorExportC1Test1Report: integrity check failed");
      dstrep->stpidxa = srcrep->stpidxa;
      dstrep->stpidxb = srcrep->stpidxb;
      dstrep->inneriter = srcrep->inneriter;
      dstrep->outeriter = srcrep->outeriter;
      dstrep->fidx = srcrep->fidx;
      dstrep->vidx = srcrep->vidx;
      dstrep->cnt = srcrep->cnt;
      dstrep->n = srcrep->n;
      ae_vector_set_length(&dstrep->x0, srcrep->n);
      ae_vector_set_length(&dstrep->d, srcrep->n);
      for (i = 0; i < srcrep->n; i++) {
         dstrep->x0.xR[i] = srcrep->x0.xR[i] * s->xR[i];
         dstrep->d.xR[i] = srcrep->d.xR[i] * s->xR[i];
      }
      ae_vector_set_length(&dstrep->stp, srcrep->cnt);
      ae_vector_set_length(&dstrep->g, srcrep->cnt);
      for (i = 0; i < srcrep->cnt; i++) {
         dstrep->stp.xR[i] = srcrep->stp.xR[i];
         dstrep->g.xR[i] = srcrep->g.xR[i] / s->xR[srcrep->vidx];
      }
   } else {
      dstrep->stpidxa = -1;
      dstrep->stpidxb = -1;
      dstrep->inneriter = -1;
      dstrep->outeriter = -1;
      dstrep->fidx = -1;
      dstrep->vidx = -1;
      dstrep->cnt = 0;
      dstrep->n = 0;
      ae_vector_set_length(&dstrep->x0, 0);
      ae_vector_set_length(&dstrep->d, 0);
      ae_vector_set_length(&dstrep->stp, 0);
      ae_vector_set_length(&dstrep->g, 0);
   }
}

// Returns True when all flags are clear. Intended for easy  coding  of  unit
// tests.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
bool optguardallclear(optguardreport *rep) {
   bool result;
   result = !(rep->badgradsuspected || rep->nonc0suspected || rep->nonc1suspected);
   return result;
}

void optguardreport_init(void *_p, bool make_automatic) {
   optguardreport *p = (optguardreport *)_p;
   ae_vector_init(&p->badgradxbase, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->badgraduser, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->badgradnum, 0, 0, DT_REAL, make_automatic);
}

void optguardreport_copy(void *_dst, const void *_src, bool make_automatic) {
   optguardreport *dst = (optguardreport *)_dst;
   const optguardreport *src = (const optguardreport *)_src;
   dst->nonc0suspected = src->nonc0suspected;
   dst->nonc0test0positive = src->nonc0test0positive;
   dst->nonc0fidx = src->nonc0fidx;
   dst->nonc0lipschitzc = src->nonc0lipschitzc;
   dst->nonc1suspected = src->nonc1suspected;
   dst->nonc1test0positive = src->nonc1test0positive;
   dst->nonc1test1positive = src->nonc1test1positive;
   dst->nonc1fidx = src->nonc1fidx;
   dst->nonc1lipschitzc = src->nonc1lipschitzc;
   dst->badgradsuspected = src->badgradsuspected;
   dst->badgradfidx = src->badgradfidx;
   dst->badgradvidx = src->badgradvidx;
   ae_vector_copy(&dst->badgradxbase, &src->badgradxbase, make_automatic);
   ae_matrix_copy(&dst->badgraduser, &src->badgraduser, make_automatic);
   ae_matrix_copy(&dst->badgradnum, &src->badgradnum, make_automatic);
}

void optguardreport_free(void *_p, bool make_automatic) {
   optguardreport *p = (optguardreport *)_p;
   ae_vector_free(&p->badgradxbase, make_automatic);
   ae_matrix_free(&p->badgraduser, make_automatic);
   ae_matrix_free(&p->badgradnum, make_automatic);
}

void optguardnonc0report_init(void *_p, bool make_automatic) {
   optguardnonc0report *p = (optguardnonc0report *)_p;
   ae_vector_init(&p->x0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->f, 0, DT_REAL, make_automatic);
}

void optguardnonc0report_copy(void *_dst, const void *_src, bool make_automatic) {
   optguardnonc0report *dst = (optguardnonc0report *)_dst;
   const optguardnonc0report *src = (const optguardnonc0report *)_src;
   dst->positive = src->positive;
   dst->fidx = src->fidx;
   ae_vector_copy(&dst->x0, &src->x0, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->n = src->n;
   ae_vector_copy(&dst->stp, &src->stp, make_automatic);
   ae_vector_copy(&dst->f, &src->f, make_automatic);
   dst->cnt = src->cnt;
   dst->stpidxa = src->stpidxa;
   dst->stpidxb = src->stpidxb;
   dst->inneriter = src->inneriter;
   dst->outeriter = src->outeriter;
}

void optguardnonc0report_free(void *_p, bool make_automatic) {
   optguardnonc0report *p = (optguardnonc0report *)_p;
   ae_vector_free(&p->x0, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->stp, make_automatic);
   ae_vector_free(&p->f, make_automatic);
}

void optguardnonc1test0report_init(void *_p, bool make_automatic) {
   optguardnonc1test0report *p = (optguardnonc1test0report *)_p;
   ae_vector_init(&p->x0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->f, 0, DT_REAL, make_automatic);
}

void optguardnonc1test0report_copy(void *_dst, const void *_src, bool make_automatic) {
   optguardnonc1test0report *dst = (optguardnonc1test0report *)_dst;
   const optguardnonc1test0report *src = (const optguardnonc1test0report *)_src;
   dst->positive = src->positive;
   dst->fidx = src->fidx;
   ae_vector_copy(&dst->x0, &src->x0, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->n = src->n;
   ae_vector_copy(&dst->stp, &src->stp, make_automatic);
   ae_vector_copy(&dst->f, &src->f, make_automatic);
   dst->cnt = src->cnt;
   dst->stpidxa = src->stpidxa;
   dst->stpidxb = src->stpidxb;
   dst->inneriter = src->inneriter;
   dst->outeriter = src->outeriter;
}

void optguardnonc1test0report_free(void *_p, bool make_automatic) {
   optguardnonc1test0report *p = (optguardnonc1test0report *)_p;
   ae_vector_free(&p->x0, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->stp, make_automatic);
   ae_vector_free(&p->f, make_automatic);
}

void optguardnonc1test1report_init(void *_p, bool make_automatic) {
   optguardnonc1test1report *p = (optguardnonc1test1report *)_p;
   ae_vector_init(&p->x0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
}

void optguardnonc1test1report_copy(void *_dst, const void *_src, bool make_automatic) {
   optguardnonc1test1report *dst = (optguardnonc1test1report *)_dst;
   const optguardnonc1test1report *src = (const optguardnonc1test1report *)_src;
   dst->positive = src->positive;
   dst->fidx = src->fidx;
   dst->vidx = src->vidx;
   ae_vector_copy(&dst->x0, &src->x0, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->n = src->n;
   ae_vector_copy(&dst->stp, &src->stp, make_automatic);
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->cnt = src->cnt;
   dst->stpidxa = src->stpidxa;
   dst->stpidxb = src->stpidxb;
   dst->inneriter = src->inneriter;
   dst->outeriter = src->outeriter;
}

void optguardnonc1test1report_free(void *_p, bool make_automatic) {
   optguardnonc1test1report *p = (optguardnonc1test1report *)_p;
   ae_vector_free(&p->x0, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->stp, make_automatic);
   ae_vector_free(&p->g, make_automatic);
}
} // end of namespace alglib_impl

namespace alglib {
// This structure is used to store  OptGuard  report,  i.e.  report  on   the
// properties of the nonlinear function being optimized with ALGLIB.
//
// After you tell your optimizer to activate OptGuard  this technology starts
// to silently monitor function values and gradients/Jacobians  being  passed
// all around during your optimization session. Depending on specific set  of
// checks enabled OptGuard may perform additional function evaluations  (say,
// about 3*N evaluations if you want to check analytic gradient for errors).
//
// Upon discovering that something strange happens  (function  values  and/or
// gradient components change too sharply and/or unexpectedly) OptGuard  sets
// one of the "suspicion  flags" (without interrupting optimization session).
// After optimization is done, you can examine OptGuard report.
//
// Following report fields can be set:
// * nonc0suspected
// * nonc1suspected
// * badgradsuspected
//
// ==== WHAT CAN BE DETECTED WITH OptGuard INTEGRITY CHECKER ====
//
// Following  types  of  errors  in your target function (constraints) can be
// caught:
// a) discontinuous functions ("non-C0" part of the report)
// b) functions with discontinuous derivative ("non-C1" part of the report)
// c) errors in the analytic gradient provided by user
//
// These types of errors result in optimizer  stopping  well  before reaching
// solution (most often - right after encountering discontinuity).
//
// Type A errors are usually  coding  errors  during  implementation  of  the
// target function. Most "normal" problems involve continuous functions,  and
// anyway you can't reliably optimize discontinuous function.
//
// Type B errors are either coding errors or (in case code itself is correct)
// evidence of the fact  that  your  problem  is  an  "incorrect"  one.  Most
// optimizers (except for ones provided by MINNS subpackage) do  not  support
// nonsmooth problems.
//
// Type C errors are coding errors which often prevent optimizer from  making
// even one step  or result in optimizing stopping  too  early,  as  soon  as
// actual descent direction becomes too different from one suggested by user-
// supplied gradient.
//
// ==== WHAT IS REPORTED ====
//
// Following set of report fields deals with discontinuous  target functions,
// ones not belonging to C0 continuity class:
//
// * nonc0suspected - is a flag which is set upon discovering some indication
//   of the discontinuity. If this flag is false, the rest of "non-C0" fields
//   should be ignored
// * nonc0fidx - is an index of the function (0 for  target  function,  1  or
//   higher for nonlinear constraints) which is suspected of being "non-C0"
// * nonc0lipshitzc - a Lipchitz constant for a function which was  suspected
//   of being non-continuous.
// * nonc0test0positive -  set  to  indicate  specific  test  which  detected
//   continuity violation (test #0)
//
// Following set of report fields deals with discontinuous gradient/Jacobian,
// i.e. with functions violating C1 continuity:
//
// * nonc1suspected - is a flag which is set upon discovering some indication
//   of the discontinuity. If this flag is false, the rest of "non-C1" fields
//   should be ignored
// * nonc1fidx - is an index of the function (0 for  target  function,  1  or
//   higher for nonlinear constraints) which is suspected of being "non-C1"
// * nonc1lipshitzc - a Lipchitz constant for a function gradient  which  was
//   suspected of being non-smooth.
// * nonc1test0positive -  set  to  indicate  specific  test  which  detected
//   continuity violation (test #0)
// * nonc1test1positive -  set  to  indicate  specific  test  which  detected
//   continuity violation (test #1)
//
// Following set of report fields deals with errors in the gradient:
// * badgradsuspected - is a flad which is set upon discovering an  error  in
//   the analytic gradient supplied by user
// * badgradfidx - index  of   the  function  with bad gradient (0 for target
//   function, 1 or higher for nonlinear constraints)
// * badgradvidx - index of the variable
// * badgradxbase - location where Jacobian is tested
// * following  matrices  store  user-supplied  Jacobian  and  its  numerical
//   differentiation version (which is assumed to be  free  from  the  coding
//   errors), both of them computed near the initial point:
//   * badgraduser, an array[K,N], analytic Jacobian supplied by user
//   * badgradnum,  an array[K,N], numeric  Jacobian computed by ALGLIB
//   Here K is a total number of  nonlinear  functions  (target  +  nonlinear
//   constraints), N is a variable number.
//   The  element  of  badgraduser[] with index [badgradfidx,badgradvidx]  is
//   assumed to be wrong.
//
// More detailed error log can  be  obtained  from  optimizer  by  explicitly
// requesting reports for tests C0.0, C1.0, C1.1.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
DefClass(optguardreport, DecVal(nonc0suspected) DecVal(nonc0test0positive) DecVal(nonc0fidx) DecVal(nonc0lipschitzc) DecVal(nonc1suspected) DecVal(nonc1test0positive) DecVal(nonc1test1positive) DecVal(nonc1fidx) DecVal(nonc1lipschitzc) DecVal(badgradsuspected) DecVal(badgradfidx) DecVal(badgradvidx) DecVar(badgradxbase) DecVar(badgraduser) DecVar(badgradnum))

// This  structure  is  used  for  detailed   reporting  about  suspected  C0
// continuity violation.
//
// ==== WHAT IS TESTED ====
//
// C0 test  studies  function  values (not gradient!)  obtained  during  line
// searches and monitors estimate of the Lipschitz  constant.  Sudden  spikes
// usually indicate that discontinuity was detected.
//
// ==== WHAT IS REPORTED ====
//
// Actually, report retrieval function returns TWO report structures:
//
// * one for most suspicious point found so far (one with highest  change  in
//   the function value), so called "strongest" report
// * another one for most detailed line search (more function  evaluations  =
//   easier to understand what's going on) which triggered  test #0 criteria,
//   so called "longest" report
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * fidx - is an index of the function (0 for  target  function, 1 or higher
//   for nonlinear constraints) which is suspected of being "non-C1"
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
// * inneriter, outeriter - inner and outer iteration indexes (can be -1 if no
//   iteration information was specified)
//
// You can plot function values stored in stp[]  and  f[]  arrays  and  study
// behavior of your function by your own eyes, just  to  be  sure  that  test
// correctly reported C1 violation.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
DefClass(optguardnonc0report, DecVal(positive) DecVal(fidx) DecVar(x0) DecVar(d) DecVal(n) DecVar(stp) DecVar(f) DecVal(cnt) DecVal(stpidxa) DecVal(stpidxb) DecVal(inneriter) DecVal(outeriter))

// This  structure  is  used  for  detailed   reporting  about  suspected  C1
// continuity violation as flagged by C1 test #0 (OptGuard  has several tests
// for C1 continuity, this report is used by #0).
//
// ==== WHAT IS TESTED ====
//
// C1 test #0 studies function values (not gradient!)  obtained  during  line
// searches and monitors behavior of directional  derivative  estimate.  This
// test is less powerful than test #1, but it does  not  depend  on  gradient
// values  and  thus  it  is  more  robust  against  artifacts  introduced by
// numerical differentiation.
//
// ==== WHAT IS REPORTED ====
//
// Actually, report retrieval function returns TWO report structures:
//
// * one for most suspicious point found so far (one with highest  change  in
//   the directional derivative), so called "strongest" report
// * another one for most detailed line search (more function  evaluations  =
//   easier to understand what's going on) which triggered  test #0 criteria,
//   so called "longest" report
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * fidx - is an index of the function (0 for  target  function, 1 or higher
//   for nonlinear constraints) which is suspected of being "non-C1"
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
// * inneriter, outeriter - inner and outer iteration indexes (can be -1 if no
//   iteration information was specified)
//
// You can plot function values stored in stp[]  and  f[]  arrays  and  study
// behavior of your function by your own eyes, just  to  be  sure  that  test
// correctly reported C1 violation.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
DefClass(optguardnonc1test0report, DecVal(positive) DecVal(fidx) DecVar(x0) DecVar(d) DecVal(n) DecVar(stp) DecVar(f) DecVal(cnt) DecVal(stpidxa) DecVal(stpidxb) DecVal(inneriter) DecVal(outeriter))

// This  structure  is  used  for  detailed   reporting  about  suspected  C1
// continuity violation as flagged by C1 test #1 (OptGuard  has several tests
// for C1 continuity, this report is used by #1).
//
// ==== WHAT IS TESTED ====
//
// C1 test #1 studies individual  components  of  the  gradient  as  recorded
// during line searches. Upon discovering discontinuity in the gradient  this
// test records specific component which was suspected (or  one  with  highest
// indication of discontinuity if multiple components are suspected).
//
// When precise analytic gradient is provided this test is more powerful than
// test #0  which  works  with  function  values  and  ignores  user-provided
// gradient.  However,  test  #0  becomes  more   powerful   when   numerical
// differentiation is employed (in such cases test #1 detects  higher  levels
// of numerical noise and becomes too conservative).
//
// This test also tells specific components of the gradient which violate  C1
// continuity, which makes it more informative than #0, which just tells that
// continuity is violated.
//
// ==== WHAT IS REPORTED ====
//
// Actually, report retrieval function returns TWO report structures:
//
// * one for most suspicious point found so far (one with highest  change  in
//   the directional derivative), so called "strongest" report
// * another one for most detailed line search (more function  evaluations  =
//   easier to understand what's going on) which triggered  test #1 criteria,
//   so called "longest" report
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * fidx - is an index of the function (0 for  target  function, 1 or higher
//   for nonlinear constraints) which is suspected of being "non-C1"
// * vidx - is an index of the variable in [0,N) with nonsmooth derivative
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], g[] - arrays of length CNT which store step lengths and  gradient
//   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
//   vidx-th component of the gradient.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
// * inneriter, outeriter - inner and outer iteration indexes (can be -1 if  no
//   iteration information was specified)
//
// You can plot function values stored in stp[]  and  g[]  arrays  and  study
// behavior of your function by your own eyes, just  to  be  sure  that  test
// correctly reported C1 violation.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
DefClass(optguardnonc1test1report, DecVal(positive) DecVal(fidx) DecVal(vidx) DecVar(x0) DecVar(d) DecVal(n) DecVar(stp) DecVar(g) DecVal(cnt) DecVal(stpidxa) DecVal(stpidxb) DecVal(inneriter) DecVal(outeriter))
} // end of namespace alglib

// === OPTSERV Package ===
// Depends on: (LinAlg) SVD, MATINV
// Depends on: OPTGUARDAPI
namespace alglib_impl {
static const double optserv_ognoiselevelf = 100.0 * machineepsilon;
static const double optserv_ognoiselevelg = 10000.0 * machineepsilon;
static const double optserv_ogminrating0 = 50.0;
static const double optserv_ogminrating1 = 50.0;

// This subroutine checks violation of the box constraints. On output it sets
// bcerr to the maximum scaled violation, bcidx to the index of the violating
// constraint.
//
// if bcerr == 0 (say, if no constraints are violated) then bcidx == -1.
//
// If nonunits == false then s[] is not referenced at all (assumed unit).
// ALGLIB: Copyright 07.11.2018 by Sergey Bochkanov
void checkbcviolation(BVector *hasbndl, RVector *bndl, BVector *hasbndu, RVector *bndu, RVector *x, ae_int_t n, RVector *s, bool nonunits, double *bcerr, ae_int_t *bcidx) {
   ae_int_t i;
   double vs;
   double ve;
   *bcerr = 0.0;
   *bcidx = 0;
   *bcerr = 0.0;
   *bcidx = -1;
   for (i = 0; i < n; i++) {
   // Fetch scale
      if (nonunits) {
         vs = 1.0 / s->xR[i];
      } else {
         vs = 1.0;
      }
   // Check lower bound
      if (hasbndl->xB[i] && x->xR[i] < bndl->xR[i]) {
         ve = (bndl->xR[i] - x->xR[i]) * vs;
         if (ve > *bcerr) {
            *bcerr = ve;
            *bcidx = i;
         }
      }
   // Check upper bound
      if (hasbndu->xB[i] && x->xR[i] > bndu->xR[i]) {
         ve = (x->xR[i] - bndu->xR[i]) * vs;
         if (ve > *bcerr) {
            *bcerr = ve;
            *bcidx = i;
         }
      }
   }
}

// This subroutine checks violation of the general linear constraints.
//
// Constraints are assumed to be un-normalized and stored in the format "NEC
// equality ones followed by NIC inequality ones".
//
// On output it sets lcerr to the maximum scaled violation, lcidx to the source
// index of the most violating constraint (row indexes of CLEIC are mapped to
// the indexes of the "original" constraints via LCSrcIdx[] array.
//
// if lcerr == 0 (say, if no constraints are violated) then lcidx == -1.
//
// If nonunits == false then s[] is not referenced at all (assumed unit).
// ALGLIB: Copyright 07.11.2018 by Sergey Bochkanov
void checklcviolation(RMatrix *cleic, ZVector *lcsrcidx, ae_int_t nec, ae_int_t nic, RVector *x, ae_int_t n, double *lcerr, ae_int_t *lcidx) {
   ae_int_t i;
   ae_int_t j;
   double cx;
   double cnrm;
   double v;
   *lcerr = 0.0;
   *lcidx = 0;
   *lcerr = 0.0;
   *lcidx = -1;
   for (i = 0; i < nec + nic; i++) {
      cx = -cleic->xyR[i][n];
      cnrm = 0.0;
      for (j = 0; j < n; j++) {
         v = cleic->xyR[i][j];
         cx += v * x->xR[j];
         cnrm += v * v;
      }
      cnrm = sqrt(cnrm);
      cx /= coalesce(cnrm, 1.0);
      if (i < nec) {
         cx = fabs(cx);
      } else {
         cx = rmax2(cx, 0.0);
      }
      if (cx > *lcerr) {
         *lcerr = cx;
         *lcidx = lcsrcidx->xZ[i];
      }
   }
}

// This subroutine checks violation of the nonlinear constraints. Fi[0] is the
// target value (ignored), Fi[1:NG+NH] are values of nonlinear constraints.
//
// On output it sets nlcerr to the scaled violation, nlcidx to the index
// of the most violating constraint in [0,NG+NH-1] range.
//
// if nlcerr == 0 (say, if no constraints are violated) then nlcidx == -1.
//
// If nonunits == false then s[] is not referenced at all (assumed unit).
// ALGLIB: Copyright 07.11.2018 by Sergey Bochkanov
void checknlcviolation(RVector *fi, ae_int_t ng, ae_int_t nh, double *nlcerr, ae_int_t *nlcidx) {
   ae_int_t i;
   double v;
   *nlcerr = 0.0;
   *nlcidx = 0;
   *nlcerr = 0.0;
   *nlcidx = -1;
   for (i = 0; i < ng + nh; i++) {
      v = fi->xR[i + 1];
      if (i < ng) {
         v = fabs(v);
      } else {
         v = rmax2(v, 0.0);
      }
      if (v > *nlcerr) {
         *nlcerr = v;
         *nlcidx = i;
      }
   }
}

// This subroutine is same as CheckNLCViolation, but  is  works  with  scaled
// constraints: it assumes that Fi[] were divided by FScales[] vector  BEFORE
// passing them to this function.
//
// The function checks scaled values, but reports unscaled errors.
// ALGLIB: Copyright 07.11.2018 by Sergey Bochkanov
void unscaleandchecknlcviolation(RVector *fi, RVector *fscales, ae_int_t ng, ae_int_t nh, double *nlcerr, ae_int_t *nlcidx) {
   ae_int_t i;
   double v;
   *nlcerr = 0.0;
   *nlcidx = 0;
   *nlcerr = 0.0;
   *nlcidx = -1;
   for (i = 0; i < ng + nh; i++) {
      ae_assert(fscales->xR[i + 1] > 0.0, "UnscaleAndCheckNLCViolation: integrity check failed");
      v = fi->xR[i + 1] * fscales->xR[i + 1];
      if (i < ng) {
         v = fabs(v);
      } else {
         v = rmax2(v, 0.0);
      }
      if (v > *nlcerr) {
         *nlcerr = v;
         *nlcidx = i;
      }
   }
}

// This subroutine is used to prepare threshold value which will be used for
// trimming of the target function (see comments on TrimFunction() for more
// information).
//
// This function accepts only one parameter: function value at the starting
// point. It returns threshold which will be used for trimming.
// ALGLIB: Copyright 10.05.2011 by Sergey Bochkanov
void trimprepare(double f, double *threshold) {
   *threshold = 0.0;
   *threshold = 10.0 * (fabs(f) + 1.0);
}

// This subroutine is used to "trim" target function, i.e. to do following
// transformation:
//
//                    { {F,G}          if F < Threshold
//     {F_tr, G_tr} = {
//                    { {Threshold, 0} if F >= Threshold
//
// Such transformation allows us to  solve  problems  with  singularities  by
// redefining function in such way that it becomes bounded from above.
// ALGLIB: Copyright 10.05.2011 by Sergey Bochkanov
void trimfunction(double *f, RVector *g, ae_int_t n, double threshold) {
   ae_int_t i;
   if (*f >= threshold) {
      *f = threshold;
      for (i = 0; i < n; i++) {
         g->xR[i] = 0.0;
      }
   }
}

// This function enforces boundary constraints in the X.
//
// This function correctly (although a bit inefficient) handles BL[i] which
// are -INF and BU[i] which are +INF.
//
// We have NMain+NSlack  dimensional  X,  with first NMain components bounded
// by BL/BU, and next NSlack ones bounded by non-negativity constraints.
//
// Inputs:
//     X       -   array[NMain+NSlack], point
//     BL      -   array[NMain], lower bounds
//                 (may contain -INF, when bound is not present)
//     HaveBL  -   array[NMain], if HaveBL[i] is False,
//                 then i-th bound is not present
//     BU      -   array[NMain], upper bounds
//                 (may contain +INF, when bound is not present)
//     HaveBU  -   array[NMain], if HaveBU[i] is False,
//                 then i-th bound is not present
//
// Outputs:
//     X       -   X with all constraints being enforced
//
// It returns True when constraints are consistent,
// False - when constraints are inconsistent.
// ALGLIB: Copyright 10.01.2012 by Sergey Bochkanov
bool enforceboundaryconstraints(RVector *x, RVector *bl, BVector *havebl, RVector *bu, BVector *havebu, ae_int_t nmain, ae_int_t nslack) {
   ae_int_t i;
   bool result;
   result = false;
   for (i = 0; i < nmain; i++) {
      if (havebl->xB[i] && havebu->xB[i] && bl->xR[i] > bu->xR[i]) {
         return result;
      }
      if (havebl->xB[i] && x->xR[i] < bl->xR[i]) {
         x->xR[i] = bl->xR[i];
      }
      if (havebu->xB[i] && x->xR[i] > bu->xR[i]) {
         x->xR[i] = bu->xR[i];
      }
   }
   for (i = 0; i < nslack; i++) {
      if (x->xR[nmain + i] < 0.0) {
         x->xR[nmain + i] = 0.0;
      }
   }
   result = true;
   return result;
}

// This function projects gradient into feasible area of boundary constrained
// optimization  problem.  X  can  be  infeasible  with  respect  to boundary
// constraints.  We  have  NMain+NSlack  dimensional  X,   with  first  NMain
// components bounded by BL/BU, and next NSlack ones bounded by non-negativity
// constraints.
//
// Inputs:
//     X       -   array[NMain+NSlack], point
//     G       -   array[NMain+NSlack], gradient
//     BL      -   lower bounds (may contain -INF, when bound is not present)
//     HaveBL  -   if HaveBL[i] is False, then i-th bound is not present
//     BU      -   upper bounds (may contain +INF, when bound is not present)
//     HaveBU  -   if HaveBU[i] is False, then i-th bound is not present
//
// Outputs:
//     G       -   projection of G. Components of G which satisfy one of the
//                 following
//                     (1) (X[I] <= BndL[I]) and (G[I] > 0), OR
//                     (2) (X[I] >= BndU[I]) and (G[I] < 0)
//                 are replaced by zeros.
//
// NOTE 1: this function assumes that constraints are feasible. It throws
// exception otherwise.
//
// NOTE 2: in fact, projection of ANTI-gradient is calculated,  because  this
// function trims components of -G which points outside of the feasible area.
// However, working with -G is considered confusing, because all optimization
// source work with G.
// ALGLIB: Copyright 10.01.2012 by Sergey Bochkanov
void projectgradientintobc(RVector *x, RVector *g, RVector *bl, BVector *havebl, RVector *bu, BVector *havebu, ae_int_t nmain, ae_int_t nslack) {
   ae_int_t i;
   for (i = 0; i < nmain; i++) {
      ae_assert(!havebl->xB[i] || !havebu->xB[i] || bl->xR[i] <= bu->xR[i], "ProjectGradientIntoBC: internal error (infeasible constraints)");
      if (havebl->xB[i] && x->xR[i] <= bl->xR[i] && g->xR[i] > 0.0) {
         g->xR[i] = 0.0;
      }
      if (havebu->xB[i] && x->xR[i] >= bu->xR[i] && g->xR[i] < 0.0) {
         g->xR[i] = 0.0;
      }
   }
   for (i = 0; i < nslack; i++) {
      if (x->xR[nmain + i] <= 0.0 && g->xR[nmain + i] > 0.0) {
         g->xR[nmain + i] = 0.0;
      }
   }
}

// Given
//     a) initial point X0[NMain+NSlack]
//        (feasible with respect to bound constraints)
//     b) step vector alpha*D[NMain+NSlack]
//     c) boundary constraints BndL[NMain], BndU[NMain]
//     d) implicit non-negativity constraints for slack variables
// this  function  calculates  bound  on  the step length subject to boundary
// constraints.
//
// It returns:
//     *  MaxStepLen - such step length that X0+MaxStepLen*alpha*D is exactly
//        at the boundary given by constraints
//     *  VariableToFreeze - index of the constraint to be activated,
//        0 <= VariableToFreeze < NMain+NSlack
//     *  ValueToFreeze - value of the corresponding constraint.
//
// Notes:
//     * it is possible that several constraints can be activated by the step
//       at once. In such cases only one constraint is returned. It is caller
//       responsibility to check other constraints. This function makes  sure
//       that we activate at least one constraint, and everything else is the
//       responsibility of the caller.
//     * steps smaller than MaxStepLen still can activate constraints due  to
//       numerical errors. Thus purpose of this  function  is  not  to  guard
//       against accidental activation of the constraints - quite the reverse,
//       its purpose is to activate at least constraint upon performing  step
//       which is too long.
//     * in case there is no constraints to activate, we return negative
//       VariableToFreeze and zero MaxStepLen and ValueToFreeze.
//     * this function assumes that constraints are consistent; it throws
//       exception otherwise.
//
// Inputs:
//     X           -   array[NMain+NSlack], point. Must be feasible with respect
//                     to bound constraints (exception will be thrown otherwise)
//     D           -   array[NMain+NSlack], step direction
//     alpha       -   scalar multiplier before D, alpha != 0
//     BndL        -   lower bounds, array[NMain]
//                     (may contain -INF, when bound is not present)
//     HaveBndL    -   array[NMain], if HaveBndL[i] is False,
//                     then i-th bound is not present
//     BndU        -   array[NMain], upper bounds
//                     (may contain +INF, when bound is not present)
//     HaveBndU    -   array[NMain], if HaveBndU[i] is False,
//                     then i-th bound is not present
//     NMain       -   number of main variables
//     NSlack      -   number of slack variables
//
// Outputs:
//     VariableToFreeze:
//                     * negative value     = step is unbounded, ValueToFreeze == 0,
//                                            MaxStepLen == 0.
//                     * non-negative value = at least one constraint, given by
//                                            this parameter, will  be  activated
//                                            upon performing maximum step.
//     ValueToFreeze-  value of the variable which will be constrained
//     MaxStepLen  -   maximum length of the step. Can be zero when step vector
//                     looks outside of the feasible area.
// ALGLIB: Copyright 10.01.2012 by Sergey Bochkanov
void calculatestepbound(RVector *x, RVector *d, double alpha, RVector *bndl, BVector *havebndl, RVector *bndu, BVector *havebndu, ae_int_t nmain, ae_int_t nslack, ae_int_t *variabletofreeze, double *valuetofreeze, double *maxsteplen) {
   ae_int_t i;
   double prevmax;
   double initval;
   *variabletofreeze = 0;
   *valuetofreeze = 0.0;
   *maxsteplen = 0.0;
   ae_assert(alpha != 0.0, "CalculateStepBound: zero alpha");
   *variabletofreeze = -1;
   initval = maxrealnumber;
   *maxsteplen = initval;
   for (i = 0; i < nmain; i++) {
      if (havebndl->xB[i] && alpha * d->xR[i] < 0.0) {
         ae_assert(x->xR[i] >= bndl->xR[i], "CalculateStepBound: infeasible X");
         prevmax = *maxsteplen;
         *maxsteplen = safeminposrv(x->xR[i] - bndl->xR[i], -alpha * d->xR[i], *maxsteplen);
         if (*maxsteplen < prevmax) {
            *variabletofreeze = i;
            *valuetofreeze = bndl->xR[i];
         }
      }
      if (havebndu->xB[i] && alpha * d->xR[i] > 0.0) {
         ae_assert(x->xR[i] <= bndu->xR[i], "CalculateStepBound: infeasible X");
         prevmax = *maxsteplen;
         *maxsteplen = safeminposrv(bndu->xR[i] - x->xR[i], alpha * d->xR[i], *maxsteplen);
         if (*maxsteplen < prevmax) {
            *variabletofreeze = i;
            *valuetofreeze = bndu->xR[i];
         }
      }
   }
   for (i = 0; i < nslack; i++) {
      if (alpha * d->xR[nmain + i] < 0.0) {
         ae_assert(x->xR[nmain + i] >= 0.0, "CalculateStepBound: infeasible X");
         prevmax = *maxsteplen;
         *maxsteplen = safeminposrv(x->xR[nmain + i], -alpha * d->xR[nmain + i], *maxsteplen);
         if (*maxsteplen < prevmax) {
            *variabletofreeze = nmain + i;
            *valuetofreeze = 0.0;
         }
      }
   }
   if (*maxsteplen == initval) {
      *valuetofreeze = 0.0;
      *maxsteplen = 0.0;
   }
}

// This function postprocesses bounded step by:
// * analysing step length (whether it is equal to MaxStepLen) and activating
//   constraint given by VariableToFreeze if needed
// * checking for additional bound constraints to activate
//
// This function uses final point of the step, quantities calculated  by  the
// CalculateStepBound()  function.  As  result,  it  returns  point  which is
// exactly feasible with respect to boundary constraints.
//
// NOTE 1: this function does NOT handle and check linear equality constraints
// NOTE 2: when StepTaken == MaxStepLen we always activate at least one constraint
//
// Inputs:
//     X           -   array[NMain+NSlack], final point to postprocess
//     XPrev       -   array[NMain+NSlack], initial point
//     BndL        -   lower bounds, array[NMain]
//                     (may contain -INF, when bound is not present)
//     HaveBndL    -   array[NMain], if HaveBndL[i] is False,
//                     then i-th bound is not present
//     BndU        -   array[NMain], upper bounds
//                     (may contain +INF, when bound is not present)
//     HaveBndU    -   array[NMain], if HaveBndU[i] is False,
//                     then i-th bound is not present
//     NMain       -   number of main variables
//     NSlack      -   number of slack variables
//     VariableToFreeze-result of CalculateStepBound()
//     ValueToFreeze-  result of CalculateStepBound()
//     StepTaken   -   actual step length (actual step is equal to the possibly
//                     non-unit step direction vector times this parameter).
//                     StepTaken <= MaxStepLen.
//     MaxStepLen  -   result of CalculateStepBound()
//
// Outputs:
//     X           -   point bounded with respect to constraints.
//                     components corresponding to active constraints are exactly
//                     equal to the boundary values.
//
// Result:
//     number of constraints activated in addition to previously active ones.
//     Constraints which were DEACTIVATED are ignored (do not influence
//     function value).
// ALGLIB: Copyright 10.01.2012 by Sergey Bochkanov
ae_int_t postprocessboundedstep(RVector *x, RVector *xprev, RVector *bndl, BVector *havebndl, RVector *bndu, BVector *havebndu, ae_int_t nmain, ae_int_t nslack, ae_int_t variabletofreeze, double valuetofreeze, double steptaken, double maxsteplen) {
   ae_int_t i;
   bool wasactivated;
   ae_int_t result;
   ae_assert(variabletofreeze < 0 || steptaken <= maxsteplen, "Assertion failed");
// Activate constraints
   if (variabletofreeze >= 0 && steptaken == maxsteplen) {
      x->xR[variabletofreeze] = valuetofreeze;
   }
   for (i = 0; i < nmain; i++) {
      if (havebndl->xB[i] && x->xR[i] < bndl->xR[i]) {
         x->xR[i] = bndl->xR[i];
      }
      if (havebndu->xB[i] && x->xR[i] > bndu->xR[i]) {
         x->xR[i] = bndu->xR[i];
      }
   }
   for (i = 0; i < nslack; i++) {
      if (x->xR[nmain + i] <= 0.0) {
         x->xR[nmain + i] = 0.0;
      }
   }
// Calculate number of constraints being activated
   result = 0;
   for (i = 0; i < nmain; i++) {
      wasactivated = x->xR[i] != xprev->xR[i] && (havebndl->xB[i] && x->xR[i] == bndl->xR[i] || havebndu->xB[i] && x->xR[i] == bndu->xR[i]);
      wasactivated = wasactivated || variabletofreeze == i;
      if (wasactivated) {
         result++;
      }
   }
   for (i = 0; i < nslack; i++) {
      wasactivated = x->xR[nmain + i] != xprev->xR[nmain + i] && x->xR[nmain + i] == 0.0;
      wasactivated = wasactivated || variabletofreeze == nmain + i;
      if (wasactivated) {
         result++;
      }
   }
   return result;
}

// The  purpose  of  this  function is to prevent algorithm from "unsticking"
// from  the  active  bound  constraints  because  of  numerical noise in the
// gradient or Hessian.
//
// It is done by zeroing some components of the search direction D.  D[i]  is
// zeroed when both (a) and (b) are true:
// a) corresponding X[i] is exactly at the boundary
// b) |D[i]*S[i]| <= DropTol*sqrt(SUM(D[i]^2*S[I]^2))
//
// D  can  be  step  direction , antigradient, gradient, or anything similar.
// Sign of D does not matter, nor matters step length.
//
// NOTE 1: boundary constraints are expected to be consistent, as well as X
//         is expected to be feasible. Exception will be thrown otherwise.
//
// Inputs:
//     D           -   array[NMain+NSlack], direction
//     X           -   array[NMain+NSlack], current point
//     BndL        -   lower bounds, array[NMain]
//                     (may contain -INF, when bound is not present)
//     HaveBndL    -   array[NMain], if HaveBndL[i] is False,
//                     then i-th bound is not present
//     BndU        -   array[NMain], upper bounds
//                     (may contain +INF, when bound is not present)
//     HaveBndU    -   array[NMain], if HaveBndU[i] is False,
//                     then i-th bound is not present
//     S           -   array[NMain+NSlack], scaling of the variables
//     NMain       -   number of main variables
//     NSlack      -   number of slack variables
//     DropTol     -   drop tolerance, >= 0
//
// Outputs:
//     X           -   point bounded with respect to constraints.
//                     components corresponding to active constraints are exactly
//                     equal to the boundary values.
// ALGLIB: Copyright 10.01.2012 by Sergey Bochkanov
void filterdirection(RVector *d, RVector *x, RVector *bndl, BVector *havebndl, RVector *bndu, BVector *havebndu, RVector *s, ae_int_t nmain, ae_int_t nslack, double droptol) {
   ae_int_t i;
   double scalednorm;
   bool isactive;
   scalednorm = 0.0;
   for (i = 0; i < nmain + nslack; i++) {
      scalednorm += sqr(d->xR[i] * s->xR[i]);
   }
   scalednorm = sqrt(scalednorm);
   for (i = 0; i < nmain; i++) {
      ae_assert(!havebndl->xB[i] || x->xR[i] >= bndl->xR[i], "FilterDirection: infeasible point");
      ae_assert(!havebndu->xB[i] || x->xR[i] <= bndu->xR[i], "FilterDirection: infeasible point");
      isactive = havebndl->xB[i] && x->xR[i] == bndl->xR[i] || havebndu->xB[i] && x->xR[i] == bndu->xR[i];
      if (isactive && SmallAtR(d->xR[i] * s->xR[i], droptol * scalednorm)) {
         d->xR[i] = 0.0;
      }
   }
   for (i = 0; i < nslack; i++) {
      ae_assert(x->xR[nmain + i] >= 0.0, "FilterDirection: infeasible point");
      if (x->xR[nmain + i] == 0.0 && SmallAtR(d->xR[nmain + i] * s->xR[nmain + i], droptol * scalednorm)) {
         d->xR[nmain + i] = 0.0;
      }
   }
}

// This function returns number of bound constraints whose state was  changed
// (either activated or deactivated) when making step from XPrev to X.
//
// Constraints are considered:
// * active - when we are exactly at the boundary
// * inactive - when we are not at the boundary
//
// You should note that antigradient direction is NOT taken into account when
// we make decions on the constraint status.
//
// Inputs:
//     X           -   array[NMain+NSlack], final point.
//                     Must be feasible with respect to bound constraints.
//     XPrev       -   array[NMain+NSlack], initial point.
//                     Must be feasible with respect to bound constraints.
//     BndL        -   lower bounds, array[NMain]
//                     (may contain -INF, when bound is not present)
//     HaveBndL    -   array[NMain], if HaveBndL[i] is False,
//                     then i-th bound is not present
//     BndU        -   array[NMain], upper bounds
//                     (may contain +INF, when bound is not present)
//     HaveBndU    -   array[NMain], if HaveBndU[i] is False,
//                     then i-th bound is not present
//     NMain       -   number of main variables
//     NSlack      -   number of slack variables
//
// Result:
//     number of constraints whose state was changed.
// ALGLIB: Copyright 10.01.2012 by Sergey Bochkanov
ae_int_t numberofchangedconstraints(RVector *x, RVector *xprev, RVector *bndl, BVector *havebndl, RVector *bndu, BVector *havebndu, ae_int_t nmain, ae_int_t nslack) {
   ae_int_t i;
   bool statuschanged;
   ae_int_t result;
   result = 0;
   for (i = 0; i < nmain; i++) {
      if (x->xR[i] != xprev->xR[i]) {
         statuschanged = false;
         if (havebndl->xB[i] && (x->xR[i] == bndl->xR[i] || xprev->xR[i] == bndl->xR[i])) {
            statuschanged = true;
         }
         if (havebndu->xB[i] && (x->xR[i] == bndu->xR[i] || xprev->xR[i] == bndu->xR[i])) {
            statuschanged = true;
         }
         if (statuschanged) {
            result++;
         }
      }
   }
   for (i = 0; i < nslack; i++) {
      if (x->xR[nmain + i] != xprev->xR[nmain + i] && (x->xR[nmain + i] == 0.0 || xprev->xR[nmain + i] == 0.0)) {
         result++;
      }
   }
   return result;
}

// This function calculates feasibility error (square root of sum of  squared
// errors) for a Kx(NMain+NSlack) system of linear equalities.
//
// Inputs:
//     CE      -   set of K equality constraints, array[K,NMain+NSlack+1]
//     X       -   candidate point, array [NMain+NSlack]
//     NMain   -   number of primary variables
//     NSlack  -   number of slack variables
//     K       -   number of constraints
//     Tmp0    -   possible preallocated buffer, automatically resized
//
// Result:
//     sqrt(SUM(Err^2))
// ALGLIB: Copyright 17.09.2015 by Sergey Bochkanov
static double optserv_feasibilityerror(RMatrix *ce, RVector *x, ae_int_t nmain, ae_int_t nslack, ae_int_t k, RVector *tmp0) {
   ae_int_t i;
   double result;
   vectorsetlengthatleast(tmp0, k);
   for (i = 0; i < k; i++) {
      tmp0->xR[i] = -ce->xyR[i][nmain + nslack];
   }
   rmatrixgemv(k, nmain + nslack, 1.0, ce, 0, 0, 0, x, 0, 1.0, tmp0, 0);
   result = 0.0;
   for (i = 0; i < k; i++) {
      result += tmp0->xR[i] * tmp0->xR[i];
   }
   result = sqrt(result);
   return result;
}

// This function calculates feasibility error (square root of sum of  squared
// errors) for a Kx(NMain+NSlack)  system  of  linear  equalities  and  error
// gradient (with respect to x)
//
// Inputs:
//     CE      -   set of K equality constraints, array[K,NMain+NSlack+1]
//     X       -   candidate point, array [NMain+NSlack]
//     NMain   -   number of primary variables
//     NSlack  -   number of slack variables
//     K       -   number of constraints
//     Grad    -   preallocated array[NMain+NSlack]
//     Tmp0    -   possible preallocated buffer, automatically resized
//
// Result:
//     Err     -   sqrt(SUM(Err^2))
//     Grad    -   error gradient with respect to X, array[NMain+NSlack]
// ALGLIB: Copyright 17.09.2015 by Sergey Bochkanov
static double optserv_feasibilityerrorgrad(RMatrix *ce, RVector *x, ae_int_t nmain, ae_int_t nslack, ae_int_t k, RVector *grad, RVector *tmp0) {
   ae_assert(grad->cnt >= nmain + nslack, "FeasibilityErrorGrad: integrity check failed");
   vectorsetlengthatleast(tmp0, k);
   rmatrixgemv(k, nmain + nslack, 1.0, ce, 0, 0, 0, x, 0, 0.0, tmp0, 0);
   double err = 0.0;
   for (ae_int_t i = 0; i < k; i++) {
      double v = tmp0->xR[i] -= ce->xyR[i][nmain + nslack];
      err += v * v;
   }
   rmatrixgemv(nmain + nslack, k, 1.0, ce, 0, 0, 1, tmp0, 0, 0.0, grad, 0);
   return sqrt(err);
}

// This function finds feasible point of  (NMain+NSlack)-dimensional  problem
// subject to NMain explicit boundary constraints (some  constraints  can  be
// omitted), NSlack implicit non-negativity constraints,  K  linear  equality
// constraints.
//
// Inputs:
//     X           -   array[NMain+NSlack], initial point.
//     BndL        -   lower bounds, array[NMain]
//                     (may contain -INF, when bound is not present)
//     HaveBndL    -   array[NMain], if HaveBndL[i] is False,
//                     then i-th bound is not present
//     BndU        -   array[NMain], upper bounds
//                     (may contain +INF, when bound is not present)
//     HaveBndU    -   array[NMain], if HaveBndU[i] is False,
//                     then i-th bound is not present
//     NMain       -   number of main variables
//     NSlack      -   number of slack variables
//     CE          -   array[K,NMain+NSlack+1], equality  constraints CE*x == b.
//                     Rows contain constraints, first  NMain+NSlack  columns
//                     contain coefficients before X[], last  column  contain
//                     right part.
//     K           -   number of linear constraints
//     EpsI        -   infeasibility (error in the right part) allowed in the
//                     solution
//
// Outputs:
//     X           -   feasible point or best infeasible point found before
//                     algorithm termination
//     QPIts       -   number of QP iterations (for debug purposes)
//     GPAIts      -   number of GPA iterations (for debug purposes)
//
// Result:
//     True in case X is feasible, False - if it is infeasible.
// ALGLIB: Copyright 20.01.2012 by Sergey Bochkanov
bool findfeasiblepoint(RVector *x, RVector *bndl, BVector *havebndl, RVector *bndu, BVector *havebndu, ae_int_t nmain, ae_int_t nslack, RMatrix *ce, ae_int_t k, double epsi, ae_int_t *qpits, ae_int_t *gpaits) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t idx0;
   ae_int_t idx1;
   double armijostep;
   double armijobeststep;
   double armijobestfeas;
   double v;
   double vv;
   double mx;
   double feaserr;
   double feaserr0;
   double feaserr1;
   double feasold;
   double feasnew;
   double pgnorm;
   double vn;
   double vd;
   double stp;
   ae_int_t vartofreeze;
   double valtofreeze;
   double maxsteplen;
   bool werechangesinconstraints;
   bool stage1isover;
   bool converged;
   ae_int_t nactive;
   ae_int_t nfree;
   ae_int_t itscount;
   ae_int_t itswithintolerance;
   ae_int_t maxitswithintolerance;
   ae_int_t badits;
   ae_int_t maxbadits;
   ae_int_t gparuns;
   ae_int_t maxarmijoruns;
   double infeasibilityincreasetolerance;
   bool result;
   EnFrame();
   DupMatrix(ce);
   *qpits = 0;
   *gpaits = 0;
   NewRVector(permx, 0);
   NewRVector(xn, 0);
   NewRVector(xa, 0);
   NewRVector(newtonstep, 0);
   NewRVector(g, 0);
   NewRVector(pg, 0);
   NewRVector(tau, 0);
   NewRVector(s, 0);
   NewRVector(activeconstraints, 0);
   NewRVector(tmpk, 0);
   NewRVector(colnorms, 0);
   NewZVector(p1, 0);
   NewZVector(p2, 0);
   NewObj(apbuffers, buf);
   NewRMatrix(permce, 0, 0);
   NewRMatrix(q, 0, 0);
   maxitswithintolerance = 3;
   maxbadits = 3;
   maxarmijoruns = 5;
   *qpits = 0;
   *gpaits = 0;
// Initial enforcement of the feasibility with respect to boundary constraints
// NOTE: after this block we assume that boundary constraints are consistent.
   if (!enforceboundaryconstraints(x, bndl, havebndl, bndu, havebndu, nmain, nslack)) {
      result = false;
      DeFrame(result);
   }
   if (k == 0) {
   // No linear constraints, we can exit right now
      result = true;
      DeFrame(result);
   }
// Scale rows of CE in such way that max(CE[i,0..nmain+nslack-1]) == 1 for any i = 0..k-1
   for (i = 0; i < k; i++) {
      v = 0.0;
      for (j = 0; j < nmain + nslack; j++) {
         v = rmax2(v, fabs(ce->xyR[i][j]));
      }
      if (v != 0.0) {
         v = 1.0 / v;
         ae_v_muld(ce->xyR[i], 1, nmain + nslack + 1, v);
      }
   }
// Allocate temporaries
   ae_vector_set_length(&xn, nmain + nslack);
   ae_vector_set_length(&xa, nmain + nslack);
   ae_vector_set_length(&permx, nmain + nslack);
   ae_vector_set_length(&g, nmain + nslack);
   ae_vector_set_length(&pg, nmain + nslack);
   ae_vector_set_length(&tmpk, k);
   ae_matrix_set_length(&permce, k, nmain + nslack);
   ae_vector_set_length(&activeconstraints, nmain + nslack);
   ae_vector_set_length(&newtonstep, nmain + nslack);
   ae_vector_set_length(&s, nmain + nslack);
   ae_vector_set_length(&colnorms, nmain + nslack);
   for (i = 0; i < nmain + nslack; i++) {
      s.xR[i] = 1.0;
      colnorms.xR[i] = 0.0;
      for (j = 0; j < k; j++) {
         colnorms.xR[i] += sqr(ce->xyR[j][i]);
      }
   }
// K > 0, we have linear equality constraints combined with bound constraints.
//
// Try to find feasible point as minimizer of the quadratic function
//     F(x) = 0.5*||CE*x-b||^2 = 0.5*x'*(CE'*CE)*x - (b'*CE)*x + 0.5*b'*b
// subject to boundary constraints given by BL, BU and non-negativity of
// the slack variables. BTW, we drop constant term because it does not
// actually influences on the solution.
//
// Below we will assume that K > 0.
   itswithintolerance = 0;
   badits = 0;
   itscount = 0;
   while (true) {
   // Dynamically adjust infeasibility error tolerance
      infeasibilityincreasetolerance = rmax2(rmaxabsv(nmain + nslack, x), 1.0) * (1000 + nmain) * machineepsilon;
   // Stage 0: check for exact convergence
      converged = true;
      feaserr = optserv_feasibilityerror(ce, x, nmain, nslack, k, &tmpk);
      for (i = 0; i < k; i++) {
      // Calculate MX - maximum term in the left part
      //
      // Terminate if error in the right part is not greater than 100*Eps*MX.
      //
      // IMPORTANT: we must perform check for non-strict inequality, i.e. to use <= instead of <.
      //            it will allow us to easily handle situations with zero rows of CE.
      //
      // NOTE:      it is important to calculate feasibility error with dedicated
      //            function. Once we had a situation when usage of "inline" code
      //            resulted in different numerical values calculated at different
      //            parts of program for exactly same X. However, this value is
      //            essential for algorithm's ability to terminate before entering
      //            infinite loop, so reproducibility of numerical results is very
      //            important.
         mx = 0.0;
         v = -ce->xyR[i][nmain + nslack];
         for (j = 0; j < nmain + nslack; j++) {
            mx = rmax2(mx, fabs(ce->xyR[i][j] * x->xR[j]));
            v += ce->xyR[i][j] * x->xR[j];
         }
         converged = converged && SmallAtR(v, 100.0 * machineepsilon * mx);
      }
      feaserr0 = feaserr;
      if (converged) {
         result = feaserr <= epsi;
         break;
      }
   // Stage 1: equality constrained quadratic programming
   //
   // * treat active bound constraints as equality ones (constraint is considered
   //   active when we are at the boundary, independently of the antigradient direction)
   // * calculate unrestricted Newton step to point XM (which may be infeasible)
   //   calculate MaxStepLen = largest step in direction of XM which retains feasibility.
   // * perform bounded step from X to XN:
   //   a) XN == XM                  (if XM is feasible)
   //   b) XN == X-MaxStepLen*(XM-X) (otherwise)
   // * X = XN
   // * if XM (Newton step subject to currently active constraints) was feasible, goto Stage 2
   // * repeat Stage 1
   //
   // NOTE 1: in order to solve constrained qudratic subproblem we will have to reorder
   //         variables in such way that ones corresponding to inactive constraints will
   //         be first, and active ones will be last in the list. CE and X are now
   //                                                       [ xi ]
   //         separated into two parts: CE = [CEi CEa], x = [    ], where CEi/Xi correspond
   //                                                       [ xa ]
   //         to INACTIVE constraints, and CEa/Xa correspond to the ACTIVE ones.
   //
   //         Now, instead of F == 0.5*x'*(CE'*CE)*x - (b'*CE)*x + 0.5*b'*b, we have
   //         F(xi) = 0.5*(CEi*xi,CEi*xi) + (CEa*xa-b,CEi*xi) + (0.5*CEa*xa-b,CEa*xa).
   //         Here xa is considered constant, i.e. we optimize with respect to xi, leaving xa fixed.
   //
   //         We can solve it by performing SVD of CEi and calculating pseudoinverse of the
   //         Hessian matrix. Of course, we do NOT calculate pseudoinverse explicitly - we
   //         just use singular vectors to perform implicit multiplication by it.
   //
      while (true) {
      // Calculate G - gradient subject to equality constraints,
      // multiply it by inverse of the Hessian diagonal to obtain initial
      // step vector.
      //
      // Bound step subject to constraints which can be activated,
      // run Armijo search with increasing step size.
      // Search is terminated when feasibility error stops to decrease.
      //
      // NOTE: it is important to test for "stops to decrease" instead
      // of "starts to increase" in order to correctly handle cases with
      // zero CE.
         armijobeststep = 0.0;
         armijobestfeas = optserv_feasibilityerrorgrad(ce, x, nmain, nslack, k, &g, &tmpk);
         for (i = 0; i < nmain; i++) {
            if (havebndl->xB[i] && x->xR[i] == bndl->xR[i]) {
               g.xR[i] = 0.0;
            }
            if (havebndu->xB[i] && x->xR[i] == bndu->xR[i]) {
               g.xR[i] = 0.0;
            }
         }
         for (i = 0; i < nslack; i++) {
            if (x->xR[nmain + i] == 0.0) {
               g.xR[nmain + i] = 0.0;
            }
         }
         v = 0.0;
         for (i = 0; i < nmain + nslack; i++) {
            if (sqr(colnorms.xR[i]) != 0.0) {
               newtonstep.xR[i] = -g.xR[i] / sqr(colnorms.xR[i]);
            } else {
               newtonstep.xR[i] = 0.0;
            }
            v += sqr(newtonstep.xR[i]);
         }
         if (v == 0.0) {
         // Constrained gradient is zero, QP iterations are over
            break;
         }
         calculatestepbound(x, &newtonstep, 1.0, bndl, havebndl, bndu, havebndu, nmain, nslack, &vartofreeze, &valtofreeze, &maxsteplen);
         if (vartofreeze >= 0 && maxsteplen == 0.0) {
         // Can not perform step, QP iterations are over
            break;
         }
         if (vartofreeze >= 0) {
            armijostep = rmin2(1.0, maxsteplen);
         } else {
            armijostep = 1.0;
         }
         while (true) {
            ae_v_move(xa.xR, 1, x->xR, 1, nmain + nslack);
            ae_v_addd(xa.xR, 1, newtonstep.xR, 1, nmain + nslack, armijostep);
            enforceboundaryconstraints(&xa, bndl, havebndl, bndu, havebndu, nmain, nslack);
            feaserr = optserv_feasibilityerror(ce, &xa, nmain, nslack, k, &tmpk);
            if (feaserr >= armijobestfeas) {
               break;
            }
            armijobestfeas = feaserr;
            armijobeststep = armijostep;
            armijostep *= 2.0;
         }
         ae_v_addd(x->xR, 1, newtonstep.xR, 1, nmain + nslack, armijobeststep);
         enforceboundaryconstraints(x, bndl, havebndl, bndu, havebndu, nmain, nslack);
      // Determine number of active and free constraints
         nactive = 0;
         for (i = 0; i < nmain; i++) {
            activeconstraints.xR[i] = 0.0;
            if (havebndl->xB[i] && x->xR[i] == bndl->xR[i]) {
               activeconstraints.xR[i] = 1.0;
            }
            if (havebndu->xB[i] && x->xR[i] == bndu->xR[i]) {
               activeconstraints.xR[i] = 1.0;
            }
            if (activeconstraints.xR[i] > 0.0) {
               nactive++;
            }
         }
         for (i = 0; i < nslack; i++) {
            activeconstraints.xR[nmain + i] = 0.0;
            if (x->xR[nmain + i] == 0.0) {
               activeconstraints.xR[nmain + i] = 1.0;
            }
            if (activeconstraints.xR[nmain + i] > 0.0) {
               nactive++;
            }
         }
         nfree = nmain + nslack - nactive;
         if (nfree == 0) {
            break;
         }
         ++*qpits;
      // Reorder variables: CE is reordered to PermCE, X is reordered to PermX
         tagsortbuf(&activeconstraints, nmain + nslack, &p1, &p2, &buf);
         for (i = 0; i < k; i++) {
            for (j = 0; j < nmain + nslack; j++) {
               permce.xyR[i][j] = ce->xyR[i][j];
            }
         }
         for (j = 0; j < nmain + nslack; j++) {
            permx.xR[j] = x->xR[j];
         }
         for (j = 0; j < nmain + nslack; j++) {
            if (p2.xZ[j] != j) {
               idx0 = p2.xZ[j];
               idx1 = j;
               for (i = 0; i < k; i++) {
                  swapr(&permce.xyR[i][idx0], &permce.xyR[i][idx1]);
               }
               swapr(&permx.xR[idx0], &permx.xR[idx1]);
            }
         }
      // Calculate (unprojected) gradient:
      // G(xi) = CEi'*(CEi*xi + CEa*xa - b)
         for (i = 0; i < nfree; i++) {
            g.xR[i] = 0.0;
         }
         for (i = 0; i < k; i++) {
            v = ae_v_dotproduct(permce.xyR[i], 1, permx.xR, 1, nmain + nslack);
            tmpk.xR[i] = v - ce->xyR[i][nmain + nslack];
         }
         for (i = 0; i < k; i++) {
            v = tmpk.xR[i];
            ae_v_addd(g.xR, 1, permce.xyR[i], 1, nfree, v);
         }
      // Calculate Newton step using pseudoinverse PermCE:
      //     F(xi)  = 0.5*xi'*H*xi + g'*xi    (Taylor decomposition)
      //     XN     = -H^(-1)*g               (new point, solution of the QP subproblem)
      //     H      = CEi'*CEi
      //     H^(-1) can be calculated via QR or LQ decomposition (see below)
      //     step   = -H^(-1)*g
      //
      // NOTE: PermCE is destroyed after this block
         for (i = 0; i < nmain + nslack; i++) {
            newtonstep.xR[i] = 0.0;
         }
         if (k <= nfree) {
         // CEi    = L*Q
         // H      = Q'*L'*L*Q
         // inv(H) = Q'*inv(L)*inv(L')*Q
         //
         // NOTE: we apply minor regularizing perturbation to diagonal of L,
         //       which is equal to 10*K*Eps
            rmatrixlq(&permce, k, nfree, &tau);
            rmatrixlqunpackq(&permce, k, nfree, &tau, k, &q);
            v = 0.0;
            for (i = 0; i < k; i++) {
               v = rmax2(v, fabs(permce.xyR[i][i]));
            }
            v = coalesce(v, 1.0);
            for (i = 0; i < k; i++) {
               permce.xyR[i][i] += 10.0 * k * machineepsilon * v;
            }
            rmatrixgemv(k, nfree, 1.0, &q, 0, 0, 0, &g, 0, 0.0, &tmpk, 0);
            rmatrixtrsv(k, &permce, 0, 0, false, false, 1, &tmpk, 0);
            rmatrixtrsv(k, &permce, 0, 0, false, false, 0, &tmpk, 0);
            rmatrixgemv(nfree, k, -1.0, &q, 0, 0, 1, &tmpk, 0, 0.0, &newtonstep, 0);
         } else {
         // CEi    = Q*R
         // H      = R'*R
         // inv(H) = inv(R)*inv(R')
         //
         // NOTE: we apply minor regularizing perturbation to diagonal of R,
         //       which is equal to 10*K*Eps
            rmatrixqr(&permce, k, nfree, &tau);
            v = 0.0;
            for (i = 0; i < nfree; i++) {
               v = rmax2(v, fabs(permce.xyR[i][i]));
            }
            v = coalesce(v, 1.0);
            for (i = 0; i < nfree; i++) {
               vv = 10.0 * nfree * machineepsilon * v;
               if (permce.xyR[i][i] < 0.0) {
                  vv = -vv;
               }
               permce.xyR[i][i] += vv;
            }
            ae_v_moveneg(newtonstep.xR, 1, g.xR, 1, nfree);
            rmatrixtrsv(nfree, &permce, 0, 0, true, false, 1, &newtonstep, 0);
            rmatrixtrsv(nfree, &permce, 0, 0, true, false, 0, &newtonstep, 0);
         }
      // Post-reordering of Newton step
         for (j = nmain + nslack - 1; j >= 0; j--) {
            if (p2.xZ[j] != j) {
               swapr(&newtonstep.xR[p2.xZ[j]], &newtonstep.xR[j]);
            }
         }
      // NewtonStep contains Newton step subject to active bound constraints.
      //
      // Such step leads us to the minimizer of the equality constrained F,
      // but such minimizer may be infeasible because some constraints which
      // are inactive at the initial point can be violated at the solution.
      //
      // Thus, we perform optimization in two stages:
      // a) perform bounded Newton step, i.e. step in the Newton direction
      //    until activation of the first constraint
      // b) in case (MaxStepLen > 0)and(MaxStepLen < 1), perform additional iteration
      //    of the Armijo line search in the rest of the Newton direction.
         calculatestepbound(x, &newtonstep, 1.0, bndl, havebndl, bndu, havebndu, nmain, nslack, &vartofreeze, &valtofreeze, &maxsteplen);
         if (vartofreeze >= 0 && maxsteplen == 0.0) {
         // Activation of the constraints prevent us from performing step,
         // QP iterations are over
            break;
         }
         if (vartofreeze >= 0) {
            v = rmin2(1.0, maxsteplen);
         } else {
            v = 1.0;
         }
         ae_v_moved(xn.xR, 1, newtonstep.xR, 1, nmain + nslack, v);
         ae_v_add(xn.xR, 1, x->xR, 1, nmain + nslack);
         postprocessboundedstep(&xn, x, bndl, havebndl, bndu, havebndu, nmain, nslack, vartofreeze, valtofreeze, v, maxsteplen);
         if (maxsteplen > 0.0 && maxsteplen < 1.0) {
         // Newton step was restricted by activation of the constraints,
         // perform Armijo iteration.
         //
         // Initial estimate for best step is zero step. We try different
         // step sizes, from the 1-MaxStepLen (residual of the full Newton
         // step) to progressively smaller and smaller steps.
            armijobeststep = 0.0;
            armijobestfeas = optserv_feasibilityerror(ce, &xn, nmain, nslack, k, &tmpk);
            armijostep = 1.0 - maxsteplen;
            for (j = 0; j < maxarmijoruns; j++) {
               ae_v_move(xa.xR, 1, xn.xR, 1, nmain + nslack);
               ae_v_addd(xa.xR, 1, newtonstep.xR, 1, nmain + nslack, armijostep);
               enforceboundaryconstraints(&xa, bndl, havebndl, bndu, havebndu, nmain, nslack);
               feaserr = optserv_feasibilityerror(ce, &xa, nmain, nslack, k, &tmpk);
               if (feaserr < armijobestfeas) {
                  armijobestfeas = feaserr;
                  armijobeststep = armijostep;
               }
               armijostep *= 0.5;
            }
            ae_v_move(xa.xR, 1, xn.xR, 1, nmain + nslack);
            ae_v_addd(xa.xR, 1, newtonstep.xR, 1, nmain + nslack, armijobeststep);
            enforceboundaryconstraints(&xa, bndl, havebndl, bndu, havebndu, nmain, nslack);
         } else {
         // Armijo iteration is not performed
            ae_v_move(xa.xR, 1, xn.xR, 1, nmain + nslack);
         }
         stage1isover = maxsteplen >= 1.0 || maxsteplen == 0.0;
      // Calculate feasibility errors for old and new X.
      // These quantinies are used for debugging purposes only.
      // However, we can leave them in release code because performance impact is insignificant.
      //
      // Update X. Exit if needed.
         feasold = optserv_feasibilityerror(ce, x, nmain, nslack, k, &tmpk);
         feasnew = optserv_feasibilityerror(ce, &xa, nmain, nslack, k, &tmpk);
         if (feasnew >= feasold + infeasibilityincreasetolerance) {
            break;
         }
         ae_v_move(x->xR, 1, xa.xR, 1, nmain + nslack);
         if (stage1isover) {
            break;
         }
      }
   // Stage 2: gradient projection algorithm (GPA)
   //
   // * calculate feasibility error (with respect to linear equality constraints)
   // * calculate gradient G of F, project it into feasible area (G => PG)
   // * exit if norm(PG) is exactly zero or feasibility error is smaller than EpsC
   // * let XM be exact minimum of F along -PG (XM may be infeasible).
   //   calculate MaxStepLen = largest step in direction of -PG which retains feasibility.
   // * perform bounded step from X to XN:
   //   a) XN == XM              (if XM is feasible)
   //   b) XN == X-MaxStepLen*PG (otherwise)
   // * X = XN
   // * stop after specified number of iterations or when no new constraints was activated
   //
   // NOTES:
   // * grad(F) = (CE'*CE)*x - (b'*CE)^T
   // * CE[i] denotes I-th row of CE
   // * XM = X+stp*(-PG) where stp == (grad(F(X)),PG)/(CE*PG,CE*PG).
   //   Here PG is a projected gradient, but in fact it can be arbitrary non-zero
   //   direction vector - formula for minimum of F along PG still will be correct.
      werechangesinconstraints = false;
      for (gparuns = 1; gparuns <= k; gparuns++) {
      // calculate feasibility error and G
         feaserr = optserv_feasibilityerrorgrad(ce, x, nmain, nslack, k, &g, &tmpk);
      // project G, filter it (strip numerical noise)
         ae_v_move(pg.xR, 1, g.xR, 1, nmain + nslack);
         projectgradientintobc(x, &pg, bndl, havebndl, bndu, havebndu, nmain, nslack);
         filterdirection(&pg, x, bndl, havebndl, bndu, havebndu, &s, nmain, nslack, 1.0E-9);
         for (i = 0; i < nmain + nslack; i++) {
            if (sqr(colnorms.xR[i]) != 0.0) {
               pg.xR[i] /= sqr(colnorms.xR[i]);
            } else {
               pg.xR[i] = 0.0;
            }
         }
      // Check GNorm and feasibility.
      // Exit when GNorm is exactly zero.
         pgnorm = ae_v_dotproduct(pg.xR, 1, pg.xR, 1, nmain + nslack);
         pgnorm = sqrt(pgnorm);
         if (pgnorm == 0.0) {
            result = feaserr <= epsi;
            DeFrame(result);
         }
      // calculate planned step length
         vn = ae_v_dotproduct(g.xR, 1, pg.xR, 1, nmain + nslack);
         vd = 0.0;
         rmatrixgemv(k, nmain + nslack, 1.0, ce, 0, 0, 0, &pg, 0, 0.0, &tmpk, 0);
         for (i = 0; i < k; i++) {
            vd += sqr(tmpk.xR[i]);
         }
         stp = vn / vd;
      // Calculate step bound.
      // Perform bounded step and post-process it
         calculatestepbound(x, &pg, -1.0, bndl, havebndl, bndu, havebndu, nmain, nslack, &vartofreeze, &valtofreeze, &maxsteplen);
         if (vartofreeze >= 0 && maxsteplen == 0.0) {
            result = false;
            DeFrame(result);
         }
         if (vartofreeze >= 0) {
            v = rmin2(stp, maxsteplen);
         } else {
            v = stp;
         }
         ae_v_move(xn.xR, 1, x->xR, 1, nmain + nslack);
         ae_v_subd(xn.xR, 1, pg.xR, 1, nmain + nslack, v);
         postprocessboundedstep(&xn, x, bndl, havebndl, bndu, havebndu, nmain, nslack, vartofreeze, valtofreeze, v, maxsteplen);
      // update X
      // check stopping criteria
         werechangesinconstraints = werechangesinconstraints || numberofchangedconstraints(&xn, x, bndl, havebndl, bndu, havebndu, nmain, nslack) > 0;
         ae_v_move(x->xR, 1, xn.xR, 1, nmain + nslack);
         ++*gpaits;
         if (!werechangesinconstraints) {
            break;
         }
      }
   // Stage 3: decide to stop algorithm or not to stop
   //
   // 1. we can stop when last GPA run did NOT changed constraints status.
   //    It means that we've found final set of the active constraints even
   //    before GPA made its run. And it means that Newton step moved us to
   //    the minimum subject to the present constraints.
   //    Depending on feasibility error, True or False is returned.
      feaserr = optserv_feasibilityerror(ce, x, nmain, nslack, k, &tmpk);
      feaserr1 = feaserr;
      if (feaserr1 >= feaserr0 - infeasibilityincreasetolerance) {
         badits++;
      } else {
         badits = 0;
      }
      if (feaserr <= epsi) {
         itswithintolerance++;
      } else {
         itswithintolerance = 0;
      }
      if (!werechangesinconstraints || itswithintolerance >= maxitswithintolerance || badits >= maxbadits) {
         result = feaserr <= epsi;
         break;
      }
      itscount++;
   }
   DeFrame(result);
}

// This function checks that input derivatives are right. First it scales
// parameters DF0 and DF1 from segment [A;B] to [0;1]. Then it builds Hermite
// spline and derivative of it in 0.5. Search scale as Max(DF0,DF1, |F0-F1|).
// Right derivative has to satisfy condition:
//     |H-F|/S <= 0,001, |H'-F'|/S <= 0,001.
//
// Inputs:
//     F0  -   function's value in X-TestStep point;
//     DF0 -   derivative's value in X-TestStep point;
//     F1  -   function's value in X+TestStep point;
//     DF1 -   derivative's value in X+TestStep point;
//     F   -   testing function's value;
//     DF  -   testing derivative's value;
//    Width-   width of verification segment.
//
// Result:
//     If input derivatives is right then function returns true, else
//     function returns false.
// ALGLIB: Copyright 29.05.2012 by Sergey Bochkanov
bool derivativecheck(double f0, double df0, double f1, double df1, double f, double df, double width) {
   double s;
   double h;
   double dh;
   bool result;
// Rescale input data to [0,1]
   df *= width;
   df0 *= width;
   df1 *= width;
// Compute error scale, two sources are used:
// * magnitudes of derivatives and secants
// * magnitudes of input data times sqrt(machine_epsilon)
   s = 0.0;
   s = rmax2(s, fabs(df0));
   s = rmax2(s, fabs(df1));
   s = rmax2(s, fabs(f1 - f0));
   s = rmax2(s, sqrt(machineepsilon) * fabs(f0));
   s = rmax2(s, sqrt(machineepsilon) * fabs(f1));
// Compute H and dH/dX at the middle of interval
   h = 0.5 * (f0 + f1) + 0.125 * (df0 - df1);
   dh = 1.5 * (f1 - f0) - 0.250 * (df0 + df1);
// Check
   if (s > 0.0) {
      if (!NearAtR(h, f, s * 0.001) || !NearAtR(dh, df, s * 0.001)) {
         result = false;
         return result;
      }
   } else {
      if (h - f != 0.0 || dh - df != 0.0) {
         result = false;
         return result;
      }
   }
   result = true;
   return result;
}

// Having quadratic target function
//
//     f(x) = 0.5*x'*A*x + b'*x + penaltyfactor*0.5*(C*x-b)'*(C*x-b)
//
// and its parabolic model along direction D
//
//     F(x0+alpha*D) = D2*alpha^2 + D1*alpha
//
// this function estimates numerical errors in the coefficients of the model.
//
// It is important that this  function  does  NOT calculate D1/D2  -  it only
// estimates numerical errors introduced during evaluation and compares their
// magnitudes against magnitudes of numerical errors. As result, one of three
// outcomes is returned for each coefficient:
//     * "true" coefficient is almost surely positive
//     * "true" coefficient is almost surely negative
//     * numerical errors in coefficient are so large that it can not be
//       reliably distinguished from zero
//
// Inputs:
//     AbsASum -   SUM(|A[i,j]|)
//     AbsASum2-   SUM(A[i,j]^2)
//     MB      -   max(|B|)
//     MX      -   max(|X|)
//     MD      -   max(|D|)
//     D1      -   linear coefficient
//     D2      -   quadratic coefficient
//
// Outputs:
//     D1Est   -   estimate of D1 sign,  accounting  for  possible  numerical
//                 errors:
//                 * > 0  means "almost surely positive" (D1 > 0 and large)
//                 * < 0  means "almost surely negative" (D1 < 0 and large)
//                 * == 0 means "pessimistic estimate  of  numerical  errors
//                        in D1 is larger than magnitude of D1 itself; it is
//                        impossible to reliably distinguish D1 from zero".
//     D2Est   -   estimate of D2 sign,  accounting  for  possible  numerical
//                 errors:
//                 * > 0  means "almost surely positive" (D2 > 0 and large)
//                 * < 0  means "almost surely negative" (D2 < 0 and large)
//                 * == 0 means "pessimistic estimate  of  numerical  errors
//                        in D2 is larger than magnitude of D2 itself; it is
//                        impossible to reliably distinguish D2 from zero".
// ALGLIB: Copyright 14.05.2014 by Sergey Bochkanov
void estimateparabolicmodel(double absasum, double absasum2, double mx, double mb, double md, double d1, double d2, ae_int_t *d1est, ae_int_t *d2est) {
   double d1esterror;
   double d2esterror;
   double eps;
   double e1;
   double e2;
   *d1est = 0;
   *d2est = 0;
// Error estimates:
//
// * error in D1 == d'*(A*x+b) is estimated as
//   ED1 = eps*MAX_ABS(D)*(MAX_ABS(X)*ENORM(A)+MAX_ABS(B))
// * error in D2 == 0.5*d'*A*d is estimated as
//   ED2 = eps*MAX_ABS(D)^2*ENORM(A)
//
// Here ENORM(A) is some pseudo-norm which reflects the way numerical
// error accumulates during addition. Two ways of accumulation are
// possible - worst case (errors always increase) and mean-case (errors
// may cancel each other). We calculate geometrical average of both:
// * ENORM_WORST(A) = SUM(|A[i,j]|)         error in N-term sum grows as O(N)
// * ENORM_MEAN(A)  = SQRT(SUM(A[i,j]^2))   error in N-term sum grows as O(sqrt(N))
// * ENORM(A)       = SQRT(ENORM_WORST(A),ENORM_MEAN(A))
   eps = 4.0 * machineepsilon;
   e1 = eps * md * (mx * absasum + mb);
   e2 = eps * md * (mx * sqrt(absasum2) + mb);
   d1esterror = sqrt(e1 * e2);
   if (SmallAtR(d1, d1esterror)) {
      *d1est = 0;
   } else {
      *d1est = sign(d1);
   }
   e1 = eps * md * md * absasum;
   e2 = eps * md * md * sqrt(absasum2);
   d2esterror = sqrt(e1 * e2);
   if (SmallAtR(d2, d2esterror)) {
      *d2est = 0;
   } else {
      *d2est = sign(d2);
   }
}

// This function calculates inexact rank-K preconditioner for Hessian  matrix
// H == D+W'*C*W, where:
// * H is a Hessian matrix, which is approximated by D/W/C
// * D is a diagonal matrix with positive entries
// * W is a rank-K correction
// * C is a diagonal factor of rank-K correction
//
// This preconditioner is inexact but fast - it requires O(N*K)  time  to  be
// applied. Its main purpose - to be  used  in  barrier/penalty/AUL  methods,
// where ill-conditioning is created by combination of two factors:
// * simple bounds on variables => ill-conditioned D
// * general barrier/penalty => correction W  with large coefficient C (makes
//   problem ill-conditioned) but W itself is well conditioned.
//
// Preconditioner P is calculated by artificially constructing a set of  BFGS
// updates which tries to reproduce behavior of H:
// * Sk = Wk (k-th row of W)
// * Yk = (D+Wk'*Ck*Wk)*Sk
// * Yk/Sk are reordered by ascending of C[k]*norm(Wk)^2
//
// Here we assume that rows of Wk are orthogonal or nearly orthogonal,  which
// allows us to have O(N*K+K^2) update instead of O(N*K^2) one. Reordering of
// updates is essential for having good performance on non-orthogonal problems
// (updates which do not add much of curvature are added first,  and  updates
// which add very large eigenvalues are added last and override effect of the
// first updates).
//
// On input this function takes direction S and components of H.
// On output it returns inv(H)*S
// ALGLIB: Copyright 30.06.2014 by Sergey Bochkanov
void inexactlbfgspreconditioner(RVector *s, ae_int_t n, RVector *d, RVector *c, RMatrix *w, ae_int_t k, precbuflbfgs *buf) {
   ae_int_t idx;
   ae_int_t i;
   ae_int_t j;
   double v;
   double v0;
   double v1;
   double vx;
   double vy;
   vectorsetlengthatleast(&buf->norms, k);
   vectorsetlengthatleast(&buf->alpha, k);
   vectorsetlengthatleast(&buf->rho, k);
   matrixsetlengthatleast(&buf->yk, k, n);
   vectorsetlengthatleast(&buf->idx, k);
// Check inputs
   for (i = 0; i < n; i++) {
      ae_assert(d->xR[i] > 0.0, "InexactLBFGSPreconditioner: D[] <= 0");
   }
   for (i = 0; i < k; i++) {
      ae_assert(c->xR[i] >= 0.0, "InexactLBFGSPreconditioner: C[] < 0");
   }
// Reorder linear terms according to increase of second derivative.
// Fill Norms[] array.
   for (idx = 0; idx < k; idx++) {
      v = ae_v_dotproduct(w->xyR[idx], 1, w->xyR[idx], 1, n);
      buf->norms.xR[idx] = v * c->xR[idx];
      buf->idx.xZ[idx] = idx;
   }
   tagsortfasti(&buf->norms, &buf->idx, &buf->bufa, &buf->bufb, k);
// Apply updates
   for (idx = 0; idx < k; idx++) {
   // Select update to perform (ordered by ascending of second derivative)
      i = buf->idx.xZ[idx];
   // Calculate YK and Rho
      v = ae_v_dotproduct(w->xyR[i], 1, w->xyR[i], 1, n);
      v *= c->xR[i];
      for (j = 0; j < n; j++) {
         buf->yk.xyR[i][j] = (d->xR[j] + v) * w->xyR[i][j];
      }
      v = 0.0;
      v0 = 0.0;
      v1 = 0.0;
      for (j = 0; j < n; j++) {
         vx = w->xyR[i][j];
         vy = buf->yk.xyR[i][j];
         v += vx * vy;
         v0 += vx * vx;
         v1 += vy * vy;
      }
      if (v > 0.0 && v0 * v1 > 0.0 && v > n * 10.0 * machineepsilon * sqrt(v0 * v1)) {
         buf->rho.xR[i] = 1.0 / v;
      } else {
         buf->rho.xR[i] = 0.0;
      }
   }
   for (idx = k - 1; idx >= 0; idx--) {
   // Select update to perform (ordered by ascending of second derivative)
      i = buf->idx.xZ[idx];
   // Calculate Alpha[] according to L-BFGS algorithm
   // and update S[]
      v = ae_v_dotproduct(w->xyR[i], 1, s->xR, 1, n);
      v *= buf->rho.xR[i];
      buf->alpha.xR[i] = v;
      ae_v_subd(s->xR, 1, buf->yk.xyR[i], 1, n, v);
   }
   for (j = 0; j < n; j++) {
      s->xR[j] /= d->xR[j];
   }
   for (idx = 0; idx < k; idx++) {
   // Select update to perform (ordered by ascending of second derivative)
      i = buf->idx.xZ[idx];
   // Calculate Beta according to L-BFGS algorithm
   // and update S[]
      v = ae_v_dotproduct(buf->yk.xyR[i], 1, s->xR, 1, n);
      v = buf->alpha.xR[i] - buf->rho.xR[i] * v;
      ae_v_addd(s->xR, 1, w->xyR[i], 1, n, v);
   }
}

// This function prepares exact low-rank preconditioner  for  Hessian  matrix
// H == D+W'*C*W, where:
// * H is a Hessian matrix, which is approximated by D/W/C
// * D is a diagonal matrix with positive entries
// * W is a rank-K correction
// * C is a diagonal factor of rank-K correction, positive semidefinite
//
// This preconditioner is exact but relatively slow -  it  requires  O(N*K^2)
// time to be prepared and O(N*K) time to be applied. It is  calculated  with
// the help of Woodbury matrix identity.
//
// It should be used as follows:
// * PrepareLowRankPreconditioner() call PREPARES data structure
// * subsequent calls to ApplyLowRankPreconditioner() APPLY preconditioner to
//   user-specified search direction.
// ALGLIB: Copyright 30.06.2014 by Sergey Bochkanov
void preparelowrankpreconditioner(RVector *d, RVector *c, RMatrix *w, ae_int_t n, ae_int_t k, precbuflowrank *buf) {
   ae_int_t i;
   ae_int_t j;
   double v;
   bool b;
// Check inputs
   ae_assert(n > 0, "PrepareLowRankPreconditioner: N <= 0");
   ae_assert(k >= 0, "PrepareLowRankPreconditioner: N <= 0");
   for (i = 0; i < n; i++) {
      ae_assert(d->xR[i] > 0.0, "PrepareLowRankPreconditioner: D[] <= 0");
   }
   for (i = 0; i < k; i++) {
      ae_assert(c->xR[i] >= 0.0, "PrepareLowRankPreconditioner: C[] < 0");
   }
// Prepare buffer structure; skip zero entries of update.
   vectorsetlengthatleast(&buf->d, n);
   matrixsetlengthatleast(&buf->v, k, n);
   vectorsetlengthatleast(&buf->bufc, k);
   matrixsetlengthatleast(&buf->bufw, k + 1, n);
   buf->n = n;
   buf->k = 0;
   for (i = 0; i < k; i++) {
   // Estimate magnitude of update row; skip zero rows (either W or C are zero)
      v = 0.0;
      for (j = 0; j < n; j++) {
         v += w->xyR[i][j] * w->xyR[i][j];
      }
      v *= c->xR[i];
      if (v == 0.0) {
         continue;
      }
      ae_assert(v > 0.0, "PrepareLowRankPreconditioner: internal error");
   // Copy non-zero update to buffer
      buf->bufc.xR[buf->k] = c->xR[i];
      for (j = 0; j < n; j++) {
         buf->v.xyR[buf->k][j] = w->xyR[i][j];
         buf->bufw.xyR[buf->k][j] = w->xyR[i][j];
      }
      buf->k++;
   }
// Reset K (for convenience)
   k = buf->k;
// Prepare diagonal factor; quick exit for K == 0
   for (i = 0; i < n; i++) {
      buf->d.xR[i] = 1.0 / d->xR[i];
   }
   if (k == 0) {
      return;
   }
// Use Woodbury matrix identity
   matrixsetlengthatleast(&buf->bufz, k, k);
   for (i = 0; i < k; i++) {
      for (j = 0; j < k; j++) {
         buf->bufz.xyR[i][j] = 0.0;
      }
   }
   for (i = 0; i < k; i++) {
      buf->bufz.xyR[i][i] = 1.0 / buf->bufc.xR[i];
   }
   for (j = 0; j < n; j++) {
      buf->bufw.xyR[k][j] = 1.0 / sqrt(d->xR[j]);
   }
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         buf->bufw.xyR[i][j] *= buf->bufw.xyR[k][j];
      }
   }
   rmatrixgemm(k, k, n, 1.0, &buf->bufw, 0, 0, 0, &buf->bufw, 0, 0, 1, 1.0, &buf->bufz, 0, 0);
   b = spdmatrixcholeskyrec(&buf->bufz, 0, k, true, &buf->tmp);
   ae_assert(b, "PrepareLowRankPreconditioner: internal error (Cholesky failure)");
   rmatrixlefttrsm(k, n, &buf->bufz, 0, 0, true, false, 1, &buf->v, 0, 0);
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         buf->v.xyR[i][j] *= buf->d.xR[j];
      }
   }
}

// This function apply exact low-rank preconditioner prepared by
// PrepareLowRankPreconditioner function (see its comments for more information).
// ALGLIB: Copyright 30.06.2014 by Sergey Bochkanov
void applylowrankpreconditioner(RVector *s, precbuflowrank *buf) {
   ae_int_t n;
   ae_int_t k;
   ae_int_t i;
   ae_int_t j;
   double v;
   n = buf->n;
   k = buf->k;
   vectorsetlengthatleast(&buf->tmp, n);
   for (j = 0; j < n; j++) {
      buf->tmp.xR[j] = buf->d.xR[j] * s->xR[j];
   }
   for (i = 0; i < k; i++) {
      v = 0.0;
      for (j = 0; j < n; j++) {
         v += buf->v.xyR[i][j] * s->xR[j];
      }
      for (j = 0; j < n; j++) {
         buf->tmp.xR[j] -= v * buf->v.xyR[i][j];
      }
   }
   for (i = 0; i < n; i++) {
      s->xR[i] = buf->tmp.xR[i];
   }
}

// This subroutine initializes smoothness monitor at  the  beginning  of  the
// optimization session. It requires variable scales to be passed.
//
// It is possible to perform "dummy" initialization with N == K == 0.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorinit(smoothnessmonitor *monitor, RVector *s, ae_int_t n, ae_int_t k, bool checksmoothness) {
   ae_int_t i;
   monitor->n = n;
   monitor->k = k;
   monitor->checksmoothness = checksmoothness;
   monitor->linesearchspoiled = false;
   monitor->linesearchstarted = false;
   monitor->linesearchinneridx = -1;
   monitor->linesearchouteridx = -1;
   monitor->enqueuedcnt = 0;
   monitor->sortedcnt = 0;
   vectorsetlengthatleast(&monitor->s, n);
   for (i = 0; i < n; i++) {
      monitor->s.xR[i] = s->xR[i];
   }
   monitor->nonc0currentrating = 0.0;
   monitor->nonc1currentrating = 0.0;
   optguardinitinternal(&monitor->rep, n, k);
   monitor->nonc0strrating = 0.0;
   monitor->nonc0lngrating = -maxrealnumber;
   monitor->nonc0strrep.positive = false;
   monitor->nonc0lngrep.positive = false;
   monitor->nonc1test0strrating = 0.0;
   monitor->nonc1test0lngrating = -maxrealnumber;
   monitor->nonc1test0strrep.positive = false;
   monitor->nonc1test0lngrep.positive = false;
   monitor->nonc1test1strrating = 0.0;
   monitor->nonc1test1lngrating = -maxrealnumber;
   monitor->nonc1test1strrep.positive = false;
   monitor->nonc1test1lngrep.positive = false;
   monitor->badgradhasxj = false;
   monitor->PQ = -1;
}

// This subroutine finalizes line search
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorfinalizelinesearch(smoothnessmonitor *monitor) {
// As for now - nothing to be done.
}

// This subroutine starts line search
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorstartlinesearch(smoothnessmonitor *monitor, RVector *x, RVector *fi, RMatrix *jac, ae_int_t inneriter, ae_int_t outeriter) {
   ae_int_t n;
   ae_int_t k;
   ae_int_t i;
   ae_int_t j;
   double v;
   n = monitor->n;
   k = monitor->k;
// Skip if inactive or spoiled by NAN
   if (!monitor->checksmoothness) {
      return;
   }
   v = 0.0;
   for (i = 0; i < n; i++) {
      v = 0.5 * v + x->xR[i];
   }
   for (i = 0; i < k; i++) {
      v = 0.5 * v + fi->xR[i];
   }
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         v = 0.5 * v + jac->xyR[i][j];
      }
   }
   if (!isfinite(v)) {
      monitor->linesearchspoiled = true;
      return;
   }
// Finalize previous line search
   if (monitor->enqueuedcnt > 0) {
      smoothnessmonitorfinalizelinesearch(monitor);
   }
// Store initial point
   monitor->linesearchstarted = true;
   monitor->linesearchinneridx = inneriter;
   monitor->linesearchouteridx = outeriter;
   monitor->enqueuedcnt = 1;
   rvectorgrowto(&monitor->enqueuedstp, monitor->enqueuedcnt);
   rvectorgrowto(&monitor->enqueuedx, monitor->enqueuedcnt * n);
   rvectorgrowto(&monitor->enqueuedfunc, monitor->enqueuedcnt * k);
   rmatrixgrowrowsto(&monitor->enqueuedjac, monitor->enqueuedcnt * k, n);
   monitor->enqueuedstp.xR[0] = 0.0;
   for (j = 0; j < n; j++) {
      monitor->enqueuedx.xR[j] = x->xR[j];
   }
   for (i = 0; i < k; i++) {
      monitor->enqueuedfunc.xR[i] = fi->xR[i];
   }
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         monitor->enqueuedjac.xyR[i][j] = jac->xyR[i][j];
      }
   }
// Initialize sorted representation
   rvectorgrowto(&monitor->sortedstp, 1);
   ivectorgrowto(&monitor->sortedidx, 1);
   monitor->sortedstp.xR[0] = 0.0;
   monitor->sortedidx.xZ[0] = 0;
   monitor->sortedcnt = 1;
}

// This subroutine starts line search for a scalar function - convenience
// wrapper for ....StartLineSearch() with unscaled variables.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorstartlinesearch1u(smoothnessmonitor *monitor, RVector *s, RVector *invs, RVector *x, double f0, RVector *j0, ae_int_t inneriter, ae_int_t outeriter) {
   ae_int_t n;
   ae_int_t k;
   ae_int_t i;
   n = monitor->n;
   k = monitor->k;
   if (!monitor->checksmoothness) {
      return;
   }
   ae_assert(k == 1, "SmoothnessMonitorStartLineSearch1: K != 1");
   vectorsetlengthatleast(&monitor->xu, n);
   vectorsetlengthatleast(&monitor->f0, 1);
   matrixsetlengthatleast(&monitor->j0, 1, n);
   monitor->f0.xR[0] = f0;
   for (i = 0; i < n; i++) {
      monitor->xu.xR[i] = x->xR[i] * invs->xR[i];
      monitor->j0.xyR[0][i] = j0->xR[i] * s->xR[i];
   }
   smoothnessmonitorstartlinesearch(monitor, &monitor->xu, &monitor->f0, &monitor->j0, inneriter, outeriter);
}

// This  subroutine  checks  C0  continuity  and  returns  continuity  rating
// (normalized value, with values above 50-500 being good indication  of  the
// discontinuity) and Lipschitz constant.
//
// An interval between F1 and F2 is  tested  for  (dis)continuity.  Per-point
// noise estimates are provided. Delta[i] is a step from F[i] to F[i+1].
//
// ApplySpecialCorrection parameter should be set to True  if  you  use  this
// function to estimate continuity of  the  model  around  minimum;  it  adds
// special correction which helps to detect "max(0,1/x)"-like discontinuities.
// Without this correction algorithm will still work, but will be a bit  less
// powerful. Do not use this correction  for  situations  when  you  want  to
// estimate continuity around some non-extremal point  -  it  may  result  in
// spurious discontinuities being reported.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
static void optserv_testc0continuity(double f0, double f1, double f2, double f3, double noise0, double noise1, double noise2, double noise3, double delta0, double delta1, double delta2, bool applyspecialcorrection, double *rating, double *lipschitz) {
   double lipschitz01;
   double lipschitz12;
   double lipschitz23;
   *rating = 0.0;
   *lipschitz = 0.0;
// Compute Lipschitz constant for the interval [0,1],
// add noise correction in order to get increased estimate (makes
// comparison below more conservative).
   lipschitz01 = (fabs(f1 - f0) + (noise0 + noise1)) / delta0;
// Compute Lipschitz constant for the interval [StpIdx+1,StpIdx+2],
// SUBTRACT noise correction in order to get decreased estimate (makes
// comparison below more conservative).
   lipschitz12 = rmax2(fabs(f2 - f1) - (noise1 + noise2), 0.0) / delta1;
// Compute Lipschitz constant for the interval [StpIdx+2,StpIdx+3]
// using special algorithm:
// a) if F3 < F2-Noise23, Lipschitz constant is assumed to be zero
// b) otherwise, we compute Lipschitz constant as usual,
//    with noise correction term being added
//
// We need case (a) because some kinds of discontinuities
// (like one introduced by max(1/x,0)) manifest themselves
// in a quite special way.
   if (applyspecialcorrection && f3 < f2 - (noise2 + noise3)) {
      lipschitz23 = 0.0;
   } else {
      lipschitz23 = (fabs(f3 - f2) + (noise2 + noise3)) / delta2;
   }
// Compute rating (ratio of two Lipschitz constants)
   ae_assert(rmax2(lipschitz01, lipschitz23) > 0.0, "OptGuard: integrity check failed");
   *rating = lipschitz12 / rmax2(lipschitz01, lipschitz23);
   *lipschitz = lipschitz12;
}

// This subroutine checks C1 continuity using test #0 (function  values  from
// the line search log are studied, gradient is not used).
//
// An interval between F[StpIdx] and F[StpIdx+5] is  tested for  continuity.
// An normalized error metric (Lipschitz constant growth for the  derivative)
// for the interval in question is calculated. Values above  50  are  a  good
// indication of the discontinuity.
//
// A six-point algorithm is used for testing, so we expect that Monitor.F and
// Monitor.Stp have enough points for this test.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
static void optserv_c1continuitytest0(smoothnessmonitor *monitor, ae_int_t funcidx, ae_int_t stpidx, ae_int_t sortedcnt) {
   double f0;
   double f1;
   double f2;
   double f3;
   double f4;
   double f5;
   double noise0;
   double noise1;
   double noise2;
   double noise3;
   double noise4;
   double noise5;
   double delta0;
   double delta1;
   double delta2;
   double delta3;
   double delta4;
   double d0;
   double d1;
   double d2;
   double d3;
   double newnoise0;
   double newnoise1;
   double newnoise2;
   double newnoise3;
   double newdelta0;
   double newdelta1;
   double newdelta2;
   double rating;
   double lipschitz;
   double lengthrating;
   ae_int_t i;
   ae_int_t n;
   double nrm;
   n = monitor->n;
   ae_assert(stpidx + 5 < sortedcnt, "C1ContinuityTest0: integrity check failed");
   ae_assert(monitor->sortedstp.xR[0] == 0.0, "C1ContinuityTest0: integrity check failed");
   ae_assert(monitor->sortedstp.xR[sortedcnt - 1] > 0.0, "C1ContinuityTest0: integrity check failed");
// Fetch F, noise, Delta's
   f0 = monitor->f.xR[stpidx];
   f1 = monitor->f.xR[stpidx + 1];
   f2 = monitor->f.xR[stpidx + 2];
   f3 = monitor->f.xR[stpidx + 3];
   f4 = monitor->f.xR[stpidx + 4];
   f5 = monitor->f.xR[stpidx + 5];
   noise0 = optserv_ognoiselevelf * rmax2(fabs(f0), 1.0);
   noise1 = optserv_ognoiselevelf * rmax2(fabs(f1), 1.0);
   noise2 = optserv_ognoiselevelf * rmax2(fabs(f2), 1.0);
   noise3 = optserv_ognoiselevelf * rmax2(fabs(f3), 1.0);
   noise4 = optserv_ognoiselevelf * rmax2(fabs(f4), 1.0);
   noise5 = optserv_ognoiselevelf * rmax2(fabs(f5), 1.0);
   delta0 = monitor->sortedstp.xR[stpidx + 1] - monitor->sortedstp.xR[stpidx];
   delta1 = monitor->sortedstp.xR[stpidx + 2] - monitor->sortedstp.xR[stpidx + 1];
   delta2 = monitor->sortedstp.xR[stpidx + 3] - monitor->sortedstp.xR[stpidx + 2];
   delta3 = monitor->sortedstp.xR[stpidx + 4] - monitor->sortedstp.xR[stpidx + 3];
   delta4 = monitor->sortedstp.xR[stpidx + 5] - monitor->sortedstp.xR[stpidx + 4];
// Differentiate functions, get derivative values and noise
// estimates at points (0+1)/2, (1+2)/2, (3+4)/2, (3+4)/2,
// (4+5)/2. Compute new step values NewDelta[i] and new
// noise estimates.
   d0 = (f1 - f0) / delta0;
   d1 = (f2 - f1) / delta1;
   d2 = (f4 - f3) / delta3;
   d3 = (f5 - f4) / delta4;
   newnoise0 = (noise0 + noise1) / delta0;
   newnoise1 = (noise1 + noise2) / delta1;
   newnoise2 = (noise3 + noise4) / delta3;
   newnoise3 = (noise4 + noise5) / delta4;
   newdelta0 = 0.5 * (delta0 + delta1);
   newdelta1 = 0.5 * delta1 + delta2 + 0.5 * delta3;
   newdelta2 = 0.5 * (delta3 + delta4);
// Test with C0 continuity tester. "Special correction" is
// turned off for this test.
   optserv_testc0continuity(d0, d1, d2, d3, newnoise0, newnoise1, newnoise2, newnoise3, newdelta0, newdelta1, newdelta2, false, &rating, &lipschitz);
// Store results
   if (rating > optserv_ogminrating1) {
   // Store to total report
      monitor->rep.nonc1test0positive = true;
      if (rating > monitor->nonc1currentrating) {
         monitor->nonc1currentrating = rating;
         monitor->rep.nonc1suspected = true;
         monitor->rep.nonc1lipschitzc = lipschitz;
         monitor->rep.nonc1fidx = funcidx;
      }
   // Store to "strongest" report
      if (rating > monitor->nonc1test0strrating) {
         monitor->nonc1test0strrating = rating;
         monitor->nonc1test0strrep.positive = true;
         monitor->nonc1test0strrep.fidx = funcidx;
         monitor->nonc1test0strrep.n = n;
         monitor->nonc1test0strrep.cnt = sortedcnt;
         monitor->nonc1test0strrep.stpidxa = stpidx + 1;
         monitor->nonc1test0strrep.stpidxb = stpidx + 4;
         monitor->nonc1test0strrep.inneriter = monitor->linesearchinneridx;
         monitor->nonc1test0strrep.outeriter = monitor->linesearchouteridx;
         vectorsetlengthatleast(&monitor->nonc1test0strrep.x0, n);
         vectorsetlengthatleast(&monitor->nonc1test0strrep.d, n);
         for (i = 0; i < n; i++) {
            monitor->nonc1test0strrep.x0.xR[i] = monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i];
            monitor->nonc1test0strrep.d.xR[i] = monitor->dcur.xR[i];
         }
         vectorsetlengthatleast(&monitor->nonc1test0strrep.stp, sortedcnt);
         vectorsetlengthatleast(&monitor->nonc1test0strrep.f, sortedcnt);
         for (i = 0; i < sortedcnt; i++) {
            monitor->nonc1test0strrep.stp.xR[i] = monitor->sortedstp.xR[i];
            monitor->nonc1test0strrep.f.xR[i] = monitor->f.xR[i];
         }
      }
   // Store to "longest" report
      nrm = 0.0;
      for (i = 0; i < n; i++) {
         nrm += sqr(monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i] - monitor->enqueuedx.xR[monitor->sortedidx.xZ[sortedcnt - 1] * n + i]);
      }
      nrm = sqrt(nrm);
      nrm = rmin2(nrm, 1.0);
      nrm = coalesce(nrm, machineepsilon);
      lengthrating = sortedcnt + log(nrm) / log(100.0);
      if (lengthrating > monitor->nonc1test0lngrating) {
         monitor->nonc1test0lngrating = lengthrating;
         monitor->nonc1test0lngrep.positive = true;
         monitor->nonc1test0lngrep.fidx = funcidx;
         monitor->nonc1test0lngrep.n = n;
         monitor->nonc1test0lngrep.cnt = sortedcnt;
         monitor->nonc1test0lngrep.stpidxa = stpidx + 1;
         monitor->nonc1test0lngrep.stpidxb = stpidx + 4;
         monitor->nonc1test0lngrep.inneriter = monitor->linesearchinneridx;
         monitor->nonc1test0lngrep.outeriter = monitor->linesearchouteridx;
         vectorsetlengthatleast(&monitor->nonc1test0lngrep.x0, n);
         vectorsetlengthatleast(&monitor->nonc1test0lngrep.d, n);
         for (i = 0; i < n; i++) {
            monitor->nonc1test0lngrep.x0.xR[i] = monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i];
            monitor->nonc1test0lngrep.d.xR[i] = monitor->dcur.xR[i];
         }
         vectorsetlengthatleast(&monitor->nonc1test0lngrep.stp, sortedcnt);
         vectorsetlengthatleast(&monitor->nonc1test0lngrep.f, sortedcnt);
         for (i = 0; i < sortedcnt; i++) {
            monitor->nonc1test0lngrep.stp.xR[i] = monitor->sortedstp.xR[i];
            monitor->nonc1test0lngrep.f.xR[i] = monitor->f.xR[i];
         }
      }
   }
}

// This  subroutine checks C1 continuity using test #1  (individual  gradient
// components from the line search log are studied for continuity).
//
// An interval between F[StpIdx] and F[StpIdx+3] is  tested for  continuity.
// An normalized error metric (Lipschitz constant growth for the  derivative)
// for the interval in question is calculated. Values above  50  are  a  good
// indication of the discontinuity.
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
static void optserv_c1continuitytest1(smoothnessmonitor *monitor, ae_int_t funcidx, ae_int_t stpidx, ae_int_t sortedcnt) {
   ae_int_t i;
   ae_int_t varidx;
   ae_int_t n;
   double f0;
   double f1;
   double f2;
   double f3;
   double noise0;
   double noise1;
   double noise2;
   double noise3;
   double nrm;
   double rating;
   double lengthrating;
   double lipschitz;
   n = monitor->n;
   ae_assert(stpidx + 3 < sortedcnt, "C1ContinuityTest1: integrity check failed");
   ae_assert(monitor->sortedstp.xR[0] == 0.0, "C1ContinuityTest1: integrity check failed");
   ae_assert(monitor->sortedstp.xR[sortedcnt - 1] > 0.0, "C1ContinuityTest1: integrity check failed");
// Study each component of the gradient in the interval in question
   for (varidx = 0; varidx < n; varidx++) {
      f0 = monitor->g.xR[stpidx * n + varidx];
      f1 = monitor->g.xR[(stpidx + 1) * n + varidx];
      f2 = monitor->g.xR[(stpidx + 2) * n + varidx];
      f3 = monitor->g.xR[(stpidx + 3) * n + varidx];
      noise0 = optserv_ognoiselevelg * rmax2(fabs(f0), 1.0);
      noise1 = optserv_ognoiselevelg * rmax2(fabs(f1), 1.0);
      noise2 = optserv_ognoiselevelg * rmax2(fabs(f2), 1.0);
      noise3 = optserv_ognoiselevelg * rmax2(fabs(f3), 1.0);
      optserv_testc0continuity(f0, f1, f2, f3, noise0, noise1, noise2, noise3, monitor->sortedstp.xR[stpidx + 1] - monitor->sortedstp.xR[stpidx], monitor->sortedstp.xR[stpidx + 2] - monitor->sortedstp.xR[stpidx + 1], monitor->sortedstp.xR[stpidx + 3] - monitor->sortedstp.xR[stpidx + 2], false, &rating, &lipschitz);
   // Store results
      if (rating > optserv_ogminrating1) {
      // Store to total report
         monitor->rep.nonc1test1positive = true;
         if (rating > monitor->nonc1currentrating) {
            monitor->nonc1currentrating = rating;
            monitor->rep.nonc1suspected = true;
            monitor->rep.nonc1lipschitzc = lipschitz;
            monitor->rep.nonc1fidx = funcidx;
         }
      // Store to "strongest" report
         if (rating > monitor->nonc1test1strrating) {
            monitor->nonc1test1strrating = rating;
            monitor->nonc1test1strrep.positive = true;
            monitor->nonc1test1strrep.fidx = funcidx;
            monitor->nonc1test1strrep.vidx = varidx;
            monitor->nonc1test1strrep.n = n;
            monitor->nonc1test1strrep.cnt = sortedcnt;
            monitor->nonc1test1strrep.stpidxa = stpidx;
            monitor->nonc1test1strrep.stpidxb = stpidx + 3;
            monitor->nonc1test1strrep.inneriter = monitor->linesearchinneridx;
            monitor->nonc1test1strrep.outeriter = monitor->linesearchouteridx;
            vectorsetlengthatleast(&monitor->nonc1test1strrep.x0, n);
            vectorsetlengthatleast(&monitor->nonc1test1strrep.d, n);
            for (i = 0; i < n; i++) {
               monitor->nonc1test1strrep.x0.xR[i] = monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i];
               monitor->nonc1test1strrep.d.xR[i] = monitor->dcur.xR[i];
            }
            vectorsetlengthatleast(&monitor->nonc1test1strrep.stp, sortedcnt);
            vectorsetlengthatleast(&monitor->nonc1test1strrep.g, sortedcnt);
            for (i = 0; i < sortedcnt; i++) {
               monitor->nonc1test1strrep.stp.xR[i] = monitor->sortedstp.xR[i];
               monitor->nonc1test1strrep.g.xR[i] = monitor->g.xR[i * n + varidx];
            }
         }
      // Store to "longest" report
         nrm = 0.0;
         for (i = 0; i < n; i++) {
            nrm += sqr(monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i] - monitor->enqueuedx.xR[monitor->sortedidx.xZ[sortedcnt - 1] * n + i]);
         }
         nrm = sqrt(nrm);
         nrm = rmin2(nrm, 1.0);
         nrm = coalesce(nrm, machineepsilon);
         lengthrating = sortedcnt + log(nrm) / log(100.0);
         if (lengthrating > monitor->nonc1test1lngrating) {
            monitor->nonc1test1lngrating = lengthrating;
            monitor->nonc1test1lngrep.positive = true;
            monitor->nonc1test1lngrep.fidx = funcidx;
            monitor->nonc1test1lngrep.vidx = varidx;
            monitor->nonc1test1lngrep.n = n;
            monitor->nonc1test1lngrep.cnt = sortedcnt;
            monitor->nonc1test1lngrep.stpidxa = stpidx;
            monitor->nonc1test1lngrep.stpidxb = stpidx + 3;
            monitor->nonc1test1lngrep.inneriter = monitor->linesearchinneridx;
            monitor->nonc1test1lngrep.outeriter = monitor->linesearchouteridx;
            vectorsetlengthatleast(&monitor->nonc1test1lngrep.x0, n);
            vectorsetlengthatleast(&monitor->nonc1test1lngrep.d, n);
            for (i = 0; i < n; i++) {
               monitor->nonc1test1lngrep.x0.xR[i] = monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i];
               monitor->nonc1test1lngrep.d.xR[i] = monitor->dcur.xR[i];
            }
            vectorsetlengthatleast(&monitor->nonc1test1lngrep.stp, sortedcnt);
            vectorsetlengthatleast(&monitor->nonc1test1lngrep.g, sortedcnt);
            for (i = 0; i < sortedcnt; i++) {
               monitor->nonc1test1lngrep.stp.xR[i] = monitor->sortedstp.xR[i];
               monitor->nonc1test1lngrep.g.xR[i] = monitor->g.xR[i * n + varidx];
            }
         }
      }
   }
}

// This subroutine enqueues one more trial point
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorenqueuepoint(smoothnessmonitor *monitor, RVector *d, double stp, RVector *x, RVector *fi, RMatrix *jac) {
   ae_int_t n;
   ae_int_t k;
   ae_int_t i;
   ae_int_t j;
   double v;
   ae_int_t enqueuedcnt;
   ae_int_t sortedcnt;
   bool hasduplicates;
   ae_int_t funcidx;
   ae_int_t stpidx;
   double f0;
   double f1;
   double f2;
   double f3;
   double f4;
   double noise0;
   double noise1;
   double noise2;
   double noise3;
   double rating;
   double lipschitz;
   double nrm;
   double lengthrating;
   n = monitor->n;
   k = monitor->k;
// Skip if inactive or spoiled by NAN
   if (!monitor->checksmoothness || monitor->linesearchspoiled || !monitor->linesearchstarted) {
      return;
   }
   v = stp;
   for (i = 0; i < n; i++) {
      v = 0.5 * v + x->xR[i];
   }
   for (i = 0; i < n; i++) {
      v = 0.5 * v + d->xR[i];
   }
   for (i = 0; i < k; i++) {
      v = 0.5 * v + fi->xR[i];
   }
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         v = 0.5 * v + jac->xyR[i][j];
      }
   }
   if (!isfinite(v)) {
      monitor->linesearchspoiled = true;
      return;
   }
// Enqueue
   monitor->enqueuedcnt++;
   enqueuedcnt = monitor->enqueuedcnt;
   rvectorgrowto(&monitor->dcur, n);
   rvectorgrowto(&monitor->enqueuedstp, enqueuedcnt);
   rvectorgrowto(&monitor->enqueuedx, enqueuedcnt * n);
   rvectorgrowto(&monitor->enqueuedfunc, enqueuedcnt * k);
   rmatrixgrowrowsto(&monitor->enqueuedjac, enqueuedcnt * k, n);
   monitor->enqueuedstp.xR[enqueuedcnt - 1] = stp;
   for (j = 0; j < n; j++) {
      monitor->dcur.xR[j] = d->xR[j];
   }
   for (j = 0; j < n; j++) {
      monitor->enqueuedx.xR[(enqueuedcnt - 1) * n + j] = x->xR[j];
   }
   for (i = 0; i < k; i++) {
      monitor->enqueuedfunc.xR[(enqueuedcnt - 1) * k + i] = fi->xR[i];
   }
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         monitor->enqueuedjac.xyR[(enqueuedcnt - 1) * k + i][j] = jac->xyR[i][j];
      }
   }
// Update sorted representation: insert to the end, reorder
   sortedcnt = monitor->sortedcnt;
   hasduplicates = false;
   for (i = 0; i < sortedcnt; i++) {
      hasduplicates = hasduplicates || monitor->sortedstp.xR[i] == stp;
   }
   if (!hasduplicates) {
      monitor->sortedcnt++;
      sortedcnt = monitor->sortedcnt;
      rvectorgrowto(&monitor->sortedstp, sortedcnt);
      ivectorgrowto(&monitor->sortedidx, sortedcnt);
      monitor->sortedstp.xR[sortedcnt - 1] = stp;
      monitor->sortedidx.xZ[sortedcnt - 1] = enqueuedcnt - 1;
      for (i = sortedcnt - 2; i >= 0; i--) {
         if (monitor->sortedstp.xR[i] <= monitor->sortedstp.xR[i + 1]) {
            break;
         }
         swapr(&monitor->sortedstp.xR[i], &monitor->sortedstp.xR[i + 1]);
         swapi(&monitor->sortedidx.xZ[i], &monitor->sortedidx.xZ[i + 1]);
      }
   }
// Scan sorted representation, check for C0 and C1 continuity
// violations.
   vectorsetlengthatleast(&monitor->f, sortedcnt);
   vectorsetlengthatleast(&monitor->g, sortedcnt * n);
   for (funcidx = 0; funcidx < k; funcidx++) {
   // Fetch current function and its gradient to the contiguous storage
      for (i = 0; i < sortedcnt; i++) {
         monitor->f.xR[i] = monitor->enqueuedfunc.xR[monitor->sortedidx.xZ[i] * k + funcidx];
         for (j = 0; j < n; j++) {
            monitor->g.xR[i * n + j] = monitor->enqueuedjac.xyR[monitor->sortedidx.xZ[i] * k + funcidx][j];
         }
      }
   // Check C0 continuity.
   //
   // The basis approach is that we find appropriate candidate point
   // (either a local minimum along the line - for target; or an interval
   // where function sign is changed - for constraints), calculate left
   // and right estimates of the Lipschitz constant (slopes between points
   // #0 and #1, #2 and #3), and then calculate slope between points #1 and
   // #2 and compare it with left/right estimates.
   //
   // The actual approach is a bit more complex to account for different
   // sources of numerical noise and different false positive scenarios.
      if (funcidx == 0) {
         for (stpidx = 0; stpidx < sortedcnt - 3; stpidx++) {
            f0 = monitor->f.xR[stpidx];
            f1 = monitor->f.xR[stpidx + 1];
            f2 = monitor->f.xR[stpidx + 2];
            f3 = monitor->f.xR[stpidx + 3];
            noise0 = optserv_ognoiselevelf * rmax2(fabs(f0), 1.0);
            noise1 = optserv_ognoiselevelf * rmax2(fabs(f1), 1.0);
            noise2 = optserv_ognoiselevelf * rmax2(fabs(f2), 1.0);
            noise3 = optserv_ognoiselevelf * rmax2(fabs(f3), 1.0);
            if (!(f1 < f0 + (noise0 + noise1) && f1 < f2)) {
               continue;
            }
            optserv_testc0continuity(f0, f1, f2, f3, noise0, noise1, noise2, noise3, monitor->sortedstp.xR[stpidx + 1] - monitor->sortedstp.xR[stpidx], monitor->sortedstp.xR[stpidx + 2] - monitor->sortedstp.xR[stpidx + 1], monitor->sortedstp.xR[stpidx + 3] - monitor->sortedstp.xR[stpidx + 2], false, &rating, &lipschitz);
            if (rating > optserv_ogminrating0) {
            // Store to total report
               monitor->rep.nonc0suspected = true;
               monitor->rep.nonc0test0positive = true;
               if (rating > monitor->nonc0currentrating) {
                  monitor->nonc0currentrating = rating;
                  monitor->rep.nonc0lipschitzc = lipschitz;
                  monitor->rep.nonc0fidx = funcidx;
               }
            // Store to "strongest" report
               if (rating > monitor->nonc0strrating) {
                  monitor->nonc0strrating = rating;
                  monitor->nonc0strrep.positive = true;
                  monitor->nonc0strrep.fidx = funcidx;
                  monitor->nonc0strrep.n = n;
                  monitor->nonc0strrep.cnt = sortedcnt;
                  monitor->nonc0strrep.stpidxa = stpidx;
                  monitor->nonc0strrep.stpidxb = stpidx + 3;
                  monitor->nonc0strrep.inneriter = monitor->linesearchinneridx;
                  monitor->nonc0strrep.outeriter = monitor->linesearchouteridx;
                  vectorsetlengthatleast(&monitor->nonc0strrep.x0, n);
                  vectorsetlengthatleast(&monitor->nonc0strrep.d, n);
                  for (i = 0; i < n; i++) {
                     monitor->nonc0strrep.x0.xR[i] = monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i];
                     monitor->nonc0strrep.d.xR[i] = monitor->dcur.xR[i];
                  }
                  vectorsetlengthatleast(&monitor->nonc0strrep.stp, sortedcnt);
                  vectorsetlengthatleast(&monitor->nonc0strrep.f, sortedcnt);
                  for (i = 0; i < sortedcnt; i++) {
                     monitor->nonc0strrep.stp.xR[i] = monitor->sortedstp.xR[i];
                     monitor->nonc0strrep.f.xR[i] = monitor->f.xR[i];
                  }
               }
            // Store to "longest" report
               nrm = 0.0;
               for (i = 0; i < n; i++) {
                  nrm += sqr(monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i] - monitor->enqueuedx.xR[monitor->sortedidx.xZ[sortedcnt - 1] * n + i]);
               }
               nrm = sqrt(nrm);
               nrm = rmin2(nrm, 1.0);
               nrm = coalesce(nrm, machineepsilon);
               lengthrating = sortedcnt + log(nrm) / log(100.0);
               if (lengthrating > monitor->nonc0lngrating) {
                  monitor->nonc0lngrating = lengthrating;
                  monitor->nonc0lngrep.positive = true;
                  monitor->nonc0lngrep.fidx = funcidx;
                  monitor->nonc0lngrep.n = n;
                  monitor->nonc0lngrep.cnt = sortedcnt;
                  monitor->nonc0lngrep.stpidxa = stpidx;
                  monitor->nonc0lngrep.stpidxb = stpidx + 3;
                  monitor->nonc0lngrep.inneriter = monitor->linesearchinneridx;
                  monitor->nonc0lngrep.outeriter = monitor->linesearchouteridx;
                  vectorsetlengthatleast(&monitor->nonc0lngrep.x0, n);
                  vectorsetlengthatleast(&monitor->nonc0lngrep.d, n);
                  for (i = 0; i < n; i++) {
                     monitor->nonc0lngrep.x0.xR[i] = monitor->enqueuedx.xR[monitor->sortedidx.xZ[0] * n + i];
                     monitor->nonc0lngrep.d.xR[i] = monitor->dcur.xR[i];
                  }
                  vectorsetlengthatleast(&monitor->nonc0lngrep.stp, sortedcnt);
                  vectorsetlengthatleast(&monitor->nonc0lngrep.f, sortedcnt);
                  for (i = 0; i < sortedcnt; i++) {
                     monitor->nonc0lngrep.stp.xR[i] = monitor->sortedstp.xR[i];
                     monitor->nonc0lngrep.f.xR[i] = monitor->f.xR[i];
                  }
               }
            }
         }
      }
   // C1 continuity test #0
      for (stpidx = 0; stpidx < sortedcnt - 6; stpidx++) {
      // Fetch function values
         f2 = monitor->f.xR[stpidx + 2];
         f3 = monitor->f.xR[stpidx + 3];
         f4 = monitor->f.xR[stpidx + 4];
         noise2 = optserv_ognoiselevelf * rmax2(fabs(f2), 1.0);
         noise3 = optserv_ognoiselevelf * rmax2(fabs(f3), 1.0);
      // Decide whether we want to test this interval or not; for target
      // function we test intervals around minimum, for constraints we
      // additionally test intervals of sign change.
         if (funcidx == 0) {
         // Target function: skip if not minimum
            if (!(f3 < f2 + (noise2 + noise3) && f3 < f4)) {
               continue;
            }
         } else {
         // Constraint: skip if both (a) sign does not change, and (b) is not minumum
            if (sign(f2 * f4) > 0 && !(f3 < f2 + (noise2 + noise3) && f3 < f4)) {
               continue;
            }
         }
         optserv_c1continuitytest0(monitor, funcidx, stpidx, sortedcnt);
         optserv_c1continuitytest0(monitor, funcidx, stpidx + 1, sortedcnt);
      }
   // C1 continuity test #1
      for (stpidx = 0; stpidx < sortedcnt - 3; stpidx++) {
      // Fetch function values from the interval being tested
         f0 = monitor->f.xR[stpidx];
         f1 = monitor->f.xR[stpidx + 1];
         f2 = monitor->f.xR[stpidx + 2];
         f3 = monitor->f.xR[stpidx + 3];
         noise0 = optserv_ognoiselevelf * rmax2(fabs(f0), 1.0);
         noise1 = optserv_ognoiselevelf * rmax2(fabs(f1), 1.0);
         noise2 = optserv_ognoiselevelf * rmax2(fabs(f2), 1.0);
         noise3 = optserv_ognoiselevelf * rmax2(fabs(f3), 1.0);
      // Decide whether we want to test this interval or not; for target
      // function we test intervals around minimum, for constraints we
      // additionally test intervals of sign change.
         if (funcidx == 0) {
         // Skip if not minimum
            if (!(f1 < f0 + (noise0 + noise1) && f2 < f3 + (noise2 + noise3))) {
               continue;
            }
         } else {
         // Skip if sign does not change
            if (sign(f0 * f3) > 0 && !(f1 < f0 + (noise0 + noise1) && f2 < f3 + (noise2 + noise3))) {
               continue;
            }
         }
         optserv_c1continuitytest1(monitor, funcidx, stpidx, sortedcnt);
      }
   }
}

// This subroutine enqueues one more trial point for a task with scalar
// function with unscaled variables - a convenience wrapper for more general
// EnqueuePoint()
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorenqueuepoint1u(smoothnessmonitor *monitor, RVector *s, RVector *invs, RVector *d, double stp, RVector *x, double f0, RVector *j0) {
   ae_int_t n;
   ae_int_t k;
   ae_int_t i;
   n = monitor->n;
   k = monitor->k;
   if (!monitor->checksmoothness) {
      return;
   }
   ae_assert(k == 1, "SmoothnessMonitorEnqueuePoint1: K != 1");
   vectorsetlengthatleast(&monitor->xu, n);
   vectorsetlengthatleast(&monitor->du, n);
   vectorsetlengthatleast(&monitor->f0, 1);
   matrixsetlengthatleast(&monitor->j0, 1, n);
   monitor->f0.xR[0] = f0;
   for (i = 0; i < n; i++) {
      monitor->xu.xR[i] = x->xR[i] * invs->xR[i];
      monitor->du.xR[i] = d->xR[i] * invs->xR[i];
      monitor->j0.xyR[0][i] = j0->xR[i] * s->xR[i];
   }
   smoothnessmonitorenqueuepoint(monitor, &monitor->du, stp, &monitor->xu, &monitor->f0, &monitor->j0);
}

// This function starts aggressive probing of the Lagrangian for a  range  of
// step lengths [0,StpMax].
//
// Inputs:
//     Monitor         -   monitor object
//     LagMult         -   array[K-1], lagrange multipliers for nonlinear
//                         constraints
//     X               -   array[N], initial point for probing
//     D               -   array[N], probing direction
//     StpMax          -   range of steps to probe
//
// ALGLIB: Copyright 10.10.2019 by Sergey Bochkanov
void smoothnessmonitorstartlagrangianprobing(smoothnessmonitor *monitor, RVector *x, RVector *d, double stpmax, ae_int_t inneriter, ae_int_t outeriter) {
   ae_int_t n;
   ae_int_t k;
   ae_int_t i;
   n = monitor->n;
   k = monitor->k;
   ae_assert(isfinitevector(x, n), "SmoothnessMonitorStartLagrangianProbing: bad X[] array");
   ae_assert(isfinitevector(d, n), "SmoothnessMonitorStartLagrangianProbing: bad D[] array");
   ae_assert(isfinite(stpmax) && stpmax > 0.0, "SmoothnessMonitorStartLagrangianProbing: StpMax <= 0");
   ae_assert(k >= 1, "SmoothnessMonitorStartLagrangianProbing: monitor object is initialized with K <= 0");
   monitor->lagprobnstepsstored = 0;
   monitor->lagprobstepmax = stpmax;
   monitor->lagprobinneriter = inneriter;
   monitor->lagprobouteriter = outeriter;
   vectorsetlengthatleast(&monitor->lagprobxs, n);
   vectorsetlengthatleast(&monitor->lagprobd, n);
   for (i = 0; i < n; i++) {
      monitor->lagprobxs.xR[i] = x->xR[i];
      monitor->lagprobd.xR[i] = d->xR[i];
   }
   vectorsetlengthatleast(&monitor->lagprobx, n);
   vectorsetlengthatleast(&monitor->lagprobfi, k);
   matrixsetlengthatleast(&monitor->lagprobj, k, n);
   monitor->ProbePQ = -1;
}

#if 0 //(@) Not used.
// This function performs aggressive probing and sends points  to  smoothness
// monitoring queue via EnqueuePoint() call.
//
// After  each  call  it  returns  point to evaluate in  Monitor.LagProbX and
// current step in Monitor.LagProbStp. Caller has to load function values and
// Jacobian at X into Monitor.LagProbFi and Monitor.LagProbJ, current Lagrangian
// to Monitor.LagProbRawLag and continue iteration.
//
// NOTE: LagProbX[] is not guarded against constraint violation. Both non-box
//       and box constraints are ignored.  It  is  caller  responsibility  to
//       provide appropriate  X[],  D[]  and  StpMax  which  do  not  violate
//       important constraints
// ALGLIB: Copyright 10.10.2019 by Sergey Bochkanov
bool smoothnessmonitorprobelagrangian(smoothnessmonitor *monitor) {
   AutoS ae_int_t stpidx;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t idx;
   AutoS double stp;
   AutoS double vlargest;
   AutoS double v;
   AutoS double v0;
   AutoS double v1;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (monitor->ProbePQ >= 0) switch (monitor->ProbePQ) {
      case 0: goto Resume0;
      default: goto Exit;
   }
Spawn:
   for (stpidx = 0; stpidx < 40; stpidx++) {
   // Increase storage size
      rvectorgrowto(&monitor->lagprobsteps, monitor->lagprobnstepsstored + 1);
      rvectorgrowto(&monitor->lagproblagrangians, monitor->lagprobnstepsstored + 1);
      rmatrixgrowrowsto(&monitor->lagprobvalues, monitor->lagprobnstepsstored + 1, monitor->k);
      rmatrixgrowrowsto(&monitor->lagprobjacobians, monitor->lagprobnstepsstored + 1, monitor->n * monitor->k);
   // Determine probing step length, save step to the end of the storage
      if (stpidx <= 10) {
      // First 11 steps are performed over equidistant grid
         stp = stpidx / 10.0 * monitor->lagprobstepmax;
      } else {
      // Subsequent steps target interesting points
         ae_assert(monitor->lagprobnstepsstored >= 3, "SMonitor: critical integrity check failed");
         stp = 0.0;
         if (stpidx % 3 == 0) {
         // Target interval with maximum change in Lagrangian
            idx = -1;
            vlargest = 0.0;
            for (j = 0; j < monitor->lagprobnstepsstored - 1; j++) {
               v = fabs(monitor->lagproblagrangians.xR[j + 1] - monitor->lagproblagrangians.xR[j]);
               if (idx < 0 || v > vlargest) {
                  idx = j;
                  vlargest = v;
               }
            }
            stp = 0.5 * (monitor->lagprobsteps.xR[idx] + monitor->lagprobsteps.xR[idx + 1]);
         }
         if (stpidx % 3 == 1) {
         // Target interval [J,J+2] with maximum change in slope of Lagrangian,
         // select subinterval [J,J+1] or [J+1,J+2] (one with maximum length).
            idx = -1;
            vlargest = 0.0;
            for (j = 0; j < monitor->lagprobnstepsstored - 2; j++) {
               v0 = (monitor->lagproblagrangians.xR[j + 1] - monitor->lagproblagrangians.xR[j]) / (monitor->lagprobsteps.xR[j + 1] - monitor->lagprobsteps.xR[j] + machineepsilon);
               v1 = (monitor->lagproblagrangians.xR[j + 2] - monitor->lagproblagrangians.xR[j + 1]) / (monitor->lagprobsteps.xR[j + 2] - monitor->lagprobsteps.xR[j + 1] + machineepsilon);
               v = fabs(v0 - v1);
               if (idx < 0 || v > vlargest) {
                  idx = j;
                  vlargest = v;
               }
            }
            if (monitor->lagprobsteps.xR[idx + 2] - monitor->lagprobsteps.xR[idx + 1] > monitor->lagprobsteps.xR[idx + 1] - monitor->lagprobsteps.xR[idx]) {
               stp = 0.5 * (monitor->lagprobsteps.xR[idx + 2] + monitor->lagprobsteps.xR[idx + 1]);
            } else {
               stp = 0.5 * (monitor->lagprobsteps.xR[idx + 1] + monitor->lagprobsteps.xR[idx]);
            }
         }
         if (stpidx % 3 == 2) {
         // Target interval with maximum change in sum of squared Jacobian differences
            idx = -1;
            vlargest = 0.0;
            for (j = 0; j < monitor->lagprobnstepsstored - 1; j++) {
               v = 0.0;
               for (i = 0; i < monitor->k * monitor->n; i++) {
                  v += sqr(monitor->lagprobjacobians.xyR[j + 1][i] - monitor->lagprobjacobians.xyR[j][i]);
               }
               if (idx < 0 || v > vlargest) {
                  idx = j;
                  vlargest = v;
               }
            }
            stp = 0.5 * (monitor->lagprobsteps.xR[idx] + monitor->lagprobsteps.xR[idx + 1]);
         }
      }
      monitor->lagprobsteps.xR[monitor->lagprobnstepsstored] = stp;
   // Retrieve user values
      for (i = 0; i < monitor->n; i++) {
         monitor->lagprobx.xR[i] = monitor->lagprobxs.xR[i] + monitor->lagprobd.xR[i] * stp;
      }
      monitor->lagprobstp = stp;
      monitor->ProbePQ = 0; goto Pause; Resume0:
      for (i = 0; i < monitor->k; i++) {
         monitor->lagprobvalues.xyR[monitor->lagprobnstepsstored][i] = monitor->lagprobfi.xR[i];
         for (j = 0; j < monitor->n; j++) {
            monitor->lagprobjacobians.xyR[monitor->lagprobnstepsstored][i * monitor->n + j] = monitor->lagprobj.xyR[i][j];
         }
      }
      monitor->lagproblagrangians.xR[monitor->lagprobnstepsstored] = monitor->lagprobrawlag;
      monitor->lagprobnstepsstored++;
      if (stpidx == 0) {
         ae_assert(stp == 0.0, "SmoothnessMonitorProbeLagrangian: integrity check failed");
         smoothnessmonitorstartlinesearch(monitor, &monitor->lagprobx, &monitor->lagprobfi, &monitor->lagprobj, monitor->lagprobinneriter, monitor->lagprobouteriter);
      } else {
         smoothnessmonitorenqueuepoint(monitor, &monitor->lagprobd, stp, &monitor->lagprobx, &monitor->lagprobfi, &monitor->lagprobj);
      }
   // Resort
      for (j = monitor->lagprobnstepsstored - 1; j >= 1; j--) {
         if (monitor->lagprobsteps.xR[j - 1] <= monitor->lagprobsteps.xR[j]) {
            break;
         }
         swapelements(&monitor->lagprobsteps, j - 1, j);
         swapelements(&monitor->lagproblagrangians, j - 1, j);
         swaprows(&monitor->lagprobvalues, j - 1, j, monitor->k);
         swaprows(&monitor->lagprobjacobians, j - 1, j, monitor->n * monitor->k);
      }
   }
   smoothnessmonitorfinalizelinesearch(monitor);
Exit:
   monitor->ProbePQ = -1;
   return false;
Pause:
   return true;
}
#endif

// This subroutine exports report to user-readable representation (all arrays
// are forced to have exactly same size as needed; unused arrays are  set  to
// zero length).
// ALGLIB: Copyright 19.11.2018 by Sergey Bochkanov
void smoothnessmonitorexportreport(smoothnessmonitor *monitor, optguardreport *rep) {
// Finalize last line search, just to be sure
   if (monitor->enqueuedcnt > 0) {
      smoothnessmonitorfinalizelinesearch(monitor);
   }
// Export report
   optguardexportreport(&monitor->rep, monitor->n, monitor->k, monitor->badgradhasxj, rep);
}

// Check numerical gradient at point X0 (unscaled variables!), with  optional
// box constraints [BndL,BndU] (if  HasBoxConstraints == True)  and  with  scale
// vector S[].
//
// Step S[i]*TestStep is performed along I-th variable.
//
// NeedFiJ RComm protocol is used to request derivative information. //(@) Redundant and removed.
//
// Box constraints BndL/BndU are expected to be feasible. It is  possible  to
// have BndL == BndU.
// ALGLIB: Copyright 06.12.2018 by Sergey Bochkanov
bool smoothnessmonitorcheckgradientatx0(smoothnessmonitor *monitor, RVector *unscaledx0, RVector *s, RVector *bndl, RVector *bndu, bool hasboxconstraints, double teststep) {
   AutoS ae_int_t n;
   AutoS ae_int_t k;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t varidx;
   AutoS double v;
   AutoS double vp;
   AutoS double vm;
   AutoS double vc;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (monitor->PQ >= 0) switch (monitor->PQ) {
      case 0: goto Resume0; case 1: goto Resume1; case 2: goto Resume2; case 3: goto Resume3;
      default: goto Exit;
   }
Spawn:
   n = monitor->n;
   k = monitor->k;
   monitor->needfij = false;
// Quick exit
   if (n <= 0 || k <= 0 || !isfinite(teststep) || teststep == 0.0) {
      goto Exit;
   }
   teststep = fabs(teststep);
// Allocate storage
   vectorsetlengthatleast(&monitor->x, n);
   vectorsetlengthatleast(&monitor->fi, k);
   matrixsetlengthatleast(&monitor->j, k, n);
   vectorsetlengthatleast(&monitor->xbase, n);
   vectorsetlengthatleast(&monitor->fbase, k);
   vectorsetlengthatleast(&monitor->fm, k);
   vectorsetlengthatleast(&monitor->fc, k);
   vectorsetlengthatleast(&monitor->fp, k);
   vectorsetlengthatleast(&monitor->jm, k);
   vectorsetlengthatleast(&monitor->jc, k);
   vectorsetlengthatleast(&monitor->jp, k);
   matrixsetlengthatleast(&monitor->jbaseusr, k, n);
   matrixsetlengthatleast(&monitor->jbasenum, k, n);
   vectorsetlengthatleast(&monitor->rep.badgradxbase, n);
   matrixsetlengthatleast(&monitor->rep.badgraduser, k, n);
   matrixsetlengthatleast(&monitor->rep.badgradnum, k, n);
// Set XBase/Jacobian presence flag
   monitor->badgradhasxj = true;
// Determine reference point, compute function vector and user-supplied Jacobian
   for (i = 0; i < n; i++) {
      v = unscaledx0->xR[i];
      if (hasboxconstraints && isfinite(bndl->xR[i]) && v < bndl->xR[i]) {
         v = bndl->xR[i];
      }
      if (hasboxconstraints && isfinite(bndu->xR[i]) && v > bndu->xR[i]) {
         v = bndu->xR[i];
      }
      monitor->xbase.xR[i] = v;
      monitor->rep.badgradxbase.xR[i] = v;
      monitor->x.xR[i] = v;
   }
   monitor->needfij = true, monitor->PQ = 0; goto Pause; Resume0: monitor->needfij = false;
   for (i = 0; i < k; i++) {
      monitor->fbase.xR[i] = monitor->fi.xR[i];
      for (j = 0; j < n; j++) {
         monitor->jbaseusr.xyR[i][j] = monitor->j.xyR[i][j];
         monitor->rep.badgraduser.xyR[i][j] = monitor->j.xyR[i][j];
      }
   }
// Check Jacobian column by column
   for (varidx = 0; varidx < n; varidx++) {
   // Determine test location.
      v = monitor->xbase.xR[varidx];
      vm = v - s->xR[varidx] * teststep;
      vp = v + s->xR[varidx] * teststep;
      if (hasboxconstraints && isfinite(bndl->xR[varidx]) && vm < bndl->xR[varidx]) {
         vm = bndl->xR[varidx];
      }
      if (hasboxconstraints && isfinite(bndu->xR[varidx]) && vp > bndu->xR[varidx]) {
         vp = bndu->xR[varidx];
      }
      vc = vm + (vp - vm) / 2.0;
   // Quickly skip fixed variables
      if (vm == vp || vc == vm || vc == vp) {
         for (i = 0; i < k; i++) {
            monitor->rep.badgradnum.xyR[i][varidx] = 0.0;
         }
         continue;
      }
   // Compute F/J at three trial points
      for (i = 0; i < n; i++) {
         monitor->x.xR[i] = monitor->xbase.xR[i];
      }
      monitor->x.xR[varidx] = vm;
      monitor->needfij = true, monitor->PQ = 1; goto Pause; Resume1: monitor->needfij = false;
      for (i = 0; i < k; i++) {
         monitor->fm.xR[i] = monitor->fi.xR[i];
         monitor->jm.xR[i] = monitor->j.xyR[i][varidx];
      }
      for (i = 0; i < n; i++) {
         monitor->x.xR[i] = monitor->xbase.xR[i];
      }
      monitor->x.xR[varidx] = vc;
      monitor->needfij = true, monitor->PQ = 2; goto Pause; Resume2: monitor->needfij = false;
      for (i = 0; i < k; i++) {
         monitor->fc.xR[i] = monitor->fi.xR[i];
         monitor->jc.xR[i] = monitor->j.xyR[i][varidx];
      }
      for (i = 0; i < n; i++) {
         monitor->x.xR[i] = monitor->xbase.xR[i];
      }
      monitor->x.xR[varidx] = vp;
      monitor->needfij = true, monitor->PQ = 3; goto Pause; Resume3: monitor->needfij = false;
      for (i = 0; i < k; i++) {
         monitor->fp.xR[i] = monitor->fi.xR[i];
         monitor->jp.xR[i] = monitor->j.xyR[i][varidx];
      }
   // Check derivative
      for (i = 0; i < k; i++) {
         monitor->rep.badgradnum.xyR[i][varidx] = (monitor->fp.xR[i] - monitor->fm.xR[i]) / (vp - vm);
         if (!derivativecheck(monitor->fm.xR[i], monitor->jm.xR[i] * s->xR[varidx], monitor->fp.xR[i], monitor->jp.xR[i] * s->xR[varidx], monitor->fc.xR[i], monitor->jc.xR[i] * s->xR[varidx], (vp - vm) / s->xR[varidx])) {
            monitor->rep.badgradsuspected = true;
            monitor->rep.badgradfidx = i;
            monitor->rep.badgradvidx = varidx;
         }
      }
   }
Exit:
   monitor->PQ = -1;
   return false;
Pause:
   return true;
}

// Lowe-level Hessian update function, to be used by HessianUpdate()
//
// Inputs:
//     Hess            -   Hessian state
//     H               -   specific Hessian matrix to update, usually one
//                         of the Hess fields
//     X0, G0          -   point #0 and gradient at #0, array[N]
//     X1, G1          -   point #1 and gradient at #1, array[N]
//
// Outputs:
//     Status          -   sets update status (informative)
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
static void optserv_hessianupdatelowlevel(xbfgshessian *hess, RMatrix *h, RVector *sk, RVector *yk, ae_int_t *status) {
   ae_int_t i;
   ae_int_t n;
   double shs;
   double sy;
   double snrm2;
   double hsnrm2;
   double ynrm2;
   double ski;
   double yki;
   double mxs;
   double mxy;
   double mxhs;
   double mxd;
   double big;
   *status = 0;
   n = hess->n;
   *status = 0;
   big = 1.0 / hess->reg;
// Perform preliminary analysis
   vectorsetlengthatleast(&hess->hsk, n);
   rmatrixgemv(n, n, 1.0, h, 0, 0, 0, sk, 0, 0.0, &hess->hsk, 0);
   shs = 0.0;
   sy = 0.0;
   snrm2 = 0.0;
   ynrm2 = 0.0;
   mxs = 0.0;
   mxy = 0.0;
   mxhs = 0.0;
   hsnrm2 = 0.0;
   mxd = 0.0;
   for (i = 0; i < n; i++) {
      ski = sk->xR[i];
      yki = yk->xR[i];
      shs += ski * hess->hsk.xR[i];
      sy += ski * yki;
      snrm2 += ski * ski;
      ynrm2 += yki * yki;
      mxs = rmax2(mxs, fabs(ski));
      mxy = rmax2(mxy, fabs(yki));
      mxhs = rmax2(mxhs, fabs(hess->hsk.xR[i]));
      hsnrm2 += sqr(hess->hsk.xR[i]);
      mxd = rmax2(mxd, fabs(h->xyR[i][i]));
   }
// Completely skip updates with too short steps and degenerate updates
//
// NOTE: may prevent us from updating Hessian near the solution
   if (mxs <= hess->stpshort) {
   // Sk is too small
      return;
   }
   if (hsnrm2 == 0.0) {
   // H*Sk is exactly zero, exit
      return;
   }
   if (shs <= 0.0 || shs <= mxs * mxd * mxs * hess->microreg) {
   // Sk'*H*Sk is too small.
   //
   // Apply regularization to Hessian before exiting
      ae_assert(hsnrm2 > 0.0, "UpdateHessian: integrity check failed");
      rmatrixger(n, n, h, 0, 0, hess->reg / hsnrm2, &hess->hsk, 0, &hess->hsk, 0);
      return;
   }
// First, we discard Hessian components which give non-zero product with Sk.
//
// We apply some damping in order to avoid problems arising with very small
// Sk'*H*Sk, and we apply some regularization term in order to have Sk'*Hnew*Sk
// still slightly larger than zero.
//
// Traditional BFGS update adds -(Hk*Sk)*(Hk*Sk)'/(Sk'*H*Sk). We use
// modified, more robust formula (below Z=(H*Sk)/|H*Sk|)
//
//     (                         (H*Sk,H*Sk)                               )
//     ( - --------------------------------------------------------- + Reg ) * Z * Z'
//     (    Sk'*H*Sk + Reg*(H*Sk,H*Sk) + MicroReg*(max(H)*max(S))^2        )
   ae_assert(hsnrm2 > 0.0, "UpdateHessian: integrity check failed");
   rmatrixger(n, n, h, 0, 0, -1.0 / (shs + hsnrm2 * hess->reg + sqr(mxd * mxs) * hess->microreg) + hess->reg / hsnrm2, &hess->hsk, 0, &hess->hsk, 0);
   *status = 1;
// Before we update Hessian with Yk, decide whether we need this update - or
// maybe it is better to leave Hessian as is, with small curvature along Sk
// (in the latter case we still treat BFGS update as successful).
//
// Traditional BFGS update adds Yk*Yk'/(Sk,Yk) to the Hessian. Instead we
// use modified update (below U == Yk/|Yk|)
//
//               (Yk,Yk)
//     -------------------------------------- * U * U'
//      (Sk,Yk)+Reg*(Yk,Yk)+MicroReg*(Sk,Sk)
   if (ynrm2 == 0.0) {
      return;
   }
   if (sy <= 0.0) {
      return;
   }
   if (sqr(mxy) >= sy * big) {
      return;
   }
   ae_assert(sy > 0.0, "UpdateHessian: integrity check failed");
   rmatrixger(n, n, h, 0, 0, 1.0 / (sy + hess->reg * ynrm2 + hess->microreg * snrm2), yk, 0, yk, 0);
   *status = 2;
}

// Invalidate low-rank model
//
// Inputs:
//     Hess            -   Hessian state
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
static void optserv_resetlowrankmodel(xbfgshessian *hess) {
   ae_assert(hess->htype == 3, "OPTSERV: integrity check 9940 failed");
   hess->lowrankmodelvalid = false;
   hess->lowrankeffdvalid = false;
}

// Recomputes low-rank model (DIAG and CORR fields) according to the  current
// state of the LBFGS memory
//
// Inputs:
//     Hess            -   Hessian state
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
static void optserv_recomputelowrankmodel(xbfgshessian *hess) {
   ae_int_t n;
   ae_int_t memlen;
   ae_int_t i;
   ae_int_t j;
   bool success;
   n = hess->n;
   memlen = hess->memlen;
// If the model is valid, exit.
// Otherwise, recompute it from scratch
   if (hess->lowrankmodelvalid) {
      return;
   }
   optserv_resetlowrankmodel(hess);
// Quick exit for MemLen == 0.
// After this block we assume that MemLen > 0
   if (memlen == 0) {
      hess->lowrankmodelvalid = true;
      hess->lowrankk = 0;
      hess->sigma = 1.0;
      return;
   }
// Prepare RAW_CORR2, a right part of correction matrix
//
//     Bk = sigma*I - RAW_CORR2'*RAW_BLOCK*RAW_CORR2
//
// with RAW_CORR2 being 2MEMLEN*N matrix and RAW_BLOCK being 2MEMLEN*2MEMLEN matrix,
// as defined by equations 2.17 and 3.22 in 'REPRESENTATION OF QUASI-NEWTON MATRICES
// AND THEIR USE IN LIMITED MEMORY METHODS' by Byrd, Nocedal and Schnabel.
//
// The initial form for Bk is
//
//                    [          ]   [ -Dk     Lk' ]-1 [  Y   ]
//     Bk = sigma*I - [ Y' B0*S' ] * [             ] * [      ]
//                    [          ]   [ Lk  S*B0*S' ]   [ S*B0 ]
//
// with
//
//     Lk[i,j]=(Si,Yj) for i>j, 0 otherwise
//     Dk = diag[(Si,Yj)]
//
   allocm(2 * memlen, n, &hess->corr2);
   for (i = 0; i < memlen; i++) {
      rcopyrr(n, &hess->s, i, &hess->corr2, memlen + i);
      rmulr(n, hess->sigma, &hess->corr2, memlen + i);
      rcopyrr(n, &hess->y, i, &hess->corr2, i);
   }
// Start factorizing central block. Whilst it is indefinite, it has
// pretty simple factorization
//
//     [ -Dk     Lk' ]   [ Dk^(0.5)          ]   [ -I      ]   [ Dk^(0.5)  -Dk^(-0.5)*Lk' ]
//     [             ] = [                   ] * [         ] * [                          ]
//     [ Lk  S*B0*S' ]   [ -Lk*Dk^(-0.5)  Jk ]   [      +I ]   [                      Jk' ]
//
// First, we compute lower triangular Jk such that Jk*Jk' = S*B0*S' + Lk*inv(Dk)*Lk'
   allocv(memlen, &hess->buf);
   for (i = 0; i < memlen; i++) {
      hess->buf.xR[i] = 1.0 / sqrt(hess->lowranksyt.xyR[i][i]);
   }
   rsetallocm(memlen, memlen, 0.0, &hess->invsqrtdlk);
   for (i = 1; i < memlen; i++) {
      rcopyrr(i, &hess->lowranksyt, i, &hess->invsqrtdlk, i);
      rmergemulvr(i, &hess->buf, &hess->invsqrtdlk, i);
   }
   rcopyallocm(memlen, memlen, &hess->lowranksst, &hess->jk);
   rmatrixgemm(memlen, memlen, memlen, 1.0, &hess->invsqrtdlk, 0, 0, 0, &hess->invsqrtdlk, 0, 0, 1, hess->sigma, &hess->jk, 0, 0);
   success = spdmatrixcholeskyrec(&hess->jk, 0, memlen, false, &hess->buf);
   ae_assert(success, "OPTSERV: integrity check 9828 failed");
// After computing Jk we proceed to form triangular factorization of the entire block matrix
   rsetallocm(2 * memlen, 2 * memlen, 0.0, &hess->blk);
   for (i = 0; i < memlen; i++) {
      hess->blk.xyR[i][i] = sqrt(hess->lowranksyt.xyR[i][i]);
   }
   for (i = 0; i < memlen; i++) {
      for (j = 0; j < i; j++) {
         hess->blk.xyR[memlen + i][j] = -hess->invsqrtdlk.xyR[i][j];
      }
   }
   for (i = 0; i < memlen; i++) {
      for (j = 0; j <= i; j++) {
         hess->blk.xyR[memlen + i][memlen + j] = hess->jk.xyR[i][j];
      }
   }
// And finally we merge triangular factor into CORR2 in order to get desired two-factor
// low rank representation without additional middle matrix. This representation is
// computed in CORR2 and unpacked into LowRankCp and LowRankCm ('minus' and 'plus' terms).
   rmatrixlefttrsm(2 * memlen, n, &hess->blk, 0, 0, false, false, 0, &hess->corr2, 0, 0);
   allocm(memlen, n, &hess->lowrankcp);
   for (i = 0; i < memlen; i++) {
      rcopyrr(n, &hess->corr2, i, &hess->lowrankcp, i);
   }
   allocm(memlen, n, &hess->lowrankcm);
   for (i = 0; i < memlen; i++) {
      rcopyrr(n, &hess->corr2, memlen + i, &hess->lowrankcm, i);
   }
// The model was created
   hess->lowrankmodelvalid = true;
   hess->lowrankk = memlen;
}

// Recomputes diagonal of the low-rank model (EFFD) according to the  current
// state of the LBFGS memory
//
// Inputs:
//     Hess            -   Hessian state
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
static void optserv_recomputelowrankdiagonal(xbfgshessian *hess) {
   ae_int_t n;
   ae_int_t memlen;
   ae_int_t i;
   n = hess->n;
   memlen = hess->memlen;
// If the diagonal is valid, exit.
// Otherwise, recompute it from scratch
   if (hess->lowrankeffdvalid) {
      return;
   }
   optserv_recomputelowrankmodel(hess);
// Quick exit for MemLen == 0
   if (memlen == 0) {
      hess->lowrankeffdvalid = true;
      rsetallocv(n, hess->sigma, &hess->lowrankeffd);
      return;
   }
// Assuming MemLen > 0
   rsetallocv(n, hess->sigma, &hess->lowrankeffd);
   allocv(n, &hess->buf);
   for (i = 0; i < hess->lowrankk; i++) {
      rcopyrv(n, &hess->lowrankcp, i, &hess->buf);
      rmuladdv(n, &hess->buf, &hess->buf, &hess->lowrankeffd);
      rcopyrv(n, &hess->lowrankcm, i, &hess->buf);
      rnegmuladdv(n, &hess->buf, &hess->buf, &hess->lowrankeffd);
   }
   hess->lowrankeffdvalid = true;
}

// This function initializes approximation of a Hessian.
//
// Direct BFGS (Hessian matrix H is stored) with stability improvements is used.
//
// Inputs:
//     Hess            -   Hessian structure, initial state is ignored, but
//                         previously allocated memory is reused as much as
//                         possible
//     N               -   dimensions count
//     ResetFreq       -   reset frequency for BFGS :
//                         * ResetFreq == 0 for standard BFGS
//                         * ResetFreq > 0 for BFGS with periodic resets (helps
//                           to maintain fresh curvature information, works
//                           better for highly nonquadratic problems)
//     StpShort        -   short step length (INF-norm); steps shorter than that
//                         are not used for Hessian updates
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
void hessianinitbfgs(xbfgshessian *hess, ae_int_t n, ae_int_t resetfreq, double stpshort) {
   ae_int_t i;
   ae_assert(resetfreq >= 0, "HessianInit: ResetFreq < 0");
   resetfreq = imin2(resetfreq, n);
   hess->htype = 0;
   hess->n = n;
   hess->resetfreq = resetfreq;
   hess->stpshort = stpshort;
   hess->hage = 0;
   hess->gammasml = 0.000001;
   hess->reg = 100.0 * sqrt(machineepsilon);
   hess->smallreg = 0.01 * sqrt(machineepsilon);
   hess->microreg = (1000.0 + sqrt(n)) * machineepsilon;
   hess->sumsy = sqr(machineepsilon);
   hess->sumy2 = hess->sumsy * hess->gammasml;
   hess->sums2 = 0.0;
   hess->updatestatus = 0;
   vectorsetlengthatleast(&hess->sk, n);
   vectorsetlengthatleast(&hess->yk, n);
   rsetallocm(n, n, 0.0, &hess->hcurrent);
   rsetallocm(n, n, 0.0, &hess->hincoming);
   for (i = 0; i < n; i++) {
      hess->hcurrent.xyR[i][i] = 1.0;
      hess->hincoming.xyR[i][i] = 1.0;
   }
}

// This function initializes approximation of a Hessian.
//
// Explicit low-rank representation of LBFGS is used.
//
// Inputs:
//     Hess            -   Hessian structure, initial state is ignored, but
//                         previously allocated memory is reused as much as
//                         possible
//     N               -   dimensions count, N > 0
//     M               -   memory size, M >= 0 (values above N will be reduced
//                         to N)
//     StpShort        -   short step length (INF-norm); steps shorter than that
//                         are not used for Hessian updates
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
void hessianinitlowrank(xbfgshessian *hess, ae_int_t n, ae_int_t m, double stpshort) {
   ae_assert(n > 0, "HessianInitLowRank: N <= 0");
   ae_assert(m >= 0, "HessianInitLowRank: M < 0");
   m = imin2(m, n);
// Initialize generic fields
   hess->htype = 3;
   hess->n = n;
// Initialize mode-specific fields
   hess->m = m;
   hess->memlen = 0;
   hess->sigma = 1.0;
   hess->gamma = 1.0;
   if (m > 0) {
      allocm(m, n, &hess->s);
      allocm(m, n, &hess->y);
      allocm(m, m, &hess->lowranksst);
      allocm(m, m, &hess->lowranksyt);
   }
   optserv_resetlowrankmodel(hess);
// Other fields
   hess->resetfreq = 0;
   hess->stpshort = stpshort;
   hess->hage = 0;
   hess->gammasml = 0.000001;
   hess->reg = 100.0 * sqrt(machineepsilon);
   hess->smallreg = 0.01 * sqrt(machineepsilon);
   hess->microreg = (1000.0 + sqrt(n)) * machineepsilon;
   hess->sumsy = 0.0;
   hess->sumy2 = 0.0;
   hess->sums2 = 0.0;
   hess->updatestatus = 0;
   allocv(n, &hess->sk);
   allocv(n, &hess->yk);
}

// Updates Hessian estimate, uses regularized formula which prevents  Hessian
// eigenvalues from decreasing below ~sqrt(Eps)  and  rejects  updates larger
// than ~1/sqrt(Eps) in magnitude.
//
// Either BFGS or LBFGS formula is used, depending on Hessian model settings.
//
// Inputs:
//     Hess            -   Hessian state
//     X0, G0          -   point #0 and gradient at #0, array[N]
//     X1, G1          -   point #1 and gradient at #1, array[N]
//
// On return sets Hess.UpdateStatus flag
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
void hessianupdate(xbfgshessian *hess, RVector *x0, RVector *g0, RVector *x1, RVector *g1) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   double gamma;
   double sy;
   double snrm2;
   double ynrm2;
   double ski;
   double yki;
   n = hess->n;
// Prepare Sk, Yk
   sy = 0.0;
   snrm2 = 0.0;
   ynrm2 = 0.0;
   for (i = 0; i < n; i++) {
      ski = x1->xR[i] - x0->xR[i];
      yki = g1->xR[i] - g0->xR[i];
      hess->sk.xR[i] = ski;
      hess->yk.xR[i] = yki;
      sy += ski * yki;
      snrm2 += ski * ski;
      ynrm2 += yki * yki;
   }
   hess->updatestatus = 0;
// Update current and incoming Hessians
   ae_assert(hess->htype == 0 || hess->htype == 3, "HessianUpdate: Hessian mode not supported");
   if (hess->htype == 0) {
   // Update dense Hessian using BFGS formula for Bk
      optserv_hessianupdatelowlevel(hess, &hess->hcurrent, &hess->sk, &hess->yk, &hess->updatestatus);
      optserv_hessianupdatelowlevel(hess, &hess->hincoming, &hess->sk, &hess->yk, &i);
      if (sy > 0.0) {
         hess->sumsy += sy;
         hess->sumy2 += ynrm2;
      }
      hess->sums2 += snrm2;
      hess->hage++;
   // Perform Hessian reset if needed
      if (hess->resetfreq > 0 && hess->hage >= hess->resetfreq) {
         rmatrixcopy(n, n, &hess->hincoming, 0, 0, &hess->hcurrent, 0, 0);
         gamma = hess->sumy2 / (hess->sumsy + hess->reg * hess->sumy2 + hess->smallreg * hess->sums2);
         rsetm(n, n, 0.0, &hess->hincoming);
         for (i = 0; i < n; i++) {
            hess->hincoming.xyR[i][i] = gamma;
         }
         hess->sumsy = sqr(machineepsilon);
         hess->sumy2 = hess->sumsy * hess->gammasml;
         hess->sums2 = 0.0;
         hess->hage = 0;
         hess->updatestatus = 3;
      }
      return;
   }
   if (hess->htype == 3) {
   // Decide whether update is good enough to be remembered
      if (hess->m == 0) {
      // Zero memory was specified, update ignored
         return;
      }
      if (rmaxabsv(n, &hess->sk) <= hess->stpshort) {
      // Sk is too small, skip update
         return;
      }
      if (rdotv2(n, &hess->yk) == 0.0) {
      // The function is linear in the step direction, no update applied
         return;
      }
      if (rdotv(n, &hess->sk, &hess->yk) <= 0.0) {
      // The function is nonconvex in the step direction, no update applied
         return;
      }
   // Apply regularization:
   // * first,  add REG*Sk to Yk in order to make model at least slightly convex (Sigma is at least REG
   // * second, add REG*Yk to Xk in order to limit model curvature (Sigma is at most 1/REG)
   //
   // Whilst specific order of these operations is not very important, we prefer to Yk+ == REG*Sk be first
   // due to Sk being better guarded away from zero.
      raddv(n, hess->reg, &hess->sk, &hess->yk);
      raddv(n, hess->reg, &hess->yk, &hess->sk);
   // Update low rank Hessian data
      ae_assert(hess->memlen <= hess->m, "HessianUpdate: integrity check 5763 failed");
      if (hess->memlen == hess->m) {
      // Memory is full, shift data
         for (i = 0; i < hess->memlen - 1; i++) {
            rcopyrr(n, &hess->s, i + 1, &hess->s, i);
            rcopyrr(n, &hess->y, i + 1, &hess->y, i);
         }
         for (i = 0; i < hess->memlen - 1; i++) {
            for (j = 0; j < hess->memlen - 1; j++) {
               hess->lowranksst.xyR[i][j] = hess->lowranksst.xyR[i + 1][j + 1];
               hess->lowranksyt.xyR[i][j] = hess->lowranksyt.xyR[i + 1][j + 1];
            }
         }
      } else {
      // There is a place in a buffer, just append data
         hess->memlen++;
      }
   // Append to S and Y
      rcopyvr(n, &hess->sk, &hess->s, hess->memlen - 1);
      rcopyvr(n, &hess->yk, &hess->y, hess->memlen - 1);
   // Append row/col to LowRankSST and LowRankSYT
      allocv(hess->memlen, &hess->buf);
      rgemv(hess->memlen, n, 1.0, &hess->s, 0, &hess->sk, 0.0, &hess->buf);
      rcopyvr(hess->memlen, &hess->buf, &hess->lowranksst, hess->memlen - 1);
      rcopyvc(hess->memlen, &hess->buf, &hess->lowranksst, hess->memlen - 1);
      rgemv(hess->memlen, n, 1.0, &hess->y, 0, &hess->sk, 0.0, &hess->buf);
      rcopyvr(hess->memlen, &hess->buf, &hess->lowranksyt, hess->memlen - 1);
      rgemv(hess->memlen, n, 1.0, &hess->s, 0, &hess->yk, 0.0, &hess->buf);
      rcopyvc(hess->memlen, &hess->buf, &hess->lowranksyt, hess->memlen - 1);
   // Recompute scaling
      hess->sigma = rdotv2(n, &hess->yk) / rdotv(n, &hess->sk, &hess->yk);
      hess->sigma = rmin2(hess->sigma, 1.0 / (hess->reg + machineepsilon));
      hess->gamma = 1.0 / hess->sigma;
   // Invalidate model
      optserv_resetlowrankmodel(hess);
   }
}

// Get diagonal of the Hessian.
//
// This function works only with the following Hessian modes:
// * direct BFGS
// * low-rank LBFGS
//
// Any attempt to call it for other Hessian type will result in exception.
//
// Inputs:
//     Hess            -   Hessian state
//     D               -   possibly preallocated array; resized if needed
//
// Outputs:
//     D               -   first N elements are filled with Hessian diagonal
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
void hessiangetdiagonal(xbfgshessian *hess, RVector *d) {
   ae_int_t i;
   ae_int_t n;
   ae_assert(hess->htype == 0 || hess->htype == 3, "HessianGetDiagonal: Hessian mode is not supported");
   n = hess->n;
   allocv(n, d);
   if (hess->htype == 0) {
   // Explicit dense Hessian
      for (i = 0; i < n; i++) {
         d->xR[i] = hess->hcurrent.xyR[i][i];
      }
   }
   if (hess->htype == 3) {
   // Low-rank model
      optserv_recomputelowrankmodel(hess);
      optserv_recomputelowrankdiagonal(hess);
      rcopyv(n, &hess->lowrankeffd, d);
   }
}

// Get Hessian matrix in a dense format.
//
// This function works only with the following Hessian modes:
// * direct BFGS
// * low-rank LBFGS (needs k*N*N operations)
//
// Any attempt to call it for other Hessian type will result in exception.
//
// Inputs:
//     Hess            -   Hessian state
//     IsUpper         -   whether upper or lower triangle is needed
//     H               -   possibly preallocated array; resized if needed
//
// Outputs:
//     H               -   either upper or lower NxN elements are filled
//                         with Hessian
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
void hessiangetmatrix(xbfgshessian *hess, bool isupper, RMatrix *h) {
   ae_int_t i;
   ae_int_t n;
   ae_assert(hess->htype == 0 || hess->htype == 3, "HessianGetHessian: Hessian mode is not supported");
   n = hess->n;
   allocm(n, n, h);
   if (hess->htype == 0) {
   // Dense direct Hessian
      rcopym(n, n, &hess->hcurrent, h);
   }
   if (hess->htype == 3) {
   // Low-rank model
      optserv_recomputelowrankmodel(hess);
      rsetm(n, n, 0.0, h);
      for (i = 0; i < n; i++) {
         h->xyR[i][i] = hess->sigma;
      }
      rmatrixgemm(n, n, hess->lowrankk, 1.0, &hess->lowrankcp, 0, 0, 1, &hess->lowrankcp, 0, 0, 0, 1.0, h, 0, 0);
      rmatrixgemm(n, n, hess->lowrankk, -1.0, &hess->lowrankcm, 0, 0, 1, &hess->lowrankcm, 0, 0, 0, 1.0, h, 0, 0);
   }
}

// Computes direct product H*x (here H is a Hessian matrix, not its inverse).
// Either BFGS or LBFGS formula is used, depending on Hessian model settings.
//
// NOTE: this function modifies internal state of Hess,  it  uses  temporary
//       arrays allocated in Hess. Thus, it is not thread-safe.
//
// Inputs:
//     Hess            -   Hessian state
//     X               -   array[N]
//
// Outputs:
//     HX              -   array[N], H*x
// ALGLIB: Copyright 28.11.2022 by Sergey Bochkanov
void hessianmv(xbfgshessian *hess, RVector *x, RVector *hx) {
   ae_int_t n;
   ae_assert(hess->htype == 0 || hess->htype == 3, "HessianGetHessian: Hessian mode is not supported");
   n = hess->n;
   allocv(n, hx);
   if (hess->htype == 0) {
   // Dense direct Hessian
      rgemv(n, n, 1.0, &hess->hcurrent, 0, x, 0.0, hx);
   }
   if (hess->htype == 3) {
   // Low-rank model
      optserv_recomputelowrankmodel(hess);
      rcopymulv(n, hess->sigma, x, hx);
      if (hess->lowrankk > 0) {
         allocv(hess->lowrankk, &hess->buf);
         rgemv(hess->lowrankk, n, 1.0, &hess->lowrankcp, 0, x, 0.0, &hess->buf);
         rgemv(n, hess->lowrankk, 1.0, &hess->lowrankcp, 1, &hess->buf, 1.0, hx);
         rgemv(hess->lowrankk, n, 1.0, &hess->lowrankcm, 0, x, 0.0, &hess->buf);
         rgemv(n, hess->lowrankk, -1.0, &hess->lowrankcm, 1, &hess->buf, 1.0, hx);
      }
   }
}

void precbuflbfgs_init(void *_p, bool make_automatic) {
   precbuflbfgs *p = (precbuflbfgs *)_p;
   ae_vector_init(&p->norms, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->alpha, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rho, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->yk, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->idx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->bufa, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufb, 0, DT_INT, make_automatic);
}

void precbuflbfgs_copy(void *_dst, const void *_src, bool make_automatic) {
   precbuflbfgs *dst = (precbuflbfgs *)_dst;
   const precbuflbfgs *src = (const precbuflbfgs *)_src;
   ae_vector_copy(&dst->norms, &src->norms, make_automatic);
   ae_vector_copy(&dst->alpha, &src->alpha, make_automatic);
   ae_vector_copy(&dst->rho, &src->rho, make_automatic);
   ae_matrix_copy(&dst->yk, &src->yk, make_automatic);
   ae_vector_copy(&dst->idx, &src->idx, make_automatic);
   ae_vector_copy(&dst->bufa, &src->bufa, make_automatic);
   ae_vector_copy(&dst->bufb, &src->bufb, make_automatic);
}

void precbuflbfgs_free(void *_p, bool make_automatic) {
   precbuflbfgs *p = (precbuflbfgs *)_p;
   ae_vector_free(&p->norms, make_automatic);
   ae_vector_free(&p->alpha, make_automatic);
   ae_vector_free(&p->rho, make_automatic);
   ae_matrix_free(&p->yk, make_automatic);
   ae_vector_free(&p->idx, make_automatic);
   ae_vector_free(&p->bufa, make_automatic);
   ae_vector_free(&p->bufb, make_automatic);
}

void precbuflowrank_init(void *_p, bool make_automatic) {
   precbuflowrank *p = (precbuflowrank *)_p;
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->v, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufc, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->bufz, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->bufw, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp, 0, DT_REAL, make_automatic);
}

void precbuflowrank_copy(void *_dst, const void *_src, bool make_automatic) {
   precbuflowrank *dst = (precbuflowrank *)_dst;
   const precbuflowrank *src = (const precbuflowrank *)_src;
   dst->n = src->n;
   dst->k = src->k;
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_matrix_copy(&dst->v, &src->v, make_automatic);
   ae_vector_copy(&dst->bufc, &src->bufc, make_automatic);
   ae_matrix_copy(&dst->bufz, &src->bufz, make_automatic);
   ae_matrix_copy(&dst->bufw, &src->bufw, make_automatic);
   ae_vector_copy(&dst->tmp, &src->tmp, make_automatic);
}

void precbuflowrank_free(void *_p, bool make_automatic) {
   precbuflowrank *p = (precbuflowrank *)_p;
   ae_vector_free(&p->d, make_automatic);
   ae_matrix_free(&p->v, make_automatic);
   ae_vector_free(&p->bufc, make_automatic);
   ae_matrix_free(&p->bufz, make_automatic);
   ae_matrix_free(&p->bufw, make_automatic);
   ae_vector_free(&p->tmp, make_automatic);
}

void xbfgshessian_init(void *_p, bool make_automatic) {
   xbfgshessian *p = (xbfgshessian *)_p;
   ae_matrix_init(&p->hcurrent, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->s, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->y, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lowrankcp, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lowrankcm, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lowrankeffd, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lowranksst, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lowranksyt, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->hincoming, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->yk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hsk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->buf, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->corr2, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->blk, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->jk, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->invsqrtdlk, 0, 0, DT_REAL, make_automatic);
}

void xbfgshessian_copy(void *_dst, const void *_src, bool make_automatic) {
   xbfgshessian *dst = (xbfgshessian *)_dst;
   const xbfgshessian *src = (const xbfgshessian *)_src;
   dst->htype = src->htype;
   dst->n = src->n;
   dst->resetfreq = src->resetfreq;
   dst->stpshort = src->stpshort;
   dst->gammasml = src->gammasml;
   dst->reg = src->reg;
   dst->smallreg = src->smallreg;
   dst->microreg = src->microreg;
   dst->m = src->m;
   ae_matrix_copy(&dst->hcurrent, &src->hcurrent, make_automatic);
   dst->hage = src->hage;
   dst->sumy2 = src->sumy2;
   dst->sums2 = src->sums2;
   dst->sumsy = src->sumsy;
   dst->memlen = src->memlen;
   dst->sigma = src->sigma;
   dst->gamma = src->gamma;
   ae_matrix_copy(&dst->s, &src->s, make_automatic);
   ae_matrix_copy(&dst->y, &src->y, make_automatic);
   dst->lowrankmodelvalid = src->lowrankmodelvalid;
   dst->lowrankk = src->lowrankk;
   ae_matrix_copy(&dst->lowrankcp, &src->lowrankcp, make_automatic);
   ae_matrix_copy(&dst->lowrankcm, &src->lowrankcm, make_automatic);
   dst->lowrankeffdvalid = src->lowrankeffdvalid;
   ae_vector_copy(&dst->lowrankeffd, &src->lowrankeffd, make_automatic);
   ae_matrix_copy(&dst->lowranksst, &src->lowranksst, make_automatic);
   ae_matrix_copy(&dst->lowranksyt, &src->lowranksyt, make_automatic);
   dst->updatestatus = src->updatestatus;
   ae_matrix_copy(&dst->hincoming, &src->hincoming, make_automatic);
   ae_vector_copy(&dst->sk, &src->sk, make_automatic);
   ae_vector_copy(&dst->yk, &src->yk, make_automatic);
   ae_vector_copy(&dst->hsk, &src->hsk, make_automatic);
   ae_vector_copy(&dst->buf, &src->buf, make_automatic);
   ae_matrix_copy(&dst->corr2, &src->corr2, make_automatic);
   ae_matrix_copy(&dst->blk, &src->blk, make_automatic);
   ae_matrix_copy(&dst->jk, &src->jk, make_automatic);
   ae_matrix_copy(&dst->invsqrtdlk, &src->invsqrtdlk, make_automatic);
}

void xbfgshessian_free(void *_p, bool make_automatic) {
   xbfgshessian *p = (xbfgshessian *)_p;
   ae_matrix_free(&p->hcurrent, make_automatic);
   ae_matrix_free(&p->s, make_automatic);
   ae_matrix_free(&p->y, make_automatic);
   ae_matrix_free(&p->lowrankcp, make_automatic);
   ae_matrix_free(&p->lowrankcm, make_automatic);
   ae_vector_free(&p->lowrankeffd, make_automatic);
   ae_matrix_free(&p->lowranksst, make_automatic);
   ae_matrix_free(&p->lowranksyt, make_automatic);
   ae_matrix_free(&p->hincoming, make_automatic);
   ae_vector_free(&p->sk, make_automatic);
   ae_vector_free(&p->yk, make_automatic);
   ae_vector_free(&p->hsk, make_automatic);
   ae_vector_free(&p->buf, make_automatic);
   ae_matrix_free(&p->corr2, make_automatic);
   ae_matrix_free(&p->blk, make_automatic);
   ae_matrix_free(&p->jk, make_automatic);
   ae_matrix_free(&p->invsqrtdlk, make_automatic);
}

void smoothnessmonitor_init(void *_p, bool make_automatic) {
   smoothnessmonitor *p = (smoothnessmonitor *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dcur, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->enqueuedstp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->enqueuedx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->enqueuedfunc, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->enqueuedjac, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sortedstp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sortedidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->lagprobxs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagprobd, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagprobx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagprobfi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lagprobj, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lagprobvalues, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->lagprobjacobians, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagprobsteps, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagproblagrangians, 0, DT_REAL, make_automatic);
   optguardreport_init(&p->rep, make_automatic);
   optguardnonc0report_init(&p->nonc0strrep, make_automatic);
   optguardnonc0report_init(&p->nonc0lngrep, make_automatic);
   optguardnonc1test0report_init(&p->nonc1test0strrep, make_automatic);
   optguardnonc1test0report_init(&p->nonc1test0lngrep, make_automatic);
   optguardnonc1test1report_init(&p->nonc1test1strrep, make_automatic);
   optguardnonc1test1report_init(&p->nonc1test1lngrep, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fm, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->jm, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->jc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->jp, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->jbaseusr, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->jbasenum, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufr, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->f, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->deltax, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->bufi, 0, DT_INT, make_automatic);
   ae_vector_init(&p->xu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->du, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->f0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j0, 0, 0, DT_REAL, make_automatic);
}

void smoothnessmonitor_copy(void *_dst, const void *_src, bool make_automatic) {
   smoothnessmonitor *dst = (smoothnessmonitor *)_dst;
   const smoothnessmonitor *src = (const smoothnessmonitor *)_src;
   dst->n = src->n;
   dst->k = src->k;
   dst->checksmoothness = src->checksmoothness;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->dcur, &src->dcur, make_automatic);
   dst->enqueuedcnt = src->enqueuedcnt;
   ae_vector_copy(&dst->enqueuedstp, &src->enqueuedstp, make_automatic);
   ae_vector_copy(&dst->enqueuedx, &src->enqueuedx, make_automatic);
   ae_vector_copy(&dst->enqueuedfunc, &src->enqueuedfunc, make_automatic);
   ae_matrix_copy(&dst->enqueuedjac, &src->enqueuedjac, make_automatic);
   ae_vector_copy(&dst->sortedstp, &src->sortedstp, make_automatic);
   ae_vector_copy(&dst->sortedidx, &src->sortedidx, make_automatic);
   dst->sortedcnt = src->sortedcnt;
   dst->lagprobinneriter = src->lagprobinneriter;
   dst->lagprobouteriter = src->lagprobouteriter;
   dst->lagprobstepmax = src->lagprobstepmax;
   dst->lagprobnstepsstored = src->lagprobnstepsstored;
   ae_vector_copy(&dst->lagprobxs, &src->lagprobxs, make_automatic);
   ae_vector_copy(&dst->lagprobd, &src->lagprobd, make_automatic);
   dst->lagprobstp = src->lagprobstp;
   ae_vector_copy(&dst->lagprobx, &src->lagprobx, make_automatic);
   ae_vector_copy(&dst->lagprobfi, &src->lagprobfi, make_automatic);
   dst->lagprobrawlag = src->lagprobrawlag;
   ae_matrix_copy(&dst->lagprobj, &src->lagprobj, make_automatic);
   ae_matrix_copy(&dst->lagprobvalues, &src->lagprobvalues, make_automatic);
   ae_matrix_copy(&dst->lagprobjacobians, &src->lagprobjacobians, make_automatic);
   ae_vector_copy(&dst->lagprobsteps, &src->lagprobsteps, make_automatic);
   ae_vector_copy(&dst->lagproblagrangians, &src->lagproblagrangians, make_automatic);
   dst->ProbePQ = src->ProbePQ;
   dst->linesearchspoiled = src->linesearchspoiled;
   dst->linesearchstarted = src->linesearchstarted;
   dst->linesearchinneridx = src->linesearchinneridx;
   dst->linesearchouteridx = src->linesearchouteridx;
   dst->nonc0currentrating = src->nonc0currentrating;
   dst->nonc1currentrating = src->nonc1currentrating;
   dst->badgradhasxj = src->badgradhasxj;
   optguardreport_copy(&dst->rep, &src->rep, make_automatic);
   dst->nonc0strrating = src->nonc0strrating;
   dst->nonc0lngrating = src->nonc0lngrating;
   optguardnonc0report_copy(&dst->nonc0strrep, &src->nonc0strrep, make_automatic);
   optguardnonc0report_copy(&dst->nonc0lngrep, &src->nonc0lngrep, make_automatic);
   dst->nonc1test0strrating = src->nonc1test0strrating;
   dst->nonc1test0lngrating = src->nonc1test0lngrating;
   optguardnonc1test0report_copy(&dst->nonc1test0strrep, &src->nonc1test0strrep, make_automatic);
   optguardnonc1test0report_copy(&dst->nonc1test0lngrep, &src->nonc1test0lngrep, make_automatic);
   dst->nonc1test1strrating = src->nonc1test1strrating;
   dst->nonc1test1lngrating = src->nonc1test1lngrating;
   optguardnonc1test1report_copy(&dst->nonc1test1strrep, &src->nonc1test1strrep, make_automatic);
   optguardnonc1test1report_copy(&dst->nonc1test1lngrep, &src->nonc1test1lngrep, make_automatic);
   dst->needfij = src->needfij;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   ae_matrix_copy(&dst->j, &src->j, make_automatic);
   dst->PQ = src->PQ;
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   ae_vector_copy(&dst->fbase, &src->fbase, make_automatic);
   ae_vector_copy(&dst->fm, &src->fm, make_automatic);
   ae_vector_copy(&dst->fc, &src->fc, make_automatic);
   ae_vector_copy(&dst->fp, &src->fp, make_automatic);
   ae_vector_copy(&dst->jm, &src->jm, make_automatic);
   ae_vector_copy(&dst->jc, &src->jc, make_automatic);
   ae_vector_copy(&dst->jp, &src->jp, make_automatic);
   ae_matrix_copy(&dst->jbaseusr, &src->jbaseusr, make_automatic);
   ae_matrix_copy(&dst->jbasenum, &src->jbasenum, make_automatic);
   ae_vector_copy(&dst->stp, &src->stp, make_automatic);
   ae_vector_copy(&dst->bufr, &src->bufr, make_automatic);
   ae_vector_copy(&dst->f, &src->f, make_automatic);
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   ae_vector_copy(&dst->deltax, &src->deltax, make_automatic);
   ae_vector_copy(&dst->tmpidx, &src->tmpidx, make_automatic);
   ae_vector_copy(&dst->bufi, &src->bufi, make_automatic);
   ae_vector_copy(&dst->xu, &src->xu, make_automatic);
   ae_vector_copy(&dst->du, &src->du, make_automatic);
   ae_vector_copy(&dst->f0, &src->f0, make_automatic);
   ae_matrix_copy(&dst->j0, &src->j0, make_automatic);
}

void smoothnessmonitor_free(void *_p, bool make_automatic) {
   smoothnessmonitor *p = (smoothnessmonitor *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->dcur, make_automatic);
   ae_vector_free(&p->enqueuedstp, make_automatic);
   ae_vector_free(&p->enqueuedx, make_automatic);
   ae_vector_free(&p->enqueuedfunc, make_automatic);
   ae_matrix_free(&p->enqueuedjac, make_automatic);
   ae_vector_free(&p->sortedstp, make_automatic);
   ae_vector_free(&p->sortedidx, make_automatic);
   ae_vector_free(&p->lagprobxs, make_automatic);
   ae_vector_free(&p->lagprobd, make_automatic);
   ae_vector_free(&p->lagprobx, make_automatic);
   ae_vector_free(&p->lagprobfi, make_automatic);
   ae_matrix_free(&p->lagprobj, make_automatic);
   ae_matrix_free(&p->lagprobvalues, make_automatic);
   ae_matrix_free(&p->lagprobjacobians, make_automatic);
   ae_vector_free(&p->lagprobsteps, make_automatic);
   ae_vector_free(&p->lagproblagrangians, make_automatic);
   optguardreport_free(&p->rep, make_automatic);
   optguardnonc0report_free(&p->nonc0strrep, make_automatic);
   optguardnonc0report_free(&p->nonc0lngrep, make_automatic);
   optguardnonc1test0report_free(&p->nonc1test0strrep, make_automatic);
   optguardnonc1test0report_free(&p->nonc1test0lngrep, make_automatic);
   optguardnonc1test1report_free(&p->nonc1test1strrep, make_automatic);
   optguardnonc1test1report_free(&p->nonc1test1lngrep, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_matrix_free(&p->j, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_vector_free(&p->fbase, make_automatic);
   ae_vector_free(&p->fm, make_automatic);
   ae_vector_free(&p->fc, make_automatic);
   ae_vector_free(&p->fp, make_automatic);
   ae_vector_free(&p->jm, make_automatic);
   ae_vector_free(&p->jc, make_automatic);
   ae_vector_free(&p->jp, make_automatic);
   ae_matrix_free(&p->jbaseusr, make_automatic);
   ae_matrix_free(&p->jbasenum, make_automatic);
   ae_vector_free(&p->stp, make_automatic);
   ae_vector_free(&p->bufr, make_automatic);
   ae_vector_free(&p->f, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   ae_vector_free(&p->deltax, make_automatic);
   ae_vector_free(&p->tmpidx, make_automatic);
   ae_vector_free(&p->bufi, make_automatic);
   ae_vector_free(&p->xu, make_automatic);
   ae_vector_free(&p->du, make_automatic);
   ae_vector_free(&p->f0, make_automatic);
   ae_matrix_free(&p->j0, make_automatic);
}
} // end of namespace alglib_impl

// === MINLBFGS Package ===
// Depends on: (AlgLibInternal) LINMIN
// Depends on: (LinAlg) FBLS
// Depends on: OPTSERV
namespace alglib_impl {
// This function sets stopping conditions for L-BFGS optimization algorithm.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsG    -   >= 0
//                 The  subroutine  finishes  its  work   if   the  condition
//                 |v| < EpsG is satisfied, where:
//                 * |.| means Euclidian norm
//                 * v - scaled gradient vector, v[i] == g[i]*s[i]
//                 * g - gradient
//                 * s - scaling coefficients set by MinLBFGSSetScale()
//     EpsF    -   >= 0
//                 The  subroutine  finishes  its work if on k+1-th iteration
//                 the  condition  |F(k+1)-F(k)| <= EpsF*max{|F(k)|,|F(k+1)|,1}
//                 is satisfied.
//     EpsX    -   >= 0
//                 The subroutine finishes its work if  on  k+1-th  iteration
//                 the condition |v| <= EpsX is fulfilled, where:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - ste pvector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinLBFGSSetScale()
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited.
//
// Passing EpsG == 0, EpsF == 0, EpsX == 0 and MaxIts == 0 (simultaneously) will lead to
// automatic stopping criterion selection (small EpsX).
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlbfgssetcond(const minlbfgsstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits);
void minlbfgssetcond(minlbfgsstate *state, double epsg, double epsf, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsg), "MinLBFGSSetCond: EpsG is not finite number!");
   ae_assert(epsg >= 0.0, "MinLBFGSSetCond: negative EpsG!");
   ae_assert(isfinite(epsf), "MinLBFGSSetCond: EpsF is not finite number!");
   ae_assert(epsf >= 0.0, "MinLBFGSSetCond: negative EpsF!");
   ae_assert(isfinite(epsx), "MinLBFGSSetCond: EpsX is not finite number!");
   ae_assert(epsx >= 0.0, "MinLBFGSSetCond: negative EpsX!");
   ae_assert(maxits >= 0, "MinLBFGSSetCond: negative MaxIts!");
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->epsg = epsg;
   state->epsf = epsf;
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to MinLBFGSOptimize().
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlbfgssetxrep(const minlbfgsstate &state, const bool needxrep);
void minlbfgssetxrep(minlbfgsstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This function sets maximum step length
//
// Inputs:
//     State   -   structure which stores algorithm state
//     StpMax  -   maximum step length, >= 0. Set StpMax to 0.0 (default),  if
//                 you don't want to limit step length.
//
// Use this subroutine when you optimize target function which contains exp()
// or  other  fast  growing  functions,  and optimization algorithm makes too
// large  steps  which  leads  to overflow. This function allows us to reject
// steps  that  are  too  large  (and  therefore  expose  us  to the possible
// overflow) without actually calculating function value at the x+stp*d.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlbfgssetstpmax(const minlbfgsstate &state, const double stpmax);
void minlbfgssetstpmax(minlbfgsstate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinLBFGSSetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinLBFGSSetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// This function sets scaling coefficients for LBFGS optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Scaling is also used by finite difference variant of the optimizer  - step
// along I-th axis is equal to DiffStep*S[I].
//
// In  most  optimizers  (and  in  the  LBFGS  too)  scaling is NOT a form of
// preconditioning. It just  affects  stopping  conditions.  You  should  set
// preconditioner  by  separate  call  to  one  of  the  MinLBFGSSetPrec...()
// functions.
//
// There  is  special  preconditioning  mode, however,  which  uses   scaling
// coefficients to form diagonal preconditioning matrix. You  can  turn  this
// mode on, if you want.   But  you should understand that scaling is not the
// same thing as preconditioning - these are two different, although  related
// forms of tuning solver.
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minlbfgssetscale(const minlbfgsstate &state, const real_1d_array &s);
void minlbfgssetscale(minlbfgsstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinLBFGSSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinLBFGSSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinLBFGSSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// This  subroutine restarts LBFGS algorithm from new point. All optimization
// parameters are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure used to store algorithm state
//     X       -   new starting point.
// ALGLIB: Copyright 30.07.2010 by Sergey Bochkanov
// API: void minlbfgsrestartfrom(const minlbfgsstate &state, const real_1d_array &x);
void minlbfgsrestartfrom(minlbfgsstate *state, RVector *x) {
   ae_assert(x->cnt >= state->n, "MinLBFGSRestartFrom: Length(X) < N!");
   ae_assert(isfinitevector(x, state->n), "MinLBFGSRestartFrom: X contains infinite or NaN values!");
   ae_v_move(state->xbase.xR, 1, x->xR, 1, state->n);
   state->PQ = -1;
}

// Extended subroutine for internal use only.
//
// Accepts additional parameters:
//
//     Flags - additional settings:
//             * Flags = 0     means no additional settings
//             * Flags = 1     "do not allocate memory". used when solving
//                             a many subsequent tasks with  same N/M  values.
//                             First  call MUST  be without this flag bit set,
//                             subsequent  calls   of   MinLBFGS   with   same
//                             MinLBFGSState structure can set Flags to 1.
//     DiffStep - numerical differentiation step
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
void minlbfgscreatex(ae_int_t n, ae_int_t m, RVector *x, ae_int_t flags, double diffstep, minlbfgsstate *state) {
   bool allocatemem;
   ae_int_t i;
   ae_assert(n >= 1, "MinLBFGS: N too small!");
   ae_assert(m >= 1, "MinLBFGS: M too small!");
   ae_assert(m <= n, "MinLBFGS: M too large!");
// Initialize
   state->teststep = 0.0;
   state->smoothnessguardlevel = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, 0, 0, false);
   state->diffstep = diffstep;
   state->n = n;
   state->m = m;
   allocatemem = flags % 2 == 0;
   flags /= 2;
   if (allocatemem) {
      vectorsetlengthatleast(&state->rho, m);
      vectorsetlengthatleast(&state->theta, m);
      matrixsetlengthatleast(&state->yk, m, n);
      matrixsetlengthatleast(&state->sk, m, n);
      vectorsetlengthatleast(&state->d, n);
      vectorsetlengthatleast(&state->xp, n);
      vectorsetlengthatleast(&state->x, n);
      vectorsetlengthatleast(&state->xbase, n);
      vectorsetlengthatleast(&state->s, n);
      vectorsetlengthatleast(&state->invs, n);
      vectorsetlengthatleast(&state->lastscaleused, n);
      vectorsetlengthatleast(&state->g, n);
      vectorsetlengthatleast(&state->work, n);
   }
   for (i = 0; i < n; i++) {
      state->s.xR[i] = 1.0;
      state->invs.xR[i] = 1.0;
      state->lastscaleused.xR[i] = 1.0;
   }
   state->prectype = 0;
   minlbfgssetcond(state, 0.0, 0.0, 0.0, 0);
   minlbfgssetxrep(state, false);
   minlbfgssetstpmax(state, 0.0);
   minlbfgsrestartfrom(state, x);
}

// LIMITED MEMORY BFGS METHOD FOR LARGE SCALE OPTIMIZATION
// The subroutine minimizes function F(x) of N arguments by  using  a  quasi-
// Newton method (LBFGS scheme) which is optimized to use  a  minimum  amount
// of memory.
// The subroutine generates the approximation of an inverse Hessian matrix by
// using information about the last M steps of the algorithm  (instead of N).
// It lessens a required amount of memory from a value  of  order  N^2  to  a
// value of order 2*N*M.
//
// REQUIREMENTS:
// Algorithm will request following information during its operation:
// * function value F and its gradient G (simultaneously) at given point X
//
// USAGE:
// 1. User initializes algorithm state with MinLBFGSCreate() call
// 2. User tunes solver parameters with MinLBFGSSetCond() MinLBFGSSetStpMax()
//    and other functions
// 3. User calls MinLBFGSOptimize() function which takes algorithm  state and
//    pointer (delegate, etc.) to callback function which calculates F/G.
// 4. User calls MinLBFGSResults() to get solution
// 5. Optionally user may call MinLBFGSRestartFrom() to solve another problem
//    with same N/M but another starting point and/or another function.
//    MinLBFGSRestartFrom() allows to reuse already initialized structure.
//
// Inputs:
//     N       -   problem dimension. N > 0
//     M       -   number of corrections in the BFGS scheme of Hessian
//                 approximation update. Recommended value:  3 <= M <= 7. The smaller
//                 value causes worse convergence, the bigger will  not  cause  a
//                 considerably better convergence, but will cause a fall in  the
//                 performance. M <= N.
//     X       -   initial solution approximation, array[0..N-1].
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. you may tune stopping conditions with MinLBFGSSetCond() function
// 2. if target function contains exp() or other fast growing functions,  and
//    optimization algorithm makes too large steps which leads  to  overflow,
//    use MinLBFGSSetStpMax() function to bound algorithm's  steps.  However,
//    L-BFGS rarely needs such a tuning.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlbfgscreate(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlbfgsstate &state);
// API: void minlbfgscreate(const ae_int_t m, const real_1d_array &x, minlbfgsstate &state);
void minlbfgscreate(ae_int_t n, ae_int_t m, RVector *x, minlbfgsstate *state) {
   SetObj(minlbfgsstate, state);
   ae_assert(n >= 1, "MinLBFGSCreate: N < 1!");
   ae_assert(m >= 1, "MinLBFGSCreate: M < 1");
   ae_assert(m <= n, "MinLBFGSCreate: M > N");
   ae_assert(x->cnt >= n, "MinLBFGSCreate: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinLBFGSCreate: X contains infinite or NaN values!");
   minlbfgscreatex(n, m, x, 0, 0.0, state);
}

// The subroutine is finite difference variant of MinLBFGSCreate().  It  uses
// finite differences in order to differentiate target function.
//
// Description below contains information which is specific to  this function
// only. We recommend to read comments on MinLBFGSCreate() in  order  to  get
// more information about creation of LBFGS optimizer.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     M       -   number of corrections in the BFGS scheme of Hessian
//                 approximation update. Recommended value:  3 <= M <= 7. The smaller
//                 value causes worse convergence, the bigger will  not  cause  a
//                 considerably better convergence, but will cause a fall in  the
//                 performance. M <= N.
//     X       -   starting point, array[0..N-1].
//     DiffStep-   differentiation step, > 0
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. algorithm uses 4-point central formula for differentiation.
// 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
//    S[] is scaling vector which can be set by MinLBFGSSetScale() call.
// 3. we recommend you to use moderate values of  differentiation  step.  Too
//    large step will result in too large truncation  errors, while too small
//    step will result in too large numerical  errors.  0.000001  can be good
//    value to start with.
// 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
//    calculation needs 4*N function evaluations. This function will work for
//    any N - either small (1...10), moderate (10...100) or  large  (100...).
//    However, performance penalty will be too severe for any N's except  for
//    small ones.
//    We should also say that code which relies on numerical  differentiation
//    is   less  robust  and  precise.  LBFGS  needs  exact  gradient values.
//    Imprecise gradient may slow  down  convergence,  especially  on  highly
//    nonlinear problems.
//    Thus  we  recommend to use this function for fast prototyping on small-
//    dimensional problems only, and to implement analytical gradient as soon
//    as possible.
// ALGLIB: Copyright 16.05.2011 by Sergey Bochkanov
// API: void minlbfgscreatef(const ae_int_t n, const ae_int_t m, const real_1d_array &x, const double diffstep, minlbfgsstate &state);
// API: void minlbfgscreatef(const ae_int_t m, const real_1d_array &x, const double diffstep, minlbfgsstate &state);
void minlbfgscreatef(ae_int_t n, ae_int_t m, RVector *x, double diffstep, minlbfgsstate *state) {
   SetObj(minlbfgsstate, state);
   ae_assert(n >= 1, "MinLBFGSCreateF: N too small!");
   ae_assert(m >= 1, "MinLBFGSCreateF: M < 1");
   ae_assert(m <= n, "MinLBFGSCreateF: M > N");
   ae_assert(x->cnt >= n, "MinLBFGSCreateF: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinLBFGSCreateF: X contains infinite or NaN values!");
   ae_assert(isfinite(diffstep), "MinLBFGSCreateF: DiffStep is infinite or NaN!");
   ae_assert(diffstep > 0.0, "MinLBFGSCreateF: DiffStep is non-positive!");
   minlbfgscreatex(n, m, x, 0, diffstep, state);
}

// Modification  of  the  preconditioner:  default  preconditioner    (simple
// scaling, same for all elements of X) is used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//
// NOTE:  you  can  change  preconditioner  "on  the  fly",  during algorithm
// iterations.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minlbfgssetprecdefault(const minlbfgsstate &state);
void minlbfgssetprecdefault(minlbfgsstate *state) {
   state->prectype = 0;
}

// Modification of the preconditioner: Cholesky factorization of  approximate
// Hessian is used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     P       -   triangular preconditioner, Cholesky factorization of
//                 the approximate Hessian. array[0..N-1,0..N-1],
//                 (if larger, only leading N elements are used).
//     IsUpper -   whether upper or lower triangle of P is given
//                 (other triangle is not referenced)
//
// After call to this function preconditioner is changed to P  (P  is  copied
// into the internal buffer).
//
// NOTE:  you  can  change  preconditioner  "on  the  fly",  during algorithm
// iterations.
//
// NOTE 2:  P  should  be nonsingular. Exception will be thrown otherwise.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minlbfgssetpreccholesky(const minlbfgsstate &state, const real_2d_array &p, const bool isupper);
void minlbfgssetpreccholesky(minlbfgsstate *state, RMatrix *p, bool isupper) {
   ae_int_t i;
   double mx;
   ae_assert(isfinitertrmatrix(p, state->n, isupper), "MinLBFGSSetPrecCholesky: P contains infinite or NAN values!");
   mx = 0.0;
   for (i = 0; i < state->n; i++) {
      mx = rmax2(mx, fabs(p->xyR[i][i]));
   }
   ae_assert(mx > 0.0, "MinLBFGSSetPrecCholesky: P is strictly singular!");
   matrixsetlengthatleast(&state->denseh, state->n, state->n);
   state->prectype = 1;
   if (isupper) {
      rmatrixcopy(state->n, state->n, p, 0, 0, &state->denseh, 0, 0);
   } else {
      rmatrixtranspose(state->n, state->n, p, 0, 0, &state->denseh, 0, 0);
   }
}

// Modification  of  the  preconditioner:  diagonal of approximate Hessian is
// used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     D       -   diagonal of the approximate Hessian, array[0..N-1],
//                 (if larger, only leading N elements are used).
//
// NOTE:  you  can  change  preconditioner  "on  the  fly",  during algorithm
// iterations.
//
// NOTE 2: D[i] should be positive. Exception will be thrown otherwise.
//
// NOTE 3: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minlbfgssetprecdiag(const minlbfgsstate &state, const real_1d_array &d);
void minlbfgssetprecdiag(minlbfgsstate *state, RVector *d) {
   ae_int_t i;
   ae_assert(d->cnt >= state->n, "MinLBFGSSetPrecDiag: D is too short");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(d->xR[i]), "MinLBFGSSetPrecDiag: D contains infinite or NAN elements");
      ae_assert(d->xR[i] > 0.0, "MinLBFGSSetPrecDiag: D contains non-positive elements");
   }
   vectorsetlengthatleast(&state->diagh, state->n);
   state->prectype = 2;
   for (i = 0; i < state->n; i++) {
      state->diagh.xR[i] = d->xR[i];
   }
}

// Modification of the preconditioner: scale-based diagonal preconditioning.
//
// This preconditioning mode can be useful when you  don't  have  approximate
// diagonal of Hessian, but you know that your  variables  are  badly  scaled
// (for  example,  one  variable is in [1,10], and another in [1000,100000]),
// and most part of the ill-conditioning comes from different scales of vars.
//
// In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
// can greatly improve convergence.
//
// IMPRTANT: you should set scale of your variables  with  MinLBFGSSetScale()
// call  (before  or after MinLBFGSSetPrecScale() call). Without knowledge of
// the scale of your variables scale-based preconditioner will be  just  unit
// matrix.
//
// Inputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minlbfgssetprecscale(const minlbfgsstate &state);
void minlbfgssetprecscale(minlbfgsstate *state) {
   state->prectype = 3;
}

// This function sets low-rank preconditioner for Hessian matrix  H == D+W'*C*W,
// where:
// * H is a Hessian matrix, which is approximated by D/W/C
// * D is a NxN diagonal positive definite matrix
// * W is a KxN low-rank correction
// * C is a KxK positive definite diagonal factor of low-rank correction
//
// This preconditioner is inexact but fast - it requires O(N*K)  time  to  be
// applied. Preconditioner P is calculated by artificially constructing a set
// of BFGS updates which tries to reproduce behavior of H:
// * Sk = Wk (k-th row of W)
// * Yk = (D+Wk'*Ck*Wk)*Sk
// * Yk/Sk are reordered by ascending of C[k]*norm(Wk)^2
//
// Here we assume that rows of Wk are orthogonal or nearly orthogonal,  which
// allows us to have O(N*K+K^2) update instead of O(N*K^2) one. Reordering of
// updates is essential for having good performance on non-orthogonal problems
// (updates which do not add much of curvature are added first,  and  updates
// which add very large eigenvalues are added last and override effect of the
// first updates).
//
// In practice, this preconditioner is perfect when ortogonal  correction  is
// applied; on non-orthogonal problems sometimes  it  allows  to  achieve  5x
// speedup (when compared to non-preconditioned solver).
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
void minlbfgssetprecrankklbfgsfast(minlbfgsstate *state, RVector *d, RVector *c, RMatrix *w, ae_int_t cnt) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   n = state->n;
   state->prectype = 4;
   state->preck = cnt;
   vectorsetlengthatleast(&state->precc, cnt);
   vectorsetlengthatleast(&state->precd, n);
   matrixsetlengthatleast(&state->precw, cnt, n);
   for (i = 0; i < n; i++) {
      state->precd.xR[i] = d->xR[i];
   }
   for (i = 0; i < cnt; i++) {
      state->precc.xR[i] = c->xR[i];
      for (j = 0; j < n; j++) {
         state->precw.xyR[i][j] = w->xyR[i][j];
      }
   }
}

// This function  sets  exact  low-rank  preconditioner  for  Hessian  matrix
// H == D+W'*C*W, where:
// * H is a Hessian matrix, which is approximated by D/W/C
// * D is a NxN diagonal positive definite matrix
// * W is a KxN low-rank correction
// * C is a KxK semidefinite diagonal factor of low-rank correction
//
// This preconditioner is exact but slow - it requires O(N*K^2)  time  to  be
// built and O(N*K) time to be applied. Woodbury matrix identity is  used  to
// build inverse matrix.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
void minlbfgssetpreclowrankexact(minlbfgsstate *state, RVector *d, RVector *c, RMatrix *w, ae_int_t cnt) {
   state->prectype = 5;
   preparelowrankpreconditioner(d, c, w, state->n, cnt, &state->lowrankbuf);
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions minlbfgsoptimize() listed below.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
// API: bool minlbfgsiteration(const minlbfgsstate &state);
// API: void minlbfgsoptimize(minlbfgsstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minlbfgsoptimize(minlbfgsstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minlbfgsiteration(minlbfgsstate *state) {
   const double gtol = 0.4;
   AutoS ae_int_t n;
   AutoS ae_int_t m;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t ic;
   AutoS ae_int_t mcinfo;
   AutoS double v;
   AutoS double vv;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14;
      default: goto Exit;
   }
Spawn:
// Unload frequently used variables from State structure
// (just for typing convenience)
   n = state->n;
   m = state->m;
// Init
   state->xupdated = state->needfg = state->needf = false;
   state->userterminationneeded = false;
   state->repterminationtype = 0;
   state->repiterationscount = 0;
   state->repnfev = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, n, 1, state->smoothnessguardlevel > 0);
   vectorsetlengthatleast(&state->invs, n);
   for (i = 0; i < n; i++) {
      state->lastscaleused.xR[i] = state->s.xR[i];
      state->invs.xR[i] = 1.0 / state->s.xR[i];
   }
// Check, that transferred derivative value is right
   state->stp = 0.0;
   if (state->diffstep == 0.0 && state->teststep > 0.0) {
      while (smoothnessmonitorcheckgradientatx0(&state->smonitor, &state->xbase, &state->s, &state->s, &state->s, false, state->teststep)) {
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->smonitor.x.xR[i];
         }
         state->needfg = true, state->PQ = 0; goto Pause; Resume00: state->needfg = false;
         state->smonitor.fi.xR[0] = state->f;
         for (i = 0; i < n; i++) {
            state->smonitor.j.xyR[0][i] = state->g.xR[i];
         }
      }
   }
// Calculate F/G at the initial point
   for (i = 0; i < n; i++) {
      state->x.xR[i] = state->xbase.xR[i];
   }
   state->stp = 0.0;
   if (state->diffstep == 0.0) {
      state->needfg = true, state->PQ = 1; goto Pause; Resume01: state->needfg = false;
   } else {
      state->needf = true;
      state->PQ = 2; goto Pause; Resume02:
      state->fbase = state->f;
      for (i = 0; i < n; i++) {
         v = state->x.xR[i];
         state->x.xR[i] = v - state->diffstep * state->s.xR[i];
         state->PQ = 3; goto Pause; Resume03:
         state->fm2 = state->f;
         state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
         state->PQ = 4; goto Pause; Resume04:
         state->fm1 = state->f;
         state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
         state->PQ = 5; goto Pause; Resume05:
         state->fp1 = state->f;
         state->x.xR[i] = v + state->diffstep * state->s.xR[i];
         state->PQ = 6; goto Pause; Resume06:
         state->fp2 = state->f;
         state->x.xR[i] = v;
         state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
      }
      state->needf = false;
      state->f = state->fbase;
   }
   trimprepare(state->f, &state->trimthreshold);
   if (state->xrep) {
      state->xupdated = true, state->PQ = 7; goto Pause; Resume07: state->xupdated = false;
   }
   if (state->userterminationneeded) {
   // User requested termination
      state->repterminationtype = 8;
      goto Exit;
   }
   state->repnfev = 1;
   state->fold = state->f;
   v = 0.0;
   for (i = 0; i < n; i++) {
      v += sqr(state->g.xR[i] * state->s.xR[i]);
   }
   if (sqrt(v) <= state->epsg) {
      state->repterminationtype = 4;
      goto Exit;
   }
// Choose initial step and direction.
// Apply preconditioner, if we have something other than default.
   ae_v_moveneg(state->d.xR, 1, state->g.xR, 1, n);
   if (state->prectype == 0) {
   // Default preconditioner is used, but we can't use it before iterations will start
      v = ae_v_dotproduct(state->g.xR, 1, state->g.xR, 1, n);
      v = sqrt(v);
      if (state->stpmax == 0.0) {
         state->stp = rmin2(1.0 / v, 1.0);
      } else {
         state->stp = rmin2(1.0 / v, state->stpmax);
      }
   }
   if (state->prectype == 1) {
   // Cholesky preconditioner is used
      fblscholeskysolve(&state->denseh, 1.0, n, true, &state->d, &state->autobuf);
      state->stp = 1.0;
   }
   if (state->prectype == 2) {
   // diagonal approximation is used
      for (i = 0; i < n; i++) {
         state->d.xR[i] /= state->diagh.xR[i];
      }
      state->stp = 1.0;
   }
   if (state->prectype == 3) {
   // scale-based preconditioner is used
      for (i = 0; i < n; i++) {
         state->d.xR[i] *= state->s.xR[i] * state->s.xR[i];
      }
      state->stp = 1.0;
   }
   if (state->prectype == 4) {
   // rank-k BFGS-based preconditioner is used
      inexactlbfgspreconditioner(&state->d, n, &state->precd, &state->precc, &state->precw, state->preck, &state->precbuf);
      state->stp = 1.0;
   }
   if (state->prectype == 5) {
   // exact low-rank preconditioner is used
      applylowrankpreconditioner(&state->d, &state->lowrankbuf);
      state->stp = 1.0;
   }
// Main cycle
   state->k = 0;
   while (true) {
   // Main cycle: prepare to 1-D line search
      state->p = state->k % m;
      state->q = imin2(state->k, m - 1);
   // Store X[k], G[k]
      ae_v_move(state->xp.xR, 1, state->x.xR, 1, n);
      ae_v_moveneg(state->sk.xyR[state->p], 1, state->x.xR, 1, n);
      ae_v_moveneg(state->yk.xyR[state->p], 1, state->g.xR, 1, n);
   // Minimize F(x+alpha*d)
   // Calculate S[k], Y[k]
      state->mcstage = 0;
      if (state->k != 0) {
         state->stp = 1.0;
      }
      linminnormalized(&state->d, &state->stp, n);
      smoothnessmonitorstartlinesearch1u(&state->smonitor, &state->s, &state->invs, &state->x, state->f, &state->g, state->k, -1);
      while (mcsrch(n, &state->x, state->f, &state->g, &state->d, &state->stp, state->stpmax, gtol, &mcinfo, &state->nfev, &state->work, &state->lstate, &state->mcstage)) {
         if (state->diffstep == 0.0) {
            state->needfg = true, state->PQ = 8; goto Pause; Resume08: state->needfg = false;
         } else {
            state->needf = true;
            state->PQ = 9; goto Pause; Resume09:
            state->fbase = state->f;
            for (i = 0; i < n; i++) {
               v = state->x.xR[i];
               state->x.xR[i] = v - state->diffstep * state->s.xR[i];
               state->PQ = 10; goto Pause; Resume10:
               state->fm2 = state->f;
               state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 11; goto Pause; Resume11:
               state->fm1 = state->f;
               state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 12; goto Pause; Resume12:
               state->fp1 = state->f;
               state->x.xR[i] = v + state->diffstep * state->s.xR[i];
               state->PQ = 13; goto Pause; Resume13:
               state->fp2 = state->f;
               state->x.xR[i] = v;
               state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
            }
            state->needf = false;
            state->f = state->fbase;
         }
         smoothnessmonitorenqueuepoint1u(&state->smonitor, &state->s, &state->invs, &state->d, state->stp, &state->x, state->f, &state->g);
         trimfunction(&state->f, &state->g, n, state->trimthreshold);
      }
      smoothnessmonitorfinalizelinesearch(&state->smonitor);
      if (state->userterminationneeded) {
      // User requested termination.
      // Restore previous point and return.
         ae_v_move(state->x.xR, 1, state->xp.xR, 1, n);
         state->repterminationtype = 8;
         goto Exit;
      }
      if (state->xrep) {
      // report
         state->xupdated = true, state->PQ = 14; goto Pause; Resume14: state->xupdated = false;
      }
      state->repnfev += state->nfev;
      state->repiterationscount++;
      ae_v_add(state->sk.xyR[state->p], 1, state->x.xR, 1, n);
      ae_v_add(state->yk.xyR[state->p], 1, state->g.xR, 1, n);
   // Stopping conditions
      v = 0.0;
      for (i = 0; i < n; i++) {
         v += sqr(state->g.xR[i] * state->s.xR[i]);
      }
      if (!isfinite(v) || !isfinite(state->f)) {
      // Abnormal termination - infinities in function/gradient
         state->repterminationtype = -8;
         goto Exit;
      }
      if (state->repiterationscount >= state->maxits && state->maxits > 0) {
      // Too many iterations
         state->repterminationtype = 5;
         goto Exit;
      }
      if (sqrt(v) <= state->epsg) {
      // Gradient is small enough
         state->repterminationtype = 4;
         goto Exit;
      }
      if (state->fold - state->f <= state->epsf * rmax2(fabs(state->fold), rmax2(fabs(state->f), 1.0))) {
      // F(k+1)-F(k) is small enough
         state->repterminationtype = 1;
         goto Exit;
      }
      v = 0.0;
      for (i = 0; i < n; i++) {
         v += sqr(state->sk.xyR[state->p][i] / state->s.xR[i]);
      }
      if (sqrt(v) <= state->epsx) {
      // X(k+1)-X(k) is small enough
         state->repterminationtype = 2;
         goto Exit;
      }
   // If Wolfe conditions are satisfied, we can update
   // limited memory model.
   //
   // However, if conditions are not satisfied (NFEV limit is met,
   // function is too wild, ...), we'll skip L-BFGS update
      if (mcinfo != 1) {
      // Skip update.
      //
      // In such cases we'll initialize search direction by
      // antigradient vector, because it  leads to more
      // transparent code with less number of special cases
         state->fold = state->f;
         ae_v_moveneg(state->d.xR, 1, state->g.xR, 1, n);
      } else {
      // Calculate Rho[k], GammaK
         v = ae_v_dotproduct(state->yk.xyR[state->p], 1, state->sk.xyR[state->p], 1, n);
         vv = ae_v_dotproduct(state->yk.xyR[state->p], 1, state->yk.xyR[state->p], 1, n);
         if (v == 0.0 || vv == 0.0) {
         // Rounding errors make further iterations impossible.
            state->repterminationtype = -2;
            goto Exit;
         }
         state->rho.xR[state->p] = 1.0 / v;
         state->gammak = v / vv;
      // Calculate d(k+1) = -H(k+1)*g(k+1)
      //
      // for I = K downto K-Q do
      //    V = s(i)^T * work(iteration:I)
      //    theta(i) = V
      //    work(iteration:I+1) = work(iteration:I) - V*Rho(i)*y(i)
      // work(last iteration) = H0*work(last iteration) - preconditioner
      // for I = K-Q to K do
      //    V = y(i)^T*work(iteration:I)
      //    work(iteration:I+1) = work(iteration:I) +(-V+theta(i))*Rho(i)*s(i)
      //
      // NOW WORK CONTAINS d(k+1)
         ae_v_move(state->work.xR, 1, state->g.xR, 1, n);
         for (i = state->k; i >= state->k - state->q; i--) {
            ic = i % m;
            v = ae_v_dotproduct(state->sk.xyR[ic], 1, state->work.xR, 1, n);
            state->theta.xR[ic] = v;
            vv = v * state->rho.xR[ic];
            ae_v_subd(state->work.xR, 1, state->yk.xyR[ic], 1, n, vv);
         }
         if (state->prectype == 0) {
         // Simple preconditioner is used
            v = state->gammak;
            ae_v_muld(state->work.xR, 1, n, v);
         }
         if (state->prectype == 1) {
         // Cholesky preconditioner is used
            fblscholeskysolve(&state->denseh, 1.0, n, true, &state->work, &state->autobuf);
         }
         if (state->prectype == 2) {
         // diagonal approximation is used
            for (i = 0; i < n; i++) {
               state->work.xR[i] /= state->diagh.xR[i];
            }
         }
         if (state->prectype == 3) {
         // scale-based preconditioner is used
            for (i = 0; i < n; i++) {
               state->work.xR[i] *= state->s.xR[i] * state->s.xR[i];
            }
         }
         if (state->prectype == 4) {
         // Rank-K BFGS-based preconditioner is used
            inexactlbfgspreconditioner(&state->work, n, &state->precd, &state->precc, &state->precw, state->preck, &state->precbuf);
         }
         if (state->prectype == 5) {
         // Exact low-rank preconditioner is used
            applylowrankpreconditioner(&state->work, &state->lowrankbuf);
         }
         for (i = state->k - state->q; i <= state->k; i++) {
            ic = i % m;
            v = ae_v_dotproduct(state->yk.xyR[ic], 1, state->work.xR, 1, n);
            vv = state->rho.xR[ic] * (-v + state->theta.xR[ic]);
            ae_v_addd(state->work.xR, 1, state->sk.xyR[ic], 1, n, vv);
         }
         ae_v_moveneg(state->d.xR, 1, state->work.xR, 1, n);
      // Next step
         state->fold = state->f;
         state->k++;
      }
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This  function  activates/deactivates verification  of  the  user-supplied
// analytic gradient.
//
// Upon  activation  of  this  option  OptGuard  integrity  checker  performs
// numerical differentiation of your target function  at  the  initial  point
// (note: future versions may also perform check  at  the  final  point)  and
// compares numerical gradient with analytic one provided by you.
//
// If difference is too large, an error flag is set and optimization  session
// continues. After optimization session is over, you can retrieve the report
// which  stores  both  gradients  and  specific  components  highlighted  as
// suspicious by the OptGuard.
//
// The primary OptGuard report can be retrieved with minlbfgsoptguardresults().
//
// IMPORTANT: gradient check is a high-overhead option which  will  cost  you
//            about 3*N additional function evaluations. In many cases it may
//            cost as much as the rest of the optimization session.
//
//            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
//            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
//
// NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
//       does NOT interrupt optimization even if it discovers bad gradient.
//
// Inputs:
//     State       -   structure used to store algorithm state
//     TestStep    -   verification step used for numerical differentiation:
//                     * TestStep == 0 turns verification off
//                     * TestStep > 0 activates verification
//                     You should carefully choose TestStep. Value  which  is
//                     too large (so large that  function  behavior  is  non-
//                     cubic at this scale) will lead  to  false  alarms. Too
//                     short step will result in rounding  errors  dominating
//                     numerical derivative.
//
//                     You may use different step for different parameters by
//                     means of setting scale with minlbfgssetscale().
//
// ==== EXPLANATION ====
//
// In order to verify gradient algorithm performs following steps:
//   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
//     where X[i] is i-th component of the initial point and S[i] is a  scale
//     of i-th parameter
//   * F(X) is evaluated at these trial points
//   * we perform one more evaluation in the middle point of the interval
//   * we  build  cubic  model using function values and derivatives at trial
//     points and we compare its prediction with actual value in  the  middle
//     point
// ALGLIB: Copyright 15.06.2014 by Sergey Bochkanov
// API: void minlbfgsoptguardgradient(const minlbfgsstate &state, const double teststep);
void minlbfgsoptguardgradient(minlbfgsstate *state, double teststep) {
   ae_assert(isfinite(teststep), "MinLBFGSOptGuardGradient: TestStep contains NaN or INF");
   ae_assert(teststep >= 0.0, "MinLBFGSOptGuardGradient: invalid argument TestStep(TestStep < 0)");
   state->teststep = teststep;
}

// This  function  activates/deactivates nonsmoothness monitoring  option  of
// the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
// solution process and tries to detect ill-posed problems, i.e. ones with:
// a) discontinuous target function (non-C0)
// b) nonsmooth     target function (non-C1)
//
// Smoothness monitoring does NOT interrupt optimization  even if it suspects
// that your problem is nonsmooth. It just sets corresponding  flags  in  the
// OptGuard report which can be retrieved after optimization is over.
//
// Smoothness monitoring is a moderate overhead option which often adds  less
// than 1% to the optimizer running time. Thus, you can use it even for large
// scale problems.
//
// NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
//       continuity violations.
//
//       First, minor errors are hard to  catch - say, a 0.0001 difference in
//       the model values at two sides of the gap may be due to discontinuity
//       of the model - or simply because the model has changed.
//
//       Second, C1-violations  are  especially  difficult  to  detect  in  a
//       noninvasive way. The optimizer usually  performs  very  short  steps
//       near the nonsmoothness, and differentiation  usually   introduces  a
//       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
//       discontinuity in the slope is due to real nonsmoothness or just  due
//       to numerical noise alone.
//
//       Our top priority was to avoid false positives, so in some rare cases
//       minor errors may went unnoticed (however, in most cases they can  be
//       spotted with restart from different initial point).
//
// Inputs:
//     state   -   algorithm state
//     level   -   monitoring level:
//                 * 0 - monitoring is disabled
//                 * 1 - noninvasive low-overhead monitoring; function values
//                       and/or gradients are recorded, but OptGuard does not
//                       try to perform additional evaluations  in  order  to
//                       get more information about suspicious locations.
//
// ==== EXPLANATION ====
//
// One major source of headache during optimization  is  the  possibility  of
// the coding errors in the target function/constraints (or their gradients).
// Such  errors   most   often   manifest   themselves  as  discontinuity  or
// nonsmoothness of the target/constraints.
//
// Another frequent situation is when you try to optimize something involving
// lots of min() and max() operations, i.e. nonsmooth target. Although not  a
// coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
// stop right after encountering nonsmoothness, well before reaching solution.
//
// OptGuard integrity checker helps you to catch such situations: it monitors
// function values/gradients being passed  to  the  optimizer  and  tries  to
// errors. Upon discovering suspicious pair of points it  raises  appropriate
// flag (and allows you to continue optimization). When optimization is done,
// you can study OptGuard result.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minlbfgsoptguardsmoothness(const minlbfgsstate &state, const ae_int_t level);
// API: void minlbfgsoptguardsmoothness(const minlbfgsstate &state);
void minlbfgsoptguardsmoothness(minlbfgsstate *state, ae_int_t level) {
   ae_assert(level == 0 || level == 1, "MinLBFGSOptGuardSmoothness: unexpected value of level parameter");
   state->smoothnessguardlevel = level;
}

// Results of OptGuard integrity check, should be called  after  optimization
// session is over.
//
// ==== PRIMARY REPORT ====
//
// OptGuard performs several checks which are intended to catch common errors
// in the implementation of nonlinear function/gradient:
// * incorrect analytic gradient
// * discontinuous (non-C0) target functions (constraints)
// * nonsmooth     (non-C1) target functions (constraints)
//
// Each of these checks is activated with appropriate function:
// * minlbfgsoptguardgradient() for gradient verification
// * minlbfgsoptguardsmoothness() for C0/C1 checks
//
// Following flags are set when these errors are suspected:
// * rep.badgradsuspected, and additionally:
//   * rep.badgradvidx for specific variable (gradient element) suspected
//   * rep.badgradxbase, a point where gradient is tested
//   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
//     single row in order to make  report  structure  compatible  with  more
//     complex optimizers like MinNLC or MinLM)
//   * rep.badgradnum,   reference    gradient    obtained    via   numerical
//     differentiation (stored as  2D matrix with single row in order to make
//     report structure compatible with more complex optimizers  like  MinNLC
//     or MinLM)
// * rep.nonc0suspected
// * rep.nonc1suspected
//
// ==== ADDITIONAL REPORTS/LOGS ====
//
// Several different tests are performed to catch C0/C1 errors, you can  find
// out specific test signaled error by looking to:
// * rep.nonc0test0positive, for non-C0 test #0
// * rep.nonc1test0positive, for non-C1 test #0
// * rep.nonc1test1positive, for non-C1 test #1
//
// Additional information (including line search logs)  can  be  obtained  by
// means of:
// * minlbfgsoptguardnonc1test0results()
// * minlbfgsoptguardnonc1test1results()
// which return detailed error reports, specific points where discontinuities
// were found, and so on.
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     rep     -   generic OptGuard report;  more  detailed  reports  can  be
//                 retrieved with other functions.
//
// NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
//       ones) are possible although unlikely.
//
//       The reason  is  that  you  need  to  make several evaluations around
//       nonsmoothness  in  order  to  accumulate  enough  information  about
//       function curvature. Say, if you start right from the nonsmooth point,
//       optimizer simply won't get enough data to understand what  is  going
//       wrong before it terminates due to abrupt changes in the  derivative.
//       It is also  possible  that  "unlucky"  step  will  move  us  to  the
//       termination too quickly.
//
//       Our current approach is to have less than 0.1%  false  negatives  in
//       our test examples  (measured  with  multiple  restarts  from  random
//       points), and to have exactly 0% false positives.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minlbfgsoptguardresults(const minlbfgsstate &state, optguardreport &rep);
void minlbfgsoptguardresults(minlbfgsstate *state, optguardreport *rep) {
   SetObj(optguardreport, rep);
   smoothnessmonitorexportreport(&state->smonitor, rep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #0
//
// Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
// obtained during line searches and monitors  behavior  of  the  directional
// derivative estimate.
//
// This test is less powerful than test #1, but it does  not  depend  on  the
// gradient values and thus it is more robust against artifacts introduced by
// numerical differentiation.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #0 "strong" report
//     lngrep  -   C1 test #0 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minlbfgsoptguardnonc1test0results(const minlbfgsstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep);
void minlbfgsoptguardnonc1test0results(minlbfgsstate *state, optguardnonc1test0report *strrep, optguardnonc1test0report *lngrep) {
   SetObj(optguardnonc1test0report, strrep);
   SetObj(optguardnonc1test0report, lngrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0lngrep, &state->lastscaleused, lngrep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #1
//
// Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
// gradient computed during line search.
//
// When precise analytic gradient is provided this test is more powerful than
// test #0  which  works  with  function  values  and  ignores  user-provided
// gradient.  However,  test  #0  becomes  more   powerful   when   numerical
// differentiation is employed (in such cases test #1 detects  higher  levels
// of numerical noise and becomes too conservative).
//
// This test also tells specific components of the gradient which violate  C1
// continuity, which makes it more informative than #0, which just tells that
// continuity is violated.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * vidx - is an index of the variable in [0,N) with nonsmooth derivative
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], g[] - arrays of length CNT which store step lengths and  gradient
//   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
//   vidx-th component of the gradient.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #1 "strong" report
//     lngrep  -   C1 test #1 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minlbfgsoptguardnonc1test1results(const minlbfgsstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep);
void minlbfgsoptguardnonc1test1results(minlbfgsstate *state, optguardnonc1test1report *strrep, optguardnonc1test1report *lngrep) {
   SetObj(optguardnonc1test1report, strrep);
   SetObj(optguardnonc1test1report, lngrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1lngrep, &state->lastscaleused, lngrep);
}

// L-BFGS algorithm results
//
// Buffered implementation of MinLBFGSResults which uses preallocated buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 20.08.2010 by Sergey Bochkanov
// API: void minlbfgsresultsbuf(const minlbfgsstate &state, real_1d_array &x, minlbfgsreport &rep);
void minlbfgsresultsbuf(minlbfgsstate *state, RVector *x, minlbfgsreport *rep) {
   vectorsetlengthatleast(x, state->n);
   ae_v_move(x->xR, 1, state->x.xR, 1, state->n);
   rep->iterationscount = state->repiterationscount;
   rep->nfev = state->repnfev;
   rep->terminationtype = state->repterminationtype;
}

// L-BFGS algorithm results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization report:
//                 * Rep.TerminationType completetion code:
//                     * -8    internal integrity control  detected  infinite
//                             or NAN values in  function/gradient.  Abnormal
//                             termination signalled.
//                     * -2    rounding errors prevent further improvement.
//                             X contains best point found.
//                     * -1    incorrect parameters were specified
//                     *  1    relative function improvement is no more than
//                             EpsF.
//                     *  2    relative step is no more than EpsX.
//                     *  4    gradient norm is no more than EpsG
//                     *  5    MaxIts steps was taken
//                     *  7    stopping conditions are too stringent,
//                             further improvement is impossible
//                     *  8    terminated by user who called minlbfgsrequesttermination().
//                             X contains point which was "current accepted" when
//                             termination request was submitted.
//                 * Rep.IterationsCount contains iterations count
//                 * NFEV countains number of function calculations
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlbfgsresults(const minlbfgsstate &state, real_1d_array &x, minlbfgsreport &rep);
void minlbfgsresults(minlbfgsstate *state, RVector *x, minlbfgsreport *rep) {
   SetVector(x);
   SetObj(minlbfgsreport, rep);
   minlbfgsresultsbuf(state, x, rep);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 08.10.2014 by Sergey Bochkanov
// API: void minlbfgsrequesttermination(const minlbfgsstate &state);
void minlbfgsrequesttermination(minlbfgsstate *state) {
   state->userterminationneeded = true;
}

void minlbfgsstate_init(void *_p, bool make_automatic) {
   minlbfgsstate *p = (minlbfgsstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rho, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->yk, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->sk, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->theta, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->work, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->denseh, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagh, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->precc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->precd, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->precw, 0, 0, DT_REAL, make_automatic);
   precbuflbfgs_init(&p->precbuf, make_automatic);
   precbuflowrank_init(&p->lowrankbuf, make_automatic);
   ae_vector_init(&p->autobuf, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->invs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   linminstate_init(&p->lstate, make_automatic);
   smoothnessmonitor_init(&p->smonitor, make_automatic);
   ae_vector_init(&p->lastscaleused, 0, DT_REAL, make_automatic);
}

void minlbfgsstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minlbfgsstate *dst = (minlbfgsstate *)_dst;
   const minlbfgsstate *src = (const minlbfgsstate *)_src;
   dst->n = src->n;
   dst->m = src->m;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->xrep = src->xrep;
   dst->stpmax = src->stpmax;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   dst->diffstep = src->diffstep;
   dst->nfev = src->nfev;
   dst->mcstage = src->mcstage;
   dst->k = src->k;
   dst->q = src->q;
   dst->p = src->p;
   ae_vector_copy(&dst->rho, &src->rho, make_automatic);
   ae_matrix_copy(&dst->yk, &src->yk, make_automatic);
   ae_matrix_copy(&dst->sk, &src->sk, make_automatic);
   ae_vector_copy(&dst->xp, &src->xp, make_automatic);
   ae_vector_copy(&dst->theta, &src->theta, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->stp = src->stp;
   ae_vector_copy(&dst->work, &src->work, make_automatic);
   dst->fold = src->fold;
   dst->trimthreshold = src->trimthreshold;
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   dst->prectype = src->prectype;
   dst->gammak = src->gammak;
   ae_matrix_copy(&dst->denseh, &src->denseh, make_automatic);
   ae_vector_copy(&dst->diagh, &src->diagh, make_automatic);
   ae_vector_copy(&dst->precc, &src->precc, make_automatic);
   ae_vector_copy(&dst->precd, &src->precd, make_automatic);
   ae_matrix_copy(&dst->precw, &src->precw, make_automatic);
   dst->preck = src->preck;
   precbuflbfgs_copy(&dst->precbuf, &src->precbuf, make_automatic);
   precbuflowrank_copy(&dst->lowrankbuf, &src->lowrankbuf, make_automatic);
   dst->fbase = src->fbase;
   dst->fm2 = src->fm2;
   dst->fm1 = src->fm1;
   dst->fp1 = src->fp1;
   dst->fp2 = src->fp2;
   ae_vector_copy(&dst->autobuf, &src->autobuf, make_automatic);
   ae_vector_copy(&dst->invs, &src->invs, make_automatic);
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->needf = src->needf;
   dst->needfg = src->needfg;
   dst->xupdated = src->xupdated;
   dst->userterminationneeded = src->userterminationneeded;
   dst->teststep = src->teststep;
   dst->PQ = src->PQ;
   dst->repiterationscount = src->repiterationscount;
   dst->repnfev = src->repnfev;
   dst->repterminationtype = src->repterminationtype;
   linminstate_copy(&dst->lstate, &src->lstate, make_automatic);
   dst->smoothnessguardlevel = src->smoothnessguardlevel;
   smoothnessmonitor_copy(&dst->smonitor, &src->smonitor, make_automatic);
   ae_vector_copy(&dst->lastscaleused, &src->lastscaleused, make_automatic);
}

void minlbfgsstate_free(void *_p, bool make_automatic) {
   minlbfgsstate *p = (minlbfgsstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->rho, make_automatic);
   ae_matrix_free(&p->yk, make_automatic);
   ae_matrix_free(&p->sk, make_automatic);
   ae_vector_free(&p->xp, make_automatic);
   ae_vector_free(&p->theta, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->work, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_matrix_free(&p->denseh, make_automatic);
   ae_vector_free(&p->diagh, make_automatic);
   ae_vector_free(&p->precc, make_automatic);
   ae_vector_free(&p->precd, make_automatic);
   ae_matrix_free(&p->precw, make_automatic);
   precbuflbfgs_free(&p->precbuf, make_automatic);
   precbuflowrank_free(&p->lowrankbuf, make_automatic);
   ae_vector_free(&p->autobuf, make_automatic);
   ae_vector_free(&p->invs, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   linminstate_free(&p->lstate, make_automatic);
   smoothnessmonitor_free(&p->smonitor, make_automatic);
   ae_vector_free(&p->lastscaleused, make_automatic);
}

void minlbfgsreport_init(void *_p, bool make_automatic) {
}

void minlbfgsreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minlbfgsreport *dst = (minlbfgsreport *)_dst;
   const minlbfgsreport *src = (const minlbfgsreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->terminationtype = src->terminationtype;
}

void minlbfgsreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
DefClass(minlbfgsstate, DecVal(needf) DecVal(needfg) DecVal(xupdated) DecVal(f) DecVar(g) DecVar(x))

// This structure stores optimization report:
// * IterationsCount           total number of inner iterations
// * NFEV                      number of gradient evaluations
// * TerminationType           termination type (see below)
//
// TERMINATION CODES
//
// TerminationType field contains completion code, which can be:
//   -8    internal integrity control detected  infinite  or  NAN  values  in
//         function/gradient. Abnormal termination signalled.
//    1    relative function improvement is no more than EpsF.
//    2    relative step is no more than EpsX.
//    4    gradient norm is no more than EpsG
//    5    MaxIts steps was taken
//    7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//    8    terminated    by  user  who  called  minlbfgsrequesttermination().
//         X contains point which was   "current accepted"  when  termination
//         request was submitted.
//
// Other fields of this structure are not documented and should not be used!
DefClass(minlbfgsreport, DecVal(iterationscount) DecVal(nfev) DecVal(terminationtype))

void minlbfgssetcond(const minlbfgsstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetcond(ConstT(minlbfgsstate, state), epsg, epsf, epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minlbfgssetxrep(const minlbfgsstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetxrep(ConstT(minlbfgsstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minlbfgssetstpmax(const minlbfgsstate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetstpmax(ConstT(minlbfgsstate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void minlbfgssetscale(const minlbfgsstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetscale(ConstT(minlbfgsstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minlbfgsrestartfrom(const minlbfgsstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsrestartfrom(ConstT(minlbfgsstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minlbfgscreate(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgscreate(n, m, ConstT(ae_vector, x), ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlbfgscreate(const ae_int_t m, const real_1d_array &x, minlbfgsstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgscreate(n, m, ConstT(ae_vector, x), ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlbfgscreatef(const ae_int_t n, const ae_int_t m, const real_1d_array &x, const double diffstep, minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgscreatef(n, m, ConstT(ae_vector, x), diffstep, ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlbfgscreatef(const ae_int_t m, const real_1d_array &x, const double diffstep, minlbfgsstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgscreatef(n, m, ConstT(ae_vector, x), diffstep, ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlbfgssetprecdefault(const minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetprecdefault(ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}

void minlbfgssetpreccholesky(const minlbfgsstate &state, const real_2d_array &p, const bool isupper) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetpreccholesky(ConstT(minlbfgsstate, state), ConstT(ae_matrix, p), isupper);
   alglib_impl::ae_state_clear();
}

void minlbfgssetprecdiag(const minlbfgsstate &state, const real_1d_array &d) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetprecdiag(ConstT(minlbfgsstate, state), ConstT(ae_vector, d));
   alglib_impl::ae_state_clear();
}

void minlbfgssetprecscale(const minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetprecscale(ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}

bool minlbfgsiteration(const minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minlbfgsiteration(ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     func    -   callback which calculates function (or merit function)
//                 value func at given point x
//     grad    -   callback which calculates function (or merit function)
//                 value func and gradient grad at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. This function has two different implementations: one which  uses  exact
//    (analytical) user-supplied gradient,  and one which uses function value
//    only  and  numerically  differentiates  function  in  order  to  obtain
//    gradient.
//
//    Depending  on  the  specific  function  used to create optimizer object
//    (either MinLBFGSCreate() for analytical gradient  or  MinLBFGSCreateF()
//    for numerical differentiation) you should choose appropriate variant of
//    MinLBFGSOptimize() - one  which  accepts  function  AND gradient or one
//    which accepts function ONLY.
//
//    Be careful to choose variant of MinLBFGSOptimize() which corresponds to
//    your optimization scheme! Table below lists different  combinations  of
//    callback (function/gradient) passed to MinLBFGSOptimize()  and specific
//    function used to create optimizer.
//
//                      |         USER PASSED TO MinLBFGSOptimize()
//    CREATED WITH      |  function only   |  function and gradient
//    ------------------------------------------------------------
//    MinLBFGSCreateF() |     work                FAIL
//    MinLBFGSCreate()  |     FAIL                work
//
//    Here "FAIL" denotes inappropriate combinations  of  optimizer  creation
//    function  and  MinLBFGSOptimize()  version.   Attemps   to   use   such
//    combination (for example, to create optimizer with MinLBFGSCreateF() and
//    to pass gradient information to MinCGOptimize()) will lead to exception
//    being thrown. Either  you  did  not pass gradient when it WAS needed or
//    you passed gradient when it was NOT needed.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
void minlbfgsoptimize(minlbfgsstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "minlbfgsoptimize: func is NULL");
   while (alglib_impl::minlbfgsiteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlbfgsoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minlbfgsoptimize(minlbfgsstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(grad != NULL, "minlbfgsoptimize: grad is NULL");
   while (alglib_impl::minlbfgsiteration(state.c_ptr()))
   BegPoll
      if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlbfgsoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minlbfgsoptguardgradient(const minlbfgsstate &state, const double teststep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsoptguardgradient(ConstT(minlbfgsstate, state), teststep);
   alglib_impl::ae_state_clear();
}

void minlbfgsoptguardsmoothness(const minlbfgsstate &state, const ae_int_t level) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsoptguardsmoothness(ConstT(minlbfgsstate, state), level);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlbfgsoptguardsmoothness(const minlbfgsstate &state) {
   ae_int_t level = 1;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsoptguardsmoothness(ConstT(minlbfgsstate, state), level);
   alglib_impl::ae_state_clear();
}
#endif

void minlbfgsoptguardresults(const minlbfgsstate &state, optguardreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsoptguardresults(ConstT(minlbfgsstate, state), ConstT(optguardreport, rep));
   alglib_impl::ae_state_clear();
}

void minlbfgsoptguardnonc1test0results(const minlbfgsstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsoptguardnonc1test0results(ConstT(minlbfgsstate, state), ConstT(optguardnonc1test0report, strrep), ConstT(optguardnonc1test0report, lngrep));
   alglib_impl::ae_state_clear();
}

void minlbfgsoptguardnonc1test1results(const minlbfgsstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsoptguardnonc1test1results(ConstT(minlbfgsstate, state), ConstT(optguardnonc1test1report, strrep), ConstT(optguardnonc1test1report, lngrep));
   alglib_impl::ae_state_clear();
}

void minlbfgsresultsbuf(const minlbfgsstate &state, real_1d_array &x, minlbfgsreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsresultsbuf(ConstT(minlbfgsstate, state), ConstT(ae_vector, x), ConstT(minlbfgsreport, rep));
   alglib_impl::ae_state_clear();
}

void minlbfgsresults(const minlbfgsstate &state, real_1d_array &x, minlbfgsreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsresults(ConstT(minlbfgsstate, state), ConstT(ae_vector, x), ConstT(minlbfgsreport, rep));
   alglib_impl::ae_state_clear();
}

void minlbfgsrequesttermination(const minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgsrequesttermination(ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === CQMODELS Package ===
// Depends on: (LinAlg) TRFAC, FBLS
namespace alglib_impl {
// This subroutine is used to initialize CQM. By default, empty NxN model  is
// generated, with Alpha == Lambda == Theta == 0.0 and zero b.
//
// Previously allocated buffer variables are reused as much as possible.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqminit(ae_int_t n, convexquadraticmodel *s) {
   ae_int_t i;
   s->n = n;
   s->k = 0;
   s->nfree = n;
   s->ecakind = -1;
   s->alpha = 0.0;
   s->tau = 0.0;
   s->theta = 0.0;
   s->ismaintermchanged = true;
   s->issecondarytermchanged = true;
   s->islineartermchanged = true;
   s->isactivesetchanged = true;
   vectorsetlengthatleast(&s->activeset, n);
   vectorsetlengthatleast(&s->xc, n);
   vectorsetlengthatleast(&s->eb, n);
   vectorsetlengthatleast(&s->tq1, n);
   vectorsetlengthatleast(&s->txc, n);
   vectorsetlengthatleast(&s->tb, n);
   vectorsetlengthatleast(&s->b, s->n);
   vectorsetlengthatleast(&s->tk1, s->n);
   for (i = 0; i < n; i++) {
      s->activeset.xB[i] = false;
      s->xc.xR[i] = 0.0;
      s->b.xR[i] = 0.0;
   }
}

// This subroutine changes main quadratic term of the model.
//
// Inputs:
//     S       -   model
//     A       -   NxN matrix, only upper or lower triangle is referenced
//     IsUpper -   True, when matrix is stored in upper triangle
//     Alpha   -   multiplier; when Alpha == 0, A is not referenced at all
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmseta(convexquadraticmodel *s, RMatrix *a, bool isupper, double alpha) {
   ae_int_t i;
   ae_int_t j;
   double v;
   ae_assert(isfinite(alpha) && alpha >= 0.0, "CQMSetA: Alpha < 0 or is not finite number");
   ae_assert(alpha == 0.0 || isfinitertrmatrix(a, s->n, isupper), "CQMSetA: A is not finite NxN matrix");
   s->alpha = alpha;
   if (alpha > 0.0) {
      matrixsetlengthatleast(&s->a, s->n, s->n);
      matrixsetlengthatleast(&s->ecadense, s->n, s->n);
      matrixsetlengthatleast(&s->tq2dense, s->n, s->n);
      for (i = 0; i < s->n; i++) {
         for (j = i; j < s->n; j++) {
            if (isupper) {
               v = a->xyR[i][j];
            } else {
               v = a->xyR[j][i];
            }
            s->a.xyR[i][j] = v;
            s->a.xyR[j][i] = v;
         }
      }
   }
   s->ismaintermchanged = true;
}

// This subroutine changes main quadratic term of the model.
//
// Inputs:
//     S       -   model
//     A       -   possibly preallocated buffer
//
// Outputs:
//     A       -   NxN matrix, full matrix is returned.
//                 Zero matrix is returned if model is empty.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmgeta(convexquadraticmodel *s, RMatrix *a) {
   ae_int_t i;
   ae_int_t j;
   double v;
   ae_int_t n;
   n = s->n;
   matrixsetlengthatleast(a, n, n);
   if (s->alpha > 0.0) {
      v = s->alpha;
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            a->xyR[i][j] = v * s->a.xyR[i][j];
         }
      }
   } else {
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            a->xyR[i][j] = 0.0;
         }
      }
   }
}

// This subroutine rewrites diagonal of the main quadratic term of the  model
// (dense  A)  by  vector  Z/Alpha (current value of the Alpha coefficient is
// used).
//
// IMPORTANT: in  case  model  has  no  dense  quadratic  term, this function
//            allocates N*N dense matrix of zeros, and fills its diagonal  by
//            non-zero values.
//
// Inputs:
//     S       -   model
//     Z       -   new diagonal, array[N]
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmrewritedensediagonal(convexquadraticmodel *s, RVector *z) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   n = s->n;
   if (s->alpha == 0.0) {
      matrixsetlengthatleast(&s->a, s->n, s->n);
      matrixsetlengthatleast(&s->ecadense, s->n, s->n);
      matrixsetlengthatleast(&s->tq2dense, s->n, s->n);
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            s->a.xyR[i][j] = 0.0;
         }
      }
      s->alpha = 1.0;
   }
   for (i = 0; i < s->n; i++) {
      s->a.xyR[i][i] = z->xR[i] / s->alpha;
   }
   s->ismaintermchanged = true;
}

// This subroutine changes diagonal quadratic term of the model.
//
// Inputs:
//     S       -   model
//     D       -   array[N], semidefinite diagonal matrix
//     Tau     -   multiplier; when Tau == 0, D is not referenced at all
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmsetd(convexquadraticmodel *s, RVector *d, double tau) {
   ae_int_t i;
   ae_assert(isfinite(tau) && tau >= 0.0, "CQMSetD: Tau < 0 or is not finite number");
   ae_assert(tau == 0.0 || isfinitevector(d, s->n), "CQMSetD: D is not finite Nx1 vector");
   s->tau = tau;
   if (tau > 0.0) {
      vectorsetlengthatleast(&s->d, s->n);
      vectorsetlengthatleast(&s->ecadiag, s->n);
      vectorsetlengthatleast(&s->tq2diag, s->n);
      for (i = 0; i < s->n; i++) {
         ae_assert(d->xR[i] >= 0.0, "CQMSetD: D[i] < 0");
         s->d.xR[i] = d->xR[i];
      }
   }
   s->ismaintermchanged = true;
}

// This subroutine drops main quadratic term A from the model. It is same  as
// call  to  CQMSetA()  with  zero  A,   but gives better performance because
// algorithm  knows  that  matrix  is  zero  and  can  optimize    subsequent
// calculations.
//
// Inputs:
//     S       -   model
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmdropa(convexquadraticmodel *s) {
   s->alpha = 0.0;
   s->ismaintermchanged = true;
}

// This subroutine changes linear term of the model
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmsetb(convexquadraticmodel *s, RVector *b) {
   ae_int_t i;
   ae_assert(isfinitevector(b, s->n), "CQMSetB: B is not finite vector");
   vectorsetlengthatleast(&s->b, s->n);
   for (i = 0; i < s->n; i++) {
      s->b.xR[i] = b->xR[i];
   }
   s->islineartermchanged = true;
}

// This subroutine changes linear term of the model
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmsetq(convexquadraticmodel *s, RMatrix *q, RVector *r, ae_int_t k, double theta) {
   ae_int_t i;
   ae_int_t j;
   ae_assert(k >= 0, "CQMSetQ: K < 0");
   ae_assert(k == 0 || theta == 0.0 || apservisfinitematrix(q, k, s->n), "CQMSetQ: Q is not finite matrix");
   ae_assert(k == 0 || theta == 0.0 || isfinitevector(r, k), "CQMSetQ: R is not finite vector");
   ae_assert(isfinite(theta) && theta >= 0.0, "CQMSetQ: Theta < 0 or is not finite number");
// degenerate case: K == 0 or Theta == 0
   if (k == 0 || theta == 0.0) {
      s->k = 0;
      s->theta = 0.0;
      s->issecondarytermchanged = true;
      return;
   }
// General case: both Theta > 0 and K > 0
   s->k = k;
   s->theta = theta;
   matrixsetlengthatleast(&s->q, s->k, s->n);
   vectorsetlengthatleast(&s->r, s->k);
   matrixsetlengthatleast(&s->eq, s->k, s->n);
   matrixsetlengthatleast(&s->eccm, s->k, s->k);
   matrixsetlengthatleast(&s->tk2, s->k, s->n);
   for (i = 0; i < s->k; i++) {
      for (j = 0; j < s->n; j++) {
         s->q.xyR[i][j] = q->xyR[i][j];
      }
      s->r.xR[i] = r->xR[i];
   }
   s->issecondarytermchanged = true;
}

// This subroutine changes active set
//
// Inputs:
//     S       -   model
//     X       -   array[N], constraint values
//     ActiveSet-  array[N], active set. If ActiveSet[I] == True, then I-th
//                 variables is constrained to X[I].
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmsetactiveset(convexquadraticmodel *s, RVector *x, BVector *activeset) {
   ae_int_t i;
   ae_assert(x->cnt >= s->n, "CQMSetActiveSet: Length(X) < N");
   ae_assert(activeset->cnt >= s->n, "CQMSetActiveSet: Length(ActiveSet) < N");
   for (i = 0; i < s->n; i++) {
      s->isactivesetchanged = s->isactivesetchanged || s->activeset.xB[i] && !activeset->xB[i];
      s->isactivesetchanged = s->isactivesetchanged || activeset->xB[i] && !s->activeset.xB[i];
      s->activeset.xB[i] = activeset->xB[i];
      if (activeset->xB[i]) {
         ae_assert(isfinite(x->xR[i]), "CQMSetActiveSet: X[] contains infinite constraints");
         s->isactivesetchanged = s->isactivesetchanged || s->xc.xR[i] != x->xR[i];
         s->xc.xR[i] = x->xR[i];
      }
   }
}

// This subroutine evaluates model at X. Active constraints are ignored.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
double cqmeval(convexquadraticmodel *s, RVector *x) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   double v;
   double result;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMEval: X is not finite vector");
   result = 0.0;
// main quadratic term
   if (s->alpha > 0.0) {
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            result += s->alpha * 0.5 * x->xR[i] * s->a.xyR[i][j] * x->xR[j];
         }
      }
   }
   if (s->tau > 0.0) {
      for (i = 0; i < n; i++) {
         result += 0.5 * sqr(x->xR[i]) * s->tau * s->d.xR[i];
      }
   }
// secondary quadratic term
   if (s->theta > 0.0) {
      for (i = 0; i < s->k; i++) {
         v = ae_v_dotproduct(s->q.xyR[i], 1, x->xR, 1, n);
         result += 0.5 * s->theta * sqr(v - s->r.xR[i]);
      }
   }
// linear term
   for (i = 0; i < s->n; i++) {
      result += x->xR[i] * s->b.xR[i];
   }
   return result;
}

// This subroutine evaluates model at X. Active constraints are ignored.
// It returns:
//     R   -   model value
//     Noise-  estimate of the numerical noise in data
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmevalx(convexquadraticmodel *s, RVector *x, double *r, double *noise) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   double v;
   double v2;
   double mxq;
   double eps;
   *r = 0.0;
   *noise = 0.0;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMEval: X is not finite vector");
   *r = 0.0;
   *noise = 0.0;
   eps = 2.0 * machineepsilon;
   mxq = 0.0;
// Main quadratic term.
//
// Noise from the main quadratic term is equal to the
// maximum summand in the term.
   if (s->alpha > 0.0) {
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            v = s->alpha * 0.5 * x->xR[i] * s->a.xyR[i][j] * x->xR[j];
            *r += v;
            *noise = rmax2(*noise, eps * fabs(v));
         }
      }
   }
   if (s->tau > 0.0) {
      for (i = 0; i < n; i++) {
         v = 0.5 * sqr(x->xR[i]) * s->tau * s->d.xR[i];
         *r += v;
         *noise = rmax2(*noise, eps * fabs(v));
      }
   }
// secondary quadratic term
//
// Noise from the secondary quadratic term is estimated as follows:
// * noise in qi*x-r[i] is estimated as
//   Eps*MXQ = Eps*max(|r[i]|, |q[i,j]*x[j]|)
// * noise in (qi*x-r[i])^2 is estimated as
//   NOISE = (|qi*x-r[i]|+Eps*MXQ)^2-(|qi*x-r[i]|)^2
//         = Eps*MXQ*(2*|qi*x-r[i]|+Eps*MXQ)
   if (s->theta > 0.0) {
      for (i = 0; i < s->k; i++) {
         v = 0.0;
         mxq = fabs(s->r.xR[i]);
         for (j = 0; j < n; j++) {
            v2 = s->q.xyR[i][j] * x->xR[j];
            v += v2;
            mxq = rmax2(mxq, fabs(v2));
         }
         *r += 0.5 * s->theta * sqr(v - s->r.xR[i]);
         *noise = rmax2(*noise, eps * mxq * (2.0 * fabs(v - s->r.xR[i]) + eps * mxq));
      }
   }
// linear term
   for (i = 0; i < s->n; i++) {
      *r += x->xR[i] * s->b.xR[i];
      *noise = rmax2(*noise, eps * fabs(x->xR[i] * s->b.xR[i]));
   }
// Final update of the noise
   *noise *= n;
}

// This  subroutine  evaluates  gradient of the model; active constraints are
// ignored.
//
// Inputs:
//     S       -   convex model
//     X       -   point, array[N]
//     G       -   possibly preallocated buffer; resized, if too small
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmgradunconstrained(convexquadraticmodel *s, RVector *x, RVector *g) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   double v;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMEvalGradUnconstrained: X is not finite vector");
   vectorsetlengthatleast(g, n);
   for (i = 0; i < n; i++) {
      g->xR[i] = 0.0;
   }
// main quadratic term
   if (s->alpha > 0.0) {
      for (i = 0; i < n; i++) {
         v = 0.0;
         for (j = 0; j < n; j++) {
            v += s->alpha * s->a.xyR[i][j] * x->xR[j];
         }
         g->xR[i] += v;
      }
   }
   if (s->tau > 0.0) {
      for (i = 0; i < n; i++) {
         g->xR[i] += x->xR[i] * s->tau * s->d.xR[i];
      }
   }
// secondary quadratic term
   if (s->theta > 0.0) {
      for (i = 0; i < s->k; i++) {
         v = ae_v_dotproduct(s->q.xyR[i], 1, x->xR, 1, n);
         v = s->theta * (v - s->r.xR[i]);
         ae_v_addd(g->xR, 1, s->q.xyR[i], 1, n, v);
      }
   }
// linear term
   for (i = 0; i < n; i++) {
      g->xR[i] += s->b.xR[i];
   }
}

// This subroutine evaluates x'*(0.5*alpha*A+tau*D)*x
//
// NOTE: Tmp[] must be preallocated array whose length is at least N
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
double cqmxtadx2(convexquadraticmodel *s, RVector *x, RVector *tmp) {
   ae_int_t n;
   ae_int_t i;
   double result;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMXTADX2: X is not finite vector");
   ae_assert(tmp->cnt >= n, "CQMXTADX2: Length(Tmp) < N");
   result = 0.0;
// main quadratic term
   if (s->alpha > 0.0) {
      result += s->alpha * 0.5 * rmatrixsyvmv(n, &s->a, 0, 0, true, x, 0, tmp);
   }
   if (s->tau > 0.0) {
      for (i = 0; i < n; i++) {
         result += 0.5 * sqr(x->xR[i]) * s->tau * s->d.xR[i];
      }
   }
   return result;
}

// This subroutine evaluates (0.5*alpha*A+tau*D)*x
//
// Y is automatically resized if needed
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmadx(convexquadraticmodel *s, RVector *x, RVector *y) {
   ae_int_t n;
   ae_int_t i;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMEval: X is not finite vector");
   vectorsetlengthatleast(y, n);
// main quadratic term
   for (i = 0; i < n; i++) {
      y->xR[i] = 0.0;
   }
   if (s->alpha > 0.0) {
      rmatrixsymv(n, s->alpha, &s->a, 0, 0, true, x, 0, 1.0, y, 0);
   }
   if (s->tau > 0.0) {
      for (i = 0; i < n; i++) {
         y->xR[i] += x->xR[i] * s->tau * s->d.xR[i];
      }
   }
}

// Internal function, rebuilds "effective" model subject to constraints.
// Returns False on failure (non-SPD main quadratic term)
// ALGLIB: Copyright 10.05.2011 by Sergey Bochkanov
static bool cqmodels_cqmrebuild(convexquadraticmodel *s) {
   ae_int_t n;
   ae_int_t nfree;
   ae_int_t k;
   ae_int_t i;
   ae_int_t j;
   ae_int_t ridx0;
   ae_int_t ridx1;
   ae_int_t cidx0;
   ae_int_t cidx1;
   double v;
   bool result;
   if (s->alpha == 0.0 && s->tau == 0.0) {
   // Non-SPD model, quick exit
      result = false;
      return result;
   }
   result = true;
   n = s->n;
   k = s->k;
// Determine number of free variables.
// Fill TXC - array whose last N-NFree elements store constraints.
   if (s->isactivesetchanged) {
      s->nfree = 0;
      for (i = 0; i < n; i++) {
         if (!s->activeset.xB[i]) {
            s->nfree++;
         }
      }
      j = s->nfree;
      for (i = 0; i < n; i++) {
         if (s->activeset.xB[i]) {
            s->txc.xR[j] = s->xc.xR[i];
            j++;
         }
      }
   }
   nfree = s->nfree;
// Re-evaluate TQ2/TQ1/TQ0, if needed
   if (s->isactivesetchanged || s->ismaintermchanged) {
   // Handle cases Alpha > 0 and Alpha == 0 separately:
   // * in the first case we have dense matrix
   // * in the second one we have diagonal matrix, which can be
   //   handled more efficiently
      if (s->alpha > 0.0) {
      // Alpha > 0, dense QP
      //
      // Split variables into two groups - free (F) and constrained (C). Reorder
      // variables in such way that free vars come first, constrained are last:
      // x = [xf, xc].
      //
      // Main quadratic term x'*(alpha*A+tau*D)*x now splits into quadratic part,
      // linear part and constant part:
      //                   ( alpha*Aff+tau*Df  alpha*Afc        ) ( xf )
      //   0.5*( xf' xc' )*(                                    )*(    ) =
      //                   ( alpha*Acf         alpha*Acc+tau*Dc ) ( xc )
      //
      //   = 0.5*xf'*(alpha*Aff+tau*Df)*xf + (alpha*Afc*xc)'*xf + 0.5*xc'(alpha*Acc+tau*Dc)*xc
      //
      // We store these parts into temporary variables:
      // * alpha*Aff+tau*Df, alpha*Afc, alpha*Acc+tau*Dc are stored into upper
      //   triangle of TQ2
      // * alpha*Afc*xc is stored into TQ1
      // * 0.5*xc'(alpha*Acc+tau*Dc)*xc is stored into TQ0
      //
      // Below comes first part of the work - generation of TQ2:
      // * we pass through rows of A and copy I-th row into upper block (Aff/Afc) or
      //   lower one (Acf/Acc) of TQ2, depending on presence of X[i] in the active set.
      //   RIdx0 variable contains current position for insertion into upper block,
      //   RIdx1 contains current position for insertion into lower one.
      // * within each row, we copy J-th element into left half (Aff/Acf) or right
      //   one (Afc/Acc), depending on presence of X[j] in the active set. CIdx0
      //   contains current position for insertion into left block, CIdx1 contains
      //   position for insertion into right one.
      // * during copying, we multiply elements by alpha and add diagonal matrix D.
         ridx0 = 0;
         ridx1 = s->nfree;
         for (i = 0; i < n; i++) {
            cidx0 = 0;
            cidx1 = s->nfree;
            for (j = 0; j < n; j++) {
               if (!s->activeset.xB[i] && !s->activeset.xB[j]) {
               // Element belongs to Aff
                  v = s->alpha * s->a.xyR[i][j];
                  if (i == j && s->tau > 0.0) {
                     v += s->tau * s->d.xR[i];
                  }
                  s->tq2dense.xyR[ridx0][cidx0] = v;
               }
               if (!s->activeset.xB[i] && s->activeset.xB[j]) {
               // Element belongs to Afc
                  s->tq2dense.xyR[ridx0][cidx1] = s->alpha * s->a.xyR[i][j];
               }
               if (s->activeset.xB[i] && !s->activeset.xB[j]) {
               // Element belongs to Acf
                  s->tq2dense.xyR[ridx1][cidx0] = s->alpha * s->a.xyR[i][j];
               }
               if (s->activeset.xB[i] && s->activeset.xB[j]) {
               // Element belongs to Acc
                  v = s->alpha * s->a.xyR[i][j];
                  if (i == j && s->tau > 0.0) {
                     v += s->tau * s->d.xR[i];
                  }
                  s->tq2dense.xyR[ridx1][cidx1] = v;
               }
               if (s->activeset.xB[j]) {
                  cidx1++;
               } else {
                  cidx0++;
               }
            }
            if (s->activeset.xB[i]) {
               ridx1++;
            } else {
               ridx0++;
            }
         }
      // Now we have TQ2, and we can evaluate TQ1.
      // In the special case when we have Alpha == 0, NFree == 0 or NFree == N,
      // TQ1 is filled by zeros.
         for (i = 0; i < n; i++) {
            s->tq1.xR[i] = 0.0;
         }
         if (s->nfree > 0 && s->nfree < n) {
            rmatrixmv(s->nfree, n - s->nfree, &s->tq2dense, 0, s->nfree, 0, &s->txc, s->nfree, &s->tq1, 0);
         }
      // And finally, we evaluate TQ0.
         v = 0.0;
         for (i = s->nfree; i < n; i++) {
            for (j = s->nfree; j < n; j++) {
               v += 0.5 * s->txc.xR[i] * s->tq2dense.xyR[i][j] * s->txc.xR[j];
            }
         }
         s->tq0 = v;
      } else {
      // Alpha == 0, diagonal QP
      //
      // Split variables into two groups - free (F) and constrained (C). Reorder
      // variables in such way that free vars come first, constrained are last:
      // x = [xf, xc].
      //
      // Main quadratic term x'*(tau*D)*x now splits into quadratic and constant
      // parts:
      //                   ( tau*Df        ) ( xf )
      //   0.5*( xf' xc' )*(               )*(    ) =
      //                   (        tau*Dc ) ( xc )
      //
      //   = 0.5*xf'*(tau*Df)*xf + 0.5*xc'(tau*Dc)*xc
      //
      // We store these parts into temporary variables:
      // * tau*Df is stored in TQ2Diag
      // * 0.5*xc'(tau*Dc)*xc is stored into TQ0
         s->tq0 = 0.0;
         ridx0 = 0;
         for (i = 0; i < n; i++) {
            if (!s->activeset.xB[i]) {
               s->tq2diag.xR[ridx0] = s->tau * s->d.xR[i];
               ridx0++;
            } else {
               s->tq0 += 0.5 * s->tau * s->d.xR[i] * sqr(s->xc.xR[i]);
            }
         }
         for (i = 0; i < n; i++) {
            s->tq1.xR[i] = 0.0;
         }
      }
   }
// Re-evaluate TK2/TK1/TK0, if needed
   if (s->isactivesetchanged || s->issecondarytermchanged) {
   // Split variables into two groups - free (F) and constrained (C). Reorder
   // variables in such way that free vars come first, constrained are last:
   // x = [xf, xc].
   //
   // Secondary term theta*(Q*x-r)'*(Q*x-r) now splits into quadratic part,
   // linear part and constant part:
   //             (          ( xf )     )'  (          ( xf )     )
   //   0.5*theta*( (Qf Qc)'*(    ) - r ) * ( (Qf Qc)'*(    ) - r ) =
   //             (          ( xc )     )   (          ( xc )     )
   //
   //   = 0.5*theta*xf'*(Qf'*Qf)*xf + theta*((Qc*xc-r)'*Qf)*xf +
   //     + theta*(-r'*(Qc*xc-r)-0.5*r'*r+0.5*xc'*Qc'*Qc*xc)
   //
   // We store these parts into temporary variables:
   // * sqrt(theta)*Qf is stored into TK2
   // * theta*((Qc*xc-r)'*Qf) is stored into TK1
   // * theta*(-r'*(Qc*xc-r)-0.5*r'*r+0.5*xc'*Qc'*Qc*xc) is stored into TK0
   //
   // We use several other temporaries to store intermediate results:
   // * Tmp0 - to store Qc*xc-r
   // * Tmp1 - to store Qc*xc
   //
   // Generation of TK2/TK1/TK0 is performed as follows:
   // * we fill TK2/TK1/TK0 (to handle K == 0 or Theta == 0)
   // * other steps are performed only for K > 0 and Theta > 0
   // * we pass through columns of Q and copy I-th column into left block (Qf) or
   //   right one (Qc) of TK2, depending on presence of X[i] in the active set.
   //   CIdx0 variable contains current position for insertion into upper block,
   //   CIdx1 contains current position for insertion into lower one.
   // * we calculate Qc*xc-r and store it into Tmp0
   // * we calculate TK0 and TK1
   // * we multiply leading part of TK2 which stores Qf by sqrt(theta)
   //   it is important to perform this step AFTER calculation of TK0 and TK1,
   //   because we need original (non-modified) Qf to calculate TK0 and TK1.
      for (j = 0; j < n; j++) {
         for (i = 0; i < k; i++) {
            s->tk2.xyR[i][j] = 0.0;
         }
         s->tk1.xR[j] = 0.0;
      }
      s->tk0 = 0.0;
      if (s->k > 0 && s->theta > 0.0) {
      // Split Q into Qf and Qc
      // Calculate Qc*xc-r, store in Tmp0
         vectorsetlengthatleast(&s->tmp0, k);
         vectorsetlengthatleast(&s->tmp1, k);
         cidx0 = 0;
         cidx1 = nfree;
         for (i = 0; i < k; i++) {
            s->tmp1.xR[i] = 0.0;
         }
         for (j = 0; j < n; j++) {
            if (s->activeset.xB[j]) {
               for (i = 0; i < k; i++) {
                  s->tk2.xyR[i][cidx1] = s->q.xyR[i][j];
                  s->tmp1.xR[i] += s->q.xyR[i][j] * s->txc.xR[cidx1];
               }
               cidx1++;
            } else {
               for (i = 0; i < k; i++) {
                  s->tk2.xyR[i][cidx0] = s->q.xyR[i][j];
               }
               cidx0++;
            }
         }
         for (i = 0; i < k; i++) {
            s->tmp0.xR[i] = s->tmp1.xR[i] - s->r.xR[i];
         }
      // Calculate TK0
         v = 0.0;
         for (i = 0; i < k; i++) {
            v += s->theta * (0.5 * sqr(s->tmp1.xR[i]) - s->r.xR[i] * s->tmp0.xR[i] - 0.5 * sqr(s->r.xR[i]));
         }
         s->tk0 = v;
      // Calculate TK1
         if (nfree > 0) {
            for (i = 0; i < k; i++) {
               v = s->theta * s->tmp0.xR[i];
               ae_v_addd(s->tk1.xR, 1, s->tk2.xyR[i], 1, nfree, v);
            }
         }
      // Calculate TK2
         if (nfree > 0) {
            v = sqrt(s->theta);
            for (i = 0; i < k; i++) {
               ae_v_muld(s->tk2.xyR[i], 1, nfree, v);
            }
         }
      }
   }
// Re-evaluate TB
   if (s->isactivesetchanged || s->islineartermchanged) {
      ridx0 = 0;
      ridx1 = nfree;
      for (i = 0; i < n; i++) {
         if (s->activeset.xB[i]) {
            s->tb.xR[ridx1] = s->b.xR[i];
            ridx1++;
         } else {
            s->tb.xR[ridx0] = s->b.xR[i];
            ridx0++;
         }
      }
   }
// Compose ECA: either dense ECA or diagonal ECA
   if ((s->isactivesetchanged || s->ismaintermchanged) && nfree > 0) {
      if (s->alpha > 0.0) {
      // Dense ECA
         s->ecakind = 0;
         for (i = 0; i < nfree; i++) {
            for (j = i; j < nfree; j++) {
               s->ecadense.xyR[i][j] = s->tq2dense.xyR[i][j];
            }
         }
         if (!spdmatrixcholeskyrec(&s->ecadense, 0, nfree, true, &s->tmp0)) {
            result = false;
            return result;
         }
      } else {
      // Diagonal ECA
         s->ecakind = 1;
         for (i = 0; i < nfree; i++) {
            if (s->tq2diag.xR[i] < 0.0) {
               result = false;
               return result;
            }
            s->ecadiag.xR[i] = sqrt(s->tq2diag.xR[i]);
         }
      }
   }
// Compose EQ
   if (s->isactivesetchanged || s->issecondarytermchanged) {
      for (i = 0; i < k; i++) {
         for (j = 0; j < nfree; j++) {
            s->eq.xyR[i][j] = s->tk2.xyR[i][j];
         }
      }
   }
// Calculate ECCM
   if ((s->isactivesetchanged || s->ismaintermchanged || s->issecondarytermchanged) && s->k > 0 && s->theta > 0.0 && nfree > 0) {
   // Calculate ECCM - Cholesky factor of the "effective" capacitance
   // matrix CM = I + EQ*inv(EffectiveA)*EQ'.
   //
   // We calculate CM as follows:
   //   CM = I + EQ*inv(EffectiveA)*EQ'
   //      = I + EQ*ECA^(-1)*ECA^(-T)*EQ'
   //      = I + (EQ*ECA^(-1))*(EQ*ECA^(-1))'
   //
   // Then we perform Cholesky decomposition of CM.
      matrixsetlengthatleast(&s->tmp2, k, n);
      rmatrixcopy(k, nfree, &s->eq, 0, 0, &s->tmp2, 0, 0);
      ae_assert(s->ecakind == 0 || s->ecakind == 1, "CQMRebuild: unexpected ECAKind");
      if (s->ecakind == 0) {
         rmatrixrighttrsm(k, nfree, &s->ecadense, 0, 0, true, false, 0, &s->tmp2, 0, 0);
      }
      if (s->ecakind == 1) {
         for (i = 0; i < k; i++) {
            for (j = 0; j < nfree; j++) {
               s->tmp2.xyR[i][j] /= s->ecadiag.xR[j];
            }
         }
      }
      for (i = 0; i < k; i++) {
         for (j = 0; j < k; j++) {
            s->eccm.xyR[i][j] = 0.0;
         }
         s->eccm.xyR[i][i] = 1.0;
      }
      rmatrixsyrk(k, nfree, 1.0, &s->tmp2, 0, 0, 0, 1.0, &s->eccm, 0, 0, true);
      if (!spdmatrixcholeskyrec(&s->eccm, 0, k, true, &s->tmp0)) {
         result = false;
         return result;
      }
   }
// Compose EB and EC
//
// NOTE: because these quantities are cheap to compute, we do not
// use caching here.
   for (i = 0; i < nfree; i++) {
      s->eb.xR[i] = s->tq1.xR[i] + s->tk1.xR[i] + s->tb.xR[i];
   }
   s->ec = s->tq0 + s->tk0;
   for (i = nfree; i < n; i++) {
      s->ec += s->tb.xR[i] * s->txc.xR[i];
   }
// Change cache status - everything is cached
   s->ismaintermchanged = false;
   s->issecondarytermchanged = false;
   s->islineartermchanged = false;
   s->isactivesetchanged = false;
   return result;
}

// Internal function, solves system Effective_A*x = b.
// It should be called after successful completion of CQMRebuild().
//
// Inputs:
//     S       -   quadratic model, after call to CQMRebuild()
//     X       -   right part B, array[S.NFree]
//     Tmp     -   temporary array, automatically reallocated if needed
//
// Outputs:
//     X       -   solution, array[S.NFree]
//
// NOTE: when called with zero S.NFree, returns silently
// NOTE: this function assumes that EA is non-degenerate
// ALGLIB: Copyright 10.05.2011 by Sergey Bochkanov
static void cqmodels_cqmsolveea(convexquadraticmodel *s, RVector *x, RVector *tmp) {
   ae_int_t i;
   ae_assert(s->ecakind == 0 || s->ecakind == 1 || s->ecakind == -1 && s->nfree == 0, "CQMSolveEA: unexpected ECAKind");
   if (s->ecakind == 0) {
   // Dense ECA, use FBLSCholeskySolve() dense solver.
      fblscholeskysolve(&s->ecadense, 1.0, s->nfree, true, x, tmp);
   }
   if (s->ecakind == 1) {
   // Diagonal ECA
      for (i = 0; i < s->nfree; i++) {
         x->xR[i] /= sqr(s->ecadiag.xR[i]);
      }
   }
}

// This subroutine finds optimum of the model. It returns  False  on  failure
// (indefinite/semidefinite matrix).  Optimum  is  found  subject  to  active
// constraints.
//
// Inputs:
//     S       -   model
//     X       -   possibly preallocated buffer; automatically resized, if
//                 too small enough.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
bool cqmconstrainedoptimum(convexquadraticmodel *s, RVector *x) {
   const ae_int_t newtonrefinementits = 3;
   ae_int_t n;
   ae_int_t nfree;
   ae_int_t k;
   ae_int_t i;
   double v;
   ae_int_t cidx0;
   ae_int_t itidx;
   bool result;
// Rebuild internal structures
   if (!cqmodels_cqmrebuild(s)) {
      result = false;
      return result;
   }
   n = s->n;
   k = s->k;
   nfree = s->nfree;
   result = true;
// Calculate initial point for the iterative refinement:
// * free components are set to zero
// * constrained components are set to their constrained values
   vectorsetlengthatleast(x, n);
   for (i = 0; i < n; i++) {
      if (s->activeset.xB[i]) {
         x->xR[i] = s->xc.xR[i];
      } else {
         x->xR[i] = 0.0;
      }
   }
// Iterative refinement.
//
// In an ideal world without numerical errors it would be enough
// to make just one Newton step from initial point:
//   x_new = -H^(-1)*grad(x == 0)
// However, roundoff errors can significantly deteriorate quality
// of the solution. So we have to recalculate gradient and to
// perform Newton steps several times.
//
// Below we perform fixed number of Newton iterations.
   for (itidx = 0; itidx < newtonrefinementits; itidx++) {
   // Calculate gradient at the current point.
   // Move free components of the gradient in the beginning.
      cqmgradunconstrained(s, x, &s->tmpg);
      cidx0 = 0;
      for (i = 0; i < n; i++) {
         if (!s->activeset.xB[i]) {
            s->tmpg.xR[cidx0] = s->tmpg.xR[i];
            cidx0++;
         }
      }
   // Free components of the extrema are calculated in the first NFree elements of TXC.
   //
   // First, we have to calculate original Newton step, without rank-K perturbations
      ae_v_moveneg(s->txc.xR, 1, s->tmpg.xR, 1, nfree);
      cqmodels_cqmsolveea(s, &s->txc, &s->tmp0);
   // Then, we account for rank-K correction.
   // Woodbury matrix identity is used.
      if (s->k > 0 && s->theta > 0.0) {
         vectorsetlengthatleast(&s->tmp0, imax2(nfree, k));
         vectorsetlengthatleast(&s->tmp1, imax2(nfree, k));
         ae_v_moveneg(s->tmp1.xR, 1, s->tmpg.xR, 1, nfree);
         cqmodels_cqmsolveea(s, &s->tmp1, &s->tmp0);
         for (i = 0; i < k; i++) {
            v = ae_v_dotproduct(s->eq.xyR[i], 1, s->tmp1.xR, 1, nfree);
            s->tmp0.xR[i] = v;
         }
         fblscholeskysolve(&s->eccm, 1.0, k, true, &s->tmp0, &s->tmp1);
         for (i = 0; i < nfree; i++) {
            s->tmp1.xR[i] = 0.0;
         }
         for (i = 0; i < k; i++) {
            v = s->tmp0.xR[i];
            ae_v_addd(s->tmp1.xR, 1, s->eq.xyR[i], 1, nfree, v);
         }
         cqmodels_cqmsolveea(s, &s->tmp1, &s->tmp0);
         ae_v_sub(s->txc.xR, 1, s->tmp1.xR, 1, nfree);
      }
   // Unpack components from TXC into X. We pass through all
   // free components of X and add our step.
      cidx0 = 0;
      for (i = 0; i < n; i++) {
         if (!s->activeset.xB[i]) {
            x->xR[i] += s->txc.xR[cidx0];
            cidx0++;
         }
      }
   }
   return result;
}

// This function scales vector  by  multiplying it by inverse of the diagonal
// of the Hessian matrix. It should be used to  accelerate  steepest  descent
// phase of the QP solver.
//
// Although  it  is  called  "scale-grad",  it  can be called for any vector,
// whether it is gradient, anti-gradient, or just some vector.
//
// This function does NOT takes into account current set of  constraints,  it
// just performs matrix-vector multiplication  without  taking  into  account
// constraints.
//
// Inputs:
//     S       -   model
//     X       -   vector to scale
//
// Outputs:
//     X       -   scaled vector
//
// NOTE:
//     when called for non-SPD matrices, it silently skips components of X
//     which correspond to zero or negative diagonal elements.
//
// NOTE:
//     this function uses diagonals of A and D; it ignores Q - rank-K term of
//     the quadratic model.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
void cqmscalevector(convexquadraticmodel *s, RVector *x) {
   ae_int_t n;
   ae_int_t i;
   double v;
   n = s->n;
   for (i = 0; i < n; i++) {
      v = 0.0;
      if (s->alpha > 0.0) {
         v += s->a.xyR[i][i];
      }
      if (s->tau > 0.0) {
         v += s->d.xR[i];
      }
      if (v > 0.0) {
         x->xR[i] /= v;
      }
   }
}

// This function returns diagonal of the A-term.
//
// Inputs:
//     S       -   model
//
// Outputs:
//     D       -   diagonal of the A (or zero)
// ALGLIB: Copyright 26.12.2017 by Sergey Bochkanov
void cqmgetdiaga(convexquadraticmodel *s, RVector *x) {
   ae_int_t n;
   ae_int_t i;
   n = s->n;
   vectorsetlengthatleast(x, n);
   for (i = 0; i < n; i++) {
      if (s->alpha > 0.0) {
         x->xR[i] = s->a.xyR[i][i];
      } else {
         x->xR[i] = 0.0;
      }
   }
}

// This subroutine calls CQMRebuild() and evaluates model at X subject to
// active constraints.
//
// It  is  intended  for  debug  purposes only, because it evaluates model by
// means of temporaries, which were calculated  by  CQMRebuild().  The   only
// purpose of this function  is  to  check  correctness  of  CQMRebuild()  by
// comparing results of this function with ones obtained by CQMEval(),  which
// is  used  as  reference  point. The  idea is that significant deviation in
// results  of  these  two  functions  is  evidence  of  some  error  in  the
// CQMRebuild().
//
// NOTE: suffix T denotes that temporaries marked by T-prefix are used. There
//       is one more variant of this function, which uses  "effective"  model
//       built by CQMRebuild().
//
// NOTE2: in case CQMRebuild() fails (due to model non-convexity), this
//       function returns NAN.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
double cqmdebugconstrainedevalt(convexquadraticmodel *s, RVector *x) {
   ae_int_t n;
   ae_int_t nfree;
   ae_int_t i;
   ae_int_t j;
   double v;
   double result;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMDebugConstrainedEvalT: X is not finite vector");
   if (!cqmodels_cqmrebuild(s)) {
      result = NAN;
      return result;
   }
   result = 0.0;
   nfree = s->nfree;
// Reorder variables
   j = 0;
   for (i = 0; i < n; i++) {
      if (!s->activeset.xB[i]) {
         ae_assert(j < nfree, "CQMDebugConstrainedEvalT: internal error");
         s->txc.xR[j] = x->xR[i];
         j++;
      }
   }
// TQ2, TQ1, TQ0
//
   if (s->alpha > 0.0) {
   // Dense TQ2
      for (i = 0; i < nfree; i++) {
         for (j = 0; j < nfree; j++) {
            result += 0.5 * s->txc.xR[i] * s->tq2dense.xyR[i][j] * s->txc.xR[j];
         }
      }
   } else {
   // Diagonal TQ2
      for (i = 0; i < nfree; i++) {
         result += 0.5 * s->tq2diag.xR[i] * sqr(s->txc.xR[i]);
      }
   }
   for (i = 0; i < nfree; i++) {
      result += s->tq1.xR[i] * s->txc.xR[i];
   }
   result += s->tq0;
// TK2, TK1, TK0
   if (s->k > 0 && s->theta > 0.0) {
      for (i = 0; i < s->k; i++) {
         v = 0.0;
         for (j = 0; j < nfree; j++) {
            v += s->tk2.xyR[i][j] * s->txc.xR[j];
         }
         result += 0.5 * sqr(v);
      }
      for (i = 0; i < nfree; i++) {
         result += s->tk1.xR[i] * s->txc.xR[i];
      }
      result += s->tk0;
   }
// TB (Bf and Bc parts)
   for (i = 0; i < n; i++) {
      result += s->tb.xR[i] * s->txc.xR[i];
   }
   return result;
}

// This subroutine calls CQMRebuild() and evaluates model at X subject to
// active constraints.
//
// It  is  intended  for  debug  purposes only, because it evaluates model by
// means of "effective" matrices built by CQMRebuild(). The only  purpose  of
// this function is to check correctness of CQMRebuild() by comparing results
// of this function with  ones  obtained  by  CQMEval(),  which  is  used  as
// reference  point.  The  idea  is  that significant deviation in results of
// these two functions is evidence of some error in the CQMRebuild().
//
// NOTE: suffix E denotes that effective matrices. There is one more  variant
//       of this function, which uses temporary matrices built by
//       CQMRebuild().
//
// NOTE2: in case CQMRebuild() fails (due to model non-convexity), this
//       function returns NAN.
// ALGLIB: Copyright 12.06.2012 by Sergey Bochkanov
double cqmdebugconstrainedevale(convexquadraticmodel *s, RVector *x) {
   ae_int_t n;
   ae_int_t nfree;
   ae_int_t i;
   ae_int_t j;
   double v;
   double result;
   n = s->n;
   ae_assert(isfinitevector(x, n), "CQMDebugConstrainedEvalE: X is not finite vector");
   if (!cqmodels_cqmrebuild(s)) {
      result = NAN;
      return result;
   }
   result = 0.0;
   nfree = s->nfree;
// Reorder variables
   j = 0;
   for (i = 0; i < n; i++) {
      if (!s->activeset.xB[i]) {
         ae_assert(j < nfree, "CQMDebugConstrainedEvalE: internal error");
         s->txc.xR[j] = x->xR[i];
         j++;
      }
   }
// ECA
   ae_assert(s->ecakind == 0 || s->ecakind == 1 || s->ecakind == -1 && nfree == 0, "CQMDebugConstrainedEvalE: unexpected ECAKind");
   if (s->ecakind == 0) {
   // Dense ECA
      for (i = 0; i < nfree; i++) {
         v = 0.0;
         for (j = i; j < nfree; j++) {
            v += s->ecadense.xyR[i][j] * s->txc.xR[j];
         }
         result += 0.5 * sqr(v);
      }
   }
   if (s->ecakind == 1) {
   // Diagonal ECA
      for (i = 0; i < nfree; i++) {
         result += 0.5 * sqr(s->ecadiag.xR[i] * s->txc.xR[i]);
      }
   }
// EQ
   for (i = 0; i < s->k; i++) {
      v = 0.0;
      for (j = 0; j < nfree; j++) {
         v += s->eq.xyR[i][j] * s->txc.xR[j];
      }
      result += 0.5 * sqr(v);
   }
// EB
   for (i = 0; i < nfree; i++) {
      result += s->eb.xR[i] * s->txc.xR[i];
   }
// EC
   result += s->ec;
   return result;
}

void convexquadraticmodel_init(void *_p, bool make_automatic) {
   convexquadraticmodel *p = (convexquadraticmodel *)_p;
   ae_matrix_init(&p->a, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->q, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->b, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->r, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->activeset, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->tq2dense, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tk2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tq2diag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tq1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tk1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->txc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tb, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->ecadense, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->eq, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->eccm, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ecadiag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->eb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpg, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmp2, 0, 0, DT_REAL, make_automatic);
}

void convexquadraticmodel_copy(void *_dst, const void *_src, bool make_automatic) {
   convexquadraticmodel *dst = (convexquadraticmodel *)_dst;
   const convexquadraticmodel *src = (const convexquadraticmodel *)_src;
   dst->n = src->n;
   dst->k = src->k;
   dst->alpha = src->alpha;
   dst->tau = src->tau;
   dst->theta = src->theta;
   ae_matrix_copy(&dst->a, &src->a, make_automatic);
   ae_matrix_copy(&dst->q, &src->q, make_automatic);
   ae_vector_copy(&dst->b, &src->b, make_automatic);
   ae_vector_copy(&dst->r, &src->r, make_automatic);
   ae_vector_copy(&dst->xc, &src->xc, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_vector_copy(&dst->activeset, &src->activeset, make_automatic);
   ae_matrix_copy(&dst->tq2dense, &src->tq2dense, make_automatic);
   ae_matrix_copy(&dst->tk2, &src->tk2, make_automatic);
   ae_vector_copy(&dst->tq2diag, &src->tq2diag, make_automatic);
   ae_vector_copy(&dst->tq1, &src->tq1, make_automatic);
   ae_vector_copy(&dst->tk1, &src->tk1, make_automatic);
   dst->tq0 = src->tq0;
   dst->tk0 = src->tk0;
   ae_vector_copy(&dst->txc, &src->txc, make_automatic);
   ae_vector_copy(&dst->tb, &src->tb, make_automatic);
   dst->nfree = src->nfree;
   dst->ecakind = src->ecakind;
   ae_matrix_copy(&dst->ecadense, &src->ecadense, make_automatic);
   ae_matrix_copy(&dst->eq, &src->eq, make_automatic);
   ae_matrix_copy(&dst->eccm, &src->eccm, make_automatic);
   ae_vector_copy(&dst->ecadiag, &src->ecadiag, make_automatic);
   ae_vector_copy(&dst->eb, &src->eb, make_automatic);
   dst->ec = src->ec;
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->tmpg, &src->tmpg, make_automatic);
   ae_matrix_copy(&dst->tmp2, &src->tmp2, make_automatic);
   dst->ismaintermchanged = src->ismaintermchanged;
   dst->issecondarytermchanged = src->issecondarytermchanged;
   dst->islineartermchanged = src->islineartermchanged;
   dst->isactivesetchanged = src->isactivesetchanged;
}

void convexquadraticmodel_free(void *_p, bool make_automatic) {
   convexquadraticmodel *p = (convexquadraticmodel *)_p;
   ae_matrix_free(&p->a, make_automatic);
   ae_matrix_free(&p->q, make_automatic);
   ae_vector_free(&p->b, make_automatic);
   ae_vector_free(&p->r, make_automatic);
   ae_vector_free(&p->xc, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->activeset, make_automatic);
   ae_matrix_free(&p->tq2dense, make_automatic);
   ae_matrix_free(&p->tk2, make_automatic);
   ae_vector_free(&p->tq2diag, make_automatic);
   ae_vector_free(&p->tq1, make_automatic);
   ae_vector_free(&p->tk1, make_automatic);
   ae_vector_free(&p->txc, make_automatic);
   ae_vector_free(&p->tb, make_automatic);
   ae_matrix_free(&p->ecadense, make_automatic);
   ae_matrix_free(&p->eq, make_automatic);
   ae_matrix_free(&p->eccm, make_automatic);
   ae_vector_free(&p->ecadiag, make_automatic);
   ae_vector_free(&p->eb, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->tmpg, make_automatic);
   ae_matrix_free(&p->tmp2, make_automatic);
}
} // end of namespace alglib_impl

// === LPQPSERV Package ===
// Depends on: (LinAlg) SPARSE
namespace alglib_impl {
// This function generates scaled (by S) and shifted (by XC) reformulation of
// the box constraints.
//
// Inputs:
//     S               -   scale vector, array[N]:
//                         * I-th element contains scale of I-th variable,
//                         * SC[I] > 0
//     XOrigin         -   origin term, array[N]. Can be zero.
//     BndL            -     raw lower bounds, array[N]
//     BndU            -   raw upper bounds, array[N]
//     N               -   number of variables.
//
// Outputs:
//     BndL            -   replaced by scaled/shifted lower bounds, array[N]
//     BndU            -   replaced by scaled/shifted upper bounds, array[N]
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void scaleshiftbcinplace(RVector *s, RVector *xorigin, RVector *bndl, RVector *bndu, ae_int_t n) {
   ae_int_t i;
   bool hasbndl;
   bool hasbndu;
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(s->xR[i]) && s->xR[i] > 0.0, "ScaleShiftBC: S[i] is nonpositive");
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "ScaleShiftBC: BndL[i] is +INF or NAN");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "ScaleShiftBC: BndU[i] is -INF or NAN");
      hasbndl = isfinite(bndl->xR[i]);
      hasbndu = isfinite(bndu->xR[i]);
      if (hasbndl && hasbndu && bndl->xR[i] == bndu->xR[i]) {
      // Make sure that BndL[I] == BndU[I] bit-to-bit
      // even with CRAZY optimizing compiler.
         bndu->xR[i] = (bndu->xR[i] - xorigin->xR[i]) / s->xR[i];
         bndl->xR[i] = bndu->xR[i];
         continue;
      }
      if (hasbndl) {
         bndl->xR[i] = (bndl->xR[i] - xorigin->xR[i]) / s->xR[i];
      }
      if (hasbndu) {
         bndu->xR[i] = (bndu->xR[i] - xorigin->xR[i]) / s->xR[i];
      }
   }
}

// This function generates scaled (by S) and shifted (by XC) reformulation of
// two-sided "lower-bound/range" constraints stored in dense format.
//
// Inputs:
//     S               -   scale vector, array[N]:
//                         * I-th element contains scale of I-th variable,
//                         * SC[I] > 0
//     XOrigin         -   origin term, array[N]. Can be zero.
//     N               -   number of variables.
//     DenseA          -   array[M,N], constraint matrix
//     AB              -   lower bounds for constraints, always present and
//                         finite, array[M]
//     AR              -   ranges for constraints, can be zero (equality
//                         constraint), positive (range constraint) or +INF
//                         (lower bound constraint), array[M]
//     M               -   constraint count, M >= 0
//
// Outputs:
//     DenseA          -   replaced by scaled/shifted constraints, array[M,N]
//     AB              -   replaced by scaled/shifted lower bounds, array[M]
//     AR              -   replaced by scaled/shifted ranges, array[M]
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void scaleshiftdensebrlcinplace(RVector *s, RVector *xorigin, ae_int_t n, RMatrix *densea, RVector *ab, RVector *ar, ae_int_t m) {
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   for (i = 0; i < m; i++) {
   // Scale/shift constraint; shift its lower bound
   //
   // NOTE: range is NOT scaled or shifted
      v = 0.0;
      for (j = 0; j < n; j++) {
         vv = densea->xyR[i][j];
         v += vv * xorigin->xR[j];
         densea->xyR[i][j] = vv * s->xR[j];
      }
      ab->xR[i] -= v;
   }
}

// This function generates scaled (by S) and shifted (by XC) reformulation of
// two-sided "lower-bound/range" constraints stored in dense format.
//
// Inputs:
//     S               -   scale vector, array[N]:
//                         * I-th element contains scale of I-th variable,
//                         * SC[I] > 0
//     XOrigin         -   origin term, array[N]. Can be zero.
//     N               -   number of variables.
//     SparseA         -   sparse MSparse*N constraint matrix in CRS format;
//                         ignored if MSparse == 0.
//     MSparse         -   dense constraint count, MSparse >= 0
//     DenseA          -   array[MDense,N], constraint matrix;
//                         ignored if MDense == 0.
//     MDense          -   dense constraint count, MDense >= 0
//     AB              -   lower bounds for constraints, always present and
//                         finite, array[MSparse+MDense]
//     AR              -   ranges for constraints, can be zero (equality
//                         constraint), positive (range constraint) or +INF
//                         (lower bound constraint), array[MSparse+MDense]
//
// Outputs:
//     DenseA          -   replaced by scaled/shifted constraints, array[MDense,N]
//     SparseA         -   replaced by scaled/shifted constraints, array[MSparse,N]
//     AB              -   replaced by scaled/shifted lower bounds, array[MDense+MSparse]
//     AR              -   replaced by scaled/shifted ranges, array[MDense+MSparse]
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void scaleshiftmixedbrlcinplace(RVector *s, RVector *xorigin, ae_int_t n, sparsematrix *sparsea, ae_int_t msparse, RMatrix *densea, ae_int_t mdense, RVector *ab, RVector *ar) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t k0;
   ae_int_t k1;
   double v;
   double vv;
   ae_assert(msparse == 0 || sparsea->matrixtype == 1 && sparsea->m == msparse && sparsea->n == n, "ScaleShiftMixedBRLCInplace: non-CRS sparse constraint matrix!");
   for (i = 0; i < msparse; i++) {
   // Scale/shift constraint; shift its lower bound
   //
   // NOTE: range is NOT scaled or shifted
      v = 0.0;
      k0 = sparsea->ridx.xZ[i];
      k1 = sparsea->ridx.xZ[i + 1] - 1;
      for (k = k0; k <= k1; k++) {
         j = sparsea->idx.xZ[k];
         vv = sparsea->vals.xR[k];
         v += vv * xorigin->xR[j];
         sparsea->vals.xR[k] = vv * s->xR[j];
      }
      ab->xR[i] -= v;
   }
   for (i = 0; i < mdense; i++) {
   // Scale/shift constraint; shift its lower bound
   //
   // NOTE: range is NOT scaled or shifted
      v = 0.0;
      for (j = 0; j < n; j++) {
         vv = densea->xyR[i][j];
         v += vv * xorigin->xR[j];
         densea->xyR[i][j] = vv * s->xR[j];
      }
      ab->xR[msparse + i] -= v;
   }
}

// This function generates scaled (by S) reformulation of dense quadratic and
// linear terms in QP problem.
//
// Inputs:
//     N               -   number of variables.
//     DenseA          -   array[NMain,NMain], quadratic term
//     IsUpper         -   whether upper or lower triangle is present
//     NMain           -   number of nonslack vars, 1 <= NMain <= NTotal
//     DenseB          -   array[NTotal], linear term
//     NTotal          -   total number of variables, NTotal >= 1
//     S               -   scale vector, array[NTotal]:
//                         * I-th element contains scale of I-th variable,
//                         * SC[I] > 0
//
// Outputs:
//     DenseA          -   replaced by scaled term, array[N,N]
//     DenseB          -   replaced by scaled term, array[N]
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void scaledenseqpinplace(RMatrix *densea, bool isupper, ae_int_t nmain, RVector *denseb, ae_int_t ntotal, RVector *s) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   double si;
   for (i = 0; i < nmain; i++) {
      si = s->xR[i];
      if (isupper) {
         j0 = i;
         j1 = nmain - 1;
      } else {
         j0 = 0;
         j1 = i;
      }
      for (j = j0; j <= j1; j++) {
         densea->xyR[i][j] *= si * s->xR[j];
      }
   }
   for (i = 0; i < ntotal; i++) {
      denseb->xR[i] *= s->xR[i];
   }
}

// This function generates scaled (by S) reformulation of sparse quadratic and
// linear terms in QP problem.
//
// Inputs:
//     S               -   scale vector, array[N]:
//                         * I-th element contains scale of I-th variable,
//                         * SC[I] > 0
//     N               -   number of variables.
//     SparseA         -   quadratic term, NxN SparseMatrix in CRS format
//                         (any triangle can be present, we will scale everything)
//     DenseCorrC      -   array[CorrRank,N], low rank correction C'*D*C being
//                         added to the quadratic term
//     DenseCorrD      -   array[CorrRank], low rank correction, diagonal factors
//     CorrRank        -   correction rank, >= 0
//     DenseB          -   array[N], linear term
//
// Outputs:
//     SparseA         -   replaced by scaled term
//     DenseB          -   replaced by scaled term
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void scalesparseqpinplace(RVector *s, ae_int_t n, sparsematrix *sparsea, RMatrix *densecorrc, RVector *densecorrd, ae_int_t corrrank, RVector *denseb) {
   ae_int_t i;
   ae_int_t k0;
   ae_int_t k1;
   ae_int_t k;
   double si;
   ae_assert(sparsea->matrixtype == 1 && sparsea->m == n && sparsea->n == n, "ScaleSparseQPInplace: SparseA in unexpected format");
   for (i = 0; i < n; i++) {
      si = s->xR[i];
      k0 = sparsea->ridx.xZ[i];
      k1 = sparsea->ridx.xZ[i + 1] - 1;
      for (k = k0; k <= k1; k++) {
         sparsea->vals.xR[k] *= si * s->xR[sparsea->idx.xZ[k]];
      }
      denseb->xR[i] *= si;
   }
   for (k = 0; k < corrrank; k++) {
      for (i = 0; i < n; i++) {
         densecorrc->xyR[k][i] *= s->xR[i];
      }
   }
}

// This function normalizes two-sided "lower-bound/range" constraints  stored
// in dense format in such a way that L2 norms of rows (right hand  side  NOT
// included) become equal to 1.0. Exactly zero rows are handled correctly.
//
// Inputs:
//     DenseA          -   array[M,N], constraint matrix
//     AB              -   lower bounds for constraints, always present and
//                         finite, array[M]
//     AR              -   ranges for constraints, can be zero (equality
//                         constraint), positive (range constraint) or +INF
//                         (lower bound constraint), array[M]
//     N               -   number of variables, N >= 1.
//     M               -   constraint count, M >= 0
//     NeedNorms       -   whether we need row norms or not
//
// Outputs:
//     DenseA          -   replaced by normalized constraints, array[M,N]
//     AB              -   replaced by normalized lower bounds, array[M]
//     AR              -   replaced by normalized ranges, array[M]
//     RowNorms        -   if NeedNorms is true, leading M elements (resized
//                         if length is less than M) are filled by row norms
//                         before normalization was performed.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void normalizedensebrlcinplace(RMatrix *densea, RVector *ab, RVector *ar, ae_int_t n, ae_int_t m, RVector *rownorms, bool neednorms) {
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   if (neednorms) {
      vectorsetlengthatleast(rownorms, m);
   }
   for (i = 0; i < m; i++) {
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = densea->xyR[i][j];
         vv += v * v;
      }
      vv = sqrt(vv);
      if (neednorms) {
         rownorms->xR[i] = vv;
      }
      if (vv > 0.0) {
         vv = 1.0 / vv;
         for (j = 0; j < n; j++) {
            densea->xyR[i][j] *= vv;
         }
         ab->xR[i] *= vv;
         if (isfinite(ar->xR[i])) {
            ar->xR[i] *= vv;
         }
      }
   }
}

// This function normalizes two-sided "lower-bound/range" constraints  stored
// in dense format in such a way that L2 norms of rows (right hand  side  NOT
// included) become equal to 1.0. Exactly zero rows are handled correctly.
//
// Inputs:
//     SparseA         -   sparse MSparse*N constraint matrix in CRS format;
//                         ignored if MSparse == 0.
//     MSparse         -   dense constraint count, MSparse >= 0
//     DenseA          -   array[MDense,N], constraint matrix;
//                         ignored if MDense == 0.
//     MDense          -   dense constraint count, MDense >= 0
//     AB              -   lower bounds for constraints, always present and
//                         finite, array[MSparse+MDense]
//     AR              -   ranges for constraints, can be zero (equality
//                         constraint), positive (range constraint) or +INF
//                         (lower bound constraint), array[MSparse+MDense]
//     N               -   number of variables, N >= 1.
//     LimitedAmplification-   whether row amplification is limited or not:
//                         * if False, rows with small norms (less than 1.0)
//                           are always normalized
//                         * if True, we do not increase individual row norms
//                           during normalization - only decrease. However,
//                           we may apply one amplification rount to entire
//                           constraint matrix, i.e. amplify all rows by same
//                           coefficient. As result, we do not overamplify
//                           any single row, but still make sure than entire
//                           problem is well scaled.
//                         If True, only large rows are normalized.
//     NeedNorms       -   whether we need row norms or not
//
// Outputs:
//     DenseA          -   replaced by normalized constraints, array[M,N]
//     AB              -   replaced by normalized lower bounds, array[M]
//     AR              -   replaced by normalized ranges, array[M]
//     RowNorms        -   if NeedNorms is true, leading M elements (resized
//                         if length is less than M) are filled by row norms
//                         before normalization was performed.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void normalizemixedbrlcinplace(sparsematrix *sparsea, ae_int_t msparse, RMatrix *densea, ae_int_t mdense, RVector *ab, RVector *ar, ae_int_t n, bool limitedamplification, RVector *rownorms, bool neednorms) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t k0;
   ae_int_t k1;
   double v;
   double vv;
   double maxnrm2;
   ae_assert(msparse == 0 || sparsea->matrixtype == 1 && sparsea->m == msparse && sparsea->n == n, "ScaleShiftMixedBRLCInplace: non-CRS sparse constraint matrix!");
   if (neednorms) {
      vectorsetlengthatleast(rownorms, mdense + msparse);
   }
// First round of normalization - normalize row 2-norms subject to limited amplification status
   maxnrm2 = 0.0;
   for (i = 0; i < msparse; i++) {
      vv = 0.0;
      k0 = sparsea->ridx.xZ[i];
      k1 = sparsea->ridx.xZ[i + 1] - 1;
      for (k = k0; k <= k1; k++) {
         v = sparsea->vals.xR[k];
         vv += v * v;
      }
      vv = sqrt(vv);
      maxnrm2 = rmax2(maxnrm2, vv);
      if (limitedamplification) {
         vv = rmax2(vv, 1.0);
      }
      if (neednorms) {
         rownorms->xR[i] = vv;
      }
      if (vv > 0.0) {
         vv = 1.0 / vv;
         for (k = k0; k <= k1; k++) {
            sparsea->vals.xR[k] *= vv;
         }
         ab->xR[i] *= vv;
         if (isfinite(ar->xR[i])) {
            ar->xR[i] *= vv;
         }
      }
   }
   for (i = 0; i < mdense; i++) {
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = densea->xyR[i][j];
         vv += v * v;
      }
      vv = sqrt(vv);
      maxnrm2 = rmax2(maxnrm2, vv);
      if (limitedamplification) {
         vv = rmax2(vv, 1.0);
      }
      if (neednorms) {
         rownorms->xR[msparse + i] = vv;
      }
      if (vv > 0.0) {
         vv = 1.0 / vv;
         for (j = 0; j < n; j++) {
            densea->xyR[i][j] *= vv;
         }
         ab->xR[msparse + i] *= vv;
         if (isfinite(ar->xR[msparse + i])) {
            ar->xR[msparse + i] *= vv;
         }
      }
   }
// If amplification was limited, perform second round of normalization
   if (limitedamplification && maxnrm2 < 1.0 && maxnrm2 > 0.0) {
      if (neednorms) {
         rmulv(mdense + msparse, maxnrm2, rownorms);
      }
      vv = 1.0 / maxnrm2;
      for (i = 0; i < msparse; i++) {
         k0 = sparsea->ridx.xZ[i];
         k1 = sparsea->ridx.xZ[i + 1] - 1;
         for (k = k0; k <= k1; k++) {
            sparsea->vals.xR[k] *= vv;
         }
         ab->xR[i] *= vv;
         if (isfinite(ar->xR[i])) {
            ar->xR[i] *= vv;
         }
      }
      for (i = 0; i < mdense; i++) {
         rmulr(n, vv, densea, i);
         ab->xR[msparse + i] *= vv;
         if (isfinite(ar->xR[msparse + i])) {
            ar->xR[msparse + i] *= vv;
         }
      }
   }
}

// This function normalizes dense QP problem in such a way that maximum  over
// its linear/quadratic coefficients max(max(A),max(B)) becomes equal to 1.0.
//
// NOTE: completely zero A and B are handled correctly.
//
// Inputs:
//     DenseA          -   array[NMain,NMain], quadratic term
//     IsUpper         -   whether upper or lower triangle is present
//     NMain           -   number of nonslack vars, 1 <= NMain <= NTotal
//     DenseB          -   array[NTotal], linear term
//     NTotal          -   total number of variables.
//
// Outputs:
//     DenseA          -   replaced by normalized term
//     DenseB          -   replaced by normalized term
//
// Result:
//     max(max(A),max(B)) is returned
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
double normalizedenseqpinplace(RMatrix *densea, bool isupper, ae_int_t nmain, RVector *denseb, ae_int_t ntotal) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   double mx;
   double v;
   double result;
   mx = 0.0;
   for (i = 0; i < nmain; i++) {
      if (isupper) {
         j0 = i;
         j1 = nmain - 1;
      } else {
         j0 = 0;
         j1 = i;
      }
      for (j = j0; j <= j1; j++) {
         mx = rmax2(mx, fabs(densea->xyR[i][j]));
      }
   }
   for (i = 0; i < ntotal; i++) {
      mx = rmax2(mx, fabs(denseb->xR[i]));
   }
   result = mx;
   if (mx == 0.0) {
      return result;
   }
   v = 1.0 / mx;
   for (i = 0; i < nmain; i++) {
      if (isupper) {
         j0 = i;
         j1 = nmain - 1;
      } else {
         j0 = 0;
         j1 = i;
      }
      for (j = j0; j <= j1; j++) {
         densea->xyR[i][j] *= v;
      }
   }
   for (i = 0; i < ntotal; i++) {
      denseb->xR[i] *= v;
   }
   return result;
}

// This function normalizes sparse QP problem in such a way that maximum over
// its linear/quadratic coefficients max(max(A),max(B)) becomes equal to 1.0.
//
// NOTE: completely zero A and B are handled correctly.
//
// Inputs:
//     SparseA         -   Sparse NxN matrix, either upper or lower triangle,
//                         diagonal MUST be present
//     IsUpper         -   which triangle is present (other one is ignored)
//     DenseCorrC      -   array[CorrRank,N], low rank correction C'*D*C being
//                         added to the quadratic term
//     DenseCorrD      -   array[CorrRank], low rank correction, diagonal factors
//     CorrRank        -   correction rank, >= 0
//     DenseB          -   array[N], linear term
//     N               -   number of variables.
//
// Outputs:
//     DenseA          -   replaced by normalized term, array[N,N]
//     DenseB          -   replaced by normalized term, array[N]
//
// Result:
//     max(max(A),max(B)) is returned
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
double normalizesparseqpinplace(sparsematrix *sparsea, bool isupper, RMatrix *densecorrc, RVector *densecorrd, ae_int_t corrrank, RVector *denseb, ae_int_t n) {
   ae_int_t i;
   ae_int_t k;
   ae_int_t k0;
   ae_int_t k1;
   double mx;
   double v;
   double result;
   ae_assert(sparsea->matrixtype == 1 && sparsea->m == n && sparsea->n == n, "ScaleSparseQPInplace: SparseA in unexpected format");
   mx = 0.0;
   for (i = 0; i < n; i++) {
      ae_assert(sparsea->didx.xZ[i] + 1 == sparsea->uidx.xZ[i], "NormalizeSparseQPInplace: critical integrity check failed, sparse diagonal not found");
      v = sparsea->vals.xR[sparsea->didx.xZ[i]];
      for (k = 0; k < corrrank; k++) {
         v += densecorrd->xR[k] * sqr(densecorrc->xyR[k][i]);
      }
      mx = rmax2(mx, fabs(v));
      mx = rmax2(mx, fabs(denseb->xR[i]));
   }
   result = mx;
   if (mx == 0.0) {
      return result;
   }
   v = 1.0 / mx;
   for (i = 0; i < n; i++) {
      k0 = sparsea->ridx.xZ[i];
      k1 = sparsea->ridx.xZ[i + 1] - 1;
      for (k = k0; k <= k1; k++) {
         sparsea->vals.xR[k] *= v;
      }
      denseb->xR[i] *= v;
   }
   for (k = 0; k < corrrank; k++) {
      densecorrd->xR[k] *= v;
   }
   return result;
}

// This function performs transformation of X from scaled/shifted coordinates
// to unscaled/unshifted ones, paying special attention to box constraints:
// * points which were exactly at the boundary before scaling will be  mapped
//   to corresponding boundary after scaling
// * in any case, unscaled box constraints will be satisfied
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
void unscaleunshiftpointbc(RVector *s, RVector *xorigin, RVector *rawbndl, RVector *rawbndu, RVector *sclsftbndl, RVector *sclsftbndu, BVector *hasbndl, BVector *hasbndu, RVector *x, ae_int_t n) {
   ae_int_t i;
   for (i = 0; i < n; i++) {
      if (hasbndl->xB[i] && x->xR[i] <= sclsftbndl->xR[i]) {
         x->xR[i] = rawbndl->xR[i];
         continue;
      }
      if (hasbndu->xB[i] && x->xR[i] >= sclsftbndu->xR[i]) {
         x->xR[i] = rawbndu->xR[i];
         continue;
      }
      x->xR[i] = x->xR[i] * s->xR[i] + xorigin->xR[i];
      if (hasbndl->xB[i] && x->xR[i] <= rawbndl->xR[i]) {
         x->xR[i] = rawbndl->xR[i];
      }
      if (hasbndu->xB[i] && x->xR[i] >= rawbndu->xR[i]) {
         x->xR[i] = rawbndu->xR[i];
      }
   }
}
} // end of namespace alglib_impl

// === SNNLS Package ===
// Depends on: (LinAlg) TRFAC, FBLS
namespace alglib_impl {
// This subroutine is used to initialize SNNLS solver.
//
// By default, empty NNLS problem is produced, but we allocated enough  space
// to store problems with NSMax+NDMax columns and  NRMax  rows.  It  is  good
// place to provide algorithm with initial estimate of the space requirements,
// although you may underestimate problem size or even pass zero estimates  -
// in this case buffer variables will be resized automatically  when  you set
// NNLS problem.
//
// Previously allocated buffer variables are reused as much as possible. This
// function does not clear structure completely, it tries to preserve as much
// dynamically allocated memory as possible.
// ALGLIB: Copyright 10.10.2012 by Sergey Bochkanov
void snnlsinit(ae_int_t nsmax, ae_int_t ndmax, ae_int_t nrmax, snnlssolver *s) {
   s->ns = 0;
   s->nd = 0;
   s->nr = 0;
   matrixsetlengthatleast(&s->densea, nrmax, ndmax);
   matrixsetlengthatleast(&s->tmpca, nrmax, ndmax);
   vectorsetlengthatleast(&s->b, nrmax);
   vectorsetlengthatleast(&s->nnc, nsmax + ndmax);
   s->debugflops = 0.0;
   s->debugmaxinnerits = 0;
}

// This subroutine is used to set NNLS problem:
//
//         ( [ 1     |      ]   [   ]   [   ] )^2
//         ( [   1   |      ]   [   ]   [   ] )
//     min ( [     1 |  Ad  ] * [ x ] - [ b ] )    s.t. x >= 0
//         ( [       |      ]   [   ]   [   ] )
//         ( [       |      ]   [   ]   [   ] )
//
// where:
// * identity matrix has NS*NS size (NS <= NR, NS can be zero)
// * dense matrix Ad has NR*ND size
// * b is NR*1 vector
// * x is (NS+ND)*1 vector
// * all elements of x are non-negative (this constraint can be removed later
//   by calling SNNLSDropNNC() function)
//
// Previously allocated buffer variables are reused as much as possible.
// After you set problem, you can solve it with SNNLSSolve().
//
// Inputs:
//     S   -   SNNLS solver, must be initialized with SNNLSInit() call
//     A   -   array[NR,ND], dense part of the system
//     B   -   array[NR], right part
//     NS  -   size of the sparse part of the system, 0 <= NS <= NR
//     ND  -   size of the dense part of the system, ND >= 0
//     NR  -   rows count, NR > 0
//
// NOTE:
//     1. You can have NS+ND == 0, solver will correctly accept such combination
//        and return empty array as problem solution.
// ALGLIB: Copyright 10.10.2012 by Sergey Bochkanov
void snnlssetproblem(snnlssolver *s, RMatrix *a, RVector *b, ae_int_t ns, ae_int_t nd, ae_int_t nr) {
   ae_int_t i;
   ae_assert(nd >= 0, "SNNLSSetProblem: ND < 0");
   ae_assert(ns >= 0, "SNNLSSetProblem: NS < 0");
   ae_assert(nr > 0, "SNNLSSetProblem: NR <= 0");
   ae_assert(ns <= nr, "SNNLSSetProblem: NS > NR");
   ae_assert(a->rows >= nr || nd == 0, "SNNLSSetProblem: rows(A) < NR");
   ae_assert(a->cols >= nd, "SNNLSSetProblem: cols(A) < ND");
   ae_assert(b->cnt >= nr, "SNNLSSetProblem: length(B) < NR");
   ae_assert(apservisfinitematrix(a, nr, nd), "SNNLSSetProblem: A contains INF/NAN");
   ae_assert(isfinitevector(b, nr), "SNNLSSetProblem: B contains INF/NAN");
// Copy problem
   s->ns = ns;
   s->nd = nd;
   s->nr = nr;
   if (nd > 0) {
      matrixsetlengthatleast(&s->densea, nr, nd);
      for (i = 0; i < nr; i++) {
         ae_v_move(s->densea.xyR[i], 1, a->xyR[i], 1, nd);
      }
   }
   vectorsetlengthatleast(&s->b, nr);
   ae_v_move(s->b.xR, 1, b->xR, 1, nr);
   vectorsetlengthatleast(&s->nnc, ns + nd);
   for (i = 0; i < ns + nd; i++) {
      s->nnc.xB[i] = true;
   }
}

// This subroutine drops non-negativity constraint from the  problem  set  by
// SNNLSSetProblem() call. This function must be called AFTER problem is set,
// because each SetProblem() call resets constraints to their  default  state
// (all constraints are present).
//
// Inputs:
//     S   -   SNNLS solver, must be initialized with SNNLSInit() call,
//             problem must be set with SNNLSSetProblem() call.
//     Idx -   constraint index, 0 <= IDX < NS+ND
// ALGLIB: Copyright 10.10.2012 by Sergey Bochkanov
void snnlsdropnnc(snnlssolver *s, ae_int_t idx) {
   ae_assert(idx >= 0, "SNNLSDropNNC: Idx < 0");
   ae_assert(idx < s->ns + s->nd, "SNNLSDropNNC: Idx >= NS+ND");
   s->nnc.xB[idx] = false;
}

// This function calculates:
// * residual vector R = A*x-b
// * unconstrained gradient vector G
// * function value F = 0.5*|R|^2
//
// R and G must have at least N elements.
// ALGLIB: Copyright 15.07.2015 by Sergey Bochkanov
static void snnls_funcgradu(snnlssolver *s, RVector *x, RVector *r, RVector *g, double *f) {
   ae_int_t i;
   ae_int_t nr;
   ae_int_t nd;
   ae_int_t ns;
   double v;
   *f = 0.0;
   nr = s->nr;
   nd = s->nd;
   ns = s->ns;
   *f = 0.0;
   for (i = 0; i < nr; i++) {
      v = ae_v_dotproduct(s->densea.xyR[i], 1, &x->xR[ns], 1, nd);
      if (i < ns) {
         v += x->xR[i];
      }
      v -= s->b.xR[i];
      r->xR[i] = v;
      *f += 0.5 * v * v;
   }
   for (i = 0; i < ns; i++) {
      g->xR[i] = r->xR[i];
   }
   for (i = ns; i < ns + nd; i++) {
      g->xR[i] = 0.0;
   }
   for (i = 0; i < nr; i++) {
      v = r->xR[i];
      ae_v_addd(&g->xR[ns], 1, s->densea.xyR[i], 1, nd, v);
   }
}

// This function calculates function value F = 0.5*|R|^2 at X.
// ALGLIB: Copyright 15.07.2015 by Sergey Bochkanov
static void snnls_func(snnlssolver *s, RVector *x, double *f) {
   ae_int_t i;
   ae_int_t nr;
   ae_int_t nd;
   ae_int_t ns;
   double v;
   *f = 0.0;
   nr = s->nr;
   nd = s->nd;
   ns = s->ns;
   *f = 0.0;
   for (i = 0; i < nr; i++) {
      v = ae_v_dotproduct(s->densea.xyR[i], 1, &x->xR[ns], 1, nd);
      if (i < ns) {
         v += x->xR[i];
      }
      v -= s->b.xR[i];
      *f += 0.5 * v * v;
   }
}

static void snnls_trdprepare(snnlssolver *s, RVector *x, RVector *diag, double lambdav, RVector *trdd, RMatrix *trda, RVector *tmp0, RVector *tmp1, RVector *tmp2, RMatrix *tmplq) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t ns;
   ae_int_t nd;
   ae_int_t nr;
   double v;
   double cs;
   double sn;
   double r;
// Prepare
   ns = s->ns;
   nd = s->nd;
   nr = s->nr;
// Triangular reduction
   vectorsetlengthatleast(trdd, ns);
   matrixsetlengthatleast(trda, ns + nd, nd);
   matrixsetlengthatleast(tmplq, nd, nr + nd);
   for (i = 0; i < ns; i++) {
   // Apply rotation to I-th row and corresponding row of
   // regularizer. Here V is diagonal element of I-th row,
   // which is set to 1.0 or 0.0 depending on variable
   // status (constrained or not).
      v = 1.0;
      if (s->nnc.xB[i] && x->xR[i] == 0.0) {
         v = 0.0;
      }
      generaterotation(v, lambdav, &cs, &sn, &r);
      trdd->xR[i] = cs * v + sn * lambdav;
      for (j = 0; j < nd; j++) {
         v = s->densea.xyR[i][j];
         trda->xyR[i][j] = cs * v;
         tmplq->xyR[j][i] = -sn * v;
      }
   }
   for (j = 0; j < nd; j++) {
      for (i = ns; i < nr; i++) {
         tmplq->xyR[j][i] = s->densea.xyR[i][j];
      }
   }
   for (j = 0; j < nd; j++) {
      if (s->nnc.xB[ns + j] && x->xR[ns + j] == 0.0) {
      // Variable is constrained, entire row is set to zero.
         for (i = 0; i < nr; i++) {
            tmplq->xyR[j][i] = 0.0;
         }
         for (i = 0; i < ns; i++) {
            trda->xyR[i][j] = 0.0;
         }
      }
   }
   for (i = 0; i < nd; i++) {
      for (j = 0; j < nd; j++) {
         tmplq->xyR[j][nr + i] = 0.0;
      }
      tmplq->xyR[i][nr + i] = lambdav * diag->xR[i];
   }
   vectorsetlengthatleast(tmp0, nr + nd + 1);
   vectorsetlengthatleast(tmp1, nr + nd + 1);
   vectorsetlengthatleast(tmp2, nr + nd + 1);
   rmatrixlqbasecase(tmplq, nd, nr + nd, tmp0, tmp1, tmp2);
   for (i = 0; i < nd; i++) {
      if (tmplq->xyR[i][i] < 0.0) {
         for (j = i; j < nd; j++) {
            tmplq->xyR[j][i] = -tmplq->xyR[j][i];
         }
      }
   }
   for (i = 0; i < nd; i++) {
      for (j = 0; j <= i; j++) {
         trda->xyR[ns + j][i] = tmplq->xyR[i][j];
      }
   }
}

static void snnls_trdsolve(RVector *trdd, RMatrix *trda, ae_int_t ns, ae_int_t nd, RVector *d) {
   ae_int_t i;
   ae_int_t j;
   double v;
// Solve U'*y == d first.
//
// This section includes two parts:
// * solve diagonal part of U'
// * solve dense part of U'
   for (i = 0; i < ns; i++) {
      d->xR[i] /= trdd->xR[i];
      v = d->xR[i];
      for (j = 0; j < nd; j++) {
         d->xR[ns + j] -= v * trda->xyR[i][j];
      }
   }
   for (i = 0; i < nd; i++) {
      d->xR[ns + i] /= trda->xyR[ns + i][i];
      v = d->xR[ns + i];
      for (j = i + 1; j < nd; j++) {
         d->xR[ns + j] -= v * trda->xyR[ns + i][j];
      }
   }
// Solve U*x == y then.
//
// This section includes two parts:
// * solve trailing triangular part of U
// * solve combination of diagonal and dense parts of U
   for (i = nd - 1; i >= 0; i--) {
      v = 0.0;
      for (j = i + 1; j < nd; j++) {
         v += trda->xyR[ns + i][j] * d->xR[ns + j];
      }
      d->xR[ns + i] = (d->xR[ns + i] - v) / trda->xyR[ns + i][i];
   }
   for (i = ns - 1; i >= 0; i--) {
      v = 0.0;
      for (j = 0; j < nd; j++) {
         v += trda->xyR[i][j] * d->xR[ns + j];
      }
      d->xR[i] = (d->xR[i] - v) / trdd->xR[i];
   }
}

static void snnls_trdfixvariable(RVector *trdd, RMatrix *trda, ae_int_t ns, ae_int_t nd, ae_int_t idx, RVector *tmp) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double cs;
   double sn;
   double r;
   double v;
   double vv;
   ae_assert(ns >= 0, "TRDFixVariable: integrity error");
   ae_assert(nd >= 0, "TRDFixVariable: integrity error");
   ae_assert(ns + nd > 0, "TRDFixVariable: integrity error");
   ae_assert(idx >= 0, "TRDFixVariable: integrity error");
   ae_assert(idx < ns + nd, "TRDFixVariable: integrity error");
   vectorsetlengthatleast(tmp, nd);
// Depending on variable index, two situations are possible
   if (idx < ns) {
   // We fix variable in the diagonal part of the model. It means
   // that prior to fixing we have:
   //
   //     (     |     )
   //     (  D  |     )
   //     (     |     )
   //     (-----|  A  )
   //     (     |0    )
   //     (     |00   )
   //     (     |000  )
   //     (     |0000 )
   //     (     |00000)
   //
   // then we replace idx-th column by zeros:
   //
   //     (D 0  |     )
   //     (  0  |     )
   //     (  0 D|     )
   //     (-----|  A  )
   //     (     |     )
   //     (     |     )
   //     (     |     )
   //
   // and append row with unit element to bottom, in order to
   // regularize problem
   //
   //     (D 0  |     )
   //     (  0  |     )
   //     (  0 D|     )
   //     (-----|  A  )
   //     (     |     )
   //     (     |     )
   //     (     |     )
   //     (00100|00000) <- appended
   //
   // and then we nullify this row by applying rotations:
   //
   //     (D 0  |     )
   //     (  0  |     ) <- first rotation is applied here
   //     (  0 D|     )
   //     (-----|  A  ) <- subsequent rotations are applied to this row and rows below
   //     (     |     )
   //     (     |     )
   //     (     |     )
   //     (  0  |  0  ) <- as result, row becomes zero
   //
   // and triangular structure is preserved
      if (nd == 0) {
      // Quick exit for empty dense part
         trdd->xR[idx] = 1.0;
         return;
      }
      for (j = 0; j < nd; j++) {
      // Apply first rotation
         tmp->xR[j] = trda->xyR[idx][j];
         trda->xyR[idx][j] = 0.0;
      }
      trdd->xR[idx] = 1.0;
      for (i = 0; i < nd; i++) {
         if (tmp->xR[i] != 0.0) {
         // Apply subsequent rotations with bottom triangular part of A
            generaterotation(trda->xyR[ns + i][i], tmp->xR[i], &cs, &sn, &r);
            for (j = i; j < nd; j++) {
               v = trda->xyR[ns + i][j];
               vv = tmp->xR[j];
               trda->xyR[ns + i][j] = v * cs + vv * sn;
               tmp->xR[j] = vv * cs - v * sn;
            }
         }
      }
   } else {
   // We fix variable in the dense part of the model. It means
   // that prior to fixing we have:
   //
   //     (     |     )
   //     (  D  |     )
   //     (     |     )
   //     (-----|  A  )
   //     (     |0    )
   //     (     |00   )
   //     (     |000  )
   //     (     |0000 )
   //     (     |00000)
   //
   // then we replace idx-th column by zeros:
   //
   //     (     |  0  )
   //     (  D  |  0  )
   //     (     |  0  )
   //     (-----|A 0 A)
   //     (     |  0  )
   //     (     |  0  )
   //     (     |  0  )
   //
   // and append row with unit element to bottom, in order to
   // regularize problem
   //
   //     (     |  0  )
   //     (  D  |  0  )
   //     (     |  0  )
   //     (-----|A 0 A)
   //     (     |  0  )
   //     (     |  0  )
   //     (     |  0  )
   //     (00000|00100) <- appended
   //
   // and then we nullify this row by applying rotations:
   //
   //     (D 0  |     )
   //     (  0  |     )
   //     (  0 D|     )
   //     (-----|  A  )
   //     (     |     )
   //     (     |     ) <- first rotation is applied here
   //     (     |     ) <- subsequent rotations are applied to rows below
   //     (  0  |  0  ) <- as result, row becomes zero
   //
   // and triangular structure is preserved.
      k = idx - ns;
      for (i = 0; i < ns + nd; i++) {
         trda->xyR[i][k] = 0.0;
      }
      for (j = k + 1; j < nd; j++) {
      // Apply first rotation
         tmp->xR[j] = trda->xyR[idx][j];
         trda->xyR[idx][j] = 0.0;
      }
      trda->xyR[idx][k] = 1.0;
      for (i = k + 1; i < nd; i++) {
         if (tmp->xR[i] != 0.0) {
         // Apply subsequent rotations with bottom triangular part of A
            generaterotation(trda->xyR[ns + i][i], tmp->xR[i], &cs, &sn, &r);
            for (j = i; j < nd; j++) {
               v = trda->xyR[ns + i][j];
               vv = tmp->xR[j];
               trda->xyR[ns + i][j] = v * cs + vv * sn;
               tmp->xR[j] = vv * cs - v * sn;
            }
         }
      }
   }
}

// This subroutine is used to solve NNLS problem.
//
// Inputs:
//     S   -   SNNLS solver, must be initialized with SNNLSInit() call and
//             problem must be set up with SNNLSSetProblem() call.
//     X   -   possibly preallocated buffer, automatically resized if needed
//
// Outputs:
//     X   -   array[NS+ND], solution
//
// NOTE:
//     1. You can have NS+ND == 0, solver will correctly accept such combination
//        and return empty array as problem solution.
//
//     2. Internal field S.DebugFLOPS contains rough estimate of  FLOPs  used
//        to solve problem. It can be used for debugging purposes. This field
//        is real-valued.
// ALGLIB: Copyright 10.10.2012 by Sergey Bochkanov
void snnlssolve(snnlssolver *s, RVector *x) {
   ae_int_t i;
   ae_int_t ns;
   ae_int_t nd;
   ae_int_t nr;
   bool wasactivation;
   double lambdav;
   double v0;
   double v1;
   double v;
   ae_int_t outerits;
   ae_int_t innerits;
   ae_int_t maxouterits;
   double xtol;
   double kicklength;
   bool kickneeded;
   double f0;
   double f1;
   double dnrm;
   ae_int_t actidx;
   double stp;
   double stpmax;
// Prepare
   ns = s->ns;
   nd = s->nd;
   nr = s->nr;
   s->debugflops = 0.0;
// Handle special cases:
// * NS+ND == 0
// * ND == 0
   if (ns + nd == 0) {
      return;
   }
   if (nd == 0) {
      vectorsetlengthatleast(x, ns);
      for (i = 0; i < ns; i++) {
         x->xR[i] = s->b.xR[i];
         if (s->nnc.xB[i]) {
            x->xR[i] = rmax2(x->xR[i], 0.0);
         }
      }
      return;
   }
// Main cycle of BLEIC-SNNLS algorithm.
// Below we assume that ND > 0.
   vectorsetlengthatleast(x, ns + nd);
   vectorsetlengthatleast(&s->xn, ns + nd);
   vectorsetlengthatleast(&s->xp, ns + nd);
   vectorsetlengthatleast(&s->g, ns + nd);
   vectorsetlengthatleast(&s->d, ns + nd);
   vectorsetlengthatleast(&s->r, nr);
   vectorsetlengthatleast(&s->diagaa, nd);
   vectorsetlengthatleast(&s->regdiag, ns + nd);
   vectorsetlengthatleast(&s->dx, ns + nd);
   for (i = 0; i < ns + nd; i++) {
      x->xR[i] = 0.0;
      s->regdiag.xR[i] = 1.0;
   }
   lambdav = 1000000.0 * machineepsilon;
   maxouterits = 10;
   outerits = 0;
   innerits = 0;
   xtol = 1000.0 * machineepsilon;
   kicklength = sqrt(minrealnumber);
   while (true) {
   // Initial check for correctness of X
      for (i = 0; i < ns + nd; i++) {
         ae_assert(!s->nnc.xB[i] || x->xR[i] >= 0.0, "SNNLS: integrity check failed");
      }
   // Calculate gradient G and constrained descent direction D
      snnls_funcgradu(s, x, &s->r, &s->g, &f0);
      for (i = 0; i < ns + nd; i++) {
         if (s->nnc.xB[i] && x->xR[i] == 0.0 && s->g.xR[i] > 0.0) {
            s->d.xR[i] = 0.0;
         } else {
            s->d.xR[i] = -s->g.xR[i];
         }
      }
   // Decide whether we need "kick" stage: special stage
   // that moves us away from boundary constraints which are
   // not strictly active (i.e. such constraints that x[i] == 0.0 and d[i] > 0).
   //
   // If we need kick stage, we make a kick - and restart iteration.
   // If not, after this block we can rely on the fact that
   // for all x[i] == 0.0 we have d[i] == 0.0
   //
   // NOTE: we do not increase outer iterations counter here
      kickneeded = false;
      for (i = 0; i < ns + nd; i++) {
         if (s->nnc.xB[i] && x->xR[i] == 0.0 && s->d.xR[i] > 0.0) {
            kickneeded = true;
         }
      }
      if (kickneeded) {
      // Perform kick.
      // Restart.
      // Do not increase iterations counter.
         for (i = 0; i < ns + nd; i++) {
            if (x->xR[i] == 0.0 && s->d.xR[i] > 0.0) {
               x->xR[i] += kicklength;
            }
         }
         continue;
      }
   // Newton phase
   // Reduce problem to constrained triangular form and perform Newton
   // steps with quick activation of constrants  (triangular  form  is
   // updated in order to handle changed constraints).
      for (i = 0; i < ns + nd; i++) {
         s->xp.xR[i] = x->xR[i];
      }
      snnls_trdprepare(s, x, &s->regdiag, lambdav, &s->trdd, &s->trda, &s->tmp0, &s->tmp1, &s->tmp2, &s->tmplq);
      while (true) {
      // Skip if debug limit on inner iterations count is turned on.
         if (s->debugmaxinnerits > 0 && innerits >= s->debugmaxinnerits) {
            break;
         }
      // Prepare step vector.
         snnls_funcgradu(s, x, &s->r, &s->g, &f0);
         for (i = 0; i < ns + nd; i++) {
            s->d.xR[i] = -s->g.xR[i];
            if (s->nnc.xB[i] && x->xR[i] == 0.0) {
               s->d.xR[i] = 0.0;
            }
         }
         snnls_trdsolve(&s->trdd, &s->trda, ns, nd, &s->d);
      // Perform unconstrained trial step and compare function values.
         for (i = 0; i < ns + nd; i++) {
            s->xn.xR[i] = x->xR[i] + s->d.xR[i];
         }
         snnls_func(s, &s->xn, &f1);
         if (f1 >= f0) {
            break;
         }
      // Calculate length of D, maximum step and component which is
      // activated by this step. Break if D is exactly zero.
         dnrm = 0.0;
         for (i = 0; i < ns + nd; i++) {
            dnrm += sqr(s->d.xR[i]);
         }
         dnrm = sqrt(dnrm);
         actidx = -1;
         stpmax = 1.0E50;
         for (i = 0; i < ns + nd; i++) {
            if (s->nnc.xB[i] && s->d.xR[i] < 0.0) {
               v = stpmax;
               stpmax = safeminposrv(x->xR[i], -s->d.xR[i], stpmax);
               if (stpmax < v) {
                  actidx = i;
               }
            }
         }
         if (dnrm == 0.0) {
            break;
         }
      // Perform constrained step and update X
      // and triangular model.
         stp = rmin2(1.0, stpmax);
         for (i = 0; i < ns + nd; i++) {
            v = x->xR[i] + stp * s->d.xR[i];
            if (s->nnc.xB[i]) {
               v = rmax2(v, 0.0);
            }
            s->xn.xR[i] = v;
         }
         if (stp == stpmax && actidx >= 0) {
            s->xn.xR[actidx] = 0.0;
         }
         wasactivation = false;
         for (i = 0; i < ns + nd; i++) {
            if (s->xn.xR[i] == 0.0 && x->xR[i] != 0.0) {
               wasactivation = true;
               snnls_trdfixvariable(&s->trdd, &s->trda, ns, nd, i, &s->tmpcholesky);
            }
         }
         for (i = 0; i < ns + nd; i++) {
            x->xR[i] = s->xn.xR[i];
         }
      // Increment iterations counter.
      // Terminate if no constraint was activated.
         innerits++;
         if (!wasactivation) {
            break;
         }
      }
   // Update outer iterations counter.
   //
   // Break if necessary:
   // * maximum number of outer iterations performed
   // * relative change in X is small enough
      outerits++;
      if (outerits >= maxouterits) {
         break;
      }
      v = 0.0;
      for (i = 0; i < ns + nd; i++) {
         v0 = fabs(s->xp.xR[i]);
         v1 = fabs(x->xR[i]);
         if (v0 != 0.0 || v1 != 0.0) {
            v = rmax2(v, fabs(x->xR[i] - s->xp.xR[i]) / rmax2(v0, v1));
         }
      }
      if (v <= xtol) {
         break;
      }
   }
}

void snnlssolver_init(void *_p, bool make_automatic) {
   snnlssolver *p = (snnlssolver *)_p;
   ae_matrix_init(&p->densea, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->b, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nnc, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xp, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmpca, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmplq, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->trda, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->trdd, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->crb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagaa, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cborg, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpcholesky, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->r, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->regdiag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rdtmprowmap, 0, DT_INT, make_automatic);
}

void snnlssolver_copy(void *_dst, const void *_src, bool make_automatic) {
   snnlssolver *dst = (snnlssolver *)_dst;
   const snnlssolver *src = (const snnlssolver *)_src;
   dst->ns = src->ns;
   dst->nd = src->nd;
   dst->nr = src->nr;
   ae_matrix_copy(&dst->densea, &src->densea, make_automatic);
   ae_vector_copy(&dst->b, &src->b, make_automatic);
   ae_vector_copy(&dst->nnc, &src->nnc, make_automatic);
   dst->debugflops = src->debugflops;
   dst->debugmaxinnerits = src->debugmaxinnerits;
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->xp, &src->xp, make_automatic);
   ae_matrix_copy(&dst->tmpca, &src->tmpca, make_automatic);
   ae_matrix_copy(&dst->tmplq, &src->tmplq, make_automatic);
   ae_matrix_copy(&dst->trda, &src->trda, make_automatic);
   ae_vector_copy(&dst->trdd, &src->trdd, make_automatic);
   ae_vector_copy(&dst->crb, &src->crb, make_automatic);
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_vector_copy(&dst->dx, &src->dx, make_automatic);
   ae_vector_copy(&dst->diagaa, &src->diagaa, make_automatic);
   ae_vector_copy(&dst->cb, &src->cb, make_automatic);
   ae_vector_copy(&dst->cx, &src->cx, make_automatic);
   ae_vector_copy(&dst->cborg, &src->cborg, make_automatic);
   ae_vector_copy(&dst->tmpcholesky, &src->tmpcholesky, make_automatic);
   ae_vector_copy(&dst->r, &src->r, make_automatic);
   ae_vector_copy(&dst->regdiag, &src->regdiag, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->tmp2, &src->tmp2, make_automatic);
   ae_vector_copy(&dst->rdtmprowmap, &src->rdtmprowmap, make_automatic);
}

void snnlssolver_free(void *_p, bool make_automatic) {
   snnlssolver *p = (snnlssolver *)_p;
   ae_matrix_free(&p->densea, make_automatic);
   ae_vector_free(&p->b, make_automatic);
   ae_vector_free(&p->nnc, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->xp, make_automatic);
   ae_matrix_free(&p->tmpca, make_automatic);
   ae_matrix_free(&p->tmplq, make_automatic);
   ae_matrix_free(&p->trda, make_automatic);
   ae_vector_free(&p->trdd, make_automatic);
   ae_vector_free(&p->crb, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->dx, make_automatic);
   ae_vector_free(&p->diagaa, make_automatic);
   ae_vector_free(&p->cb, make_automatic);
   ae_vector_free(&p->cx, make_automatic);
   ae_vector_free(&p->cborg, make_automatic);
   ae_vector_free(&p->tmpcholesky, make_automatic);
   ae_vector_free(&p->r, make_automatic);
   ae_vector_free(&p->regdiag, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->tmp2, make_automatic);
   ae_vector_free(&p->rdtmprowmap, make_automatic);
}
} // end of namespace alglib_impl

// === SACTIVESETS Package ===
// Depends on: OPTSERV, SNNLS
namespace alglib_impl {
// This   subroutine   is   used  to initialize active set. By default, empty
// N-variable model with no constraints is  generated.  Previously  allocated
// buffer variables are reused as much as possible.
//
// Two use cases for this object are described below.
//
// CASE 1 - STEEPEST DESCENT:
//
//     SASInit()
//     repeat:
//         SASReactivateConstraints()
//         SASDescentDirection()
//         SASExploreDirection()
//         SASMoveTo()
//     until convergence
//
// CASE 1 - PRECONDITIONED STEEPEST DESCENT:
//
//     SASInit()
//     repeat:
//         SASReactivateConstraintsPrec()
//         SASDescentDirectionPrec()
//         SASExploreDirection()
//         SASMoveTo()
//     until convergence
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasinit(ae_int_t n, sactiveset *s) {
   ae_int_t i;
   s->n = n;
   s->algostate = 0;
// Constraints
   s->constraintschanged = true;
   s->nec = 0;
   s->nic = 0;
   vectorsetlengthatleast(&s->bndl, n);
   vectorsetlengthatleast(&s->hasbndl, n);
   vectorsetlengthatleast(&s->bndu, n);
   vectorsetlengthatleast(&s->hasbndu, n);
   for (i = 0; i < n; i++) {
      s->bndl.xR[i] = -INFINITY;
      s->bndu.xR[i] = +INFINITY;
      s->hasbndl.xB[i] = false;
      s->hasbndu.xB[i] = false;
   }
// current point, scale
   s->hasxc = false;
   vectorsetlengthatleast(&s->xc, n);
   vectorsetlengthatleast(&s->s, n);
   vectorsetlengthatleast(&s->h, n);
   for (i = 0; i < n; i++) {
      s->xc.xR[i] = 0.0;
      s->s.xR[i] = 1.0;
      s->h.xR[i] = 1.0;
   }
// Other
   vectorsetlengthatleast(&s->unitdiagonal, n);
   for (i = 0; i < n; i++) {
      s->unitdiagonal.xR[i] = 1.0;
   }
}

// This function sets scaling coefficients for SAS object.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// During orthogonalization phase, scale is used to calculate drop tolerances
// (whether vector is significantly non-zero or not).
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sassetscale(sactiveset *state, RVector *s) {
   ae_int_t i;
   ae_assert(state->algostate == 0, "SASSetScale: you may change scale only in modification mode");
   ae_assert(s->cnt >= state->n, "SASSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "SASSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "SASSetScale: S contains zero elements");
   }
   for (i = 0; i < state->n; i++) {
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// Modification  of  the  preconditioner:  diagonal of approximate Hessian is
// used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     D       -   diagonal of the approximate Hessian, array[0..N-1],
//                 (if larger, only leading N elements are used).
//
// NOTE 1: D[i] should be positive. Exception will be thrown otherwise.
//
// NOTE 2: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sassetprecdiag(sactiveset *state, RVector *d) {
   ae_int_t i;
   ae_assert(state->algostate == 0, "SASSetPrecDiag: you may change preconditioner only in modification mode");
   ae_assert(d->cnt >= state->n, "SASSetPrecDiag: D is too short");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(d->xR[i]), "SASSetPrecDiag: D contains infinite or NAN elements");
      ae_assert(d->xR[i] > 0.0, "SASSetPrecDiag: D contains non-positive elements");
   }
   for (i = 0; i < state->n; i++) {
      state->h.xR[i] = d->xR[i];
   }
}

// This function sets/changes boundary constraints.
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF.
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF.
//
// NOTE 1: it is possible to specify BndL[i] == BndU[i]. In this case I-th
// variable will be "frozen" at X[i] == BndL[i] == BndU[i].
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sassetbc(sactiveset *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   ae_assert(state->algostate == 0, "SASSetBC: you may change constraints only in modification mode");
   n = state->n;
   ae_assert(bndl->cnt >= n, "SASSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "SASSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "SASSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "SASSetBC: BndL contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
   }
   state->constraintschanged = true;
}

// This function sets linear constraints for SAS object.
//
// Linear constraints are inactive by default (after initial creation).
//
// Inputs:
//     State   -   SAS structure
//     C       -   linear constraints, array[K,N+1].
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n+1]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n+1]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n+1]
//     K       -   number of equality/inequality constraints, K >= 0
//
// NOTE 1: linear (non-bound) constraints are satisfied only approximately:
// * there always exists some minor violation (about Epsilon in magnitude)
//   due to rounding errors
// * numerical differentiation, if used, may  lead  to  function  evaluations
//   outside  of the feasible  area,   because   algorithm  does  NOT  change
//   numerical differentiation formula according to linear constraints.
// If you want constraints to be  satisfied  exactly, try to reformulate your
// problem  in  such  manner  that  all constraints will become boundary ones
// (this kind of constraints is always satisfied exactly, both in  the  final
// solution and in all intermediate points).
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
void sassetlc(sactiveset *state, RMatrix *c, ZVector *ct, ae_int_t k) {
   ae_int_t n;
   ae_int_t i;
   ae_assert(state->algostate == 0, "SASSetLC: you may change constraints only in modification mode");
   n = state->n;
// First, check for errors in the inputs
   ae_assert(k >= 0, "SASSetLC: K < 0");
   ae_assert(c->cols > n || k == 0, "SASSetLC: Cols(C) <= N");
   ae_assert(c->rows >= k, "SASSetLC: Rows(C) < K");
   ae_assert(ct->cnt >= k, "SASSetLC: Length(CT) < K");
   ae_assert(apservisfinitematrix(c, k, n + 1), "SASSetLC: C contains infinite or NaN values!");
// Handle zero K
   if (k == 0) {
      state->nec = 0;
      state->nic = 0;
      state->constraintschanged = true;
      return;
   }
// Equality constraints are stored first, in the upper
// NEC rows of State.CLEIC matrix. Inequality constraints
// are stored in the next NIC rows.
//
// NOTE: we convert inequality constraints to the form
// A*x <= b before copying them.
   matrixsetlengthatleast(&state->cleic, k, n + 1);
   state->nec = 0;
   state->nic = 0;
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] == 0) {
         ae_v_move(state->cleic.xyR[state->nec], 1, c->xyR[i], 1, n + 1);
         state->nec++;
      }
   }
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] != 0) {
         if (ct->xZ[i] > 0) {
            ae_v_moveneg(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         } else {
            ae_v_move(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         }
         state->nic++;
      }
   }
// Mark state as changed
   state->constraintschanged = true;
}

// Another variation of SASSetLC(), which accepts  linear  constraints  using
// another representation.
//
// Linear constraints are inactive by default (after initial creation).
//
// Inputs:
//     State   -   SAS structure
//     CLEIC   -   linear constraints, array[NEC+NIC,N+1].
//                 Each row of C represents one constraint:
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 First NEC rows store equality constraints, next NIC -  are
//                 inequality ones.
//                 All elements of C (including right part) must be finite.
//     NEC     -   number of equality constraints, NEC >= 0
//     NIC     -   number of inequality constraints, NIC >= 0
//
// NOTE 1: linear (non-bound) constraints are satisfied only approximately:
// * there always exists some minor violation (about Epsilon in magnitude)
//   due to rounding errors
// * numerical differentiation, if used, may  lead  to  function  evaluations
//   outside  of the feasible  area,   because   algorithm  does  NOT  change
//   numerical differentiation formula according to linear constraints.
// If you want constraints to be  satisfied  exactly, try to reformulate your
// problem  in  such  manner  that  all constraints will become boundary ones
// (this kind of constraints is always satisfied exactly, both in  the  final
// solution and in all intermediate points).
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
void sassetlcx(sactiveset *state, RMatrix *cleic, ae_int_t nec, ae_int_t nic) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   ae_assert(state->algostate == 0, "SASSetLCX: you may change constraints only in modification mode");
   n = state->n;
// First, check for errors in the inputs
   ae_assert(nec >= 0, "SASSetLCX: NEC < 0");
   ae_assert(nic >= 0, "SASSetLCX: NIC < 0");
   ae_assert(cleic->cols > n || nec + nic == 0, "SASSetLCX: Cols(CLEIC) <= N");
   ae_assert(cleic->rows >= nec + nic, "SASSetLCX: Rows(CLEIC) < NEC+NIC");
   ae_assert(apservisfinitematrix(cleic, nec + nic, n + 1), "SASSetLCX: CLEIC contains infinite or NaN values!");
// Store constraints
   matrixsetlengthatleast(&state->cleic, nec + nic, n + 1);
   state->nec = nec;
   state->nic = nic;
   for (i = 0; i < nec + nic; i++) {
      for (j = 0; j <= n; j++) {
         state->cleic.xyR[i][j] = cleic->xyR[i][j];
      }
   }
// Mark state as changed
   state->constraintschanged = true;
}

// This subroutine turns on optimization mode:
// 1. feasibility in X is enforced  (in case X == S.XC and constraints  have not
//    changed, algorithm just uses X without any modifications at all)
// 2. constraints are marked as "candidate" or "inactive"
//
// Inputs:
//     S   -   active set object
//     X   -   initial point (candidate), array[N]. It is expected that X
//             contains only finite values (we do not check it).
//
// Outputs:
//     S   -   state is changed
//     X   -   initial point can be changed to enforce feasibility
//
// Result:
//     True in case feasible point was found (mode was changed to "optimization")
//     False in case no feasible point was found (mode was not changed)
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
bool sasstartoptimization(sactiveset *state, RVector *x) {
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t i;
   ae_int_t j;
   double v;
   double v0;
   double v1;
   double vv;
   double vc;
   double vx;
   bool result;
   ae_assert(state->algostate == 0, "SASStartOptimization: already in optimization mode");
   result = false;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
// Enforce feasibility and calculate set of "candidate"/"active" constraints.
// Always active equality constraints are marked as "active", all other constraints
// are marked as "candidate".
   vectorsetlengthatleast(&state->cstatus, n + nec + nic);
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i]) {
         if (state->bndl.xR[i] > state->bndu.xR[i]) {
            return result;
         }
      }
   }
   ae_v_move(state->xc.xR, 1, x->xR, 1, n);
   if (state->nec + state->nic > 0) {
   // General linear constraints are present.
   // Try to use fast code for feasible initial point with modest
   // memory requirements.
      vectorsetlengthatleast(&state->tmp0, n);
      state->feasinitpt = true;
      for (i = 0; i < n; i++) {
         state->tmp0.xR[i] = x->xR[i];
         state->cstatus.xZ[i] = -1;
         if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
            state->tmp0.xR[i] = state->bndl.xR[i];
            state->cstatus.xZ[i] = 1;
            continue;
         }
         if (state->hasbndl.xB[i] && state->tmp0.xR[i] <= state->bndl.xR[i]) {
            state->cstatus.xZ[i] = 0;
            state->tmp0.xR[i] = state->bndl.xR[i];
         }
         if (state->hasbndu.xB[i] && state->tmp0.xR[i] >= state->bndu.xR[i]) {
            state->cstatus.xZ[i] = 0;
            state->tmp0.xR[i] = state->bndu.xR[i];
         }
      }
      for (i = 0; i < state->nec + state->nic; i++) {
         v = -state->cleic.xyR[i][n];
         v0 = 0.0;
         v1 = 0.0;
         for (j = 0; j < n; j++) {
            vx = state->tmp0.xR[j] / state->s.xR[j];
            vc = state->cleic.xyR[i][j] * state->s.xR[j];
            v += vx * vc;
            v0 += sqr(vx);
            v1 += sqr(vc);
         }
         vv = sqrt(v0) * sqrt(v1) * 1000.0 * machineepsilon;
         if (i < state->nec) {
            state->cstatus.xZ[n + i] = 1;
            state->feasinitpt = state->feasinitpt && SmallR(v, vv);
         } else {
            state->feasinitpt = state->feasinitpt && v < vv;
            if (v < -vv) {
               state->cstatus.xZ[n + i] = -1;
            } else {
               state->cstatus.xZ[n + i] = 0;
            }
         }
      }
      if (state->feasinitpt) {
         ae_v_move(state->xc.xR, 1, state->tmp0.xR, 1, n);
      }
   // Fast code failed? Use general code with ~(N+NIC)^2 memory requirements
      if (!state->feasinitpt) {
         vectorsetlengthatleast(&state->tmp0, n);
         vectorsetlengthatleast(&state->tmpfeas, n + state->nic);
         matrixsetlengthatleast(&state->tmpm0, state->nec + state->nic, n + state->nic + 1);
         for (i = 0; i < state->nec + state->nic; i++) {
            ae_v_move(state->tmpm0.xyR[i], 1, state->cleic.xyR[i], 1, n);
            for (j = n; j < n + state->nic; j++) {
               state->tmpm0.xyR[i][j] = 0.0;
            }
            if (i >= state->nec) {
               state->tmpm0.xyR[i][n + i - state->nec] = 1.0;
            }
            state->tmpm0.xyR[i][n + state->nic] = state->cleic.xyR[i][n];
         }
         ae_v_move(state->tmpfeas.xR, 1, state->xc.xR, 1, n);
         for (i = 0; i < state->nic; i++) {
            v = ae_v_dotproduct(state->cleic.xyR[i + state->nec], 1, state->xc.xR, 1, n);
            state->tmpfeas.xR[i + n] = rmax2(state->cleic.xyR[i + state->nec][n] - v, 0.0);
         }
         if (!findfeasiblepoint(&state->tmpfeas, &state->bndl, &state->hasbndl, &state->bndu, &state->hasbndu, n, state->nic, &state->tmpm0, state->nec + state->nic, 0.000001, &i, &j)) {
            return result;
         }
         ae_v_move(state->xc.xR, 1, state->tmpfeas.xR, 1, n);
         for (i = 0; i < n; i++) {
            if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
               state->cstatus.xZ[i] = 1;
               continue;
            }
            if (state->hasbndl.xB[i] && state->xc.xR[i] == state->bndl.xR[i] || state->hasbndu.xB[i] && state->xc.xR[i] == state->bndu.xR[i]) {
               state->cstatus.xZ[i] = 0;
               continue;
            }
            state->cstatus.xZ[i] = -1;
         }
         for (i = 0; i < state->nec; i++) {
            state->cstatus.xZ[n + i] = 1;
         }
         for (i = 0; i < state->nic; i++) {
            if (state->tmpfeas.xR[n + i] == 0.0) {
               state->cstatus.xZ[n + state->nec + i] = 0;
            } else {
               state->cstatus.xZ[n + state->nec + i] = -1;
            }
         }
      }
   } else {
   // Only box constraints are present, quick code can be used
      for (i = 0; i < n; i++) {
         state->cstatus.xZ[i] = -1;
         if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
            state->cstatus.xZ[i] = 1;
            state->xc.xR[i] = state->bndl.xR[i];
            continue;
         }
         if (state->hasbndl.xB[i] && state->xc.xR[i] <= state->bndl.xR[i]) {
            state->xc.xR[i] = state->bndl.xR[i];
            state->cstatus.xZ[i] = 0;
            continue;
         }
         if (state->hasbndu.xB[i] && state->xc.xR[i] >= state->bndu.xR[i]) {
            state->xc.xR[i] = state->bndu.xR[i];
            state->cstatus.xZ[i] = 0;
            continue;
         }
      }
      state->feasinitpt = true;
   }
// Change state, allocate temporaries
   result = true;
   state->algostate = 1;
   state->basisisready = false;
   state->hasxc = true;
   return result;
}

// This function explores search direction and calculates bound for  step  as
// well as information for activation of constraints.
//
// Inputs:
//     State       -   SAS structure which stores current point and all other
//                     active set related information
//     D           -   descent direction to explore
//
// Outputs:
//     StpMax      -   upper  limit  on  step  length imposed by yet inactive
//                     constraints. Can be  zero  in  case  some  constraints
//                     can be activated by zero step.  Equal  to  some  large
//                     value in case step is unlimited.
//     CIdx        -   -1 for unlimited step, in [0,N+NEC+NIC) in case of
//                     limited step.
//     VVal        -   value which is assigned to X[CIdx] during activation.
//                     For CIdx < 0 or CIdx >= N some dummy value is assigned to
//                     this parameter.
void sasexploredirection(sactiveset *state, RVector *d, double *stpmax, ae_int_t *cidx, double *vval) {
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t i;
   double prevmax;
   double vc;
   double vd;
   *stpmax = 0.0;
   *cidx = 0;
   *vval = 0.0;
   ae_assert(state->algostate == 1, "SASExploreDirection: is not in optimization mode");
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   *cidx = -1;
   *vval = 0.0;
   *stpmax = 1.0E50;
   for (i = 0; i < n; i++) {
      if (state->cstatus.xZ[i] <= 0) {
         ae_assert(!state->hasbndl.xB[i] || state->xc.xR[i] >= state->bndl.xR[i], "SASExploreDirection: internal error - infeasible X");
         ae_assert(!state->hasbndu.xB[i] || state->xc.xR[i] <= state->bndu.xR[i], "SASExploreDirection: internal error - infeasible X");
         if (state->hasbndl.xB[i] && d->xR[i] < 0.0) {
            prevmax = *stpmax;
            *stpmax = safeminposrv(state->xc.xR[i] - state->bndl.xR[i], -d->xR[i], *stpmax);
            if (*stpmax < prevmax) {
               *cidx = i;
               *vval = state->bndl.xR[i];
            }
         }
         if (state->hasbndu.xB[i] && d->xR[i] > 0.0) {
            prevmax = *stpmax;
            *stpmax = safeminposrv(state->bndu.xR[i] - state->xc.xR[i], d->xR[i], *stpmax);
            if (*stpmax < prevmax) {
               *cidx = i;
               *vval = state->bndu.xR[i];
            }
         }
      }
   }
   for (i = nec; i < nec + nic; i++) {
      if (state->cstatus.xZ[n + i] <= 0) {
         vc = ae_v_dotproduct(state->cleic.xyR[i], 1, state->xc.xR, 1, n);
         vc -= state->cleic.xyR[i][n];
         vd = ae_v_dotproduct(state->cleic.xyR[i], 1, d->xR, 1, n);
         if (vd <= 0.0) {
            continue;
         }
         if (vc < 0.0) {
         // XC is strictly feasible with respect to I-th constraint,
         // we can perform non-zero step because there is non-zero distance
         // between XC and bound.
            prevmax = *stpmax;
            *stpmax = safeminposrv(-vc, vd, *stpmax);
            if (*stpmax < prevmax) {
               *cidx = n + i;
            }
         } else {
         // XC is at the boundary (or slightly beyond it), and step vector
         // points beyond the boundary.
         //
         // The only thing we can do is to perform zero step and activate
         // I-th constraint.
            *stpmax = 0.0;
            *cidx = n + i;
         }
      }
   }
}

// This  function  appends new constraints (if possible; sometimes it isn't!)
// to three orthonormal basises for current active set:
// * P-orthogonal one, which is orthogonalized with inner product
//   (x,y) = x'*P*y, where P == inv(H) is current preconditioner
// * S-orthogonal one, which is orthogonalized with inner product
//   (x,y) = x'*S'*S*y, where S is diagonal scaling matrix
// * I-orthogonal one, which is orthogonalized with standard dot product
//
// NOTE: all sets of orthogonal vectors are guaranteed  to  have  same  size.
//       P-orthogonal basis is built first, I/S-orthogonal basises are forced
//       to have same number of vectors as P-orthogonal one (padded  by  zero
//       vectors if needed).
//
// NOTE: this function may fail to update basis without  full  recalculation;
//       in such case it will set BasisIsReady to False and silently  return;
//       if it succeeds, it will increase BasisSize.
//
// Inputs:
//     State       -   active set object
//     NewEntries  -   array[N+NEC+NIC], indexes of constraints being  added
//                     are marked as True; it is responsibility of the caller
//                     to specify only those constraints which were previously
//                     inactive; when  some  constraint is  already  in   the
//                     active set, algorithm behavior is undefined.
//
// Outputs:
//     State   -   active set object with new basis
// ALGLIB: Copyright 03.10.2017 by Sergey Bochkanov
void sasappendtobasis(sactiveset *state, BVector *newentries) {
   const ae_int_t maxbasisage = 5;
   const double maxbasisdecay = 0.01;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t i;
   ae_int_t j;
   ae_int_t t;
   ae_int_t nact;
   double v;
   double vp;
   double vs;
   double vi;
   double initnormp;
   double projnormp;
   double projnorms;
   double projnormi;
   if (!state->basisisready) {
      return;
   }
   n = state->n;
   nec = state->nec;
   nic = state->nic;
// Count number of constraints to activate;
// perform integrity check.
   nact = 0;
   for (i = 0; i < n; i++) {
      if (newentries->xB[i]) {
         nact++;
      }
   }
   for (i = n; i < n + nec; i++) {
      ae_assert(!newentries->xB[i], "SAS: integrity check failed (appendtobasis.0)");
   }
   for (i = n + nec; i < n + nec + nic; i++) {
      if (newentries->xB[i]) {
         nact++;
      }
   }
   if (nact + state->basisage > maxbasisage) {
      state->basisisready = false;
      return;
   }
// Resize basis matrices if needed
   rmatrixgrowrowsto(&state->pdensebatch, state->densebatchsize + nact, n + 1);
   rmatrixgrowrowsto(&state->sdensebatch, state->densebatchsize + nact, n + 1);
   rmatrixgrowrowsto(&state->idensebatch, state->densebatchsize + nact, n + 1);
// Try adding recommended entries to basis.
// If reorthogonalization removes too much of candidate constraint,
// we will invalidate basis and try to rebuild it from scratch.
   vectorsetlengthatleast(&state->tmp0, n + 1);
   vectorsetlengthatleast(&state->tmpcp, n + 1);
   vectorsetlengthatleast(&state->tmpcs, n + 1);
   vectorsetlengthatleast(&state->tmpci, n + 1);
   vectorsetlengthatleast(&state->tmpprodp, n);
   vectorsetlengthatleast(&state->tmpprods, n);
   for (t = 0; t < n + nec + nic; t++) {
      if (newentries->xB[t]) {
      // Basis is full? Quick skip!
         if (state->sparsebatchsize + state->densebatchsize >= n) {
            ae_assert(state->sparsebatchsize + state->densebatchsize == n, "SAS: integrity check failed (sasappendtobasis)");
            break;
         }
      // Copy constraint to temporary storage.
         if (t < n) {
         // Copy box constraint
            for (j = 0; j <= n; j++) {
               state->tmp0.xR[j] = 0.0;
            }
            state->tmp0.xR[t] = 1.0;
            state->tmp0.xR[n] = state->xc.xR[t];
         } else {
         // Copy general linear constraint
            for (j = 0; j <= n; j++) {
               state->tmp0.xR[j] = state->cleic.xyR[t - n][j];
            }
         }
      // Calculate initial norm (preconditioner is used for norm calculation).
         initnormp = 0.0;
         for (j = 0; j < n; j++) {
            v = state->tmp0.xR[j];
            initnormp += v * v / state->h.xR[j];
         }
         initnormp = sqrt(initnormp);
         if (initnormp == 0.0) {
         // Well, it is not expected. Let's just rebuild basis
         // from scratch and forget about this strange situation...
            state->basisisready = false;
            return;
         }
      // Orthogonalize Tmp0 w.r.t. sparse batch (box constraints stored in sparse storage).
      //
      // Copy to TmpCP/TmpCS/TmpCI (P for preconditioner-based inner product
      // used for orthogonalization, S for scale-based orthogonalization,
      // I for "traditional" inner product used for Gram-Schmidt orthogonalization).
         for (i = 0; i < state->sparsebatchsize; i++) {
            j = state->sparsebatch.xZ[i];
            state->tmp0.xR[n] -= state->tmp0.xR[j] * state->xc.xR[j];
            state->tmp0.xR[j] = 0.0;
         }
         for (j = 0; j <= n; j++) {
            state->tmpcp.xR[j] = state->tmp0.xR[j];
            state->tmpcs.xR[j] = state->tmp0.xR[j];
            state->tmpci.xR[j] = state->tmp0.xR[j];
         }
      // Orthogonalize TmpCP/S/I with respect to active linear constraints from dense batch.
      // Corresponding norm (preconditioner, scale, identity) is used in each case.
         for (j = 0; j < n; j++) {
            state->tmpprodp.xR[j] = 1.0 / state->h.xR[j];
            state->tmpprods.xR[j] = sqr(state->s.xR[j]);
         }
         for (i = 0; i < state->densebatchsize; i++) {
            vp = 0.0;
            vs = 0.0;
            vi = 0.0;
            for (j = 0; j < n; j++) {
               vp += state->pdensebatch.xyR[i][j] * state->tmpcp.xR[j] * state->tmpprodp.xR[j];
               vs += state->sdensebatch.xyR[i][j] * state->tmpcs.xR[j] * state->tmpprods.xR[j];
               vi += state->idensebatch.xyR[i][j] * state->tmpci.xR[j];
            }
            ae_v_subd(state->tmpcp.xR, 1, state->pdensebatch.xyR[i], 1, n + 1, vp);
            ae_v_subd(state->tmpcs.xR, 1, state->sdensebatch.xyR[i], 1, n + 1, vs);
            ae_v_subd(state->tmpci.xR, 1, state->idensebatch.xyR[i], 1, n + 1, vi);
         }
         projnormp = 0.0;
         projnorms = 0.0;
         projnormi = 0.0;
         for (j = 0; j < n; j++) {
            projnormp += sqr(state->tmpcp.xR[j]) / state->h.xR[j];
            projnorms += sqr(state->tmpcs.xR[j]) * sqr(state->s.xR[j]);
            projnormi += sqr(state->tmpci.xR[j]);
         }
         projnormp = sqrt(projnormp);
         projnorms = sqrt(projnorms);
         projnormi = sqrt(projnormi);
         if (projnormp <= maxbasisdecay * initnormp) {
            state->basisisready = false;
            return;
         // Nearly zero row, skip
         }
         ae_assert(projnormp > 0.0, "SAS: integrity check failed, ProjNormP == 0");
         ae_assert(projnorms > 0.0, "SAS: integrity check failed, ProjNormS == 0");
         ae_assert(projnormi > 0.0, "SAS: integrity check failed, ProjNormI == 0");
         v = 1.0 / projnormp;
         ae_v_moved(state->pdensebatch.xyR[state->densebatchsize], 1, state->tmpcp.xR, 1, n + 1, v);
         v = 1.0 / projnorms;
         ae_v_moved(state->sdensebatch.xyR[state->densebatchsize], 1, state->tmpcs.xR, 1, n + 1, v);
         v = 1.0 / projnormi;
         ae_v_moved(state->idensebatch.xyR[state->densebatchsize], 1, state->tmpci.xR, 1, n + 1, v);
      // Increase set size
         state->densebatchsize++;
         state->basisage++;
      }
   }
}

// This subroutine moves current point to XN, which can be:
// a) point in the direction previously explored  with  SASExploreDirection()
//    function (in this case NeedAct/CIdx/CVal are used)
// b) point in arbitrary direction, not necessarily previously  checked  with
//    SASExploreDirection() function.
//
// Step may activate one constraint. It is assumed than XN  is  approximately
// feasible (small error as  large  as several  ulps  is  possible).   Strict
// feasibility  with  respect  to  bound  constraints  is  enforced    during
// activation, feasibility with respect to general linear constraints is  not
// enforced.
//
// This function activates boundary constraints, such that both is True:
// 1) XC[I] is not at the boundary
// 2) XN[I] is at the boundary or beyond it
//
// Inputs:
//     S       -   active set object
//     XN      -   new point.
//     NeedAct -   True in case one constraint needs activation
//     CIdx    -   index of constraint, in [0,N+NEC+NIC).
//                 Ignored if NeedAct is false.
//                 This value is calculated by SASExploreDirection().
//     CVal    -   for CIdx in [0,N) this field stores value which is
//                 assigned to XC[CIdx] during activation. CVal is ignored in
//                 other cases.
//                 This value is calculated by SASExploreDirection().
//
// Outputs:
//     S       -   current point and list of active constraints are changed.
//
// Result:
//     > 0,	in case at least one inactive non-candidate constraint was activated
//     == 0,	in case only "candidate" constraints were activated
//     < 0,	in case no constraints were activated by the step
//
// NOTE: in general case State.XC != XN because activation of  constraints  may
//       slightly change current point (to enforce feasibility).
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
ae_int_t sasmoveto(sactiveset *state, RVector *xn, bool needact, ae_int_t cidx, double cval) {
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t i;
   bool wasactivation;
   ae_int_t result;
   ae_assert(state->algostate == 1, "SASMoveTo: is not in optimization mode");
   n = state->n;
   nec = state->nec;
   nic = state->nic;
// Save previous state, update current point
   vectorsetlengthatleast(&state->mtx, n);
   vectorsetlengthatleast(&state->mtas, n + nec + nic);
   for (i = 0; i < n; i++) {
      state->mtx.xR[i] = state->xc.xR[i];
      state->xc.xR[i] = xn->xR[i];
   }
   for (i = 0; i < n + nec + nic; i++) {
      state->mtas.xZ[i] = state->cstatus.xZ[i];
   }
// Activate constraints
   vectorsetlengthatleast(&state->mtnew, n + nec + nic);
   wasactivation = false;
   for (i = 0; i < n + nec + nic; i++) {
      state->mtnew.xB[i] = false;
   }
   if (needact) {
   // Activation
      ae_assert(cidx >= 0 && cidx < n + nec + nic, "SASMoveTo: incorrect CIdx");
      if (cidx < n) {
      // CIdx in [0,N-1] means that bound constraint was activated.
      // We activate it explicitly to avoid situation when roundoff-error
      // prevents us from moving EXACTLY to x == CVal.
         state->xc.xR[cidx] = cval;
      }
      state->cstatus.xZ[cidx] = 1;
      state->mtnew.xB[cidx] = true;
      wasactivation = true;
   }
   for (i = 0; i < n; i++) {
   // Post-check (some constraints may be activated because of numerical errors)
      if (state->hasbndl.xB[i] && state->xc.xR[i] <= state->bndl.xR[i] && state->xc.xR[i] != state->mtx.xR[i]) {
         state->xc.xR[i] = state->bndl.xR[i];
         state->cstatus.xZ[i] = 1;
         state->mtnew.xB[i] = true;
         wasactivation = true;
      }
      if (state->hasbndu.xB[i] && state->xc.xR[i] >= state->bndu.xR[i] && state->xc.xR[i] != state->mtx.xR[i]) {
         state->xc.xR[i] = state->bndu.xR[i];
         state->cstatus.xZ[i] = 1;
         state->mtnew.xB[i] = true;
         wasactivation = true;
      }
   }
// Determine return status:
// * -1 in case no constraints were activated
// *  0 in case only "candidate" constraints were activated
// * +1 in case at least one "non-candidate" constraint was activated
   if (wasactivation) {
   // Step activated one/several constraints, but sometimes it is spurious
   // activation - RecalculateConstraints() tells us that constraint is
   // inactive (negative Largrange multiplier), but step activates it
   // because of numerical noise.
   //
   // This block of code checks whether step activated truly new constraints
   // (ones which were not in the active set at the solution):
   //
   // * for non-boundary constraint it is enough to check that previous value
   //   of CStatus[i] is negative ( == far from boundary), and new one is
   //   positive ( == we are at the boundary, constraint is activated).
   //
   // * for boundary constraints previous criterion won't work. Each variable
   //   has two constraints, and simply checking their status is not enough -
   //   we have to correctly identify cases when we leave one boundary
   //   (PrevActiveSet[i] == 0) and move to another boundary (CStatus[i] > 0).
   //   Such cases can be identified if we compare previous X with new X.
   //
   // In case only "candidate" constraints were activated, result variable
   // is set to 0. In case at least one new constraint was activated, result
   // is set to 1.
      result = 0;
      for (i = 0; i < n; i++) {
         if (state->cstatus.xZ[i] > 0 && state->xc.xR[i] != state->mtx.xR[i]) {
            result = 1;
         }
      }
      for (i = n; i < n + state->nec + state->nic; i++) {
         if (state->mtas.xZ[i] < 0 && state->cstatus.xZ[i] > 0) {
            result = 1;
         }
      }
   } else {
   // No activation, return -1
      result = -1;
   }
// Update basis
   sasappendtobasis(state, &state->mtnew);
   return result;
}

// This subroutine performs immediate activation of one constraint:
// * "immediate" means that we do not have to move to activate it
// * in case boundary constraint is activated, we enforce current point to be
//   exactly at the boundary
//
// Inputs:
//     S       -   active set object
//     CIdx    -   index of constraint, in [0,N+NEC+NIC).
//                 This value is calculated by SASExploreDirection().
//     CVal    -   for CIdx in [0,N) this field stores value which is
//                 assigned to XC[CIdx] during activation. CVal is ignored in
//                 other cases.
//                 This value is calculated by SASExploreDirection().
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasimmediateactivation(sactiveset *state, ae_int_t cidx, double cval) {
   ae_int_t i;
   ae_assert(state->algostate == 1, "SASMoveTo: is not in optimization mode");
   if (cidx < state->n) {
      state->xc.xR[cidx] = cval;
   }
   state->cstatus.xZ[cidx] = 1;
   vectorsetlengthatleast(&state->mtnew, state->n + state->nec + state->nic);
   for (i = 0; i < state->n + state->nec + state->nic; i++) {
      state->mtnew.xB[i] = false;
   }
   state->mtnew.xB[cidx] = true;
   sasappendtobasis(state, &state->mtnew);
}

// This function builds three orthonormal basises for current active set:
// * P-orthogonal one, which is orthogonalized with inner product
//   (x,y) = x'*P*y, where P == inv(H) is current preconditioner
// * S-orthogonal one, which is orthogonalized with inner product
//   (x,y) = x'*S'*S*y, where S is diagonal scaling matrix
// * I-orthogonal one, which is orthogonalized with standard dot product
//
// NOTE: all sets of orthogonal vectors are guaranteed  to  have  same  size.
//       P-orthogonal basis is built first, I/S-orthogonal basises are forced
//       to have same number of vectors as P-orthogonal one (padded  by  zero
//       vectors if needed).
//
// NOTE: this function tracks changes in active set; first call  will  result
//       in reorthogonalization
//
// Inputs:
//     State   -   active set object
//     H       -   diagonal preconditioner, H[i] > 0
//
// Outputs:
//     State   -   active set object with new basis
// ALGLIB: Copyright 20.06.2012 by Sergey Bochkanov
void sasrebuildbasis(sactiveset *state) {
   const double minnormseparation = 0.25;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t i;
   ae_int_t j;
   bool hasactivelin;
   ae_int_t candidatescnt;
   double v;
   double vv;
   double vmax;
   ae_int_t kmax;
   if (state->basisisready) {
      return;
   }
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   vectorsetlengthatleast(&state->tmp0, n);
   vectorsetlengthatleast(&state->tmpprodp, n);
   vectorsetlengthatleast(&state->tmpprods, n);
   vectorsetlengthatleast(&state->tmpcp, n + 1);
   vectorsetlengthatleast(&state->tmpcs, n + 1);
   vectorsetlengthatleast(&state->tmpci, n + 1);
   matrixsetlengthatleast(&state->tmpbasis, nec + nic, n + 1);
   matrixsetlengthatleast(&state->pdensebatch, nec + nic, n + 1);
   matrixsetlengthatleast(&state->idensebatch, nec + nic, n + 1);
   matrixsetlengthatleast(&state->sdensebatch, nec + nic, n + 1);
   vectorsetlengthatleast(&state->sparsebatch, n);
   state->sparsebatchsize = 0;
   state->densebatchsize = 0;
   state->basisage = 0;
   state->basisisready = true;
// Determine number of active boundary and non-boundary
// constraints, move them to TmpBasis. Quick exit if no
// non-boundary constraints were detected.
   hasactivelin = false;
   for (i = 0; i < nec + nic; i++) {
      if (state->cstatus.xZ[n + i] > 0) {
         hasactivelin = true;
      }
   }
   for (j = 0; j < n; j++) {
      if (state->cstatus.xZ[j] > 0) {
         state->sparsebatch.xZ[state->sparsebatchsize] = j;
         state->sparsebatchsize++;
      }
   }
   if (!hasactivelin) {
      return;
   }
// Prepare precomputed values
   vectorsetlengthatleast(&state->tmpreciph, n);
   for (i = 0; i < n; i++) {
      state->tmpreciph.xR[i] = 1.0 / state->h.xR[i];
   }
// Prepare initial candidate set:
// * select active constraints
// * normalize (inner product is given by preconditioner)
// * orthogonalize with respect to active box constraints
// * copy normalized/orthogonalized candidates to PBasis/SBasis/IBasis
   candidatescnt = 0;
   for (i = 0; i < nec + nic; i++) {
      if (state->cstatus.xZ[n + i] > 0) {
         ae_v_move(state->tmpbasis.xyR[candidatescnt], 1, state->cleic.xyR[i], 1, n + 1);
         candidatescnt++;
      }
   }
   for (i = 0; i < candidatescnt; i++) {
      v = 0.0;
      for (j = 0; j < n; j++) {
         v += sqr(state->tmpbasis.xyR[i][j]) * state->tmpreciph.xR[j];
      }
      if (v > 0.0) {
         v = 1.0 / sqrt(v);
         for (j = 0; j <= n; j++) {
            state->tmpbasis.xyR[i][j] *= v;
         }
      }
   }
   for (j = 0; j < n; j++) {
      if (state->cstatus.xZ[j] > 0) {
         for (i = 0; i < candidatescnt; i++) {
            state->tmpbasis.xyR[i][n] -= state->tmpbasis.xyR[i][j] * state->xc.xR[j];
            state->tmpbasis.xyR[i][j] = 0.0;
         }
      }
   }
   for (i = 0; i < candidatescnt; i++) {
      for (j = 0; j <= n; j++) {
         state->pdensebatch.xyR[i][j] = state->tmpbasis.xyR[i][j];
         state->sdensebatch.xyR[i][j] = state->tmpbasis.xyR[i][j];
         state->idensebatch.xyR[i][j] = state->tmpbasis.xyR[i][j];
      }
   }
// Perform orthogonalization of general linear constraints with respect
// to each other (constraints in P/S/IBasis are already normalized w.r.t.
// box constraints). During this process we select strictly active constraints
// from the candidate set, and drop ones which were detected as redundant
// during orthogonalization.
//
// Orthogonalization is performed with the help of Gram-Schmidt process.
// Due to accumulation of round-off errors it is beneficial to perform
// pivoting, i.e. to select candidate vector with largest norm at each
// step.
//
// First (basic) version of the algorithm is:
//     0. split all constraints into two sets: basis ones (initially empty)
//        and candidate ones (all constraints)
//     1. fill PBasis with H-normalized candidate constraints, fill
//        corresponding entries of S/IBasis with corresponding
//        (non-normalized) constraints
//     2. select row of PBasis with largest norm, move it (and its S/IBasis
//        counterparts) to the beginning of the candidate set, H-normalize
//        this row (rows of S/IBasis are normalized using corresponding norms).
//        Stop if largest row is nearly (or exactly) zero.
//     3. orthogonalize remaining rows of P/S/IBasis with respect to
//        one chosen at step (2). It can be done efficiently using
//        combination of DGEMV/DGER BLAS calls.
//     4. increase basis size by one, decrease candidate set size by one,
//        goto (2)
//
// However, naive implementation of the algorithm above spends significant
// amount of time in step (2) - selection of row with largest H-norm. Step
// (3) can be efficiently implemented with optimized BLAS, but we have no
// optimized BLAS kernels for step(2). And because step (3) changes row norms,
// step (2) have to be re-calculated every time, which is quite slow.
//
// We can save significant amount of calculations by noticing that:
// * step (3) DECREASES row norms, but never increases it
// * we can maintain upper bounds for row H-norms is a separate array,
//   use them for initial evaluation of best candidates, and update them
//   after we find some promising row (all bounds are invalidated after
//   step 3, but their old values still carry some information)
// * it is beneficial re-evaluate bounds only for rows which are
//   significantly (at least few percents) larger than best one found so far
// * because rows are initially normalized, initial values for upper bounds
//   can be set to 1.0
   ae_assert(state->densebatchsize == 0, "SAS: integrity check failed");
   ae_assert(minnormseparation > 0.0, "SAS: integrity check failed");
   vectorsetlengthatleast(&state->tmpnormestimates, candidatescnt);
   for (i = 0; i < candidatescnt; i++) {
      state->tmpnormestimates.xR[i] = 1.0;
   }
   while (state->sparsebatchsize + state->densebatchsize < n) {
   // No candidates? We are done!
      if (candidatescnt == 0) {
         break;
      }
   // Find largest vector
      vmax = 0.0;
      kmax = -1;
      for (i = state->densebatchsize; i < state->densebatchsize + candidatescnt; i++) {
      // Use upper bound for row norm for initial evaluation.
      // Skip rows whose upper bound is less than best candidate
      // found so far.
      //
      // NOTE: in fact, we may skip rows whose upper bound is
      //       marginally higher than that of best candidate.
      //       No need to perform costly re-evaluation in order
      //       to get just few percents of improvement.
         if (state->tmpnormestimates.xR[i] < vmax * (1.0 + minnormseparation)) {
            continue;
         }
      // OK, upper bound is large enough... let's perform full
      // re-evaluation and update of the estimate.
         v = 0.0;
         for (j = 0; j < n; j++) {
            vv = state->pdensebatch.xyR[i][j];
            v += vv * vv * state->tmpreciph.xR[j];
         }
         v = sqrt(v);
         state->tmpnormestimates.xR[i] = v;
      // Now compare with best candidate so far
         if (v > vmax) {
            vmax = v;
            kmax = i;
         }
      }
      if (vmax < 10000.0 * machineepsilon || kmax < 0) {
      // All candidates are either zero or too small (after orthogonalization)
         candidatescnt = 0;
         break;
      }
   // Candidate is selected for inclusion into basis set.
   //
   // Move candidate row to the beginning of candidate array (which is
   // right past the end of the approved basis). Normalize (for P-basis
   // we perform preconditioner-based normalization, for S-basis - scale
   // based, for I-basis - identity based).
      swaprows(&state->pdensebatch, state->densebatchsize, kmax, n + 1);
      swaprows(&state->sdensebatch, state->densebatchsize, kmax, n + 1);
      swaprows(&state->idensebatch, state->densebatchsize, kmax, n + 1);
      swapelements(&state->tmpnormestimates, state->densebatchsize, kmax);
      v = 1.0 / vmax;
      ae_v_muld(state->pdensebatch.xyR[state->densebatchsize], 1, n + 1, v);
      v = 0.0;
      for (j = 0; j < n; j++) {
         vv = state->sdensebatch.xyR[state->densebatchsize][j] * state->s.xR[j];
         v += vv * vv;
      }
      ae_assert(v > 0.0, "SActiveSet.RebuildBasis(): integrity check failed, SNorm == 0");
      v = 1.0 / sqrt(v);
      ae_v_muld(state->sdensebatch.xyR[state->densebatchsize], 1, n + 1, v);
      v = 0.0;
      for (j = 0; j < n; j++) {
         vv = state->idensebatch.xyR[state->densebatchsize][j];
         v += vv * vv;
      }
      ae_assert(v > 0.0, "SActiveSet.RebuildBasis(): integrity check failed, INorm == 0");
      v = 1.0 / sqrt(v);
      ae_v_muld(state->idensebatch.xyR[state->densebatchsize], 1, n + 1, v);
   // Reorthogonalize other candidates with respect to candidate #0:
   // * calculate projections en masse with GEMV()
   // * subtract projections with GER()
      vectorsetlengthatleast(&state->tmp0, candidatescnt - 1);
      for (j = 0; j < n; j++) {
         state->tmpprodp.xR[j] = state->pdensebatch.xyR[state->densebatchsize][j] / state->h.xR[j];
         state->tmpprods.xR[j] = state->sdensebatch.xyR[state->densebatchsize][j] * sqr(state->s.xR[j]);
      }
      for (j = 0; j <= n; j++) {
         state->tmpcp.xR[j] = state->pdensebatch.xyR[state->densebatchsize][j];
         state->tmpcs.xR[j] = state->sdensebatch.xyR[state->densebatchsize][j];
         state->tmpci.xR[j] = state->idensebatch.xyR[state->densebatchsize][j];
      }
      rmatrixgemv(candidatescnt - 1, n, 1.0, &state->pdensebatch, state->densebatchsize + 1, 0, 0, &state->tmpprodp, 0, 0.0, &state->tmp0, 0);
      rmatrixger(candidatescnt - 1, n + 1, &state->pdensebatch, state->densebatchsize + 1, 0, -1.0, &state->tmp0, 0, &state->tmpcp, 0);
      rmatrixgemv(candidatescnt - 1, n, 1.0, &state->sdensebatch, state->densebatchsize + 1, 0, 0, &state->tmpprods, 0, 0.0, &state->tmp0, 0);
      rmatrixger(candidatescnt - 1, n + 1, &state->sdensebatch, state->densebatchsize + 1, 0, -1.0, &state->tmp0, 0, &state->tmpcs, 0);
      rmatrixgemv(candidatescnt - 1, n, 1.0, &state->idensebatch, state->densebatchsize + 1, 0, 0, &state->tmpci, 0, 0.0, &state->tmp0, 0);
      rmatrixger(candidatescnt - 1, n + 1, &state->idensebatch, state->densebatchsize + 1, 0, -1.0, &state->tmp0, 0, &state->tmpci, 0);
   // Increase basis, decrease candidates count
      state->densebatchsize++;
      candidatescnt--;
   }
}

// This  subroutine  calculates  preconditioned  descent direction subject to
// current active set.
//
// Inputs:
//     State   -   active set object
//     G       -   array[N], gradient
//     H       -   array[N], Hessian matrix
//     HA      -   active constraints orthogonalized in such way
//                 that HA*inv(H)*HA' == I.
//     Normalize-  whether we need normalized descent or not
//     D       -   possibly preallocated buffer; automatically resized.
//
// Outputs:
//     D       -   descent direction projected onto current active set.
//                 Components of D which correspond to active boundary
//                 constraints are forced to be exactly zero.
//                 In case D is non-zero and Normalize is True, it is
//                 normalized to have unit norm.
//
// NOTE: if we have N active constraints, D is explicitly set to zero.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
static void sactivesets_constraineddescent(sactiveset *state, RVector *g, RVector *h, RMatrix *ha, bool normalize, RVector *d) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   double v;
   ae_assert(state->algostate == 1, "sactivesets_constraineddescent: internal error - not in optimization mode");
   ae_assert(state->basisisready, "sactivesets_constraineddescent: internal error - no basis");
   n = state->n;
   vectorsetlengthatleast(d, n);
// Calculate preconditioned constrained descent direction:
//
//     d = -inv(H)*( g - HA'*(HA*inv(H)*g) )
//
// Formula above always gives direction which is orthogonal to rows of HA.
// You can verify it by multiplication of both sides by HA[i] (I-th row),
// taking into account that HA*inv(H)*HA' == I (by definition of HA - it is
// orthogonal basis with inner product given by inv(H)).
   for (i = 0; i < n; i++) {
      d->xR[i] = g->xR[i];
   }
   for (i = 0; i < state->densebatchsize; i++) {
      v = 0.0;
      for (j = 0; j < n; j++) {
         v += ha->xyR[i][j] * d->xR[j] / h->xR[j];
      }
      ae_v_subd(d->xR, 1, ha->xyR[i], 1, n, v);
   }
   for (i = 0; i < n; i++) {
      if (state->cstatus.xZ[i] > 0) {
         d->xR[i] = 0.0;
      }
   }
   v = 0.0;
   for (i = 0; i < n; i++) {
      d->xR[i] /= -h->xR[i];
      v += sqr(d->xR[i]);
   }
   v = sqrt(v);
   if (state->sparsebatchsize + state->densebatchsize >= n) {
      v = 0.0;
      for (i = 0; i < n; i++) {
         d->xR[i] = 0.0;
      }
   }
   if (normalize && v > 0.0) {
      for (i = 0; i < n; i++) {
         d->xR[i] /= v;
      }
   }
}

// This subroutine calculates descent direction subject to current active set.
//
// Inputs:
//     S       -   active set object
//     G       -   array[N], gradient
//     D       -   possibly prealocated buffer;
//                 automatically resized if needed.
//
// Outputs:
//     D       -   descent direction projected onto current active set.
//                 Components of D which correspond to active boundary
//                 constraints are forced to be exactly zero.
//                 In case D is non-zero, it is normalized to have unit norm.
//
// NOTE: in  case active set has N  active  constraints  (or  more),  descent
//       direction is forced to be exactly zero.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasconstraineddescent(sactiveset *state, RVector *g, RVector *d) {
   ae_assert(state->algostate == 1, "SASConstrainedDescent: is not in optimization mode");
   sasrebuildbasis(state);
   sactivesets_constraineddescent(state, g, &state->unitdiagonal, &state->idensebatch, true, d);
}

// This  subroutine  calculates  preconditioned  descent direction subject to
// current active set.
//
// Inputs:
//     S       -   active set object
//     G       -   array[N], gradient
//     D       -   possibly prealocated buffer;
//                 automatically resized if needed.
//
// Outputs:
//     D       -   descent direction projected onto current active set.
//                 Components of D which correspond to active boundary
//                 constraints are forced to be exactly zero.
//                 In case D is non-zero, it is normalized to have unit norm.
//
// NOTE: in  case active set has N  active  constraints  (or  more),  descent
//       direction is forced to be exactly zero.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasconstraineddescentprec(sactiveset *state, RVector *g, RVector *d) {
   ae_assert(state->algostate == 1, "SASConstrainedDescentPrec: is not in optimization mode");
   sasrebuildbasis(state);
   sactivesets_constraineddescent(state, g, &state->h, &state->pdensebatch, true, d);
}

// This subroutine calculates projection   of  direction  vector  to  current
// active set.
//
// Inputs:
//     S       -   active set object
//     D       -   array[N], direction
//
// Outputs:
//     D       -   direction projected onto current active set.
//                 Components of D which correspond to active boundary
//                 constraints are forced to be exactly zero.
//
// NOTE: in  case active set has N  active  constraints  (or  more),  descent
//       direction is forced to be exactly zero.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasconstraineddirection(sactiveset *state, RVector *d) {
   ae_int_t i;
   ae_assert(state->algostate == 1, "SASConstrainedAntigradientPrec: is not in optimization mode");
   sasrebuildbasis(state);
   sactivesets_constraineddescent(state, d, &state->unitdiagonal, &state->idensebatch, false, &state->cdtmp);
   for (i = 0; i < state->n; i++) {
      d->xR[i] = -state->cdtmp.xR[i];
   }
}

// This subroutine calculates product of direction vector and  preconditioner
// multiplied subject to current active set.
//
// Inputs:
//     S       -   active set object
//     D       -   array[N], direction
//
// Outputs:
//     D       -   preconditioned direction projected onto current active set.
//                 Components of D which correspond to active boundary
//                 constraints are forced to be exactly zero.
//
// NOTE: in  case active set has N  active  constraints  (or  more),  descent
//       direction is forced to be exactly zero.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasconstraineddirectionprec(sactiveset *state, RVector *d) {
   ae_int_t i;
   ae_assert(state->algostate == 1, "SASConstrainedAntigradientPrec: is not in optimization mode");
   sasrebuildbasis(state);
   sactivesets_constraineddescent(state, d, &state->h, &state->pdensebatch, false, &state->cdtmp);
   for (i = 0; i < state->n; i++) {
      d->xR[i] = -state->cdtmp.xR[i];
   }
}

// This  subroutine returns L1 penalty for violation of active general linear
// constraints (violation of boundary or inactive linear constraints  is  not
// added to penalty).
//
// Penalty term is equal to:
//
//     Penalty = SUM( Abs((C_i*x-R_i)/Alpha_i) )
//
// Here:
// * summation is performed for I = 0...NEC+NIC-1, CStatus[N+I] > 0
//   (only for rows of CLEIC which are in active set)
// * C_i is I-th row of CLEIC
// * R_i is corresponding right part
// * S is a scale matrix
// * Alpha_i = ||S*C_i|| - is a scaling coefficient which "normalizes"
//   I-th summation term according to its scale.
//
// Inputs:
//     S       -   active set object
//     X       -   array[N], candidate point
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
double sasactivelcpenalty1(sactiveset *state, RVector *x) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   double v;
   double alpha;
   double p;
   double result;
   ae_assert(state->algostate == 1, "SASActiveLCPenalty1: is not in optimization mode");
   sasrebuildbasis(state);
   n = state->n;
   nec = state->nec;
   nic = state->nic;
// Calculate penalty term.
   result = 0.0;
   for (i = 0; i < nec + nic; i++) {
      if (state->cstatus.xZ[n + i] > 0) {
         alpha = 0.0;
         p = -state->cleic.xyR[i][n];
         for (j = 0; j < n; j++) {
            v = state->cleic.xyR[i][j];
            p += v * x->xR[j];
            alpha += sqr(v * state->s.xR[j]);
         }
         alpha = sqrt(alpha);
         if (alpha != 0.0) {
            result += fabs(p / alpha);
         }
      }
   }
   return result;
}

// This  subroutine  performs  correction of some (possibly infeasible) point
// with respect to a) current active set, b) all boundary  constraints,  both
// active and inactive:
//
// 0) we calculate L1 penalty term for violation of active linear constraints
//    (one which is returned by SASActiveLCPenalty1() function).
// 1) first, it performs projection (orthogonal with respect to scale  matrix
//    S) of X into current active set: X -> X1.
// 2) next, we perform projection with respect to  ALL  boundary  constraints
//    which are violated at X1: X1 -> X2.
// 3) X is replaced by X2.
//
// The idea is that this function can preserve and enforce feasibility during
// optimization, and additional penalty parameter can be used to prevent algo
// from leaving feasible set because of rounding errors.
//
// Inputs:
//     S       -   active set object
//     X       -   array[N], candidate point
//
// Outputs:
//     X       -   "improved" candidate point:
//                 a) feasible with respect to all boundary constraints
//                 b) feasibility with respect to active set is retained at
//                    good level.
//     Penalty -   penalty term, which can be added to function value if user
//                 wants to penalize violation of constraints (recommended).
//
// NOTE: this function is not intended to find exact  projection  (i.e.  best
//       approximation) of X into feasible set. It just improves situation  a
//       bit.
//       Regular  use  of   this function will help you to retain feasibility
//       - if you already have something to start  with  and  constrain  your
//       steps is such way that the only source of infeasibility are roundoff
//       errors.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sascorrection(sactiveset *state, RVector *x, double *penalty) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   double v;
   *penalty = 0.0;
   ae_assert(state->algostate == 1, "SASCorrection: is not in optimization mode");
   sasrebuildbasis(state);
   n = state->n;
   vectorsetlengthatleast(&state->corrtmp, n);
// Calculate penalty term.
   *penalty = sasactivelcpenalty1(state, x);
// Perform projection 1.
//
// This projecton is given by:
//
//     x_proj = x - S*S*As'*(As*x-b)
//
// where x is original x before projection, S is a scale matrix,
// As is a matrix of equality constraints (active set) which were
// orthogonalized with respect to inner product given by S (i.e. we
// have As*S*S'*As' == I), b is a right part of the orthogonalized
// constraints.
//
// NOTE: you can verify that x_proj is strictly feasible w.r.t.
//       active set by multiplying it by As - you will get
//       As*x_proj = As*x - As*x + b = b.
//
//       This formula for projection can be obtained by solving
//       following minimization problem.
//
//           min ||inv(S)*(x_proj-x)||^2 s.t. As*x_proj == b
//
// NOTE: we apply sparse batch by examining CStatus[]; it is guaranteed
//       to contain sparse batch, but avoids roundoff errors associated
//       with the fact that some box constraints were moved to sparse
//       storage
//
   ae_v_move(state->corrtmp.xR, 1, x->xR, 1, n);
   for (i = 0; i < state->densebatchsize; i++) {
      v = -state->sdensebatch.xyR[i][n];
      for (j = 0; j < n; j++) {
         v += state->sdensebatch.xyR[i][j] * state->corrtmp.xR[j];
      }
      for (j = 0; j < n; j++) {
         state->corrtmp.xR[j] -= v * state->sdensebatch.xyR[i][j] * sqr(state->s.xR[j]);
      }
   }
   for (i = 0; i < n; i++) {
      if (state->cstatus.xZ[i] > 0) {
         state->corrtmp.xR[i] = state->xc.xR[i];
      }
   }
// Perform projection 2
   for (i = 0; i < n; i++) {
      x->xR[i] = state->corrtmp.xR[i];
      if (state->hasbndl.xB[i] && x->xR[i] < state->bndl.xR[i]) {
         x->xR[i] = state->bndl.xR[i];
      }
      if (state->hasbndu.xB[i] && x->xR[i] > state->bndu.xR[i]) {
         x->xR[i] = state->bndu.xR[i];
      }
   }
}

// This subroutine calculates scaled norm of  vector  after  projection  onto
// subspace of active constraints. Most often this function is used  to  test
// stopping conditions.
//
// Inputs:
//     S       -   active set object
//     D       -   vector whose norm is calculated
//
// Result:
//     Vector norm (after projection and scaling)
//
// NOTE: projection is performed first, scaling is performed after projection
//
// NOTE: if we have N active constraints, zero value (exact zero) is returned
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
double sasscaledconstrainednorm(sactiveset *state, RVector *d) {
   ae_int_t i;
   ae_int_t n;
   double v;
   double result;
   ae_assert(state->algostate == 1, "SASMoveTo: is not in optimization mode");
   n = state->n;
   vectorsetlengthatleast(&state->scntmp, n);
// Prepare basis (if needed)
   sasrebuildbasis(state);
// Calculate descent direction
   if (state->sparsebatchsize + state->densebatchsize >= n) {
   // Quick exit if number of active constraints is N or larger
      result = 0.0;
      return result;
   }
   for (i = 0; i < n; i++) {
      state->scntmp.xR[i] = d->xR[i];
   }
   for (i = 0; i < state->densebatchsize; i++) {
      v = ae_v_dotproduct(state->idensebatch.xyR[i], 1, state->scntmp.xR, 1, n);
      ae_v_subd(state->scntmp.xR, 1, state->idensebatch.xyR[i], 1, n, v);
   }
   for (i = 0; i < n; i++) {
      if (state->cstatus.xZ[i] > 0) {
         state->scntmp.xR[i] = 0.0;
      }
   }
   v = 0.0;
   for (i = 0; i < n; i++) {
      v += sqr(state->s.xR[i] * state->scntmp.xR[i]);
   }
   result = sqrt(v);
   return result;
}

// This subroutine turns off optimization mode.
//
// Inputs:
//     S   -   active set object
//
// Outputs:
//     S   -   state is changed
//
// NOTE: this function can be called many times for optimizer which was
//       already stopped.
// ALGLIB: Copyright 21.12.2012 by Sergey Bochkanov
void sasstopoptimization(sactiveset *state) {
   state->algostate = 0;
}

// This function recalculates constraints - activates  and  deactivates  them
// according to gradient value at current point.
//
// Algorithm  assumes  that  we  want  to make Quasi-Newton step from current
// point with diagonal Quasi-Newton matrix H. Constraints are  activated  and
// deactivated in such way that we won't violate any constraint by step.
//
// Only already "active" and "candidate" elements of ActiveSet are  examined;
// constraints which are not active are not examined.
//
// Inputs:
//     State       -   active set object
//     GC          -   array[N], gradient at XC
//     H           -   array[N], Hessian matrix
//
// Outputs:
//     State       -   active set object, with new set of constraint
// ALGLIB: Copyright 26.09.2012 by Sergey Bochkanov
static void sactivesets_reactivateconstraints(sactiveset *state, RVector *gc, RVector *h) {
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t i;
   ae_int_t j;
   ae_int_t idx0;
   ae_int_t idx1;
   double v;
   ae_int_t nactivebnd;
   ae_int_t nactivelin;
   ae_int_t nactiveconstraints;
   double rowscale;
   ae_assert(state->algostate == 1, "SASReactivateConstraintsPrec: must be in optimization mode");
// Prepare
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   state->basisisready = false;
// Handle important special case - no linear constraints,
// only boundary constraints are present
   if (nec + nic == 0) {
      for (i = 0; i < n; i++) {
         if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
            state->cstatus.xZ[i] = 1;
            continue;
         }
         if (state->hasbndl.xB[i] && state->xc.xR[i] == state->bndl.xR[i] && gc->xR[i] >= 0.0) {
            state->cstatus.xZ[i] = 1;
            continue;
         }
         if (state->hasbndu.xB[i] && state->xc.xR[i] == state->bndu.xR[i] && gc->xR[i] <= 0.0) {
            state->cstatus.xZ[i] = 1;
            continue;
         }
         state->cstatus.xZ[i] = -1;
      }
      return;
   }
// General case.
// Allocate temporaries.
   vectorsetlengthatleast(&state->rctmpg, n);
   vectorsetlengthatleast(&state->rctmprightpart, n);
   vectorsetlengthatleast(&state->rctmps, n);
   matrixsetlengthatleast(&state->rctmpdense0, n, nec + nic);
   matrixsetlengthatleast(&state->rctmpdense1, n, nec + nic);
   vectorsetlengthatleast(&state->rctmpisequality, n + nec + nic);
   vectorsetlengthatleast(&state->rctmpconstraintidx, n + nec + nic);
// Calculate descent direction
   ae_v_moveneg(state->rctmpg.xR, 1, gc->xR, 1, n);
// Determine candidates to the active set.
//
// After this block constraints become either "inactive" (CStatus[i] < 0)
// or "candidates" (CStatus[i] == 0). Previously active constraints always
// become "candidates".
   for (i = 0; i < n; i++) {
      state->cstatus.xZ[i] = -1;
   }
   for (i = n; i < n + nec + nic; i++) {
      if (state->cstatus.xZ[i] > 0) {
         state->cstatus.xZ[i] = 0;
      } else {
         state->cstatus.xZ[i] = -1;
      }
   }
   nactiveconstraints = 0;
   nactivebnd = 0;
   nactivelin = 0;
   for (i = 0; i < n; i++) {
   // Activate boundary constraints:
   // * copy constraint index to RCTmpConstraintIdx
   // * set corresponding element of CStatus[] to "candidate"
   // * fill RCTmpS by either +1 (lower bound) or -1 (upper bound)
   // * set RCTmpIsEquality to False (BndL < BndU) or True (BndL == BndU)
   // * increase counters
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
      // Equality constraint is activated
         state->rctmpconstraintidx.xZ[nactiveconstraints] = i;
         state->cstatus.xZ[i] = 0;
         state->rctmps.xR[i] = 1.0;
         state->rctmpisequality.xB[nactiveconstraints] = true;
         nactiveconstraints++;
         nactivebnd++;
         continue;
      }
      if (state->hasbndl.xB[i] && state->xc.xR[i] == state->bndl.xR[i]) {
      // Lower bound is activated
         state->rctmpconstraintidx.xZ[nactiveconstraints] = i;
         state->cstatus.xZ[i] = 0;
         state->rctmps.xR[i] = -1.0;
         state->rctmpisequality.xB[nactiveconstraints] = false;
         nactiveconstraints++;
         nactivebnd++;
         continue;
      }
      if (state->hasbndu.xB[i] && state->xc.xR[i] == state->bndu.xR[i]) {
      // Upper bound is activated
         state->rctmpconstraintidx.xZ[nactiveconstraints] = i;
         state->cstatus.xZ[i] = 0;
         state->rctmps.xR[i] = 1.0;
         state->rctmpisequality.xB[nactiveconstraints] = false;
         nactiveconstraints++;
         nactivebnd++;
         continue;
      }
   }
   for (i = 0; i < nec + nic; i++) {
      if (i >= nec && state->cstatus.xZ[n + i] < 0) {
      // Inequality constraints are skipped if both (a) constraint was
      // not active, and (b) we are too far away from the boundary.
         rowscale = 0.0;
         v = -state->cleic.xyR[i][n];
         for (j = 0; j < n; j++) {
            v += state->cleic.xyR[i][j] * state->xc.xR[j];
            rowscale = rmax2(rowscale, fabs(state->cleic.xyR[i][j] * state->s.xR[j]));
         }
         if (v <= -100000.0 * machineepsilon * rowscale) {
         // NOTE: it is important to check for non-strict inequality
         //       because we have to correctly handle zero constraint
         //       0*x <= 0
            continue;
         }
      }
      ae_v_move(&state->rctmpdense0.xyR[0][nactivelin], state->rctmpdense0.stride, state->cleic.xyR[i], 1, n);
      state->rctmpconstraintidx.xZ[nactiveconstraints] = n + i;
      state->cstatus.xZ[n + i] = 0;
      state->rctmpisequality.xB[nactiveconstraints] = i < nec;
      nactiveconstraints++;
      nactivelin++;
   }
// Skip if no "candidate" constraints was found
   if (nactiveconstraints == 0) {
      for (i = 0; i < n; i++) {
         if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
            state->cstatus.xZ[i] = 1;
            continue;
         }
         if (state->hasbndl.xB[i] && state->xc.xR[i] == state->bndl.xR[i] && gc->xR[i] >= 0.0) {
            state->cstatus.xZ[i] = 1;
            continue;
         }
         if (state->hasbndu.xB[i] && state->xc.xR[i] == state->bndu.xR[i] && gc->xR[i] <= 0.0) {
            state->cstatus.xZ[i] = 1;
            continue;
         }
      }
      return;
   }
// General case.
//
// APPROACH TO CONSTRAINTS ACTIVATION/DEACTIVATION
//
// We have NActiveConstraints "candidates": NActiveBnd boundary candidates,
// NActiveLin linear candidates. Indexes of boundary constraints are stored
// in RCTmpConstraintIdx[0:NActiveBnd-1], indexes of linear ones are stored
// in RCTmpConstraintIdx[NActiveBnd:NActiveBnd+NActiveLin-1]. Some of the
// constraints are equality ones, some are inequality - as specified by
// RCTmpIsEquality[i].
//
// Now we have to determine active subset of "candidates" set. In order to
// do so we solve following constrained minimization problem:
//         (                         )^2
//     min ( SUM(lambda[i]*A[i]) + G )
//         (                         )
// Here:
// * G is a gradient (column vector)
// * A[i] is a column vector, linear (left) part of I-th constraint.
//   I = 0..NActiveConstraints-1, first NActiveBnd elements of A are just
//   subset of identity matrix (boundary constraints), next NActiveLin
//   elements are subset of rows of the matrix of general linear constraints.
// * lambda[i] is a Lagrange multiplier corresponding to I-th constraint
//
// NOTE: for preconditioned setting A is replaced by A*H^(-0.5), G is
//       replaced by G*H^(-0.5). We apply this scaling at the last stage,
//       before passing data to NNLS solver.
//
// Minimization is performed subject to non-negativity constraints on
// lambda[i] corresponding to inequality constraints. Inequality constraints
// which correspond to non-zero lambda are activated, equality constraints
// are always considered active.
//
// Informally speaking, we "decompose" descent direction -G and represent
// it as sum of constraint vectors and "residual" part (which is equal to
// the actual descent direction subject to constraints).
//
// SOLUTION OF THE NNLS PROBLEM
//
// We solve this optimization problem with Non-Negative Least Squares solver,
// which can efficiently solve least squares problems of the form
//
//         ( [ I | AU ]     )^2
//     min ( [   |    ]*x-b )   s.t. non-negativity constraints on some x[i]
//         ( [ 0 | AL ]     )
//
// In order to use this solver we have to rearrange rows of A[] and G in
// such way that first NActiveBnd columns of A store identity matrix (before
// sorting non-zero elements are randomly distributed in the first NActiveBnd
// columns of A, during sorting we move them to first NActiveBnd rows).
//
// Then we create instance of NNLS solver (we reuse instance left from the
// previous run of the optimization problem) and solve NNLS problem.
   idx0 = 0;
   idx1 = nactivebnd;
   for (i = 0; i < n; i++) {
      if (state->cstatus.xZ[i] >= 0) {
         v = 1.0 / sqrt(h->xR[i]);
         for (j = 0; j < nactivelin; j++) {
            state->rctmpdense1.xyR[idx0][j] = state->rctmpdense0.xyR[i][j] / state->rctmps.xR[i] * v;
         }
         state->rctmprightpart.xR[idx0] = state->rctmpg.xR[i] / state->rctmps.xR[i] * v;
         idx0++;
      } else {
         v = 1.0 / sqrt(h->xR[i]);
         for (j = 0; j < nactivelin; j++) {
            state->rctmpdense1.xyR[idx1][j] = state->rctmpdense0.xyR[i][j] * v;
         }
         state->rctmprightpart.xR[idx1] = state->rctmpg.xR[i] * v;
         idx1++;
      }
   }
   snnlsinit(n, imin2(nec + nic, n), n, &state->solver);
   snnlssetproblem(&state->solver, &state->rctmpdense1, &state->rctmprightpart, nactivebnd, nactiveconstraints - nactivebnd, n);
   for (i = 0; i < nactiveconstraints; i++) {
      if (state->rctmpisequality.xB[i]) {
         snnlsdropnnc(&state->solver, i);
      }
   }
   snnlssolve(&state->solver, &state->rctmplambdas);
// After solution of the problem we activate equality constraints (always active)
// and inequality constraints with non-zero Lagrange multipliers. Then we reorthogonalize
// active constraints.
   for (i = 0; i < n + nec + nic; i++) {
      state->cstatus.xZ[i] = -1;
   }
   for (i = 0; i < nactiveconstraints; i++) {
      if (state->rctmpisequality.xB[i] || state->rctmplambdas.xR[i] > 0.0) {
         state->cstatus.xZ[state->rctmpconstraintidx.xZ[i]] = 1;
      } else {
         state->cstatus.xZ[state->rctmpconstraintidx.xZ[i]] = 0;
      }
   }
   sasrebuildbasis(state);
}

// This function recalculates constraints - activates  and  deactivates  them
// according to gradient value at current point. Algorithm  assumes  that  we
// want to make steepest descent step from  current  point;  constraints  are
// activated and deactivated in such way that we won't violate any constraint
// by steepest descent step.
//
// After call to this function active set is ready to  try  steepest  descent
// step (SASDescentDirection-SASExploreDirection-SASMoveTo).
//
// Only already "active" and "candidate" elements of ActiveSet are  examined;
// constraints which are not active are not examined.
//
// Inputs:
//     State       -   active set object
//     GC          -   array[N], gradient at XC
//
// Outputs:
//     State       -   active set object, with new set of constraint
// ALGLIB: Copyright 26.09.2012 by Sergey Bochkanov
void sasreactivateconstraints(sactiveset *state, RVector *gc) {
   ae_assert(state->algostate == 1, "SASReactivateConstraints: must be in optimization mode");
   sactivesets_reactivateconstraints(state, gc, &state->unitdiagonal);
}

// This function recalculates constraints - activates  and  deactivates  them
// according to gradient value at current point.
//
// Algorithm  assumes  that  we  want  to make Quasi-Newton step from current
// point with diagonal Quasi-Newton matrix H. Constraints are  activated  and
// deactivated in such way that we won't violate any constraint by step.
//
// After call to  this  function  active set is ready to  try  preconditioned
// steepest descent step (SASDescentDirection-SASExploreDirection-SASMoveTo).
//
// Only already "active" and "candidate" elements of ActiveSet are  examined;
// constraints which are not active are not examined.
//
// Inputs:
//     State       -   active set object
//     GC          -   array[N], gradient at XC
//
// Outputs:
//     State       -   active set object, with new set of constraint
// ALGLIB: Copyright 26.09.2012 by Sergey Bochkanov
void sasreactivateconstraintsprec(sactiveset *state, RVector *gc) {
   ae_assert(state->algostate == 1, "SASReactivateConstraintsPrec: must be in optimization mode");
   sactivesets_reactivateconstraints(state, gc, &state->h);
}

void sactiveset_init(void *_p, bool make_automatic) {
   sactiveset *p = (sactiveset *)_p;
   ae_vector_init(&p->xc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->h, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cstatus, 0, DT_INT, make_automatic);
   ae_matrix_init(&p->sdensebatch, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->pdensebatch, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->idensebatch, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sparsebatch, 0, DT_INT, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->cleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->mtnew, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->mtx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->mtas, 0, DT_INT, make_automatic);
   ae_vector_init(&p->cdtmp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->corrtmp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->unitdiagonal, 0, DT_REAL, make_automatic);
   snnlssolver_init(&p->solver, make_automatic);
   ae_vector_init(&p->scntmp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpfeas, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmpm0, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rctmps, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rctmpg, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rctmprightpart, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->rctmpdense0, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->rctmpdense1, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rctmpisequality, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->rctmpconstraintidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->rctmplambdas, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmpbasis, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpnormestimates, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpreciph, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpprodp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpprods, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpcp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpcs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpci, 0, DT_REAL, make_automatic);
}

void sactiveset_copy(void *_dst, const void *_src, bool make_automatic) {
   sactiveset *dst = (sactiveset *)_dst;
   const sactiveset *src = (const sactiveset *)_src;
   dst->n = src->n;
   dst->algostate = src->algostate;
   ae_vector_copy(&dst->xc, &src->xc, make_automatic);
   dst->hasxc = src->hasxc;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->h, &src->h, make_automatic);
   ae_vector_copy(&dst->cstatus, &src->cstatus, make_automatic);
   dst->basisisready = src->basisisready;
   ae_matrix_copy(&dst->sdensebatch, &src->sdensebatch, make_automatic);
   ae_matrix_copy(&dst->pdensebatch, &src->pdensebatch, make_automatic);
   ae_matrix_copy(&dst->idensebatch, &src->idensebatch, make_automatic);
   dst->densebatchsize = src->densebatchsize;
   ae_vector_copy(&dst->sparsebatch, &src->sparsebatch, make_automatic);
   dst->sparsebatchsize = src->sparsebatchsize;
   dst->basisage = src->basisage;
   dst->feasinitpt = src->feasinitpt;
   dst->constraintschanged = src->constraintschanged;
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_matrix_copy(&dst->cleic, &src->cleic, make_automatic);
   dst->nec = src->nec;
   dst->nic = src->nic;
   ae_vector_copy(&dst->mtnew, &src->mtnew, make_automatic);
   ae_vector_copy(&dst->mtx, &src->mtx, make_automatic);
   ae_vector_copy(&dst->mtas, &src->mtas, make_automatic);
   ae_vector_copy(&dst->cdtmp, &src->cdtmp, make_automatic);
   ae_vector_copy(&dst->corrtmp, &src->corrtmp, make_automatic);
   ae_vector_copy(&dst->unitdiagonal, &src->unitdiagonal, make_automatic);
   snnlssolver_copy(&dst->solver, &src->solver, make_automatic);
   ae_vector_copy(&dst->scntmp, &src->scntmp, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmpfeas, &src->tmpfeas, make_automatic);
   ae_matrix_copy(&dst->tmpm0, &src->tmpm0, make_automatic);
   ae_vector_copy(&dst->rctmps, &src->rctmps, make_automatic);
   ae_vector_copy(&dst->rctmpg, &src->rctmpg, make_automatic);
   ae_vector_copy(&dst->rctmprightpart, &src->rctmprightpart, make_automatic);
   ae_matrix_copy(&dst->rctmpdense0, &src->rctmpdense0, make_automatic);
   ae_matrix_copy(&dst->rctmpdense1, &src->rctmpdense1, make_automatic);
   ae_vector_copy(&dst->rctmpisequality, &src->rctmpisequality, make_automatic);
   ae_vector_copy(&dst->rctmpconstraintidx, &src->rctmpconstraintidx, make_automatic);
   ae_vector_copy(&dst->rctmplambdas, &src->rctmplambdas, make_automatic);
   ae_matrix_copy(&dst->tmpbasis, &src->tmpbasis, make_automatic);
   ae_vector_copy(&dst->tmpnormestimates, &src->tmpnormestimates, make_automatic);
   ae_vector_copy(&dst->tmpreciph, &src->tmpreciph, make_automatic);
   ae_vector_copy(&dst->tmpprodp, &src->tmpprodp, make_automatic);
   ae_vector_copy(&dst->tmpprods, &src->tmpprods, make_automatic);
   ae_vector_copy(&dst->tmpcp, &src->tmpcp, make_automatic);
   ae_vector_copy(&dst->tmpcs, &src->tmpcs, make_automatic);
   ae_vector_copy(&dst->tmpci, &src->tmpci, make_automatic);
}

void sactiveset_free(void *_p, bool make_automatic) {
   sactiveset *p = (sactiveset *)_p;
   ae_vector_free(&p->xc, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->h, make_automatic);
   ae_vector_free(&p->cstatus, make_automatic);
   ae_matrix_free(&p->sdensebatch, make_automatic);
   ae_matrix_free(&p->pdensebatch, make_automatic);
   ae_matrix_free(&p->idensebatch, make_automatic);
   ae_vector_free(&p->sparsebatch, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_matrix_free(&p->cleic, make_automatic);
   ae_vector_free(&p->mtnew, make_automatic);
   ae_vector_free(&p->mtx, make_automatic);
   ae_vector_free(&p->mtas, make_automatic);
   ae_vector_free(&p->cdtmp, make_automatic);
   ae_vector_free(&p->corrtmp, make_automatic);
   ae_vector_free(&p->unitdiagonal, make_automatic);
   snnlssolver_free(&p->solver, make_automatic);
   ae_vector_free(&p->scntmp, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmpfeas, make_automatic);
   ae_matrix_free(&p->tmpm0, make_automatic);
   ae_vector_free(&p->rctmps, make_automatic);
   ae_vector_free(&p->rctmpg, make_automatic);
   ae_vector_free(&p->rctmprightpart, make_automatic);
   ae_matrix_free(&p->rctmpdense0, make_automatic);
   ae_matrix_free(&p->rctmpdense1, make_automatic);
   ae_vector_free(&p->rctmpisequality, make_automatic);
   ae_vector_free(&p->rctmpconstraintidx, make_automatic);
   ae_vector_free(&p->rctmplambdas, make_automatic);
   ae_matrix_free(&p->tmpbasis, make_automatic);
   ae_vector_free(&p->tmpnormestimates, make_automatic);
   ae_vector_free(&p->tmpreciph, make_automatic);
   ae_vector_free(&p->tmpprodp, make_automatic);
   ae_vector_free(&p->tmpprods, make_automatic);
   ae_vector_free(&p->tmpcp, make_automatic);
   ae_vector_free(&p->tmpcs, make_automatic);
   ae_vector_free(&p->tmpci, make_automatic);
}
} // end of namespace alglib_impl

// === QQPSOLVER Package ===
// Depends on: CQMODELS, SACTIVESETS
namespace alglib_impl {
// This function initializes QQPSettings structure with default settings.
//
// Newly created structure MUST be initialized by default settings  -  or  by
// copy of the already initialized structure.
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qqploaddefaults(ae_int_t n, qqpsettings *s) {
   s->epsg = 0.0;
   s->epsf = 0.0;
   s->epsx = 0.000001;
   s->maxouterits = 0;
   s->cgphase = true;
   s->cnphase = true;
   s->cgminits = 5;
   s->cgmaxits = imax2(s->cgminits, iround(1.0 + 0.33 * n));
   s->sparsesolver = 0;
   s->cnmaxupdates = iround(1.0 + 0.1 * n);
}

// This function initializes QQPSettings  structure  with  copy  of  another,
// already initialized structure.
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qqpcopysettings(qqpsettings *src, qqpsettings *dst) {
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxouterits = src->maxouterits;
   dst->cgphase = src->cgphase;
   dst->cnphase = src->cnphase;
   dst->cgminits = src->cgminits;
   dst->cgmaxits = src->cgmaxits;
   dst->sparsesolver = src->sparsesolver;
   dst->cnmaxupdates = src->cnmaxupdates;
}

// This function performs preallocation of internal 2D matrices. If matrix
// size is less than expected, we grow to some larger value (specified by user).
//
// It can be useful in cases when we solve many subsequent QP problems with
// increasing sizes - helps to avoid multiple allocations.
//
// Inputs:
//     SState      -   object which stores temporaries:
//                     * uninitialized object is automatically initialized
//                     * previously allocated memory is reused as much
//                       as possible
//     NExpected   -   if internal buffers have size enough for NExpected,
//                     no preallocation happens. If size is less than NExpected,
//                     buffers are preallocated up to NGrowTo*NGrowTo
//     NGrowTo     -   new size
//
// Outputs:
//     SState      -   temporary buffers, some of them are preallocated
// ALGLIB: Copyright 09.10.2017 by Sergey Bochkanov
void qqppreallocategrowdense(qqpbuffers *sstate, ae_int_t nexpected, ae_int_t ngrowto) {
   if (sstate->densea.rows < nexpected || sstate->densea.cols < nexpected) {
      matrixsetlengthatleast(&sstate->densea, ngrowto, ngrowto);
   }
   if (sstate->densez.rows < nexpected || sstate->densez.cols < nexpected) {
      matrixsetlengthatleast(&sstate->densez, ngrowto, ngrowto);
   }
}

// Target function at point PROJ(X+Stp*D), where PROJ(.) is a projection into
// feasible set.
//
// NOTE: if Stp == 0, D is not referenced at all. Thus,  there  is  no  need  to
//       fill it by some meaningful values for Stp == 0.
//
// This subroutine uses temporary buffers  Tmp0/1,  which  are  automatically
// resized if needed.
// ALGLIB: Copyright 21.12.2013 by Sergey Bochkanov
static double qqpsolver_projectedtargetfunction(qqpbuffers *sstate, RVector *x, RVector *d, double stp, RVector *tmp0, RVector *tmp1) {
   ae_int_t n;
   ae_int_t i;
   double v;
   double result;
   n = sstate->n;
   vectorsetlengthatleast(tmp0, n);
   vectorsetlengthatleast(tmp1, n);
// Calculate projected point
   for (i = 0; i < n; i++) {
      if (stp != 0.0) {
         v = x->xR[i] + stp * d->xR[i];
      } else {
         v = x->xR[i];
      }
      if (sstate->havebndl.xB[i] && v < sstate->bndl.xR[i]) {
         v = sstate->bndl.xR[i];
      }
      if (sstate->havebndu.xB[i] && v > sstate->bndu.xR[i]) {
         v = sstate->bndu.xR[i];
      }
      tmp0->xR[i] = v;
   }
// Function value at the Tmp0:
//
// f(x) = 0.5*x'*A*x + b'*x
   result = 0.0;
   for (i = 0; i < n; i++) {
      result += sstate->b.xR[i] * tmp0->xR[i];
   }
   if (sstate->akind == 0) {
   // Dense matrix A
      result += 0.5 * rmatrixsyvmv(n, &sstate->densea, 0, 0, true, tmp0, 0, tmp1);
   } else {
   // sparse matrix A
      ae_assert(sstate->akind == 1, "QQPOptimize: unexpected AKind in ProjectedTargetFunction");
      result += 0.5 * sparsevsmv(&sstate->sparsea, sstate->sparseupper, tmp0);
   }
   return result;
}

// Gradient of the target function:
//
//     f(x) = 0.5*x'*A*x + b'*x
//
// which is equal to
//
//     grad = A*x + b
//
// Here:
// * x is array[N]
// * A is array[N,N]
// * b is array[N]
//
// Inputs:
//     SState  -   structure which stores function terms (not modified)
//     X       -   location
//     G       -   possibly preallocated buffer
//
// Outputs:
//     G       -   array[N], gradient
// ALGLIB: Copyright 21.12.2013 by Sergey Bochkanov
static void qqpsolver_targetgradient(qqpbuffers *sstate, RVector *x, RVector *g) {
   ae_int_t n;
   n = sstate->n;
   vectorsetlengthatleast(g, n);
   if (sstate->akind == 0) {
   // Dense matrix A
      rmatrixsymv(n, 1.0, &sstate->densea, 0, 0, true, x, 0, 0.0, g, 0);
   } else {
   // Sparse matrix A
      ae_assert(sstate->akind == 1, "QQPOptimize: unexpected AKind in TargetGradient");
      sparsesmv(&sstate->sparsea, sstate->sparseupper, x, g);
   }
   ae_v_add(g->xR, 1, sstate->b.xR, 1, n);
}

// First and second derivatives  of  the  "extended"  target  function  along
// specified direction. Target  function  is  called  "extended"  because  of
// additional slack variables and has form:
//
//     f(x) = 0.5*x'*A*x + b'*x + penaltyfactor*0.5*(C*x-b)'*(C*x-b)
//
// with gradient
//
//     grad = A*x + b + penaltyfactor*C'*(C*x-b)
//
// Quadratic model has form
//
//     F(x0+alpha*D) = D2*alpha^2 + D1*alpha
//
// Inputs:
//     SState  -   structure which is used to obtain quadratic term of the model
//     X       -   current point, array[N]
//     D       -   direction across which derivatives are calculated, array[N]
//     G       -   gradient at current point (pre-calculated by caller), array[N]
//
// Outputs:
//     D1      -   linear coefficient
//     D1Est   -   estimate of D1 sign,  accounting  for  possible  numerical
//                 errors:
//                 * > 0  means "almost surely positive"
//                 * < 0  means "almost surely negative"
//                 * == 0 means "pessimistic estimate  of  numerical  errors
//                        in D1 is larger than magnitude of D1 itself; it is
//                        impossible to reliably distinguish D1 from zero".
//     D2      -   quadratic coefficient
//     D2Est   -   estimate of D2 sign,  accounting  for  possible  numerical
//                 errors:
//                 * > 0  means "almost surely positive"
//                 * < 0  means "almost surely negative"
//                 * == 0 means "pessimistic estimate  of  numerical  errors
//                        in D2 is larger than magnitude of D2 itself; it is
//                        impossible to reliably distinguish D2 from zero".
// ALGLIB: Copyright 14.05.2014 by Sergey Bochkanov
static void qqpsolver_quadraticmodel(qqpbuffers *sstate, RVector *x, RVector *d, RVector *g, double *d1, ae_int_t *d1est, double *d2, ae_int_t *d2est, RVector *tmp0) {
   ae_int_t n;
   ae_int_t i;
   double v;
   double mx;
   double mb;
   double md;
   *d1 = 0.0;
   *d1est = 0;
   *d2 = 0.0;
   *d2est = 0;
   n = sstate->n;
// Maximums
   mx = 0.0;
   md = 0.0;
   mb = 0.0;
   for (i = 0; i < n; i++) {
      mx = rmax2(mx, fabs(x->xR[i]));
      md = rmax2(md, fabs(d->xR[i]));
   }
   for (i = 0; i < n; i++) {
      mb = rmax2(mb, fabs(sstate->b.xR[i]));
   }
// D2
   if (sstate->akind == 0) {
   // Dense matrix A
      *d2 = 0.5 * rmatrixsyvmv(n, &sstate->densea, 0, 0, true, d, 0, tmp0);
   } else {
   // Sparse matrix A
      ae_assert(sstate->akind == 1, "QQPOptimize: unexpected AKind in TargetGradient");
      *d2 = 0.5 * sparsevsmv(&sstate->sparsea, sstate->sparseupper, d);
   }
   v = ae_v_dotproduct(d->xR, 1, g->xR, 1, n);
   *d1 = v;
// Error estimates
   estimateparabolicmodel(sstate->absasum, sstate->absasum2, mx, mb, md, *d1, *d2, d1est, d2est);
}

// This function accepts quadratic model of the form
//
//     f(x) = 0.5*x'*A*x + b'*x + penaltyfactor*0.5*(C*x-b)'*(C*x-b)
//
// and list of possible steps along direction D. It chooses  best  step  (one
// which achieves minimum value of the target  function)  and  moves  current
// point (given by SAS object) to the new location. Step is  bounded  subject
// to boundary constraints.
//
// Candidate steps are divided into two groups:
// * "default" step, which is always performed when no candidate steps LONGER
//   THAN THE DEFAULT  ONE  is  given.  This  candidate  MUST  reduce  target
//   function value; it is  responsibility  of  caller  to   provide  default
//   candidate which reduces target function.
// * "additional candidates", which may be shorter or longer than the default
//   step. Candidates which are shorter than the default  step  are  ignored;
//   candidates which are longer than the "default" step are tested.
//
// The idea is that we ALWAYS try "default" step, and it is responsibility of
// the caller to provide us with something which is worth trying.  This  step
// may activate some constraint - that's why we  stopped  at  "default"  step
// size. However, we may also try longer steps which may activate  additional
// constraints and further reduce function value.
//
// Inputs:
//     SState  -   structure which stores model
//     SAS     -   active set structure which stores current point in SAS.XC
//     D       -   direction for step
//     Stp     -   step length for "default" candidate
//     NeedAct -   whether   default  candidate  activates  some  constraint;
//                 if NeedAct  is True,  constraint  given  by  CIdc/CVal  is
//                 GUARANTEED to be activated in the final point.
//     CIdx    -   if NeedAct is True, stores index of the constraint to activate
//     CVal    -   if NeedAct is True, stores constrained value;
//                 SAS.XC[CIdx] is forced to be equal to CVal.
//     AddSteps-   array[AddStepsCnt] of additional steps:
//                 * AddSteps[] <= Stp are ignored
//                 * AddSteps[] > Stp are tried
//     Activated-  possibly preallocated buffer; previously allocated memory
//                 will be reused.
//     Tmp0/1   -  possibly preallocated buffers; previously allocated memory
//                 will be reused.
//
// Outputs:
//     SAS     -   SAS.XC is set to new point;  if  there  was  a  constraint
//                 specified  by  NeedAct/CIdx/CVal,  it  will  be  activated
//                 (other constraints may be activated too, but this  one  is
//                 guaranteed to be active in the final point).
//     Activated-  elements of this array are set to True, if I-th constraint
//                 as inactive at previous point, but become  active  in  the
//                 new one.
//                 Situations when we deactivate xi >= 0 and activate xi <= 1 are
//                 considered as activation of previously inactive constraint
// ALGLIB: Copyright 14.05.2014 by Sergey Bochkanov
static void qqpsolver_findbeststepandmove(qqpbuffers *sstate, sactiveset *sas, RVector *d, double stp, bool needact, ae_int_t cidx, double cval, RVector *addsteps, ae_int_t addstepscnt, BVector *activated, RVector *tmp0, RVector *tmp1) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t k;
   double v;
   double stpbest;
   double fbest;
   double fcand;
   n = sstate->n;
   vectorsetlengthatleast(tmp0, n);
   vectorsetlengthatleast(activated, n);
// Calculate initial step, store to Tmp0
//
// NOTE: Tmp0 is guaranteed to be feasible w.r.t. boundary constraints
   for (i = 0; i < n; i++) {
      v = sas->xc.xR[i] + stp * d->xR[i];
      if (sstate->havebndl.xB[i] && v < sstate->bndl.xR[i]) {
         v = sstate->bndl.xR[i];
      }
      if (sstate->havebndu.xB[i] && v > sstate->bndu.xR[i]) {
         v = sstate->bndu.xR[i];
      }
      tmp0->xR[i] = v;
   }
   if (needact) {
      tmp0->xR[cidx] = cval;
   }
// Try additional steps, if AddStepsCnt > 0
   if (addstepscnt > 0) {
   // Find best step
      stpbest = stp;
      fbest = qqpsolver_projectedtargetfunction(sstate, &sas->xc, d, stpbest, tmp0, tmp1);
      for (k = 0; k < addstepscnt; k++) {
         if (addsteps->xR[k] > stp) {
            fcand = qqpsolver_projectedtargetfunction(sstate, &sas->xc, d, addsteps->xR[k], tmp0, tmp1);
            if (fcand < fbest) {
               fbest = fcand;
               stpbest = addsteps->xR[k];
            }
         }
      }
   // Prepare best step
   //
   // NOTE: because only AddSteps[] > Stp were checked,
   //       this step will activate constraint CIdx.
      for (i = 0; i < n; i++) {
         v = sas->xc.xR[i] + stpbest * d->xR[i];
         if (sstate->havebndl.xB[i] && v < sstate->bndl.xR[i]) {
            v = sstate->bndl.xR[i];
         }
         if (sstate->havebndu.xB[i] && v > sstate->bndu.xR[i]) {
            v = sstate->bndu.xR[i];
         }
         tmp0->xR[i] = v;
      }
      if (needact) {
         tmp0->xR[cidx] = cval;
      }
   }
// Fill Activated array by information about activated constraints.
// Perform step
   for (i = 0; i < n; i++) {
      activated->xB[i] = false;
      v = tmp0->xR[i];
      if (v == sas->xc.xR[i]) {
         continue;
      }
      if (sstate->havebndl.xB[i] && v == sstate->bndl.xR[i]) {
         activated->xB[i] = true;
      }
      if (sstate->havebndu.xB[i] && v == sstate->bndu.xR[i]) {
         activated->xB[i] = true;
      }
   }
   sasmoveto(sas, tmp0, needact, cidx, cval);
}

// This function prepares data for  constrained  Newton  step  for  penalized
// quadratic model of the form
//
//     f(x) = 0.5*x'*A*x + b'*x + penaltyfactor*0.5*(C*x-b)'*(C*x-b)
//
// where A can be dense or sparse, and model is considered subject to equality
// constraints specified by SState.SAS.XC  object.  Constraint  is considered
// active if XC[i] is exactly BndL[i] or BndU[i],  i.e.  we  ignore  internal
// list of constraints monitored by SAS object. Our own  set  of  constraints
// includes all  constraints  stored  by  SAS,  but  also  may  include  some
// constraints which are inactive in SAS.
//
// "Preparation" means that Cholesky decomposition of  the  effective  system
// matrix is performed, and we can  perform  constrained  Newton  step.
//
// This function works as black box. It uses fields of SState which are marked
// as "Variables for constrained Newton phase", and only  this  function  and
// its friends know about these variables. Everyone else should use:
// * CNewtonBuild() to prepare initial Cholesky decomposition for step
// * CNewtonStep() to perform constrained Newton step
// * CNewtonUpdate() to update Cholesky matrix  after  point  was  moved  and
//   constraints were updated. In some cases it  is  possible to  efficiently
//   re-calculate Cholesky decomposition if you know which  constraints  were
//   activated. If efficient  re-calculation  is  impossible,  this  function
//   returns False.
//
// Inputs:
//     SState  -   structure which stores model and temporaries for CN phase;
//                 in particular, SAS.XC stores current point.
//     SparseSolver-which sparse solver to use for sparse model; ignored  for
//                 dense QP. Can be:
//                 * 2 -   SKS-based Cholesky
//     NCholesky-  counter which is incremented after Cholesky (successful or
//                 failed one)
//
// Outputs:
//     NCholesky-  possibly updated counter
//
// Result:
//     True, if Cholesky decomposition was successfully performed.
//     False, if a) matrix was semi-definite or indefinite, or b)  particular
//     combination of matrix type (sparse) and constraints  (general  linear)
//     is not supported.
//
// NOTE: this function may routinely return False, for indefinite matrices or
//       for sparse problems with general linear constraints. You  should  be
//       able to handle such situations.
// ALGLIB: Copyright 14.05.2014 by Sergey Bochkanov
static bool qqpsolver_cnewtonbuild(qqpbuffers *sstate, ae_int_t sparsesolver, ae_int_t *ncholesky) {
   const double regz = 1.0E-9;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   bool b;
   ae_int_t ridx0;
   ae_int_t ridx1;
   ae_int_t nfree;
   bool result;
   result = false;
// Fetch often used fields
   n = sstate->n;
// 1. Set CNModelAge to zero
// 2. Generate YIdx - reordering of variables such that free variables
//    come first and are ordered by ascending, fixed are last ones and
//    have no particular ordering.
//
// This step is same for dense and sparse problems.
   sstate->cnmodelage = 0;
   vectorsetlengthatleast(&sstate->yidx, n);
   ridx0 = 0;
   ridx1 = n - 1;
   for (i = 0; i < n; i++) {
      sstate->yidx.xZ[i] = -1;
   }
   for (i = 0; i < n; i++) {
      ae_assert(!sstate->havebndl.xB[i] || sstate->sas.xc.xR[i] >= sstate->bndl.xR[i], "CNewtonBuild: internal error");
      ae_assert(!sstate->havebndu.xB[i] || sstate->sas.xc.xR[i] <= sstate->bndu.xR[i], "CNewtonBuild: internal error");
      b =
         sstate->havebndl.xB[i] && sstate->sas.xc.xR[i] == sstate->bndl.xR[i] ||
         sstate->havebndu.xB[i] && sstate->sas.xc.xR[i] == sstate->bndu.xR[i];
      if (b) {
         sstate->yidx.xZ[ridx1] = i;
         ridx1--;
      } else {
         sstate->yidx.xZ[ridx0] = i;
         ridx0++;
      }
   }
   ae_assert(ridx0 == ridx1 + 1, "CNewtonBuild: internal error");
   nfree = ridx0;
   sstate->nfree = nfree;
   if (nfree == 0) {
      return result;
   }
// Constrained Newton matrix: dense version
   if (sstate->akind == 0) {
      matrixsetlengthatleast(&sstate->densez, n, n);
      vectorsetlengthatleast(&sstate->tmpcn, n);
      for (i = 0; i < n; i++) {
         for (j = i; j < n; j++) {
            sstate->densez.xyR[i][j] = sstate->densea.xyR[i][j];
         }
      }
      for (i = 1; i < nfree; i++) {
         ae_assert(sstate->yidx.xZ[i] > sstate->yidx.xZ[i - 1], "CNewtonBuild: integrity check failed");
      }
      for (i = 0; i < nfree; i++) {
         k = sstate->yidx.xZ[i];
         for (j = i; j < nfree; j++) {
            sstate->densez.xyR[i][j] = sstate->densez.xyR[k][sstate->yidx.xZ[j]];
         }
      }
      vectorsetlengthatleast(&sstate->regdiag, n);
      for (i = 0; i < nfree; i++) {
         v = 0.0;
         for (j = 0; j < i; j++) {
            v += fabs(sstate->densez.xyR[j][i]);
         }
         for (j = i; j < nfree; j++) {
            v += fabs(sstate->densez.xyR[i][j]);
         }
         if (v == 0.0) {
            v = 1.0;
         }
         sstate->regdiag.xR[i] = regz * v;
      }
      for (i = 0; i < nfree; i++) {
         sstate->densez.xyR[i][i] += sstate->regdiag.xR[i];
      }
      ++*ncholesky;
      if (!spdmatrixcholeskyrec(&sstate->densez, 0, nfree, true, &sstate->tmpcn)) {
         return result;
      }
      for (i = nfree - 1; i >= 0; i--) {
         ae_v_move(&sstate->tmpcn.xR[i], 1, &sstate->densez.xyR[i][i], 1, nfree - i);
         k = sstate->yidx.xZ[i];
         for (j = k; j < n; j++) {
            sstate->densez.xyR[k][j] = 0.0;
         }
         for (j = i; j < nfree; j++) {
            sstate->densez.xyR[k][sstate->yidx.xZ[j]] = sstate->tmpcn.xR[j];
         }
      }
      for (i = nfree; i < n; i++) {
         k = sstate->yidx.xZ[i];
         sstate->densez.xyR[k][k] = 1.0;
         for (j = k + 1; j < n; j++) {
            sstate->densez.xyR[k][j] = 0.0;
         }
      }
      result = true;
      return result;
   }
// Constrained Newton matrix: sparse version
   if (sstate->akind == 1) {
      ae_assert(sparsesolver == 2, "CNewtonBuild: internal error");
   // Copy sparse A to Z and fill rows/columns corresponding to active
   // constraints by zeros. Diagonal elements corresponding to active
   // constraints are filled by unit values.
      sparsecopytosksbuf(&sstate->sparsea, &sstate->sparsecca);
      vectorsetlengthatleast(&sstate->tmpcn, n);
      for (i = 0; i < n; i++) {
         sstate->tmpcn.xR[i] = 0.0;
      }
      for (i = nfree; i < n; i++) {
         sstate->tmpcn.xR[sstate->yidx.xZ[i]] = 1.0;
      }
      for (i = 0; i < n; i++) {
         k = sstate->sparsecca.ridx.xZ[i];
         for (j = i - sstate->sparsecca.didx.xZ[i]; j <= i; j++) {
            if (sstate->tmpcn.xR[i] != 0.0 || sstate->tmpcn.xR[j] != 0.0) {
            // I-th or J-th variable is in active set (constrained)
               if (i == j) {
                  sstate->sparsecca.vals.xR[k] = 1.0;
               } else {
                  sstate->sparsecca.vals.xR[k] = 0.0;
               }
            }
            k++;
         }
      }
   // Perform sparse Cholesky
      ++*ncholesky;
      if (!sparsecholeskyskyline(&sstate->sparsecca, n, sstate->sparseupper)) {
         return result;
      }
      result = true;
      return result;
   }
// Unexpected :)
   ae_assert(false, "CNewtonBuild: internal error");
   return result;
}

// This   function  updates  equality-constrained   Cholesky   matrix   after
// activation of the  new  equality  constraints.  Matrix  being  updated  is
// quadratic term of the function below
//
//     f(x) = 0.5*x'*A*x + b'*x + penaltyfactor*0.5*(C*x-b)'*(C*x-b)
//
// where A can be dense or sparse.
//
// This  function  uses  YIdx[]  array  (set by CNewtonBuild()  function)  to
// distinguish between active and inactive constraints.
//
// This function works as black box. It uses fields of SState which are marked
// as "Variables for constrained Newton phase", and only  this  function  and
// its friends know about these variables. Everyone else should use:
// * CNewtonBuild() to prepare initial Cholesky decomposition for step
// * CNewtonStep() to perform constrained Newton step
// * CNewtonUpdate() to update Cholesky matrix  after  point  was  moved  and
//   constraints were updated. In some cases it  is  possible to  efficiently
//   re-calculate Cholesky decomposition if you know which  constraints  were
//   activated. If efficient  re-calculation  is  impossible,  this  function
//   returns False.
//
// Inputs:
//     SState  -   structure which stores model and temporaries for CN phase;
//                 in particular, SAS.XC stores current point.
//     Settings -  QQPSettings object which was  initialized  by  appropriate
//                 construction function.
//     NCUpdates-  counter which is incremented after each update (one update
//                 means one variable being fixed)
//
// Outputs:
//     NCUpdates-  possibly updated counter
//
// Result:
//     True, if Cholesky decomposition was successfully performed.
//     False, if a) model age was too high, or b) particular  combination  of
//     matrix type (sparse) and constraints (general linear) is not supported
//
// NOTE: this function may routinely return False.
//       You should be able to handle such situations.
// ALGLIB: Copyright 14.05.2014 by Sergey Bochkanov
static bool qqpsolver_cnewtonupdate(qqpbuffers *sstate, qqpsettings *settings, ae_int_t *ncupdates) {
   ae_int_t n;
   ae_int_t nfree;
   ae_int_t ntofix;
   bool b;
   ae_int_t ridx0;
   ae_int_t ridx1;
   ae_int_t i;
   ae_int_t k;
   bool result;
   result = false;
// Cholesky updates for sparse problems are not supported
   if (sstate->akind == 1) {
      return result;
   }
// Fetch often used fields
   n = sstate->n;
   nfree = sstate->nfree;
// Determine variables to fix and move them to YIdx[NFree-NToFix:NFree-1]
// Exit if CNModelAge increased too much.
   vectorsetlengthatleast(&sstate->tmpcni, n);
   ridx0 = 0;
   ridx1 = nfree - 1;
   for (i = 0; i < nfree; i++) {
      sstate->tmpcni.xZ[i] = -1;
   }
   for (k = 0; k < nfree; k++) {
      i = sstate->yidx.xZ[k];
      ae_assert(!sstate->havebndl.xB[i] || sstate->sas.xc.xR[i] >= sstate->bndl.xR[i], "CNewtonUpdate: internal error");
      ae_assert(!sstate->havebndu.xB[i] || sstate->sas.xc.xR[i] <= sstate->bndu.xR[i], "CNewtonUpdate: internal error");
      b =
         sstate->havebndl.xB[i] && sstate->sas.xc.xR[i] == sstate->bndl.xR[i] ||
         sstate->havebndu.xB[i] && sstate->sas.xc.xR[i] == sstate->bndu.xR[i];
      if (b) {
         sstate->tmpcni.xZ[ridx1] = i;
         ridx1--;
      } else {
         sstate->tmpcni.xZ[ridx0] = i;
         ridx0++;
      }
   }
   ae_assert(ridx0 == ridx1 + 1, "CNewtonUpdate: internal error");
   ntofix = nfree - ridx0;
   if (ntofix == 0 || ntofix == nfree) {
      return result;
   }
   if (sstate->cnmodelage + ntofix > settings->cnmaxupdates) {
      return result;
   }
   for (i = 0; i < nfree; i++) {
      sstate->yidx.xZ[i] = sstate->tmpcni.xZ[i];
   }
// Constrained Newton matrix: dense version.
   if (sstate->akind == 0) {
   // Update Cholesky matrix with SPDMatrixCholeskyUpdateFixBuf()
      vectorsetlengthatleast(&sstate->tmpcnb, n);
      for (i = 0; i < n; i++) {
         sstate->tmpcnb.xB[i] = false;
      }
      for (i = nfree - ntofix; i < nfree; i++) {
         sstate->tmpcnb.xB[sstate->yidx.xZ[i]] = true;
      }
      spdmatrixcholeskyupdatefixbuf(&sstate->densez, n, true, &sstate->tmpcnb, &sstate->tmpcn);
   // Update information stored in State and exit
      sstate->nfree = nfree - ntofix;
      sstate->cnmodelage += ntofix;
      *ncupdates += ntofix;
      result = true;
      return result;
   }
// Unexpected :)
   ae_assert(false, "CNewtonUpdate: internal error");
   return result;
}

// This   function prepares equality-constrained Newton step using previously
// calculated constrained Cholesky matrix of the problem
//
//     f(x) = 0.5*x'*A*x + b'*x + penaltyfactor*0.5*(C*x-b)'*(C*x-b)
//
// where A can be dense or sparse.
//
// As  input,  this  function  accepts  gradient  at the current location. As
// output, it returns step vector (replaces gradient).
//
// This function works as black box. It uses fields of SState which are marked
// as "Variables for constrained Newton phase", and only  this  function  and
// its friends know about these variables. Everyone else should use:
// * CNewtonBuild() to prepare initial Cholesky decomposition for step
// * CNewtonStep() to perform constrained Newton step
// * CNewtonUpdate() to update Cholesky matrix  after  point  was  moved  and
//   constraints were updated. In some cases it  is  possible to  efficiently
//   re-calculate Cholesky decomposition if you know which  constraints  were
//   activated. If efficient  re-calculation  is  impossible,  this  function
//   returns False.
//
// Inputs:
//     SState  -   structure which stores model and temporaries for CN phase;
//                 in particular, SAS.XC stores current point.
//     Settings -  QQPSettings object which was  initialized  by  appropriate
//                 construction function.
//     GC       -  array[N], gradient of the target function
//
// Outputs:
//     GC       -  array[N], step vector (on success)
//
// Result:
//     True, if step was successfully calculated.
//     False, if step calculation failed:
//     a) gradient was exactly zero,
//     b) gradient norm was smaller than EpsG (stopping condition)
//     c) all variables were equality-constrained
//
// NOTE: this function may routinely return False.
//       You should be able to handle such situations.
// ALGLIB: Copyright 14.05.2014 by Sergey Bochkanov
static bool qqpsolver_cnewtonstep(qqpbuffers *sstate, qqpsettings *settings, RVector *gc) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t nfree;
   double v;
   bool result;
   result = false;
   n = sstate->n;
   nfree = sstate->nfree;
   for (i = nfree; i < n; i++) {
      gc->xR[sstate->yidx.xZ[i]] = 0.0;
   }
   v = ae_v_dotproduct(gc->xR, 1, gc->xR, 1, n);
   if (sqrt(v) <= settings->epsg) {
      return result;
   }
   for (i = 0; i < n; i++) {
      gc->xR[i] = -gc->xR[i];
   }
   if (sstate->akind == 0) {
   // Dense Newton step.
   // Use straightforward Cholesky solver.
      fblscholeskysolve(&sstate->densez, 1.0, n, true, gc, &sstate->tmpcn);
      result = true;
      return result;
   }
   if (sstate->akind == 1) {
   // Sparse Newton step.
   //
   // We have T*T' = L*L' = U'*U (depending on specific triangle stored in SparseCCA).
      if (sstate->sparseupper) {
         sparsetrsv(&sstate->sparsecca, sstate->sparseupper, false, 1, gc);
         sparsetrsv(&sstate->sparsecca, sstate->sparseupper, false, 0, gc);
      } else {
         sparsetrsv(&sstate->sparsecca, sstate->sparseupper, false, 0, gc);
         sparsetrsv(&sstate->sparsecca, sstate->sparseupper, false, 1, gc);
      }
      result = true;
      return result;
   }
   ae_assert(false, "CNewtonStep: internal error");
   return result;
}

// This function runs QQP solver; it returns after optimization  process  was
// completed. Following QP problem is solved:
//
//     min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//
// subject to boundary constraints.
//
// IMPORTANT: UNLIKE MANY OTHER SOLVERS, THIS FUNCTION DOES NOT  REQUIRE  YOU
//            TO INITIALIZE STATE OBJECT. IT CAN BE AUTOMATICALLY INITIALIZED
//            DURING SOLUTION PROCESS.
//
// Inputs:
//     AC          -   for dense problems given by CQM model (AKind == 0) A-term
//                     of CQM object contains system matrix. Other terms  are
//                     unspecified and should not be referenced.
//     SparseAC    -   for sparse problems (AKind == 1)
//     DenseAC     -   for traditional dense matrices (AKind == 2)
//     AKind       -   matrix term to use:
//                     * 0 for dense CQM (CQMAC)
//                     * 1 for sparse matrix (SparseAC)
//                     * 2 for dense matrix (DenseAC)
//     IsUpper     -   which triangle of  SparseAC/DenseAC  stores  matrix  -
//                     upper or lower one (for dense matrices this  parameter
//                     is not actual).
//     BC          -   linear term, array[NC]
//     BndLC       -   lower bound, array[NC]
//     BndUC       -   upper bound, array[NC]
//     SC          -   scale vector, array[NC]:
//                     * I-th element contains scale of I-th variable,
//                     * SC[I] > 0
//     XOriginC    -   origin term, array[NC]. Can be zero.
//     NC          -   number of variables in the  original  formulation  (no
//                     slack variables).
//     CLEICC      -   linear equality/inequality constraints. Present version
//                     of this function does NOT provide  publicly  available
//                     support for linear constraints. This feature  will  be
//                     introduced in the future versions of the function.
//     NEC, NIC    -   number of equality/inequality constraints.
//                     MUST BE ZERO IN THE CURRENT VERSION!!!
//     Settings    -   QQPSettings object initialized by one of the initialization
//                     functions.
//     SState      -   object which stores temporaries:
//                     * uninitialized object is automatically initialized
//                     * previously allocated memory is reused as much
//                       as possible
//     XS          -   initial point, array[NC]
//
// Outputs:
//     XS          -   last point
//     TerminationType-termination type:
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qqpoptimize(convexquadraticmodel *cqmac, sparsematrix *sparseac, RMatrix *denseac, ae_int_t akind, bool isupper, RVector *bc, RVector *bndlc, RVector *bnduc, RVector *sc, RVector *xoriginc, ae_int_t nc, qqpsettings *settings, qqpbuffers *sstate, RVector *xs, ae_int_t *terminationtype) {
   const ae_int_t quickqprestartcg = 50;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   double vv;
   double d2;
   double d1;
   ae_int_t d1est;
   ae_int_t d2est;
   bool needact;
   double reststp;
   double fullstp;
   double stpmax;
   double stp;
   ae_int_t stpcnt;
   ae_int_t cidx;
   double cval;
   ae_int_t cgcnt;
   ae_int_t cgmax;
   ae_int_t newtcnt;
   ae_int_t sparsesolver;
   double beta;
   bool b;
   double fprev;
   double fcur;
   bool problemsolved;
   bool isconstrained;
   double f0;
   double f1;
   *terminationtype = 0;
// Primary checks
   ae_assert(akind == 0 || akind == 1 || akind == 2, "QQPOptimize: incorrect AKind");
   sstate->n = nc;
   n = sstate->n;
   *terminationtype = 0;
   sstate->repinneriterationscount = 0;
   sstate->repouteriterationscount = 0;
   sstate->repncholesky = 0;
   sstate->repncupdates = 0;
// Several checks
// * matrix size
// * scale vector
// * consistency of bound constraints
// * consistency of settings
   if (akind == 1) {
      ae_assert(sparsegetnrows(sparseac) == n, "QQPOptimize: rows(SparseAC) != N");
      ae_assert(sparsegetncols(sparseac) == n, "QQPOptimize: cols(SparseAC) != N");
   }
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(sc->xR[i]) && sc->xR[i] > 0.0, "QQPOptimize: incorrect scale");
   }
   for (i = 0; i < n; i++) {
      if (isfinite(bndlc->xR[i]) && isfinite(bnduc->xR[i])) {
         if (bndlc->xR[i] > bnduc->xR[i]) {
            *terminationtype = -3;
            return;
         }
      }
   }
   ae_assert(settings->cgphase || settings->cnphase, "QQPOptimize: both phases (CG and Newton) are inactive");
// Allocate data structures
   vectorsetlengthatleast(&sstate->bndl, n);
   vectorsetlengthatleast(&sstate->bndu, n);
   vectorsetlengthatleast(&sstate->havebndl, n);
   vectorsetlengthatleast(&sstate->havebndu, n);
   vectorsetlengthatleast(&sstate->xs, n);
   vectorsetlengthatleast(&sstate->xf, n);
   vectorsetlengthatleast(&sstate->xp, n);
   vectorsetlengthatleast(&sstate->gc, n);
   vectorsetlengthatleast(&sstate->cgc, n);
   vectorsetlengthatleast(&sstate->cgp, n);
   vectorsetlengthatleast(&sstate->dc, n);
   vectorsetlengthatleast(&sstate->dp, n);
   vectorsetlengthatleast(&sstate->tmp0, n);
   vectorsetlengthatleast(&sstate->tmp1, n);
   vectorsetlengthatleast(&sstate->stpbuf, 15);
   sasinit(n, &sstate->sas);
// Scale/shift problem coefficients:
//
//     min { 0.5*(x-x0)'*A*(x-x0) + b'*(x-x0) }
//
// becomes (after transformation "x = S*y+x0")
//
//     min { 0.5*y'*(S*A*S)*y + (S*b)'*y
//
// Modified A_mod == S*A*S and b_mod == S*(b+A*x0) are
// stored into SState.DenseA and SState.B.
//
   vectorsetlengthatleast(&sstate->b, n);
   for (i = 0; i < n; i++) {
      sstate->b.xR[i] = sc->xR[i] * bc->xR[i];
   }
   sstate->akind = -99;
   if (akind == 0) {
   // Dense QP problem - just copy and scale.
      matrixsetlengthatleast(&sstate->densea, n, n);
      cqmgeta(cqmac, &sstate->densea);
      sstate->akind = 0;
      sstate->absamax = 0.0;
      sstate->absasum = 0.0;
      sstate->absasum2 = 0.0;
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            v = sc->xR[i] * sstate->densea.xyR[i][j] * sc->xR[j];
            vv = fabs(v);
            sstate->densea.xyR[i][j] = v;
            sstate->absamax = rmax2(sstate->absamax, vv);
            sstate->absasum += vv;
            sstate->absasum2 += vv * vv;
         }
      }
   }
   if (akind == 1) {
   // Sparse QP problem - a bit tricky. Depending on format of the
   // input we use different strategies for copying matrix:
   // * SKS matrices are copied to SKS format
   // * anything else is copied to CRS format
      sparsecopytosksbuf(sparseac, &sstate->sparsea);
      if (isupper) {
         sparsetransposesks(&sstate->sparsea);
      }
      sstate->akind = 1;
      sstate->sparseupper = false;
      sstate->absamax = 0.0;
      sstate->absasum = 0.0;
      sstate->absasum2 = 0.0;
      for (i = 0; i < n; i++) {
         k = sstate->sparsea.ridx.xZ[i];
         for (j = i - sstate->sparsea.didx.xZ[i]; j <= i; j++) {
            v = sc->xR[i] * sstate->sparsea.vals.xR[k] * sc->xR[j];
            vv = fabs(v);
            sstate->sparsea.vals.xR[k] = v;
            if (i == j) {
            // Diagonal terms are counted only once
               sstate->absamax = rmax2(sstate->absamax, vv);
               sstate->absasum += vv;
               sstate->absasum2 += vv * vv;
            } else {
            // Offdiagonal terms are counted twice
               sstate->absamax = rmax2(sstate->absamax, vv);
               sstate->absasum += 2.0 * vv;
               sstate->absasum2 += 2.0 * vv * vv;
            }
            k++;
         }
      }
   }
   if (akind == 2) {
   // Dense QP problem - just copy and scale.
      matrixsetlengthatleast(&sstate->densea, n, n);
      sstate->akind = 0;
      sstate->absamax = 0.0;
      sstate->absasum = 0.0;
      sstate->absasum2 = 0.0;
      if (isupper) {
         for (i = 0; i < n; i++) {
            for (j = i; j < n; j++) {
               v = sc->xR[i] * denseac->xyR[i][j] * sc->xR[j];
               vv = fabs(v);
               sstate->densea.xyR[i][j] = v;
               sstate->densea.xyR[j][i] = v;
               if (i == v) {
                  k = 1;
               } else {
                  k = 2;
               }
               sstate->absamax = rmax2(sstate->absamax, vv);
               sstate->absasum += vv * k;
               sstate->absasum2 += vv * vv * k;
            }
         }
      } else {
         for (i = 0; i < n; i++) {
            for (j = 0; j <= i; j++) {
               v = sc->xR[i] * denseac->xyR[i][j] * sc->xR[j];
               vv = fabs(v);
               sstate->densea.xyR[i][j] = v;
               sstate->densea.xyR[j][i] = v;
               if (i == v) {
                  k = 1;
               } else {
                  k = 2;
               }
               sstate->absamax = rmax2(sstate->absamax, vv);
               sstate->absasum += vv * k;
               sstate->absasum2 += vv * vv * k;
            }
         }
      }
   }
   ae_assert(sstate->akind >= 0, "QQP: integrity check failed");
// Load box constraints into State structure.
//
// We apply transformation to variables: y == (x-x_origin)/s,
// each of the constraints is appropriately shifted/scaled.
   for (i = 0; i < n; i++) {
      sstate->havebndl.xB[i] = isfinite(bndlc->xR[i]);
      if (sstate->havebndl.xB[i]) {
         sstate->bndl.xR[i] = (bndlc->xR[i] - xoriginc->xR[i]) / sc->xR[i];
      } else {
         ae_assert(isneginf(bndlc->xR[i]), "QQPOptimize: incorrect lower bound");
         sstate->bndl.xR[i] = -INFINITY;
      }
      sstate->havebndu.xB[i] = isfinite(bnduc->xR[i]);
      if (sstate->havebndu.xB[i]) {
         sstate->bndu.xR[i] = (bnduc->xR[i] - xoriginc->xR[i]) / sc->xR[i];
      } else {
         ae_assert(isposinf(bnduc->xR[i]), "QQPOptimize: incorrect upper bound");
         sstate->bndu.xR[i] = +INFINITY;
      }
   }
// Process initial point:
// * set it to XS-XOriginC
// * make sure that boundary constraints are preserved by transformation
   for (i = 0; i < n; i++) {
      sstate->xs.xR[i] = (xs->xR[i] - xoriginc->xR[i]) / sc->xR[i];
      if (sstate->havebndl.xB[i] && sstate->xs.xR[i] < sstate->bndl.xR[i]) {
         sstate->xs.xR[i] = sstate->bndl.xR[i];
      }
      if (sstate->havebndu.xB[i] && sstate->xs.xR[i] > sstate->bndu.xR[i]) {
         sstate->xs.xR[i] = sstate->bndu.xR[i];
      }
      if (sstate->havebndl.xB[i] && xs->xR[i] == bndlc->xR[i]) {
         sstate->xs.xR[i] = sstate->bndl.xR[i];
      }
      if (sstate->havebndu.xB[i] && xs->xR[i] == bnduc->xR[i]) {
         sstate->xs.xR[i] = sstate->bndu.xR[i];
      }
   }
// Select sparse direct solver
   if (akind == 1) {
      sparsesolver = settings->sparsesolver;
      if (sparsesolver == 0) {
         sparsesolver = 1;
      }
      if (sparseissks(&sstate->sparsea)) {
         sparsesolver = 2;
      }
      sparsesolver = 2;
      ae_assert(sparsesolver == 1 || sparsesolver == 2, "QQPOptimize: incorrect SparseSolver");
   } else {
      sparsesolver = 0;
   }
// For unconstrained problems - try to use fast approach which requires
// just one unregularized Cholesky decomposition for solution. If it fails,
// switch to general QQP code.
   problemsolved = false;
   isconstrained = false;
   for (i = 0; i < n; i++) {
      isconstrained = isconstrained || sstate->havebndl.xB[i] || sstate->havebndu.xB[i];
   }
   if (!isconstrained && settings->cnphase && akind == 0) {
      matrixsetlengthatleast(&sstate->densez, n, n);
      vectorsetlengthatleast(&sstate->tmpcn, n);
      for (i = 0; i < n; i++) {
         for (j = i; j < n; j++) {
            sstate->densez.xyR[i][j] = sstate->densea.xyR[i][j];
         }
      }
      sstate->repncholesky++;
      if (spdmatrixcholeskyrec(&sstate->densez, 0, n, true, &sstate->tmpcn)) {
         ae_v_move(sstate->xf.xR, 1, sstate->xs.xR, 1, n);
         for (i = 0; i < n; i++) {
            sstate->dc.xR[i] = 0.0;
         }
         f0 = qqpsolver_projectedtargetfunction(sstate, &sstate->xf, &sstate->dc, 0.0, &sstate->tmpcn, &sstate->tmp1);
         for (k = 0; k <= 3; k++) {
            rmatrixmv(n, n, &sstate->densea, 0, 0, 0, &sstate->xf, 0, &sstate->gc, 0);
            ae_v_add(sstate->gc.xR, 1, sstate->b.xR, 1, n);
            for (i = 0; i < n; i++) {
               sstate->dc.xR[i] = -sstate->gc.xR[i];
            }
            fblscholeskysolve(&sstate->densez, 1.0, n, true, &sstate->dc, &sstate->tmpcn);
            f1 = qqpsolver_projectedtargetfunction(sstate, &sstate->xf, &sstate->dc, 1.0, &sstate->tmpcn, &sstate->tmp1);
            if (f1 >= f0) {
               break;
            }
            ae_v_add(sstate->xf.xR, 1, sstate->dc.xR, 1, n);
            f0 = f1;
         }
         *terminationtype = 2;
         problemsolved = true;
      }
   }
// Attempt to solve problem with fast approach failed, use generic QQP
   if (!problemsolved) {
   // Prepare "active set" structure
      sassetbc(&sstate->sas, &sstate->bndl, &sstate->bndu);
      if (!sasstartoptimization(&sstate->sas, &sstate->xs)) {
         *terminationtype = -3;
         return;
      }
   // Main loop.
   //
   // Following variables are used:
   // * GC stores current gradient (unconstrained)
   // * CGC stores current gradient (constrained)
   // * DC stores current search direction
   // * CGP stores constrained gradient at previous point
   //   (zero on initial entry)
   // * DP stores previous search direction
   //   (zero on initial entry)
      cgmax = settings->cgminits;
      sstate->repinneriterationscount = 0;
      sstate->repouteriterationscount = 0;
      while (true) {
         if (settings->maxouterits > 0 && sstate->repouteriterationscount >= settings->maxouterits) {
            *terminationtype = 5;
            break;
         }
         if (sstate->repouteriterationscount > 0) {
         // Check EpsF- and EpsX-based stopping criteria.
         // Because problem was already scaled, we do not scale step before checking its length.
         // NOTE: these checks are performed only after at least one outer iteration was made.
            if (settings->epsf > 0.0) {
            // NOTE 1: here we rely on the fact that ProjectedTargetFunction() ignore D when Stp == 0
            // NOTE 2: code below handles situation when update increases function value instead
            //         of decreasing it.
               fprev = qqpsolver_projectedtargetfunction(sstate, &sstate->xp, &sstate->dc, 0.0, &sstate->tmp0, &sstate->tmp1);
               fcur = qqpsolver_projectedtargetfunction(sstate, &sstate->sas.xc, &sstate->dc, 0.0, &sstate->tmp0, &sstate->tmp1);
               if (fprev - fcur <= settings->epsf * rmax2(fabs(fprev), rmax2(fabs(fcur), 1.0))) {
                  *terminationtype = 1;
                  break;
               }
            }
            if (settings->epsx > 0.0) {
               v = 0.0;
               for (i = 0; i < n; i++) {
                  v += sqr(sstate->xp.xR[i] - sstate->sas.xc.xR[i]);
               }
               if (sqrt(v) <= settings->epsx) {
                  *terminationtype = 2;
                  break;
               }
            }
         }
         sstate->repouteriterationscount++;
         ae_v_move(sstate->xp.xR, 1, sstate->sas.xc.xR, 1, n);
         if (!settings->cgphase) {
            cgmax = 0;
         }
         for (i = 0; i < n; i++) {
            sstate->cgp.xR[i] = 0.0;
            sstate->dp.xR[i] = 0.0;
         }
         for (cgcnt = 0; cgcnt < cgmax; cgcnt++) {
         // Calculate unconstrained gradient GC for "extended" QP problem
         // Determine active set, current constrained gradient CGC.
         // Check gradient-based stopping condition.
         //
         // NOTE: because problem was scaled, we do not have to apply scaling
         //       to gradient before checking stopping condition.
            qqpsolver_targetgradient(sstate, &sstate->sas.xc, &sstate->gc);
            sasreactivateconstraints(&sstate->sas, &sstate->gc);
            ae_v_move(sstate->cgc.xR, 1, sstate->gc.xR, 1, n);
            sasconstraineddirection(&sstate->sas, &sstate->cgc);
            v = ae_v_dotproduct(sstate->cgc.xR, 1, sstate->cgc.xR, 1, n);
            if (sqrt(v) <= settings->epsg) {
               *terminationtype = 4;
               break;
            }
         // Prepare search direction DC and explore it.
         //
         // We try to use CGP/DP to prepare conjugate gradient step,
         // but we resort to steepest descent step (Beta == 0) in case
         // we are at I-th boundary, but DP[I] != 0.
         //
         // Such approach allows us to ALWAYS have feasible DC, with
         // guaranteed compatibility with both feasible area and current
         // active set.
         //
         // Automatic CG reset performed every time DP is incompatible
         // with current active set and/or feasible area. We also
         // perform reset every QuickQPRestartCG iterations.
            ae_v_moveneg(sstate->dc.xR, 1, sstate->cgc.xR, 1, n);
            v = 0.0;
            vv = 0.0;
            b = false;
            for (i = 0; i < n; i++) {
               v += sstate->cgc.xR[i] * sstate->cgc.xR[i];
               vv += sstate->cgp.xR[i] * sstate->cgp.xR[i];
               b = b ||
                  sstate->havebndl.xB[i] && sstate->sas.xc.xR[i] == sstate->bndl.xR[i] && sstate->dp.xR[i] != 0.0 ||
                  sstate->havebndu.xB[i] && sstate->sas.xc.xR[i] == sstate->bndu.xR[i] && sstate->dp.xR[i] != 0.0;
            }
            b = b || vv == 0.0;
            b = b || cgcnt % quickqprestartcg == 0;
            if (!b) {
               beta = v / vv;
            } else {
               beta = 0.0;
            }
            ae_v_addd(sstate->dc.xR, 1, sstate->dp.xR, 1, n, beta);
            sasconstraineddirection(&sstate->sas, &sstate->dc);
            sasexploredirection(&sstate->sas, &sstate->dc, &stpmax, &cidx, &cval);
         // Build quadratic model of F along descent direction:
         //
         //     F(xc+alpha*D) = D2*alpha^2 + D1*alpha
         //
         // Terminate algorithm if needed.
         //
         // NOTE: we do not maintain constant term D0
            qqpsolver_quadraticmodel(sstate, &sstate->sas.xc, &sstate->dc, &sstate->gc, &d1, &d1est, &d2, &d2est, &sstate->tmp0);
            if (d1 == 0.0 && d2 == 0.0) {
            // D1 and D2 are exactly zero, success.
            // After this if-then we assume that D is non-zero.
               *terminationtype = 4;
               break;
            }
            if (d1est >= 0) {
            // Numerical noise is too large, it means that we are close
            // to minimum - and that further improvement is impossible.
            //
            // After this if-then we assume that D1 is definitely negative
            // (even under presence of numerical errors).
               *terminationtype = 7;
               break;
            }
            if (d2est <= 0 && cidx < 0) {
            // Function is unbounded from below:
            // * D1 < 0 (verified by previous block)
            // * D2Est <= 0, which means that either D2 < 0 - or it can not
            //   be reliably distinguished from zero.
            // * step is unconstrained
            //
            // If these conditions are true, we abnormally terminate QP
            // algorithm with return code -4
               *terminationtype = -4;
               break;
            }
         // Perform step along DC.
         //
         // In this block of code we maintain two step length:
         // * RestStp -  restricted step, maximum step length along DC which does
         //              not violate constraints
         // * FullStp -  step length along DC which minimizes quadratic function
         //              without taking constraints into account. If problem is
         //              unbounded from below without constraints, FullStp is
         //              forced to be RestStp.
         //
         // So, if function is convex (D2 > 0):
         // * FullStp = -D1/(2*D2)
         // * RestStp = restricted FullStp
         // * 0 <= RestStp <= FullStp
         //
         // If function is non-convex, but bounded from below under constraints:
         // * RestStp = step length subject to constraints
         // * FullStp = RestStp
         //
         // After RestStp and FullStp are initialized, we generate several trial
         // steps which are different multiples of RestStp and FullStp.
            if (d2est > 0) {
               ae_assert(d1 < 0.0, "QQPOptimize: internal error");
               fullstp = -d1 / (2.0 * d2);
               needact = fullstp >= stpmax;
               if (needact) {
                  ae_assert(sstate->stpbuf.cnt >= 3, "QQPOptimize: StpBuf overflow");
                  reststp = stpmax;
                  stp = reststp;
                  sstate->stpbuf.xR[0] = reststp * 4.0;
                  sstate->stpbuf.xR[1] = fullstp;
                  sstate->stpbuf.xR[2] = fullstp / 4.0;
                  stpcnt = 3;
               } else {
                  reststp = fullstp;
                  stp = fullstp;
                  stpcnt = 0;
               }
            } else {
               ae_assert(cidx >= 0, "QQPOptimize: internal error");
               ae_assert(sstate->stpbuf.cnt >= 2, "QQPOptimize: StpBuf overflow");
               reststp = stpmax;
               fullstp = stpmax;
               stp = reststp;
               needact = true;
               sstate->stpbuf.xR[0] = 4.0 * reststp;
               stpcnt = 1;
            }
            qqpsolver_findbeststepandmove(sstate, &sstate->sas, &sstate->dc, stp, needact, cidx, cval, &sstate->stpbuf, stpcnt, &sstate->activated, &sstate->tmp0, &sstate->tmp1);
         // Update CG information.
            ae_v_move(sstate->dp.xR, 1, sstate->dc.xR, 1, n);
            ae_v_move(sstate->cgp.xR, 1, sstate->cgc.xR, 1, n);
         // Update iterations counter
            sstate->repinneriterationscount++;
         }
         if (*terminationtype != 0) {
            break;
         }
         cgmax = settings->cgmaxits;
      // Generate YIdx - reordering of variables for constrained Newton phase.
      // Free variables come first, fixed are last ones.
         newtcnt = 0;
         while (true) {
         // Skip iteration if constrained Newton is turned off.
            if (!settings->cnphase) {
               break;
            }
         // At the first iteration   - build Cholesky decomposition of Hessian.
         // At subsequent iterations - refine Hessian by adding new constraints.
         //
         // Loop is terminated in following cases:
         // * Hessian is not positive definite subject to current constraints
         //   (termination during initial decomposition)
         // * there were no new constraints being activated
         //   (termination during update)
         // * all constraints were activated during last step
         //   (termination during update)
         // * CNMaxUpdates were performed on matrix
         //   (termination during update)
            if (newtcnt == 0) {
            // Perform initial Newton step. If Cholesky decomposition fails,
            // increase number of CG iterations to CGMaxIts - it should help
            // us to find set of constraints which will make matrix positive
            // definite.
               b = qqpsolver_cnewtonbuild(sstate, sparsesolver, &sstate->repncholesky);
               if (b) {
                  cgmax = settings->cgminits;
               }
            } else {
               b = qqpsolver_cnewtonupdate(sstate, settings, &sstate->repncupdates);
            }
            if (!b) {
               break;
            }
            newtcnt++;
         // Calculate gradient GC.
            qqpsolver_targetgradient(sstate, &sstate->sas.xc, &sstate->gc);
         // Bound-constrained Newton step
            for (i = 0; i < n; i++) {
               sstate->dc.xR[i] = sstate->gc.xR[i];
            }
            if (!qqpsolver_cnewtonstep(sstate, settings, &sstate->dc)) {
               break;
            }
            qqpsolver_quadraticmodel(sstate, &sstate->sas.xc, &sstate->dc, &sstate->gc, &d1, &d1est, &d2, &d2est, &sstate->tmp0);
            if (d1est >= 0) {
            // We are close to minimum, derivative is nearly zero, break Newton iteration
               break;
            }
            if (d2est > 0) {
            // Positive definite matrix, we can perform Newton step
               ae_assert(d1 < 0.0, "QQPOptimize: internal error");
               fullstp = -d1 / (2.0 * d2);
               sasexploredirection(&sstate->sas, &sstate->dc, &stpmax, &cidx, &cval);
               needact = fullstp >= stpmax;
               if (needact) {
                  ae_assert(sstate->stpbuf.cnt >= 3, "QQPOptimize: StpBuf overflow");
                  reststp = stpmax;
                  stp = reststp;
                  sstate->stpbuf.xR[0] = reststp * 4.0;
                  sstate->stpbuf.xR[1] = fullstp;
                  sstate->stpbuf.xR[2] = fullstp / 4.0;
                  stpcnt = 3;
               } else {
                  reststp = fullstp;
                  stp = fullstp;
                  stpcnt = 0;
               }
               qqpsolver_findbeststepandmove(sstate, &sstate->sas, &sstate->dc, stp, needact, cidx, cval, &sstate->stpbuf, stpcnt, &sstate->activated, &sstate->tmp0, &sstate->tmp1);
            } else {
            // Matrix is semi-definite or indefinite, but regularized
            // Cholesky succeeded and gave us descent direction in DC.
            //
            // We will investigate it and try to perform descent step:
            // * first, we explore direction:
            //   * if it is unbounded, we stop algorithm with
            //     appropriate termination code -4.
            //   * if StpMax == 0, we break Newton phase and return to
            //     CG phase - constraint geometry is complicated near
            //     current point, so it is better to use simpler algo.
            // * second, we check that bounded step decreases function;
            //   if not, we again skip to CG phase
            // * finally, we use FindBestStep...() function to choose
            //   between bounded step and projection of full-length step
            //   (latter may give additional decrease in
               sasexploredirection(&sstate->sas, &sstate->dc, &stpmax, &cidx, &cval);
               if (cidx < 0) {
               // Function is unbounded from below:
               // * D1 < 0 (verified by previous block)
               // * D2Est <= 0, which means that either D2 < 0 - or it can not
               //   be reliably distinguished from zero.
               // * step is unconstrained
               //
               // If these conditions are true, we abnormally terminate QP
               // algorithm with return code -4
                  *terminationtype = -4;
                  break;
               }
               if (stpmax == 0.0) {
               // Resort to CG phase.
               // Increase number of CG iterations.
                  cgmax = settings->cgmaxits;
                  break;
               }
               ae_assert(stpmax > 0.0, "QQPOptimize: internal error");
               f0 = qqpsolver_projectedtargetfunction(sstate, &sstate->sas.xc, &sstate->dc, 0.0, &sstate->tmp0, &sstate->tmp1);
               f1 = qqpsolver_projectedtargetfunction(sstate, &sstate->sas.xc, &sstate->dc, stpmax, &sstate->tmp0, &sstate->tmp1);
               if (f1 >= f0) {
               // Descent direction does not actually decrease function value.
               // Resort to CG phase
               // Increase number of CG iterations.
                  cgmax = settings->cgmaxits;
                  break;
               }
               ae_assert(sstate->stpbuf.cnt >= 3, "QQPOptimize: StpBuf overflow");
               reststp = stpmax;
               stp = reststp;
               sstate->stpbuf.xR[0] = reststp * 4.0;
               sstate->stpbuf.xR[1] = 1.00;
               sstate->stpbuf.xR[2] = 0.25;
               stpcnt = 3;
               qqpsolver_findbeststepandmove(sstate, &sstate->sas, &sstate->dc, stp, true, cidx, cval, &sstate->stpbuf, stpcnt, &sstate->activated, &sstate->tmp0, &sstate->tmp1);
            }
         }
         if (*terminationtype != 0) {
            break;
         }
      }
      sasstopoptimization(&sstate->sas);
      ae_v_move(sstate->xf.xR, 1, sstate->sas.xc.xR, 1, n);
   }
// Stop optimization and unpack results.
//
// Add XOriginC to XS and make sure that boundary constraints are
// both (a) satisfied, (b) preserved. Former means that "shifted"
// point is feasible, while latter means that point which was exactly
// at the boundary before shift will be exactly at the boundary
// after shift.
   for (i = 0; i < n; i++) {
      xs->xR[i] = sc->xR[i] * sstate->xf.xR[i] + xoriginc->xR[i];
      if (sstate->havebndl.xB[i] && xs->xR[i] < bndlc->xR[i]) {
         xs->xR[i] = bndlc->xR[i];
      }
      if (sstate->havebndu.xB[i] && xs->xR[i] > bnduc->xR[i]) {
         xs->xR[i] = bnduc->xR[i];
      }
      if (sstate->havebndl.xB[i] && sstate->xf.xR[i] == sstate->bndl.xR[i]) {
         xs->xR[i] = bndlc->xR[i];
      }
      if (sstate->havebndu.xB[i] && sstate->xf.xR[i] == sstate->bndu.xR[i]) {
         xs->xR[i] = bnduc->xR[i];
      }
   }
}

void qqpsettings_init(void *_p, bool make_automatic) {
}

void qqpsettings_copy(void *_dst, const void *_src, bool make_automatic) {
   qqpsettings *dst = (qqpsettings *)_dst;
   const qqpsettings *src = (const qqpsettings *)_src;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxouterits = src->maxouterits;
   dst->cgphase = src->cgphase;
   dst->cnphase = src->cnphase;
   dst->cgminits = src->cgminits;
   dst->cgmaxits = src->cgmaxits;
   dst->cnmaxupdates = src->cnmaxupdates;
   dst->sparsesolver = src->sparsesolver;
}

void qqpsettings_free(void *_p, bool make_automatic) {
}

void qqpbuffers_init(void *_p, bool make_automatic) {
   qqpbuffers *p = (qqpbuffers *)_p;
   ae_matrix_init(&p->densea, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsea, make_automatic);
   ae_vector_init(&p->b, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->havebndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->havebndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->xs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xf, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cgc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cgp, 0, DT_REAL, make_automatic);
   sactiveset_init(&p->sas, make_automatic);
   ae_vector_init(&p->activated, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->densez, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsecca, make_automatic);
   ae_vector_init(&p->yidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->regdiag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->regx0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpcn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpcni, 0, DT_INT, make_automatic);
   ae_vector_init(&p->tmpcnb, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stpbuf, 0, DT_REAL, make_automatic);
   sparsebuffers_init(&p->sbuf, make_automatic);
}

void qqpbuffers_copy(void *_dst, const void *_src, bool make_automatic) {
   qqpbuffers *dst = (qqpbuffers *)_dst;
   const qqpbuffers *src = (const qqpbuffers *)_src;
   dst->n = src->n;
   dst->akind = src->akind;
   ae_matrix_copy(&dst->densea, &src->densea, make_automatic);
   sparsematrix_copy(&dst->sparsea, &src->sparsea, make_automatic);
   dst->sparseupper = src->sparseupper;
   dst->absamax = src->absamax;
   dst->absasum = src->absasum;
   dst->absasum2 = src->absasum2;
   ae_vector_copy(&dst->b, &src->b, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->havebndl, &src->havebndl, make_automatic);
   ae_vector_copy(&dst->havebndu, &src->havebndu, make_automatic);
   ae_vector_copy(&dst->xs, &src->xs, make_automatic);
   ae_vector_copy(&dst->xf, &src->xf, make_automatic);
   ae_vector_copy(&dst->gc, &src->gc, make_automatic);
   ae_vector_copy(&dst->xp, &src->xp, make_automatic);
   ae_vector_copy(&dst->dc, &src->dc, make_automatic);
   ae_vector_copy(&dst->dp, &src->dp, make_automatic);
   ae_vector_copy(&dst->cgc, &src->cgc, make_automatic);
   ae_vector_copy(&dst->cgp, &src->cgp, make_automatic);
   sactiveset_copy(&dst->sas, &src->sas, make_automatic);
   ae_vector_copy(&dst->activated, &src->activated, make_automatic);
   dst->nfree = src->nfree;
   dst->cnmodelage = src->cnmodelage;
   ae_matrix_copy(&dst->densez, &src->densez, make_automatic);
   sparsematrix_copy(&dst->sparsecca, &src->sparsecca, make_automatic);
   ae_vector_copy(&dst->yidx, &src->yidx, make_automatic);
   ae_vector_copy(&dst->regdiag, &src->regdiag, make_automatic);
   ae_vector_copy(&dst->regx0, &src->regx0, make_automatic);
   ae_vector_copy(&dst->tmpcn, &src->tmpcn, make_automatic);
   ae_vector_copy(&dst->tmpcni, &src->tmpcni, make_automatic);
   ae_vector_copy(&dst->tmpcnb, &src->tmpcnb, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->stpbuf, &src->stpbuf, make_automatic);
   sparsebuffers_copy(&dst->sbuf, &src->sbuf, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repncholesky = src->repncholesky;
   dst->repncupdates = src->repncupdates;
}

void qqpbuffers_free(void *_p, bool make_automatic) {
   qqpbuffers *p = (qqpbuffers *)_p;
   ae_matrix_free(&p->densea, make_automatic);
   sparsematrix_free(&p->sparsea, make_automatic);
   ae_vector_free(&p->b, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->havebndl, make_automatic);
   ae_vector_free(&p->havebndu, make_automatic);
   ae_vector_free(&p->xs, make_automatic);
   ae_vector_free(&p->xf, make_automatic);
   ae_vector_free(&p->gc, make_automatic);
   ae_vector_free(&p->xp, make_automatic);
   ae_vector_free(&p->dc, make_automatic);
   ae_vector_free(&p->dp, make_automatic);
   ae_vector_free(&p->cgc, make_automatic);
   ae_vector_free(&p->cgp, make_automatic);
   sactiveset_free(&p->sas, make_automatic);
   ae_vector_free(&p->activated, make_automatic);
   ae_matrix_free(&p->densez, make_automatic);
   sparsematrix_free(&p->sparsecca, make_automatic);
   ae_vector_free(&p->yidx, make_automatic);
   ae_vector_free(&p->regdiag, make_automatic);
   ae_vector_free(&p->regx0, make_automatic);
   ae_vector_free(&p->tmpcn, make_automatic);
   ae_vector_free(&p->tmpcni, make_automatic);
   ae_vector_free(&p->tmpcnb, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->stpbuf, make_automatic);
   sparsebuffers_free(&p->sbuf, make_automatic);
}
} // end of namespace alglib_impl

// === QPDENSEAULSOLVER Package ===
// Depends on: (Solvers) DIRECTDENSESOLVERS, LINLSQR
// Depends on: MINLBFGS, LPQPSERV, QQPSOLVER
namespace alglib_impl {
// This function initializes QPDENSEAULSettings structure with default settings.
//
// Newly created structure MUST be initialized by default settings  -  or  by
// copy of the already initialized structure.
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qpdenseaulloaddefaults(ae_int_t nmain, qpdenseaulsettings *s) {
   s->epsx = 0.000001;
   s->outerits = 5;
   s->rho = 100.0;
}

// This function generates box-constrained QP problem, which is penalized and
// augmented formulation of original linearly constrained problem
// ALGLIB: Copyright 23.02.2017 by Sergey Bochkanov
static void qpdenseaulsolver_generateexmodel(RMatrix *sclsfta, RVector *sclsftb, ae_int_t nmain, RVector *sclsftbndl, BVector *sclsfthasbndl, RVector *sclsftbndu, BVector *sclsfthasbndu, RMatrix *sclsftcleic, ae_int_t sclsftnec, ae_int_t sclsftnic, RVector *nulc, double rho, RMatrix *exa, RVector *exb, RVector *exbndl, RVector *exbndu, RMatrix *tmp2) {
   ae_int_t nslack;
   ae_int_t ntotal;
   ae_int_t i;
   ae_int_t j;
   double v;
   nslack = sclsftnic;
   ntotal = nmain + nslack;
// Integrity check for properly preallocated storage
   ae_assert(exa->rows >= ntotal && exa->cols >= ntotal, "QPDenseAUL.GenerateExModel - integrity check failed");
   ae_assert(exb->cnt >= ntotal && exbndl->cnt >= ntotal && exbndu->cnt >= ntotal, "QPDenseAUL.GenerateExModel - integrity check failed");
// Primary quadratic term
   for (i = 0; i < ntotal; i++) {
      for (j = i; j < ntotal; j++) {
         exa->xyR[i][j] = 0.0;
      }
   }
   for (i = 0; i < nmain; i++) {
      for (j = i; j < nmain; j++) {
         exa->xyR[i][j] = sclsfta->xyR[i][j];
      }
   }
// Primary linear term
   for (i = 0; i < ntotal; i++) {
      exb->xR[i] = 0.0;
   }
   for (i = 0; i < nmain; i++) {
      exb->xR[i] = sclsftb->xR[i];
   }
// Box constraints - move primary, add slack
   for (i = 0; i < nmain; i++) {
      if (sclsfthasbndl->xB[i]) {
         exbndl->xR[i] = sclsftbndl->xR[i];
      } else {
         exbndl->xR[i] = -INFINITY;
      }
      if (sclsfthasbndu->xB[i]) {
         exbndu->xR[i] = sclsftbndu->xR[i];
      } else {
         exbndu->xR[i] = +INFINITY;
      }
   }
   for (i = nmain; i < ntotal; i++) {
      exbndl->xR[i] = 0.0;
      exbndu->xR[i] = +INFINITY;
   }
// Handle equality constraints:
// * modify quadratic term
// * modify linear term
// * add Lagrangian term
   matrixsetlengthatleast(tmp2, sclsftnec + sclsftnic, ntotal);
   for (i = 0; i < sclsftnec + sclsftnic; i++) {
   // Given constraint row ci and right hand side ri,
   // I-th quadratic constraint adds penalty term
   //
   //     0.5*Rho*(ci'*x-ri)^2 =
   //     = 0.5*Rho*(ci'*x-ri)^T*(ci'*x-ri) =
   //     = 0.5*Rho*(x'*ci-ri')*(ci'*x-ri) =
   //     = 0.5*Rho*(x'*ci*ci'*x - ri'*ci'*x - x'*ci*ri + ri'*ri )
   //     = 0.5*Rho*(x'*(ci*ci')*x - 2*ri*(ci'*x) + ri^2 )
   //
   // Thus, quadratic term is updated by
   //
   //     0.5*Rho*(ci*ci')
   //
   // (with actual update to ExA being performed without 0.5
   // multiplier because entire matrix is post-multipliead by 0.5)
   // and linear term receives update
   //
   //     -Rho*ri*ci
   //
   // Similarly, lagrangian term is -NUi*(ci'*x-ri),
   // so linear term is updated by
   //
   //     -NUi*ci
   //
   // Because our model does not take into account constant term,
   // we calculate just quadratic and linear terms.
      ae_v_move(tmp2->xyR[i], 1, sclsftcleic->xyR[i], 1, nmain);
      for (j = nmain; j < ntotal; j++) {
         tmp2->xyR[i][j] = 0.0;
      }
      if (i >= sclsftnec) {
         tmp2->xyR[i][nmain + i - sclsftnec] = 1.0;
      }
      v = -rho * sclsftcleic->xyR[i][nmain];
      ae_v_addd(exb->xR, 1, tmp2->xyR[i], 1, ntotal, v);
      v = -nulc->xR[i];
      ae_v_addd(exb->xR, 1, tmp2->xyR[i], 1, ntotal, v);
   }
   rmatrixsyrk(ntotal, sclsftnec + sclsftnic, rho, tmp2, 0, 0, 2, 1.0, exa, 0, 0, true);
}

// This function generates initial point for  "extended"  box-constrained  QP
// problem.
// ALGLIB: Copyright 23.02.2017 by Sergey Bochkanov
static void qpdenseaulsolver_generateexinitialpoint(RVector *sclsftxc, ae_int_t nmain, ae_int_t nslack, RVector *exxc) {
   ae_int_t ntotal;
   ae_int_t i;
   ntotal = nmain + nslack;
   for (i = 0; i < ntotal; i++) {
      exxc->xR[i] = 0.0;
   }
   for (i = 0; i < nmain; i++) {
      exxc->xR[i] = sclsftxc->xR[i];
   }
}

// This function estimates Lagrange multipliers for scaled-shifted QP problem
// (here "scaled-shifted"  means  that we  performed  variable  scaling   and
// subtracted origin) given by quadratic term A, linear term B, box constraints
// and linear constraint matrix.
//
// It is assumed that all linear constraints are equality  ones,  with  first
// NEC ones being constraints without slack  variables,  and  next  NIC  ones
// having slack variables. The only inequality constraints we  have  are  box
// ones, with first NMain ones being "general" box constraints, and next  NIC
// ones being non-negativity constraints (not specified explicitly).
//
// We also make use of the current point XC, which is used to determine active
// box constraints.
//
// Actual QP problem size is NMain+NIC, but   some  parameters   have   lower
// dimensionality.
//
// Parameters sizes are:
// * A is assumed to be array[NMain,NMain]
// * B is assumed to be array[NMain]
// * BndL, BndU are array[NMain]
// * CLEIC is array[NEC+NIC,NMain+1] (last item in a row containts right part)
// * ExXC is array[NMain+NIC], holds current point
// * NuLCEst is array[NEC+NIC], holds initial values of Lagrange coeffs
//
// On exit NuLCEst is updated with new estimate of Lagrange multipliers.
// ALGLIB: Copyright 23.02.2017 by Sergey Bochkanov
static void qpdenseaulsolver_updatelagrangemultipliers(RMatrix *sclsfta, RVector *sclsftb, ae_int_t nmain, RVector *sclsftbndl, BVector *sclsfthasbndl, RVector *sclsftbndu, BVector *sclsfthasbndu, RMatrix *sclsftcleic, ae_int_t sclsftnec, ae_int_t sclsftnic, RVector *exxc, RVector *nulcest, qpdenseaulbuffers *buffers) {
   ae_int_t nslack;
   ae_int_t ntotal;
   ae_int_t ktotal;
   ae_int_t nqrrows;
   ae_int_t nqrcols;
   ae_int_t i;
   ae_int_t j;
   double lambdareg;
   double mxdiag;
   double v;
   bool isactive;
   nslack = sclsftnic;
   ntotal = nmain + nslack;
   ktotal = sclsftnec + sclsftnic;
// Given current point ExXC, we can determine active and inactive
// constraints. After we drop inactive inequality constraints, we
// have equality-only constrained QP problem, with mix of general
// linear equality constraints and "simple" constraints Xi == Ci.
//
// Problem min(0.5*x'*A*x + b'*x) s.t. C*x == d (general linear
// constraints) can be solved by explicitly writing out Lagrange
// equations:
//
//     [ A  C' ] [ X ]   [ -b]
//     [       ] [   ] = [   ]
//     [ C     ] [ L ]   [ d ]
//
// or
//
//         [ X ]
//     A1* [   ] = b1
//         [ L ]
//
// where X stands for solution itself, and L stands for Lagrange
// multipliers. It can be easily solved with direct linear solver.
// However, such formulation does not account for "simple" equality
// constraints on variables. It is possible to include "simple"
// constraints into "general" ones (i.e. append (0 ... 0 -1 0 ... 0)'
// to the constraint matrix), but it will increase problem
// size.
//
// Another approach is to use initial values of X and L (X0 and L0)
// as starting point, and to solve for "offset" from (X0, L0):
//
//        [ X0+X1 ]
//     A1*[       ] = b1
//        [ L0+L1 ]
//
// or
//
//        [ X1 ]           [ X0 ]
//     A1*[    ] = b1 - A1*[    ]
//        [ L1 ]           [ L0 ]
//
// In such formulation components of X1 which correspond to active
// constraints on variables are "frozen" at value 0 (because we have
// equality constraint, offset from constrained value have to be zero).
//
// Thus, we can rewrite corresponding columns of A1 with zeros - and
// use this space to store (0 ... 0 -1 0 ... 0)', which is used to
// account for Lagrange multipliers for "simple" constraints.
   nqrcols = ntotal + ktotal;
   nqrrows = nqrcols;
   vectorsetlengthatleast(&buffers->qrsv0, nqrcols);
   vectorsetlengthatleast(&buffers->qrsvx1, nqrcols);
   for (i = 0; i < ntotal; i++) {
      buffers->qrsv0.xR[i] = exxc->xR[i];
   }
   for (i = 0; i < ktotal; i++) {
      buffers->qrsv0.xR[ntotal + i] = nulcest->xR[i];
   }
   matrixsetlengthatleast(&buffers->qrkkt, nqrcols + nqrcols, nqrcols + 1);
   vectorsetlengthatleast(&buffers->qrrightpart, nqrcols + nqrcols);
   lambdareg = 0.00000001;
   while (true) {
   // Initialize matrix A1 and right part b1 with zeros
      for (i = 0; i < buffers->qrkkt.rows; i++) {
         for (j = 0; j < buffers->qrkkt.cols; j++) {
            buffers->qrkkt.xyR[i][j] = 0.0;
         }
         buffers->qrrightpart.xR[i] = 0.0;
      }
   // Append quadratic term (note: we implicitly add NSlack zeros to
   // A and b).
      mxdiag = 0.0;
      for (i = 0; i < nmain; i++) {
         for (j = 0; j < nmain; j++) {
            buffers->qrkkt.xyR[i][j] = sclsfta->xyR[i][j];
         }
         buffers->qrrightpart.xR[i] = -sclsftb->xR[i];
         mxdiag = rmax2(mxdiag, fabs(sclsfta->xyR[i][i]));
      }
      mxdiag = coalesce(mxdiag, 1.0);
   // Append general linear constraints
      for (i = 0; i < ktotal; i++) {
         for (j = 0; j < nmain; j++) {
            buffers->qrkkt.xyR[ntotal + i][j] = -sclsftcleic->xyR[i][j];
            buffers->qrkkt.xyR[j][ntotal + i] = -sclsftcleic->xyR[i][j];
         }
         if (i >= sclsftnec) {
            buffers->qrkkt.xyR[ntotal + i][nmain + (i - sclsftnec)] = -1.0;
            buffers->qrkkt.xyR[nmain + (i - sclsftnec)][ntotal + i] = -1.0;
         }
         buffers->qrrightpart.xR[ntotal + i] = -sclsftcleic->xyR[i][nmain];
      }
   // Append regularizer to the bottom of the matrix
   // (it will be factored in during QR decomposition)
      if (lambdareg > 0.0) {
         nqrrows = nqrcols + nqrcols;
         for (i = 0; i < nqrcols; i++) {
            buffers->qrkkt.xyR[nqrcols + i][i] = lambdareg * mxdiag;
         }
      }
   // Subtract reference point (X0,L0) from the system
      for (i = 0; i < nqrcols; i++) {
         v = ae_v_dotproduct(buffers->qrkkt.xyR[i], 1, buffers->qrsv0.xR, 1, nqrcols);
         buffers->qrrightpart.xR[i] -= v;
      }
   // Handle active "simple" equality constraints
      for (i = 0; i < ntotal; i++) {
         isactive = false;
         if (i < nmain && (sclsfthasbndl->xB[i] && exxc->xR[i] == sclsftbndl->xR[i] || sclsfthasbndu->xB[i] && exxc->xR[i] == sclsftbndu->xR[i])) {
            isactive = true;
         }
         if (i >= nmain && exxc->xR[i] == 0.0) {
            isactive = true;
         }
         if (!isactive) {
            continue;
         }
         for (j = 0; j < nqrrows; j++) {
            buffers->qrkkt.xyR[j][i] = 0.0;
         }
         buffers->qrkkt.xyR[i][i] = -1.0;
      }
   // Solve via QR decomposition:
   // * append right part to the system matrix
   // * perform QR decomposition of the extended matrix (right part is implicitly
   //   multiplied by Q during decomposition; believe me, it works!)
   // * check condition number, increase regularization value if necessary and retry
   // * solve triangular system, break iteration
      for (i = 0; i < nqrrows; i++) {
         buffers->qrkkt.xyR[i][nqrcols] = buffers->qrrightpart.xR[i];
      }
      rmatrixqr(&buffers->qrkkt, nqrrows, nqrcols + 1, &buffers->qrtau);
      if (rmatrixtrrcond1(&buffers->qrkkt, nqrcols, true, false) <= 1000.0 * machineepsilon) {
         lambdareg = coalesce(10.0 * lambdareg, 1.0E-13);
         continue;
      }
      for (i = nqrcols - 1; i >= 0; i--) {
         v = buffers->qrkkt.xyR[i][nqrcols];
         for (j = i + 1; j < nqrcols; j++) {
            v -= buffers->qrkkt.xyR[i][j] * buffers->qrsvx1.xR[j];
         }
         buffers->qrsvx1.xR[i] = v / buffers->qrkkt.xyR[i][i];
      }
      break;
   }
// Update Lagrange coefficients
   for (i = 0; i < ktotal; i++) {
      nulcest->xR[i] = buffers->qrsv0.xR[ntotal + i] + buffers->qrsvx1.xR[ntotal + i];
   }
}

// This function generates scaled (by S) and shifted (by XC) reformulation of
// the original problem.
//
// Inputs:
//     DenseA      -   for dense problems (AKind == 0), A-term of CQM object
//                     contains system matrix. Other terms are unspecified
//                     and should not be referenced.
//     SparseA     -   for sparse problems (AKind == 1), CRS format
//     AKind       -   sparse matrix format:
//                     * 0 for dense matrix
//                     * 1 for sparse matrix
//     SparseUpper -   which triangle of SparseAC stores matrix  -  upper  or
//                     lower one (for dense matrices this  parameter  is  not
//                     actual).
//     B           -   linear term, array[N]
//     BndL        -   lower bound, array[N]
//     BndU        -   upper bound, array[N]
//     S           -   scale vector, array[NC]:
//                     * I-th element contains scale of I-th variable,
//                     * SC[I] > 0
//     XOrigin     -   origin term, array[NC]. Can be zero.
//     N           -   number of variables in the  original  formulation  (no
//                     slack variables).
//     CLEIC       -   dense linear equality/inequality constraints. Equality
//                     constraints come first.
//     NEC, NIC    -   number of dense equality/inequality constraints.
//     SCLEIC      -   sparse linear equality/inequality constraints. Equality
//                     constraints come first.
//     SNEC, SNIC  -   number of sparse equality/inequality constraints.
//     RenormLC    -   whether constraints should be renormalized (recommended)
//                     or used "as is".
//     Settings    -   QPDENSEAULSettings object initialized by one of the initialization
//                     functions.
//     State       -   object which stores temporaries
//     XS          -   initial point, array[NC]
//
// On output, following fields of the State structure are modified:
// * SclSftA       -   array[NMain,NMain], quadratic term, both triangles
// * SclSftB       -   array[NMain], linear term
// * SclSftXC      -   array[NMain], initial point
// * SclSftHasBndL,
//   SclSftHasBndU,
//   SclSftBndL,
//   SclSftBndU    -   array[NMain], lower/upper bounds
// * SclSftCLEIC   -   array[KTotal,NMain+1], general linear constraints
//
// NOTE: State.Tmp2 is used to store temporary array[NMain,NMain]
// ALGLIB: Copyright 01.10.2017 by Sergey Bochkanov
static void qpdenseaulsolver_scaleshiftoriginalproblem(convexquadraticmodel *a, sparsematrix *sparsea, ae_int_t akind, bool sparseaupper, RVector *b, RVector *bndl, RVector *bndu, RVector *s, RVector *xorigin, ae_int_t nmain, RMatrix *cleic, ae_int_t dnec, ae_int_t dnic, sparsematrix *scleic, ae_int_t snec, ae_int_t snic, bool renormlc, qpdenseaulbuffers *state, RVector *xs) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t j0;
   ae_int_t j1;
   double v;
   double vv;
   ae_int_t ktotal;
   ae_assert(akind == 0 || akind == 1, "QPDENSEAULOptimize: unexpected AKind");
   ktotal = dnec + dnic + snec + snic;
   matrixsetlengthatleast(&state->sclsfta, nmain, nmain);
   vectorsetlengthatleast(&state->sclsftb, nmain);
   vectorsetlengthatleast(&state->sclsftxc, nmain);
   vectorsetlengthatleast(&state->sclsftbndl, nmain);
   vectorsetlengthatleast(&state->sclsftbndu, nmain);
   vectorsetlengthatleast(&state->sclsfthasbndl, nmain);
   vectorsetlengthatleast(&state->sclsfthasbndu, nmain);
   matrixsetlengthatleast(&state->sclsftcleic, ktotal, nmain + 1);
   vectorsetlengthatleast(&state->cscales, ktotal);
   if (akind == 0) {
   // Extract dense A and scale
      cqmgeta(a, &state->tmp2);
      for (i = 0; i < nmain; i++) {
         for (j = 0; j < nmain; j++) {
            state->sclsfta.xyR[i][j] = 0.0;
         }
      }
      for (i = 0; i < nmain; i++) {
         for (j = i; j < nmain; j++) {
            v = state->tmp2.xyR[i][j] * s->xR[i] * s->xR[j];
            state->sclsfta.xyR[i][j] = v;
            state->sclsfta.xyR[j][i] = v;
         }
      }
   }
   if (akind == 1) {
   // Extract sparse A and scale
      ae_assert(sparsea->matrixtype == 1, "QPDENSEAULOptimize: unexpected sparse matrix format");
      ae_assert(sparsea->m == nmain, "QPDENSEAULOptimize: unexpected sparse matrix size");
      ae_assert(sparsea->n == nmain, "QPDENSEAULOptimize: unexpected sparse matrix size");
      for (i = 0; i < nmain; i++) {
         for (j = 0; j < nmain; j++) {
            state->sclsfta.xyR[i][j] = 0.0;
         }
      }
      if (sparseaupper) {
         for (i = 0; i < nmain; i++) {
            if (sparsea->didx.xZ[i] != sparsea->uidx.xZ[i]) {
               state->sclsfta.xyR[i][i] = sparsea->vals.xR[sparsea->didx.xZ[i]] * s->xR[i] * s->xR[i];
            }
            j0 = sparsea->uidx.xZ[i];
            j1 = sparsea->ridx.xZ[i + 1] - 1;
            for (j = j0; j <= j1; j++) {
               k = sparsea->idx.xZ[j];
               v = sparsea->vals.xR[j] * s->xR[i] * s->xR[k];
               state->sclsfta.xyR[i][k] = v;
               state->sclsfta.xyR[k][i] = v;
            }
         }
      } else {
         for (i = 0; i < nmain; i++) {
            if (sparsea->didx.xZ[i] != sparsea->uidx.xZ[i]) {
               state->sclsfta.xyR[i][i] = sparsea->vals.xR[sparsea->didx.xZ[i]] * s->xR[i] * s->xR[i];
            }
            j0 = sparsea->ridx.xZ[i];
            j1 = sparsea->didx.xZ[i] - 1;
            for (j = j0; j <= j1; j++) {
               k = sparsea->idx.xZ[j];
               v = sparsea->vals.xR[j] * s->xR[i] * s->xR[k];
               state->sclsfta.xyR[i][k] = v;
               state->sclsfta.xyR[k][i] = v;
            }
         }
      }
   }
   for (i = 0; i < nmain; i++) {
      state->sclsftb.xR[i] = b->xR[i] * s->xR[i];
      state->sclsftxc.xR[i] = (xs->xR[i] - xorigin->xR[i]) / s->xR[i];
      state->sclsfthasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->sclsfthasbndu.xB[i] = isfinite(bndu->xR[i]);
      state->sclsftbndl.xR[i] = bndl->xR[i];
      state->sclsftbndu.xR[i] = bndu->xR[i];
   }
   scaleshiftbcinplace(s, xorigin, &state->sclsftbndl, &state->sclsftbndu, nmain);
   for (i = 0; i < ktotal; i++) {
      for (j = 0; j <= nmain; j++) {
         state->sclsftcleic.xyR[i][j] = 0.0;
      }
   }
   for (i = 0; i < dnec; i++) {
      for (j = 0; j < nmain; j++) {
         v = cleic->xyR[i][j] * s->xR[j];
         state->sclsftcleic.xyR[i][j] = v;
      }
      state->sclsftcleic.xyR[i][nmain] = cleic->xyR[i][nmain];
   }
   for (i = 0; i < dnic; i++) {
      for (j = 0; j < nmain; j++) {
         v = cleic->xyR[dnec + i][j] * s->xR[j];
         state->sclsftcleic.xyR[dnec + snec + i][j] = v;
      }
      state->sclsftcleic.xyR[dnec + snec + i][nmain] = cleic->xyR[dnec + i][nmain];
   }
   for (i = 0; i < snec; i++) {
   // Because constraints are sparse, everything is a bit tricky -
   // it is possible that N-th element of the row is zero and not
   // stored; it is also possible that entire row is empty.
      j0 = scleic->ridx.xZ[i];
      j1 = scleic->ridx.xZ[i + 1] - 1;
      if (j1 >= j0 && scleic->idx.xZ[j1] == nmain) {
         state->sclsftcleic.xyR[dnec + i][nmain] = scleic->vals.xR[j1];
         j1--;
      }
      for (j = j0; j <= j1; j++) {
         k = scleic->idx.xZ[j];
         v = scleic->vals.xR[j] * s->xR[k];
         state->sclsftcleic.xyR[dnec + i][k] = v;
      }
   }
   for (i = 0; i < snic; i++) {
   // Because constraints are sparse, everything is a bit tricky -
   // it is possible that N-th element of the row is zero and not
   // stored; it is also possible that entire row is empty.
      j0 = scleic->ridx.xZ[snec + i];
      j1 = scleic->ridx.xZ[snec + i + 1] - 1;
      if (j1 >= j0 && scleic->idx.xZ[j1] == nmain) {
         state->sclsftcleic.xyR[dnec + snec + dnic + i][nmain] = scleic->vals.xR[j1];
         j1--;
      }
      for (j = j0; j <= j1; j++) {
         k = scleic->idx.xZ[j];
         v = scleic->vals.xR[j] * s->xR[k];
         state->sclsftcleic.xyR[dnec + snec + dnic + i][k] = v;
      }
   }
   if (renormlc && ktotal > 0) {
   // Normalize linear constraints in such way that they have unit norm
   // (after variable scaling)
      for (i = 0; i < ktotal; i++) {
         vv = 0.0;
         for (j = 0; j < nmain; j++) {
            v = state->sclsftcleic.xyR[i][j];
            vv += v * v;
         }
         vv = sqrt(vv);
         state->cscales.xR[i] = vv;
         if (vv > 0.0) {
            vv = 1.0 / vv;
            for (j = 0; j <= nmain; j++) {
               state->sclsftcleic.xyR[i][j] *= vv;
            }
         }
      }
   } else {
   // Load unit scales
      for (i = 0; i < ktotal; i++) {
         state->cscales.xR[i] = 1.0;
      }
   }
   for (i = 0; i < ktotal; i++) {
   // Apply XOrigin
      v = 0.0;
      for (j = 0; j < nmain; j++) {
         v += state->sclsftcleic.xyR[i][j] * (xorigin->xR[j] / s->xR[j]);
      }
      state->sclsftcleic.xyR[i][nmain] -= v;
   }
}

// Normalize model in such way that norm(A)~1 (very roughly)
//
// We have two lower bounds for sigma_max(A):
// * first estimate is provided by Frobenius norm, it is equal to ANorm/NMain
// * second estimate is provided by max(CAC)
//
// We select largest one of these estimates, because using just one
// of them is prone to different failure modes. Then, we divide A and B
// by this estimate.
//
// Inputs:
//     A   -       array[N,N], quadratic term, full triangle is given
//     B   -       array[N], linear term
//     N   -       problem size
//     CLEIC-      array[NEC+NIC,N+1], linear equality/inequality constraints
//     NEC -       number of equality constraints
//     NIC -       number of inequality constraints
//     UseCLEIC-   additional normalization of A in such way that CLEIC*A*CLEIC'~1:
//                 * if False, CLEIC is ignored
//                 * if True, CLEIC rows MUST have unit norm (we check it)
//     Tmp2-       additional buffer, possibly preallocated
//
// Outputs:
//     A, B - appropriately rescaled by 1/SCL
//
// Result:
//     multiplier SCL
// ALGLIB: Copyright 01.10.2017 by Sergey Bochkanov
static double qpdenseaulsolver_normalizequadraticterm(RMatrix *a, RVector *b, ae_int_t n, RMatrix *cleic, ae_int_t nec, ae_int_t nic, bool usecleic, RMatrix *tmp2) {
   ae_int_t i;
   ae_int_t j;
   double anorm;
   double maxcac;
   double v;
   double vv;
   ae_int_t ktotal;
   ae_int_t nmain;
   double result;
   nmain = n;
   ktotal = nec + nic;
   anorm = 0.0;
   for (i = 0; i < nmain; i++) {
      for (j = 0; j < nmain; j++) {
         anorm += sqr(a->xyR[i][j]);
      }
   }
   anorm = sqrt(anorm);
   if (usecleic && ktotal > 0) {
   // Calculate max(|diag(C*A*C')|), where C is constraint matrix
      matrixsetlengthatleast(tmp2, ktotal, nmain);
      rmatrixgemm(ktotal, nmain, nmain, 1.0, cleic, 0, 0, 0, a, 0, 0, 0, 0.0, tmp2, 0, 0);
      maxcac = 0.0;
      for (i = 0; i < ktotal; i++) {
         v = 0.0;
         vv = 0.0;
         for (j = 0; j < nmain; j++) {
            v += tmp2->xyR[i][j] * cleic->xyR[i][j];
            vv += sqr(cleic->xyR[i][j]);
         }
         ae_assert(NearR(vv, 1.0, 1.0E-9) || vv == 0.0, "DENSE-AUL: integrity check failed");
         maxcac = rmax2(maxcac, fabs(v));
      }
   } else {
      maxcac = 0.0;
   }
   result = coalesce(rmax2(maxcac, anorm / nmain), 1.0);
   v = 1.0 / result;
   for (i = 0; i < nmain; i++) {
      for (j = 0; j < nmain; j++) {
         a->xyR[i][j] *= v;
      }
   }
   for (i = 0; i < nmain; i++) {
      b->xR[i] *= v;
   }
   return result;
}

// This function selects initial working set of general inequality constraints
// for QP problem:
// * for non-convex QP problems    -   NICWork == NIC is returned
// * otherwise                     -   NICWork == 0 is returned (we have to
//                                     determine working set iteratively)
//
// Inputs:
//     A           -   array[NMain], quadratic term, full matrix is stored
//     NMain       -   number of variables in the "original" QP problem
//     CLEIC       -   array[NEC+NIC,NMain+1], constraint matrix
//     NEC         -   number of equality constraints
//     NIC         -   number of inequality constraints
//
// Outputs:
//     NICWork     -   recommended size of working set; in current version
//                     either all (NICWork == NIC) or none (NICWork == 0) constraints
//                     are included.
//     AllowWSEviction-whether problem properties allow eviction of constraints
//                     from working set or not. Non-convex problems do not
//                     allow eviction, convex ones do.
// ALGLIB: Copyright 02.10.2017 by Sergey Bochkanov
static void qpdenseaulsolver_selectinitialworkingset(RMatrix *a, ae_int_t nmain, RMatrix *cleic, ae_int_t nec, ae_int_t nic, RVector *tmp0, RMatrix *tmp2, ae_int_t *nicwork, bool *allowwseviction) {
   ae_int_t i;
   ae_int_t j;
   *nicwork = 0;
   *allowwseviction = false;
   matrixsetlengthatleast(tmp2, nmain, nmain);
   vectorsetlengthatleast(tmp0, nmain);
   for (i = 0; i < nmain; i++) {
      for (j = i; j < nmain; j++) {
         tmp2->xyR[i][j] = a->xyR[i][j];
      }
   }
   if (!spdmatrixcholeskyrec(tmp2, 0, nmain, true, tmp0)) {
   // Matrix is indefinite.
   //
   // We have to select full working set, otherwise algorithm may fail
   // because problem with reduced working set can be unbounded from below.
      *nicwork = nic;
      *allowwseviction = false;
   } else {
   // Positive definite matrix.
   //
   // We can select zero initial working set and expand it later.
      *nicwork = 0;
      *allowwseviction = true;
   }
}

// This function runs Dense-AUL solver; it returns after optimization process
// was completed. Following QP problem is solved:
//
//     min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//
// subject to combination of box and general linear dense/sparse constraints.
//
// Inputs:
//     DenseA      -   for dense problems (AKind == 0), A-term of CQM object
//                     contains system matrix. Other terms are unspecified
//                     and should not be referenced.
//     SparseA     -   for sparse problems (AKind == 1), CRS format
//     AKind       -   sparse matrix format:
//                     * 0 for dense matrix
//                     * 1 for sparse matrix
//     SparseUpper -   which triangle of SparseAC stores matrix  -  upper  or
//                     lower one (for dense matrices this  parameter  is  not
//                     actual).
//     B           -   linear term, array[N]
//     BndL        -   lower bound, array[N]
//     BndU        -   upper bound, array[N]
//     S           -   scale vector, array[NC]:
//                     * I-th element contains scale of I-th variable,
//                     * SC[I] > 0
//     XOrigin     -   origin term, array[NC]. Can be zero.
//     N           -   number of variables in the  original  formulation  (no
//                     slack variables).
//     CLEIC       -   dense linear equality/inequality constraints. Equality
//                     constraints come first.
//     NEC, NIC    -   number of dense equality/inequality constraints.
//     SCLEIC      -   sparse linear equality/inequality constraints. Equality
//                     constraints come first.
//     SNEC, SNIC  -   number of sparse equality/inequality constraints.
//     RenormLC    -   whether constraints should be renormalized (recommended)
//                     or used "as is".
//     Settings    -   QPDENSEAULSettings object initialized by one of the initialization
//                     functions.
//     State       -   object which stores temporaries
//     XS          -   initial point, array[NC]
//
// Outputs:
//     XS          -   last point
//     TerminationType-termination type:
//                     *
//                     *
//                     *
// ALGLIB: Copyright 2017 by Sergey Bochkanov
void qpdenseauloptimize(convexquadraticmodel *a, sparsematrix *sparsea, ae_int_t akind, bool sparseaupper, RVector *b, RVector *bndl, RVector *bndu, RVector *s, RVector *xorigin, ae_int_t nn, RMatrix *cleic, ae_int_t dnec, ae_int_t dnic, sparsematrix *scleic, ae_int_t snec, ae_int_t snic, bool renormlc, qpdenseaulsettings *settings, qpdenseaulbuffers *state, RVector *xs, RVector *lagbc, RVector *laglc, ae_int_t *terminationtype) {
   const double evictionlevel = -0.01, expansionratio = 0.20;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   double vv;
   double rho;
   double epsx;
   ae_int_t outeridx;
   ae_int_t nmain;
   ae_int_t nslack;
   ae_int_t ntotal;
   ae_int_t ktotal;
   double maxrho;
   double feaserr;
   double feaserrprev;
   double requestedfeasdecrease;
   ae_int_t goodcounter;
   ae_int_t stagnationcounter;
   ae_int_t nectotal;
   ae_int_t nictotal;
   ae_int_t nicwork;
   ae_int_t kwork;
   ae_int_t nwork;
   bool allowwseviction;
   bool workingsetextended;
   double targetscale;
   *terminationtype = 0;
   nmain = nn;
   nslack = dnic + snic;
   ntotal = nmain + nslack;
   nectotal = dnec + snec;
   nictotal = dnic + snic;
   ktotal = dnec + dnic + snec + snic;
   rho = settings->rho;
   epsx = settings->epsx;
   requestedfeasdecrease = 0.33;
   maxrho = 1.0E12;
   if (epsx <= 0.0) {
      epsx = 1.0E-9;
   }
// Integrity checks
   if (snec + snic > 0) {
      ae_assert(scleic->matrixtype == 1, "QPDENSEAULOptimize: unexpected sparse matrix format");
      ae_assert(scleic->m == snec + snic, "QPDENSEAULOptimize: unexpected sparse matrix size");
      ae_assert(scleic->n == nmain + 1, "QPDENSEAULOptimize: unexpected sparse matrix size");
   }
// Prepare
   state->repinneriterationscount = 0;
   state->repouteriterationscount = 0;
   state->repncholesky = 0;
   state->repnmv = 0;
   state->repnwrkchanges = 0;
   state->repnwrk0 = 0;
   state->repnwrk1 = 0;
   state->repnwrkf = 0;
   *terminationtype = 0;
   vectorsetlengthatleast(&state->cidx, ktotal);
   vectorsetlengthatleast(&state->nulc, ktotal);
   vectorsetlengthatleast(&state->nulcest, ktotal);
   vectorsetlengthatleast(&state->exb, ntotal);
   vectorsetlengthatleast(&state->exxc, ntotal);
   vectorsetlengthatleast(&state->exxorigin, ntotal);
   vectorsetlengthatleast(&state->exbndl, ntotal);
   vectorsetlengthatleast(&state->exbndu, ntotal);
   vectorsetlengthatleast(&state->exscale, ntotal);
   vectorsetlengthatleast(&state->tmp0, ntotal);
   vectorsetlengthatleast(&state->nicerr, nictotal);
   vectorsetlengthatleast(&state->nicnact, nictotal);
// Allocate Lagrange multipliers, fill by default values (zeros)
   vectorsetlengthatleast(lagbc, nmain);
   vectorsetlengthatleast(laglc, ktotal);
   for (i = 0; i < nmain; i++) {
      lagbc->xR[i] = 0.0;
   }
   for (i = 0; i < ktotal; i++) {
      laglc->xR[i] = 0.0;
   }
// Prepare scaled/shifted model in dense format - input parameters
// are converted and stored in State.SclSftA/B/HasBndL/HasBndU/BndL/BndU/CLEIC/XC/CScales
   qpdenseaulsolver_scaleshiftoriginalproblem(a, sparsea, akind, sparseaupper, b, bndl, bndu, s, xorigin, nmain, cleic, dnec, dnic, scleic, snec, snic, renormlc, state, xs);
// Normalize model in such way that norm(A)~1 (very roughly)
//
// We have two lower bounds for sigma_max(A):
// * first estimate is provided by Frobenius norm, it is equal to ANorm/NMain
// * second estimate is provided by max(CAC)
//
// We select largest one of these estimates, because using just one
// of them is prone to different failure modes. Then, we divide A and B
// by this estimate.
   targetscale = qpdenseaulsolver_normalizequadraticterm(&state->sclsfta, &state->sclsftb, nmain, &state->sclsftcleic, nectotal, nictotal, renormlc, &state->tmp2);
// Select working set of inequality constraints.
//
// Although it is possible to process all inequality constraints
// at once, in one large batch, some QP problems have NIC >> N constraints,
// but only minor fraction of them is inactive in the solution.
//
// Because algorithm running time is O((N+NEC+NIC)^3), we can
// save a lot of time if we process only those inequality constraints
// which need activation. Generally, NEC < N, and only O(N) inequality
// constraints are active in the solution.
//
// We can do so by solving problem first without general inequality
// constraints at all (box and general equality constraints are added),
// and by iteratively adding more and more inequality constraints in
// order to get feasible solution. Such set of inequality constraints
// is called "working set".
//
// NOTE: such approach works reliably only for convex QP problems; non-convex
//       QP problem can be unbounded when some constraints are dropped.
//
// NOTE: we can also remove some constraints from working set, but eviction
//       can be performed only limited amount of times (at most once); if
//       constraint is added to working set second time, it is never removed.
//
// NOTE: we do not perform constraint eviction on non-convex problems
   qpdenseaulsolver_selectinitialworkingset(&state->sclsfta, nmain, &state->sclsftcleic, nectotal, nictotal, &state->tmp0, &state->tmp2, &nicwork, &allowwseviction);
   kwork = nectotal + nicwork;
   nwork = nmain + nicwork;
   state->repnwrk0 = nicwork;
   for (i = 0; i < nicwork; i++) {
      state->nicnact.xZ[i] = 1;
   }
   for (i = nicwork; i < nictotal; i++) {
      state->nicnact.xZ[i] = 0;
   }
   for (i = 0; i < ktotal; i++) {
      state->cidx.xZ[i] = i;
   }
// Perform outer iteration
   for (i = 0; i < ktotal; i++) {
      state->nulc.xR[i] = 0.0;
   }
   for (i = 0; i < ntotal; i++) {
      state->exscale.xR[i] = 1.0;
      state->exxorigin.xR[i] = 0.0;
   }
   qpdenseaulsolver_generateexinitialpoint(&state->sclsftxc, nmain, nslack, &state->exxc);
   goodcounter = 0;
   stagnationcounter = 0;
   feaserr = maxrealnumber;
   for (outeridx = 0; outeridx < settings->outerits; outeridx++) {
   // Repeat loop until working set stabilizes.
      do {
      // Preallocate space for ExA and for QQP solver; we do not allocate
      // array[NTotal,NTotal] from the start because NTotal can be much
      // larger than NMain for problems with large amount of inequality
      // constraints, and we usually need NWork == O(NMain).
      //
      // NOTE: for the sake of simplicity, 1-dimensional arrays were
      //       preallocated to the maximum size required (NTotal).
         if (state->exa.rows < nwork || state->exa.cols < nwork) {
            i = nwork + nwork / 3 + 1;
            matrixsetlengthatleast(&state->exa, i, i);
         }
         qqppreallocategrowdense(&state->qqpbuf, nwork, i);
      // Generate penalized quadratic model
         qpdenseaulsolver_generateexmodel(&state->sclsfta, &state->sclsftb, nmain, &state->sclsftbndl, &state->sclsfthasbndl, &state->sclsftbndu, &state->sclsfthasbndu, &state->sclsftcleic, nectotal, nicwork, &state->nulc, rho, &state->exa, &state->exb, &state->exbndl, &state->exbndu, &state->tmp2);
      // Solve extended QP problem subject to current working set of general
      // inequality constraints.
         qqploaddefaults(nwork, &state->qqpsettingsuser);
         state->qqpsettingsuser.maxouterits = 50;
         state->qqpsettingsuser.epsg = 0.0;
         state->qqpsettingsuser.epsf = 0.0;
         state->qqpsettingsuser.epsx = 0.01 * epsx;
         state->qqpsettingsuser.cnphase = true;
         qqpoptimize(&state->dummycqm, &state->dummysparse, &state->exa, 2, true, &state->exb, &state->exbndl, &state->exbndu, &state->exscale, &state->exxorigin, nwork, &state->qqpsettingsuser, &state->qqpbuf, &state->exxc, &k);
         state->repncholesky += state->qqpbuf.repncholesky;
      // Evaluate violation of constraints
         for (i = 0; i < nictotal; i++) {
            v = ae_v_dotproduct(state->sclsftcleic.xyR[nectotal + i], 1, state->exxc.xR, 1, nmain);
            v -= state->sclsftcleic.xyR[nectotal + i][nmain];
            state->nicerr.xR[i] = v;
         }
      // Working set expansion:
      // * select limited amount of most violated constraints
      // * perform permutation of non-work constraints such that
      //   candidate constraint is first the list (update XC and NuLC)
      // * increase working set size by 1
      // * increase activation count for new constraint by 1 (this count
      //   is used later by working set eviction phase)
      // * repeat
      //
      // NOTE: we use selection sort algorithm because its O(NAdded*NWork) cost
      //       is still comparable to the cost of constraints evaluation
         workingsetextended = false;
         for (i = 0; i < 1.0 + expansionratio * nmain && nicwork < nictotal; i++) {
         // Select most violated constraint
            k = nicwork;
            for (j = nicwork; j < nictotal; j++) {
               if (state->nicerr.xR[j] > state->nicerr.xR[k]) {
                  k = j;
               }
            }
         // If violation is positive, add it
            if (state->nicerr.xR[k] > 0.0) {
               swaprows(&state->sclsftcleic, nectotal + nicwork, nectotal + k, -1);
               swapelements(&state->nicerr, nicwork, k);
               swapelementsi(&state->nicnact, nicwork, k);
               swapelementsi(&state->cidx, nectotal + nicwork, nectotal + k);
               swapelements(&state->cscales, nectotal + nicwork, nectotal + k);
               state->exxc.xR[nmain + nicwork] = 0.0;
               state->nulc.xR[nectotal + nicwork] = 0.0;
               state->nicnact.xZ[nicwork]++;
               nicwork++;
               nwork++;
               kwork++;
               workingsetextended = true;
            } else {
               break;
            }
         }
      // Working set eviction:
      // * select constraints which are (1) far away from the
      //   boundary, AND (2) has less than two activation attempts
      //   (if constraint is regularly activated/deactivated, we keep
      //   it in the working set no matter what)
      // * remove such constraints from the working set one by one
         if (allowwseviction) {
            for (k = nicwork - 1; k >= 0; k--) {
               if (state->nicerr.xR[k] < evictionlevel && state->nicnact.xZ[k] <= 1) {
                  swaprows(&state->sclsftcleic, nectotal + nicwork - 1, nectotal + k, -1);
                  swapelementsi(&state->cidx, nectotal + nicwork - 1, nectotal + k);
                  swapelements(&state->cscales, nectotal + nicwork - 1, nectotal + k);
                  swapelements(&state->nicerr, nicwork - 1, k);
                  swapelementsi(&state->nicnact, nicwork - 1, k);
                  swapelements(&state->exxc, nmain + nicwork - 1, nmain + k);
                  swapelements(&state->nulc, nectotal + nicwork - 1, nectotal + k);
                  nicwork--;
                  nwork--;
                  kwork--;
               }
            }
         }
      // Report working set statistics
         if (state->repnwrk1 == 0) {
            state->repnwrk1 = nicwork;
         }
         state->repnwrkf = nicwork;
         if (workingsetextended) {
            state->repnwrkchanges++;
         }
      } while (workingsetextended);
   // Estimate Lagrange multipliers using alternative algorithm
      ae_v_move(state->nulcest.xR, 1, state->nulc.xR, 1, kwork);
      qpdenseaulsolver_updatelagrangemultipliers(&state->sclsfta, &state->sclsftb, nmain, &state->sclsftbndl, &state->sclsfthasbndl, &state->sclsftbndu, &state->sclsfthasbndu, &state->sclsftcleic, nectotal, nicwork, &state->exxc, &state->nulcest, state);
   // Update XC and Lagrange multipliers
      feaserrprev = feaserr;
      feaserr = 0.0;
      for (i = 0; i < kwork; i++) {
      // Calculate I-th feasibility error in V using formula for distance
      // between point and line (here we calculate actual distance between
      // XN and hyperplane Ci'*XN == Bi, which is different from error Ci'*XN-Bi).
         v = 0.0;
         vv = 0.0;
         for (j = 0; j < nmain; j++) {
            v += state->sclsftcleic.xyR[i][j] * state->exxc.xR[j];
            vv += sqr(state->sclsftcleic.xyR[i][j]);
         }
         if (i >= nectotal) {
            v += state->exxc.xR[nmain + (i - nectotal)];
            vv += sqr(1.0);
         }
         v -= state->sclsftcleic.xyR[i][nmain];
         vv = coalesce(vv, 1.0);
         v /= sqrt(vv);
      // Calculate magnitude of Lagrangian update (and Lagrangian parameters themselves)
         feaserr += sqr(v);
         state->nulc.xR[i] = state->nulcest.xR[i];
      }
      feaserr = sqrt(feaserr);
      if (feaserr < epsx) {
         goodcounter++;
      } else {
         goodcounter = 0;
      }
      if (feaserr > feaserrprev * requestedfeasdecrease) {
         stagnationcounter++;
      } else {
         stagnationcounter = 0;
      }
      if (goodcounter >= 2) {
         break;
      }
      if (stagnationcounter >= 2) {
         rho = rmin2(rho * 10.0, maxrho);
      } else {
         rho = rmin2(rho * 1.41, maxrho);
      }
   }
// Convert Lagrange multipliers from internal format to one expected
// by caller:
// * reorder multipliers for linear constraints
// * compute residual from gradient+linearconstraints
// * compute multipliers for box constraints from residual
// * rescale everything
   for (i = 0; i < nectotal + nicwork; i++) {
      laglc->xR[state->cidx.xZ[i]] = -state->nulc.xR[i] * targetscale / state->cscales.xR[i];
   }
   vectorsetlengthatleast(&state->tmpg, nmain);
   for (i = 0; i < nmain; i++) {
      v = state->sclsftb.xR[i];
      for (j = 0; j < nmain; j++) {
         v += state->sclsfta.xyR[i][j] * state->exxc.xR[j];
      }
      state->tmpg.xR[i] = v;
   }
   rmatrixgemv(nmain, nectotal + nicwork, -1.0, &state->sclsftcleic, 0, 0, 1, &state->nulc, 0, 1.0, &state->tmpg, 0);
   for (i = 0; i < nmain; i++) {
      if (state->sclsfthasbndl.xB[i] && state->exxc.xR[i] == state->sclsftbndl.xR[i] || state->sclsfthasbndu.xB[i] && state->exxc.xR[i] == state->sclsftbndu.xR[i]) {
         lagbc->xR[i] = -state->tmpg.xR[i];
      }
   }
   for (i = 0; i < nmain; i++) {
      lagbc->xR[i] *= targetscale / s->xR[i];
   }
// Unpack results.
//
// Add XOrigin to XC and make sure that boundary constraints are
// satisfied.
   for (i = 0; i < nmain; i++) {
   // Unscale/unshift
      xs->xR[i] = s->xR[i] * state->exxc.xR[i] + xorigin->xR[i];
   // Make sure that point is feasible w.r.t. box constraints.
   // Enforce box constraints which were active in the scaled/shifted solution.
      if (state->sclsfthasbndl.xB[i]) {
         if (xs->xR[i] < bndl->xR[i]) {
            xs->xR[i] = bndl->xR[i];
         }
         if (state->exxc.xR[i] == state->sclsftbndl.xR[i]) {
            xs->xR[i] = bndl->xR[i];
         }
      }
      if (state->sclsfthasbndu.xB[i]) {
         if (xs->xR[i] > bndu->xR[i]) {
            xs->xR[i] = bndu->xR[i];
         }
         if (state->exxc.xR[i] == state->sclsftbndu.xR[i]) {
            xs->xR[i] = bndu->xR[i];
         }
      }
   }
   *terminationtype = 2;
}

void qpdenseaulsettings_init(void *_p, bool make_automatic) {
}

void qpdenseaulsettings_copy(void *_dst, const void *_src, bool make_automatic) {
   qpdenseaulsettings *dst = (qpdenseaulsettings *)_dst;
   const qpdenseaulsettings *src = (const qpdenseaulsettings *)_src;
   dst->epsx = src->epsx;
   dst->outerits = src->outerits;
   dst->rho = src->rho;
}

void qpdenseaulsettings_free(void *_p, bool make_automatic) {
}

void qpdenseaulbuffers_init(void *_p, bool make_automatic) {
   qpdenseaulbuffers *p = (qpdenseaulbuffers *)_p;
   ae_vector_init(&p->nulc, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->sclsfta, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sclsftb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sclsfthasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->sclsfthasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->sclsftbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sclsftbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sclsftxc, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->sclsftcleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->cscales, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->exa, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->exb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->exxc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->exbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->exbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->exscale, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->exxorigin, 0, DT_REAL, make_automatic);
   qqpsettings_init(&p->qqpsettingsuser, make_automatic);
   qqpbuffers_init(&p->qqpbuf, make_automatic);
   ae_vector_init(&p->nulcest, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpg, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmp2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->modelg, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->deltax, 0, DT_REAL, make_automatic);
   convexquadraticmodel_init(&p->dummycqm, make_automatic);
   sparsematrix_init(&p->dummysparse, make_automatic);
   ae_matrix_init(&p->qrkkt, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->qrrightpart, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->qrtau, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->qrsv0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->qrsvx1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nicerr, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nicnact, 0, DT_INT, make_automatic);
}

void qpdenseaulbuffers_copy(void *_dst, const void *_src, bool make_automatic) {
   qpdenseaulbuffers *dst = (qpdenseaulbuffers *)_dst;
   const qpdenseaulbuffers *src = (const qpdenseaulbuffers *)_src;
   ae_vector_copy(&dst->nulc, &src->nulc, make_automatic);
   ae_matrix_copy(&dst->sclsfta, &src->sclsfta, make_automatic);
   ae_vector_copy(&dst->sclsftb, &src->sclsftb, make_automatic);
   ae_vector_copy(&dst->sclsfthasbndl, &src->sclsfthasbndl, make_automatic);
   ae_vector_copy(&dst->sclsfthasbndu, &src->sclsfthasbndu, make_automatic);
   ae_vector_copy(&dst->sclsftbndl, &src->sclsftbndl, make_automatic);
   ae_vector_copy(&dst->sclsftbndu, &src->sclsftbndu, make_automatic);
   ae_vector_copy(&dst->sclsftxc, &src->sclsftxc, make_automatic);
   ae_matrix_copy(&dst->sclsftcleic, &src->sclsftcleic, make_automatic);
   ae_vector_copy(&dst->cidx, &src->cidx, make_automatic);
   ae_vector_copy(&dst->cscales, &src->cscales, make_automatic);
   ae_matrix_copy(&dst->exa, &src->exa, make_automatic);
   ae_vector_copy(&dst->exb, &src->exb, make_automatic);
   ae_vector_copy(&dst->exxc, &src->exxc, make_automatic);
   ae_vector_copy(&dst->exbndl, &src->exbndl, make_automatic);
   ae_vector_copy(&dst->exbndu, &src->exbndu, make_automatic);
   ae_vector_copy(&dst->exscale, &src->exscale, make_automatic);
   ae_vector_copy(&dst->exxorigin, &src->exxorigin, make_automatic);
   qqpsettings_copy(&dst->qqpsettingsuser, &src->qqpsettingsuser, make_automatic);
   qqpbuffers_copy(&dst->qqpbuf, &src->qqpbuf, make_automatic);
   ae_vector_copy(&dst->nulcest, &src->nulcest, make_automatic);
   ae_vector_copy(&dst->tmpg, &src->tmpg, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_matrix_copy(&dst->tmp2, &src->tmp2, make_automatic);
   ae_vector_copy(&dst->modelg, &src->modelg, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_vector_copy(&dst->deltax, &src->deltax, make_automatic);
   convexquadraticmodel_copy(&dst->dummycqm, &src->dummycqm, make_automatic);
   sparsematrix_copy(&dst->dummysparse, &src->dummysparse, make_automatic);
   ae_matrix_copy(&dst->qrkkt, &src->qrkkt, make_automatic);
   ae_vector_copy(&dst->qrrightpart, &src->qrrightpart, make_automatic);
   ae_vector_copy(&dst->qrtau, &src->qrtau, make_automatic);
   ae_vector_copy(&dst->qrsv0, &src->qrsv0, make_automatic);
   ae_vector_copy(&dst->qrsvx1, &src->qrsvx1, make_automatic);
   ae_vector_copy(&dst->nicerr, &src->nicerr, make_automatic);
   ae_vector_copy(&dst->nicnact, &src->nicnact, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repncholesky = src->repncholesky;
   dst->repnwrkchanges = src->repnwrkchanges;
   dst->repnwrk0 = src->repnwrk0;
   dst->repnwrk1 = src->repnwrk1;
   dst->repnwrkf = src->repnwrkf;
   dst->repnmv = src->repnmv;
}

void qpdenseaulbuffers_free(void *_p, bool make_automatic) {
   qpdenseaulbuffers *p = (qpdenseaulbuffers *)_p;
   ae_vector_free(&p->nulc, make_automatic);
   ae_matrix_free(&p->sclsfta, make_automatic);
   ae_vector_free(&p->sclsftb, make_automatic);
   ae_vector_free(&p->sclsfthasbndl, make_automatic);
   ae_vector_free(&p->sclsfthasbndu, make_automatic);
   ae_vector_free(&p->sclsftbndl, make_automatic);
   ae_vector_free(&p->sclsftbndu, make_automatic);
   ae_vector_free(&p->sclsftxc, make_automatic);
   ae_matrix_free(&p->sclsftcleic, make_automatic);
   ae_vector_free(&p->cidx, make_automatic);
   ae_vector_free(&p->cscales, make_automatic);
   ae_matrix_free(&p->exa, make_automatic);
   ae_vector_free(&p->exb, make_automatic);
   ae_vector_free(&p->exxc, make_automatic);
   ae_vector_free(&p->exbndl, make_automatic);
   ae_vector_free(&p->exbndu, make_automatic);
   ae_vector_free(&p->exscale, make_automatic);
   ae_vector_free(&p->exxorigin, make_automatic);
   qqpsettings_free(&p->qqpsettingsuser, make_automatic);
   qqpbuffers_free(&p->qqpbuf, make_automatic);
   ae_vector_free(&p->nulcest, make_automatic);
   ae_vector_free(&p->tmpg, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_matrix_free(&p->tmp2, make_automatic);
   ae_vector_free(&p->modelg, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->deltax, make_automatic);
   convexquadraticmodel_free(&p->dummycqm, make_automatic);
   sparsematrix_free(&p->dummysparse, make_automatic);
   ae_matrix_free(&p->qrkkt, make_automatic);
   ae_vector_free(&p->qrrightpart, make_automatic);
   ae_vector_free(&p->qrtau, make_automatic);
   ae_vector_free(&p->qrsv0, make_automatic);
   ae_vector_free(&p->qrsvx1, make_automatic);
   ae_vector_free(&p->nicerr, make_automatic);
   ae_vector_free(&p->nicnact, make_automatic);
}
} // end of namespace alglib_impl

// === MINBLEIC Package ===
// Depends on: (AlgLibInternal) LINMIN
// Depends on: CQMODELS, SACTIVESETS
namespace alglib_impl {
// This function sets boundary constraints for BLEIC optimizer.
//
// Boundary constraints are inactive by default (after initial creation).
// They are preserved after algorithm restart with MinBLEICRestartFrom().
//
// NOTE: if you have box-only constraints (no  general  linear  constraints),
//       then MinBC optimizer can be better option. It uses  special,  faster
//       constraint activation method, which performs better on problems with
//       multiple constraints active at the solution.
//
//       On small-scale problems performance of MinBC is similar to  that  of
//       MinBLEIC, but on large-scale ones (hundreds and thousands of  active
//       constraints) it can be several times faster than MinBLEIC.
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF.
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF.
//
// NOTE 1: it is possible to specify BndL[i] == BndU[i]. In this case I-th
// variable will be "frozen" at X[i] == BndL[i] == BndU[i].
//
// NOTE 2: this solver has following useful properties:
// * bound constraints are always satisfied exactly
// * function is evaluated only INSIDE area specified by  bound  constraints,
//   even  when  numerical  differentiation is used (algorithm adjusts  nodes
//   according to boundary constraints)
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicsetbc(const minbleicstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minbleicsetbc(minbleicstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->nmain;
   ae_assert(bndl->cnt >= n, "MinBLEICSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinBLEICSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinBLEICSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinBLEICSetBC: BndL contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
   }
   sassetbc(&state->sas, bndl, bndu);
}

// This function sets linear constraints for BLEIC optimizer.
//
// Linear constraints are inactive by default (after initial creation).
// They are preserved after algorithm restart with MinBLEICRestartFrom().
//
// Inputs:
//     State   -   structure previously allocated with MinBLEICCreate call.
//     C       -   linear constraints, array[K,N+1].
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n]
//     K       -   number of equality/inequality constraints, K >= 0:
//                 * if given, only leading K elements of C/CT are used
//                 * if not given, automatically determined from sizes of C/CT
//
// NOTE 1: linear (non-bound) constraints are satisfied only approximately:
// * there always exists some minor violation (about Epsilon in magnitude)
//   due to rounding errors
// * numerical differentiation, if used, may  lead  to  function  evaluations
//   outside  of the feasible  area,   because   algorithm  does  NOT  change
//   numerical differentiation formula according to linear constraints.
// If you want constraints to be  satisfied  exactly, try to reformulate your
// problem  in  such  manner  that  all constraints will become boundary ones
// (this kind of constraints is always satisfied exactly, both in  the  final
// solution and in all intermediate points).
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicsetlc(const minbleicstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k);
// API: void minbleicsetlc(const minbleicstate &state, const real_2d_array &c, const integer_1d_array &ct);
void minbleicsetlc(minbleicstate *state, RMatrix *c, ZVector *ct, ae_int_t k) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   double v;
   n = state->nmain;
// First, check for errors in the inputs
   ae_assert(k >= 0, "MinBLEICSetLC: K < 0");
   ae_assert(c->cols > n || k == 0, "MinBLEICSetLC: Cols(C) <= N");
   ae_assert(c->rows >= k, "MinBLEICSetLC: Rows(C) < K");
   ae_assert(ct->cnt >= k, "MinBLEICSetLC: Length(CT) < K");
   ae_assert(apservisfinitematrix(c, k, n + 1), "MinBLEICSetLC: C contains infinite or NaN values!");
// Handle zero K
   if (k == 0) {
      state->nec = 0;
      state->nic = 0;
      sassetlc(&state->sas, c, ct, 0);
      return;
   }
// Equality constraints are stored first, in the upper
// NEC rows of State.CLEIC matrix. Inequality constraints
// are stored in the next NIC rows.
//
// NOTE: we convert inequality constraints to the form
// A*x <= b before copying them.
   matrixsetlengthatleast(&state->cleic, k, n + 1);
   state->nec = 0;
   state->nic = 0;
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] == 0) {
         ae_v_move(state->cleic.xyR[state->nec], 1, c->xyR[i], 1, n + 1);
         state->nec++;
      }
   }
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] != 0) {
         if (ct->xZ[i] > 0) {
            ae_v_moveneg(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         } else {
            ae_v_move(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         }
         state->nic++;
      }
   }
// Normalize rows of State.CLEIC: each row must have unit norm.
// Norm is calculated using first N elements (i.e. right part is
// not counted when we calculate norm).
   for (i = 0; i < k; i++) {
      v = 0.0;
      for (j = 0; j < n; j++) {
         v += sqr(state->cleic.xyR[i][j]);
      }
      if (v == 0.0) {
         continue;
      }
      v = 1.0 / sqrt(v);
      ae_v_muld(state->cleic.xyR[i], 1, n + 1, v);
   }
   sassetlc(&state->sas, c, ct, k);
}

// This function sets stopping conditions for the optimizer.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsG    -   >= 0
//                 The  subroutine  finishes  its  work   if   the  condition
//                 |v| < EpsG is satisfied, where:
//                 * |.| means Euclidian norm
//                 * v - scaled gradient vector, v[i] == g[i]*s[i]
//                 * g - gradient
//                 * s - scaling coefficients set by MinBLEICSetScale()
//     EpsF    -   >= 0
//                 The  subroutine  finishes  its work if on k+1-th iteration
//                 the  condition  |F(k+1)-F(k)| <= EpsF*max{|F(k)|,|F(k+1)|,1}
//                 is satisfied.
//     EpsX    -   >= 0
//                 The subroutine finishes its work if  on  k+1-th  iteration
//                 the condition |v| <= EpsX is fulfilled, where:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - step vector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinBLEICSetScale()
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited.
//
// Passing EpsG == 0, EpsF == 0 and EpsX == 0 and MaxIts == 0 (simultaneously) will lead
// to automatic stopping criterion selection.
//
// NOTE: when SetCond() called with non-zero MaxIts, BLEIC solver may perform
//       slightly more than MaxIts iterations. I.e., MaxIts  sets  non-strict
//       limit on iterations count.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicsetcond(const minbleicstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits);
void minbleicsetcond(minbleicstate *state, double epsg, double epsf, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsg), "MinBLEICSetCond: EpsG is not finite number");
   ae_assert(epsg >= 0.0, "MinBLEICSetCond: negative EpsG");
   ae_assert(isfinite(epsf), "MinBLEICSetCond: EpsF is not finite number");
   ae_assert(epsf >= 0.0, "MinBLEICSetCond: negative EpsF");
   ae_assert(isfinite(epsx), "MinBLEICSetCond: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinBLEICSetCond: negative EpsX");
   ae_assert(maxits >= 0, "MinBLEICSetCond: negative MaxIts!");
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->epsg = epsg;
   state->epsf = epsf;
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function sets scaling coefficients for BLEIC optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Scaling is also used by finite difference variant of the optimizer  - step
// along I-th axis is equal to DiffStep*S[I].
//
// In  most  optimizers  (and  in  the  BLEIC  too)  scaling is NOT a form of
// preconditioning. It just  affects  stopping  conditions.  You  should  set
// preconditioner  by  separate  call  to  one  of  the  MinBLEICSetPrec...()
// functions.
//
// There is a special  preconditioning  mode, however,  which  uses   scaling
// coefficients to form diagonal preconditioning matrix. You  can  turn  this
// mode on, if you want.   But  you should understand that scaling is not the
// same thing as preconditioning - these are two different, although  related
// forms of tuning solver.
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minbleicsetscale(const minbleicstate &state, const real_1d_array &s);
void minbleicsetscale(minbleicstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->nmain, "MinBLEICSetScale: Length(S) < N");
   for (i = 0; i < state->nmain; i++) {
      ae_assert(isfinite(s->xR[i]), "MinBLEICSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinBLEICSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
   sassetscale(&state->sas, s);
}

// Modification of the preconditioner: preconditioning is turned off.
//
// Inputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minbleicsetprecdefault(const minbleicstate &state);
void minbleicsetprecdefault(minbleicstate *state) {
   state->prectype = 0;
}

// Modification  of  the  preconditioner:  diagonal of approximate Hessian is
// used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     D       -   diagonal of the approximate Hessian, array[0..N-1],
//                 (if larger, only leading N elements are used).
//
// NOTE 1: D[i] should be positive. Exception will be thrown otherwise.
//
// NOTE 2: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minbleicsetprecdiag(const minbleicstate &state, const real_1d_array &d);
void minbleicsetprecdiag(minbleicstate *state, RVector *d) {
   ae_int_t i;
   ae_assert(d->cnt >= state->nmain, "MinBLEICSetPrecDiag: D is too short");
   for (i = 0; i < state->nmain; i++) {
      ae_assert(isfinite(d->xR[i]), "MinBLEICSetPrecDiag: D contains infinite or NAN elements");
      ae_assert(d->xR[i] > 0.0, "MinBLEICSetPrecDiag: D contains non-positive elements");
   }
   vectorsetlengthatleast(&state->diagh, state->nmain);
   state->prectype = 2;
   for (i = 0; i < state->nmain; i++) {
      state->diagh.xR[i] = d->xR[i];
   }
}

// Modification of the preconditioner: scale-based diagonal preconditioning.
//
// This preconditioning mode can be useful when you  don't  have  approximate
// diagonal of Hessian, but you know that your  variables  are  badly  scaled
// (for  example,  one  variable is in [1,10], and another in [1000,100000]),
// and most part of the ill-conditioning comes from different scales of vars.
//
// In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
// can greatly improve convergence.
//
// IMPRTANT: you should set scale of your variables  with  MinBLEICSetScale()
// call  (before  or after MinBLEICSetPrecScale() call). Without knowledge of
// the scale of your variables scale-based preconditioner will be  just  unit
// matrix.
//
// Inputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minbleicsetprecscale(const minbleicstate &state);
void minbleicsetprecscale(minbleicstate *state) {
   state->prectype = 3;
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to MinBLEICOptimize().
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicsetxrep(const minbleicstate &state, const bool needxrep);
void minbleicsetxrep(minbleicstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This function turns on/off line search reports.
// These reports are described in more details in developer-only  comments on
// MinBLEICState object.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedDRep-   whether line search reports are needed or not
//
// This function is intended for private use only. Turning it on artificially
// may cause program failure.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
void minbleicsetdrep(minbleicstate *state, bool needdrep) {
   state->drep = needdrep;
}

// This function sets maximum step length
//
// IMPORTANT: this feature is hard to combine with preconditioning. You can't
// set upper limit on step length, when you solve optimization  problem  with
// linear (non-boundary) constraints AND preconditioner turned on.
//
// When  non-boundary  constraints  are  present,  you  have to either a) use
// preconditioner, or b) use upper limit on step length.  YOU CAN'T USE BOTH!
// In this case algorithm will terminate with appropriate error code.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     StpMax  -   maximum step length, >= 0. Set StpMax to 0.0,  if you don't
//                 want to limit step length.
//
// Use this subroutine when you optimize target function which contains exp()
// or  other  fast  growing  functions,  and optimization algorithm makes too
// large  steps  which  lead   to overflow. This function allows us to reject
// steps  that  are  too  large  (and  therefore  expose  us  to the possible
// overflow) without actually calculating function value at the x+stp*d.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minbleicsetstpmax(const minbleicstate &state, const double stpmax);
void minbleicsetstpmax(minbleicstate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinBLEICSetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinBLEICSetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// This subroutine restarts algorithm from new point.
// All optimization parameters (including constraints) are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have  same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure previously allocated with MinBLEICCreate call.
//     X       -   new starting point.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicrestartfrom(const minbleicstate &state, const real_1d_array &x);
void minbleicrestartfrom(minbleicstate *state, RVector *x) {
   ae_int_t n;
   n = state->nmain;
// First, check for errors in the inputs
   ae_assert(x->cnt >= n, "MinBLEICRestartFrom: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinBLEICRestartFrom: X contains infinite or NaN values!");
// Set XC
   ae_v_move(state->xstart.xR, 1, x->xR, 1, n);
// prepare RComm facilities
   state->PQ = -1;
   sasstopoptimization(&state->sas);
}

// Internal initialization subroutine
static void minbleic_minbleicinitinternal(ae_int_t n, RVector *x, double diffstep, minbleicstate *state) {
   ae_int_t i;
   EnFrame();
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
// Initialize
   state->teststep = 0.0;
   state->smoothnessguardlevel = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, 0, 0, false);
   state->nmain = n;
   state->diffstep = diffstep;
   sasinit(n, &state->sas);
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->hasbndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->hasbndu, n);
   ae_vector_set_length(&state->xstart, n);
   ae_vector_set_length(&state->cgc, n);
   ae_vector_set_length(&state->ugc, n);
   ae_vector_set_length(&state->xn, n);
   ae_vector_set_length(&state->cgn, n);
   ae_vector_set_length(&state->ugn, n);
   ae_vector_set_length(&state->xp, n);
   ae_vector_set_length(&state->d, n);
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->invs, n);
   ae_vector_set_length(&state->lastscaleused, n);
   ae_vector_set_length(&state->x, n);
   ae_vector_set_length(&state->g, n);
   ae_vector_set_length(&state->work, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = -INFINITY;
      state->hasbndl.xB[i] = false;
      state->bndu.xR[i] = +INFINITY;
      state->hasbndu.xB[i] = false;
      state->s.xR[i] = 1.0;
      state->invs.xR[i] = 1.0;
      state->lastscaleused.xR[i] = 1.0;
   }
   minbleicsetlc(state, &c, &ct, 0);
   minbleicsetcond(state, 0.0, 0.0, 0.0, 0);
   minbleicsetxrep(state, false);
   minbleicsetdrep(state, false);
   minbleicsetstpmax(state, 0.0);
   minbleicsetprecdefault(state);
   minbleicrestartfrom(state, x);
   DeFrame();
}

// BOUND CONSTRAINED OPTIMIZATION
// WITH ADDITIONAL LINEAR EQUALITY AND INEQUALITY CONSTRAINTS
// The  subroutine  minimizes  function   F(x)  of N arguments subject to any
// combination of:
// * bound constraints
// * linear inequality constraints
// * linear equality constraints
//
// REQUIREMENTS:
// * user must provide function value and gradient
// * starting point X0 must be feasible or
//   not too far away from the feasible set
// * grad(f) must be Lipschitz continuous on a level set:
//   L = { x : f(x) <= f(x0) }
// * function must be defined everywhere on the feasible set F
//
// USAGE:
//
// Constrained optimization if far more complex than the unconstrained one.
// Here we give very brief outline of the BLEIC optimizer. We strongly recommend
// you to read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
// on optimization, which is available at http://www.alglib.net/optimization/
//
// 1. User initializes algorithm state with MinBLEICCreate() call
//
// 2. USer adds boundary and/or linear constraints by calling
//    MinBLEICSetBC() and MinBLEICSetLC() functions.
//
// 3. User sets stopping conditions with MinBLEICSetCond().
//
// 4. User calls MinBLEICOptimize() function which takes algorithm  state and
//    pointer (delegate, etc.) to callback function which calculates F/G.
//
// 5. User calls MinBLEICResults() to get solution
//
// 6. Optionally user may call MinBLEICRestartFrom() to solve another problem
//    with same N but another starting point.
//    MinBLEICRestartFrom() allows to reuse already initialized structure.
//
// NOTE: if you have box-only constraints (no  general  linear  constraints),
//       then MinBC optimizer can be better option. It uses  special,  faster
//       constraint activation method, which performs better on problems with
//       multiple constraints active at the solution.
//
//       On small-scale problems performance of MinBC is similar to  that  of
//       MinBLEIC, but on large-scale ones (hundreds and thousands of  active
//       constraints) it can be several times faster than MinBLEIC.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size ofX
//     X       -   starting point, array[N]:
//                 * it is better to set X to a feasible point
//                 * but X can be infeasible, in which case algorithm will try
//                   to find feasible point first, using X as initial
//                   approximation.
//
// Outputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleiccreate(const ae_int_t n, const real_1d_array &x, minbleicstate &state);
// API: void minbleiccreate(const real_1d_array &x, minbleicstate &state);
void minbleiccreate(ae_int_t n, RVector *x, minbleicstate *state) {
   EnFrame();
   SetObj(minbleicstate, state);
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
   ae_assert(n >= 1, "MinBLEICCreate: N < 1");
   ae_assert(x->cnt >= n, "MinBLEICCreate: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinBLEICCreate: X contains infinite or NaN values!");
   minbleic_minbleicinitinternal(n, x, 0.0, state);
   DeFrame();
}

// The subroutine is finite difference variant of MinBLEICCreate().  It  uses
// finite differences in order to differentiate target function.
//
// Description below contains information which is specific to  this function
// only. We recommend to read comments on MinBLEICCreate() in  order  to  get
// more information about creation of BLEIC optimizer.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   starting point, array[0..N-1].
//     DiffStep-   differentiation step, > 0
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. algorithm uses 4-point central formula for differentiation.
// 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
//    S[] is scaling vector which can be set by MinBLEICSetScale() call.
// 3. we recommend you to use moderate values of  differentiation  step.  Too
//    large step will result in too large truncation  errors, while too small
//    step will result in too large numerical  errors.  0.000001  can be good
//    value to start with.
// 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
//    calculation needs 4*N function evaluations. This function will work for
//    any N - either small (1...10), moderate (10...100) or  large  (100...).
//    However, performance penalty will be too severe for any N's except  for
//    small ones.
//    We should also say that code which relies on numerical  differentiation
//    is  less  robust and precise. CG needs exact gradient values. Imprecise
//    gradient may slow  down  convergence, especially  on  highly  nonlinear
//    problems.
//    Thus  we  recommend to use this function for fast prototyping on small-
//    dimensional problems only, and to implement analytical gradient as soon
//    as possible.
// ALGLIB: Copyright 16.05.2011 by Sergey Bochkanov
// API: void minbleiccreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minbleicstate &state);
// API: void minbleiccreatef(const real_1d_array &x, const double diffstep, minbleicstate &state);
void minbleiccreatef(ae_int_t n, RVector *x, double diffstep, minbleicstate *state) {
   EnFrame();
   SetObj(minbleicstate, state);
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
   ae_assert(n >= 1, "MinBLEICCreateF: N < 1");
   ae_assert(x->cnt >= n, "MinBLEICCreateF: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinBLEICCreateF: X contains infinite or NaN values!");
   ae_assert(isfinite(diffstep), "MinBLEICCreateF: DiffStep is infinite or NaN!");
   ae_assert(diffstep > 0.0, "MinBLEICCreateF: DiffStep is non-positive!");
   minbleic_minbleicinitinternal(n, x, diffstep, state);
   DeFrame();
}

// This subroutine updates estimate of the good step length given:
// 1) previous estimate
// 2) new length of the good step
//
// It makes sure that estimate does not change too rapidly - ratio of new and
// old estimates will be at least 0.01, at most 100.0
//
// In case previous estimate of good step is zero (no estimate), new estimate
// is used unconditionally.
// ALGLIB: Copyright 16.01.2013 by Sergey Bochkanov
static void minbleic_updateestimateofgoodstep(double *estimate, double newstep) {
   if (*estimate == 0.0) {
      *estimate = newstep;
      return;
   }
   if (newstep < *estimate * 0.01) {
      *estimate *= 0.01;
      return;
   }
   if (newstep > *estimate * 100.0) {
      *estimate *= 100.0;
      return;
   }
   *estimate = newstep;
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions minbleicoptimize() listed below.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: bool minbleiciteration(const minbleicstate &state);
// API: void minbleicoptimize(minbleicstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minbleicoptimize(minbleicstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minbleiciteration(minbleicstate *state) {
   const double gtol = 0.4, maxnonmonotoniclen = 0.0000001;
   const double initialdecay = 0.5, mindecay = 0.1, decaycorrection = 0.8;
   const double penaltyfactor = 100.0;
   AutoS ae_int_t n;
   AutoS ae_int_t m;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS double v;
   AutoS double vv;
   AutoS double v0;
   AutoS bool b;
   AutoS ae_int_t mcinfo;
   AutoS ae_int_t actstatus;
   AutoS ae_int_t itidx;
   AutoS double penalty;
   AutoS double ginit;
   AutoS double gdecay;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14; case 15: goto Resume15;
      case 16: goto Resume16; case 17: goto Resume17; case 18: goto Resume18;
      case 19: goto Resume19; case 20: goto Resume20; case 21: goto Resume21;
      default: goto Exit;
   }
Spawn:
// Algorithm parameters:
// * M          number of L-BFGS corrections.
//              This coefficient remains fixed during iterations.
// * GDecay     desired decrease of constrained gradient during L-BFGS iterations.
//              This coefficient is decreased after each L-BFGS round until
//              it reaches minimum decay.
   m = imin2(5, state->nmain);
   gdecay = initialdecay;
// Init
   n = state->nmain;
   state->lsstart = state->xupdated = state->needfg = state->needf = false;
   state->steepestdescentstep = false;
   state->userterminationneeded = false;
   state->repterminationtype = 0;
   state->repinneriterationscount = 0;
   state->repouteriterationscount = 0;
   state->repnfev = 0;
   state->repvaridx = -1;
   state->repdebugeqerr = 0.0;
   state->repdebugfs = NAN;
   state->repdebugff = NAN;
   state->repdebugdx = NAN;
   if (state->stpmax != 0.0 && state->prectype != 0) {
      state->repterminationtype = -10;
      goto Exit;
   }
   matrixsetlengthatleast(&state->bufyk, m + 1, n);
   matrixsetlengthatleast(&state->bufsk, m + 1, n);
   vectorsetlengthatleast(&state->bufrho, m);
   vectorsetlengthatleast(&state->buftheta, m);
   vectorsetlengthatleast(&state->tmp0, n);
   smoothnessmonitorinit(&state->smonitor, &state->s, n, 1, state->smoothnessguardlevel > 0);
   for (i = 0; i < n; i++) {
      state->lastscaleused.xR[i] = state->s.xR[i];
      state->invs.xR[i] = 1.0 / state->s.xR[i];
   }
// Check analytic derivative
   if (state->diffstep == 0.0 && state->teststep > 0.0) {
      while (smoothnessmonitorcheckgradientatx0(&state->smonitor, &state->xstart, &state->s, &state->bndl, &state->bndu, true, state->teststep)) {
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->smonitor.x.xR[i];
         }
         state->needfg = true, state->PQ = 0; goto Pause; Resume00: state->needfg = false;
         state->smonitor.fi.xR[0] = state->f;
         for (i = 0; i < n; i++) {
            state->smonitor.j.xyR[0][i] = state->g.xR[i];
         }
      }
   }
// Fill TmpPrec with current preconditioner
   vectorsetlengthatleast(&state->tmpprec, n);
   for (i = 0; i < n; i++) {
      if (state->prectype == 2) {
         state->tmpprec.xR[i] = state->diagh.xR[i];
         continue;
      }
      if (state->prectype == 3) {
         state->tmpprec.xR[i] = 1.0 / sqr(state->s.xR[i]);
         continue;
      }
      state->tmpprec.xR[i] = 1.0;
   }
   sassetprecdiag(&state->sas, &state->tmpprec);
// Start optimization
   if (!sasstartoptimization(&state->sas, &state->xstart)) {
      state->repterminationtype = -3;
      goto Exit;
   }
// Main cycle of BLEIC-PG algorithm
   state->repterminationtype = 0;
   state->lastgoodstep = 0.0;
   state->lastscaledgoodstep = 0.0;
   state->maxscaledgrad = 0.0;
   state->nonmonotoniccnt = iround(1.5 * (n + state->nic)) + 5;
   ae_v_move(state->x.xR, 1, state->sas.xc.xR, 1, n);
   if (state->diffstep == 0.0) {
      state->needfg = true, state->PQ = 1; goto Pause; Resume01: state->needfg = false;
   } else {
      state->needf = true, state->PQ = 2; goto Pause; Resume02: state->needf = false;
   }
   state->fc = state->f;
   trimprepare(state->f, &state->trimthreshold);
   state->repnfev++;
   if (state->xrep) {
   // Report current point
      ae_v_move(state->x.xR, 1, state->sas.xc.xR, 1, n);
      state->f = state->fc;
      state->xupdated = true, state->PQ = 3; goto Pause; Resume03: state->xupdated = false;
   }
   if (state->userterminationneeded) {
   // User requested termination
      sasstopoptimization(&state->sas);
      state->repterminationtype = 8;
      goto Exit;
   }
   while (true) {
   // Preparations
   //
   // (a) calculate unconstrained gradient
   // (b) determine initial active set
   // (c) update MaxScaledGrad
   // (d) check F/G for NAN/INF, abnormally terminate algorithm if needed
      ae_v_move(state->x.xR, 1, state->sas.xc.xR, 1, n);
      if (state->diffstep == 0.0) {
      // Analytic gradient
         state->needfg = true, state->PQ = 4; goto Pause; Resume04: state->needfg = false;
      } else {
      // Numerical differentiation
         state->needf = true;
         state->PQ = 5; goto Pause; Resume05:
         state->fbase = state->f;
         for (i = 0; i < n; i++) {
            v = state->x.xR[i];
            b =
               state->hasbndl.xB[i] && v - state->diffstep * state->s.xR[i] < state->bndl.xR[i] ||
               state->hasbndu.xB[i] && v + state->diffstep * state->s.xR[i] > state->bndu.xR[i];
            if (!b) {
               state->x.xR[i] = v - state->diffstep * state->s.xR[i];
               state->PQ = 6; goto Pause; Resume06:
               state->fm2 = state->f;
               state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 7; goto Pause; Resume07:
               state->fm1 = state->f;
               state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 8; goto Pause; Resume08:
               state->fp1 = state->f;
               state->x.xR[i] = v + state->diffstep * state->s.xR[i];
               state->PQ = 9; goto Pause; Resume09:
               state->fp2 = state->f;
               state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
            } else {
               state->xm1 = v - state->diffstep * state->s.xR[i];
               state->xp1 = v + state->diffstep * state->s.xR[i];
               if (state->hasbndl.xB[i] && state->xm1 < state->bndl.xR[i]) {
                  state->xm1 = state->bndl.xR[i];
               }
               if (state->hasbndu.xB[i] && state->xp1 > state->bndu.xR[i]) {
                  state->xp1 = state->bndu.xR[i];
               }
               state->x.xR[i] = state->xm1;
               state->PQ = 10; goto Pause; Resume10:
               state->fm1 = state->f;
               state->x.xR[i] = state->xp1;
               state->PQ = 11; goto Pause; Resume11:
               state->fp1 = state->f;
               if (state->xm1 != state->xp1) {
                  state->g.xR[i] = (state->fp1 - state->fm1) / (state->xp1 - state->xm1);
               } else {
                  state->g.xR[i] = 0.0;
               }
            }
            state->x.xR[i] = v;
         }
         state->needf = false;
         state->f = state->fbase;
      }
      state->fc = state->f;
      ae_v_move(state->ugc.xR, 1, state->g.xR, 1, n);
      ae_v_move(state->cgc.xR, 1, state->g.xR, 1, n);
      sasreactivateconstraintsprec(&state->sas, &state->ugc);
      sasconstraineddirection(&state->sas, &state->cgc);
      ginit = 0.0;
      for (i = 0; i < n; i++) {
         ginit += sqr(state->cgc.xR[i] * state->s.xR[i]);
      }
      ginit = sqrt(ginit);
      state->maxscaledgrad = rmax2(state->maxscaledgrad, ginit);
      if (!isfinite(ginit) || !isfinite(state->fc)) {
      // Abnormal termination - infinities in function/gradient
         sasstopoptimization(&state->sas);
         state->repterminationtype = -8;
         goto Exit;
      }
      if (state->userterminationneeded) {
      // User requested termination
         sasstopoptimization(&state->sas);
         state->repterminationtype = 8;
         goto Exit;
      }
   // LBFGS stage:
   // * during LBFGS iterations we activate new constraints, but never
   //   deactivate already active ones.
   // * we perform at most N iterations of LBFGS before re-evaluating
   //   active set and restarting LBFGS.
   // * first iteration of LBFGS is a special - it is performed with
   //   minimum set of active constraints, algorithm termination can
   //   be performed only at this state. We call this iteration
   //   "steepest descent step".
   //
   // About termination:
   // * LBFGS iterations can be terminated because of two reasons:
   //   * "termination" - non-zero termination code in RepTerminationType,
   //     which means that optimization is done
   //   * "restart" - zero RepTerminationType, which means that we
   //     have to re-evaluate active set and resume LBFGS stage.
   // * one more option is "refresh" - to continue LBFGS iterations,
   //   but with all BFGS updates (Sk/Yk pairs) being dropped;
   //   it happens after changes in active set
      state->bufsize = 0;
      state->steepestdescentstep = true;
      for (itidx = -1; itidx < n - 1; ) {
      // Increment iterations counter
      //
      // NOTE: we have strong reasons to use such complex scheme
      //       instead of just for() loop - this counter may be
      //       decreased at some occasions to perform "restart"
      //       of an iteration.
         itidx++;
      // At the beginning of each iteration:
      // * SAS.XC stores current point
      // * FC stores current function value
      // * UGC stores current unconstrained gradient
      // * CGC stores current constrained gradient
      // * D stores constrained step direction (calculated at this block)
      //
      //
      // Check gradient-based stopping criteria
      //
      // This stopping condition is tested only for step which is the
      // first step of LBFGS (subsequent steps may accumulate active
      // constraints thus they should NOT be used for stopping - gradient
      // may be small when constrained, but these constraints may be
      // deactivated by the subsequent steps)
         if (state->steepestdescentstep && sasscaledconstrainednorm(&state->sas, &state->ugc) <= state->epsg) {
         // Gradient is small enough.
         // Optimization is terminated
            state->repterminationtype = 4;
            break;
         }
      // 1. Calculate search direction D according to L-BFGS algorithm
      //    using constrained preconditioner to perform inner multiplication.
      // 2. Evaluate scaled length of direction D; restart LBFGS if D is zero
      //    (it may be possible that we found minimum, but it is also possible
      //    that some constraints need deactivation)
      // 3. If D is non-zero, try to use previous scaled step length as initial estimate for new step.
         ae_v_move(state->work.xR, 1, state->cgc.xR, 1, n);
         for (i = state->bufsize - 1; i >= 0; i--) {
            v = ae_v_dotproduct(state->bufsk.xyR[i], 1, state->work.xR, 1, n);
            state->buftheta.xR[i] = v;
            vv = v * state->bufrho.xR[i];
            ae_v_subd(state->work.xR, 1, state->bufyk.xyR[i], 1, n, vv);
         }
         sasconstraineddirectionprec(&state->sas, &state->work);
         for (i = 0; i < state->bufsize; i++) {
            v = ae_v_dotproduct(state->bufyk.xyR[i], 1, state->work.xR, 1, n);
            vv = state->bufrho.xR[i] * (-v + state->buftheta.xR[i]);
            ae_v_addd(state->work.xR, 1, state->bufsk.xyR[i], 1, n, vv);
         }
         sasconstraineddirection(&state->sas, &state->work);
         ae_v_moveneg(state->d.xR, 1, state->work.xR, 1, n);
         v = 0.0;
         for (i = 0; i < n; i++) {
            v += sqr(state->d.xR[i] / state->s.xR[i]);
         }
         v = sqrt(v);
         if (v == 0.0) {
         // Search direction is zero.
         // If we perform "steepest descent step", algorithm is terminated.
         // Otherwise we just restart LBFGS.
            if (state->steepestdescentstep) {
               state->repterminationtype = 4;
            }
            break;
         }
         ae_assert(v > 0.0, "MinBLEIC: internal error");
         if (state->lastscaledgoodstep > 0.0 && v > 0.0) {
            state->stp = state->lastscaledgoodstep / v;
         } else {
            state->stp = 1.0 / v;
         }
      // Calculate bound on step length.
      // Step direction is stored
         sasexploredirection(&state->sas, &state->d, &state->curstpmax, &state->cidx, &state->cval);
         state->activationstep = state->curstpmax;
         if (state->cidx >= 0 && state->activationstep == 0.0) {
         // We are exactly at the boundary, immediate activation
         // of constraint is required. LBFGS stage is continued
         // with "refreshed" model.
         //
         // ! IMPORTANT: we do not clear SteepestDescent flag here,
         // !            it is very important for correct stopping
         // !            of algorithm.
         //
         // ! IMPORTANT: we decrease iteration counter in order to
         //              preserve computational budget for iterations.
            sasimmediateactivation(&state->sas, state->cidx, state->cval);
            state->bufsize = 0;
            itidx--;
            continue;
         }
         if (state->stpmax > 0.0) {
            v = ae_v_dotproduct(state->d.xR, 1, state->d.xR, 1, n);
            v = sqrt(v);
            if (v > 0.0) {
               state->curstpmax = rmin2(state->curstpmax, state->stpmax / v);
            }
         }
      // Report beginning of line search (if requested by caller).
      // See description of the MinBLEICState for more information
      // about fields accessible to caller.
      //
      // Caller may do following:
      // * change State.Stp and load better initial estimate of
      //   the step length.
      // Caller may not terminate algorithm.
         if (state->drep) {
            state->boundedstep = state->cidx >= 0;
            ae_v_move(state->x.xR, 1, state->sas.xc.xR, 1, n);
            state->lsstart = true, state->PQ = 12; goto Pause; Resume12: state->lsstart = false;
         }
      // Minimize F(x+alpha*d)
         ae_v_move(state->xn.xR, 1, state->sas.xc.xR, 1, n);
         ae_v_move(state->cgn.xR, 1, state->cgc.xR, 1, n);
         ae_v_move(state->ugn.xR, 1, state->ugc.xR, 1, n);
         state->fn = state->fc;
         state->mcstage = 0;
         smoothnessmonitorstartlinesearch1u(&state->smonitor, &state->s, &state->invs, &state->xn, state->fn, &state->ugn, state->repinneriterationscount, -1);
         while (mcsrch(n, &state->xn, state->fn, &state->ugn, &state->d, &state->stp, state->curstpmax, gtol, &mcinfo, &state->nfev, &state->work, &state->lstate, &state->mcstage)) {
         // Perform correction (constraints are enforced)
         // Copy XN to X
            sascorrection(&state->sas, &state->xn, &penalty);
            for (i = 0; i < n; i++) {
               state->x.xR[i] = state->xn.xR[i];
            }
         // Gradient, either user-provided or numerical differentiation
            if (state->diffstep == 0.0) {
            // Analytic gradient
               state->needfg = true, state->PQ = 13; goto Pause; Resume13: state->needfg = false;
               state->repnfev++;
            } else {
            // Numerical differentiation
               state->needf = true;
               state->PQ = 14; goto Pause; Resume14:
               state->fbase = state->f;
               for (i = 0; i < n; i++) {
                  v = state->x.xR[i];
                  b =
                     state->hasbndl.xB[i] && v - state->diffstep * state->s.xR[i] < state->bndl.xR[i] ||
                     state->hasbndu.xB[i] && v + state->diffstep * state->s.xR[i] > state->bndu.xR[i];
                  if (!b) {
                     state->x.xR[i] = v - state->diffstep * state->s.xR[i];
                     state->PQ = 15; goto Pause; Resume15:
                     state->fm2 = state->f;
                     state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
                     state->PQ = 16; goto Pause; Resume16:
                     state->fm1 = state->f;
                     state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
                     state->PQ = 17; goto Pause; Resume17:
                     state->fp1 = state->f;
                     state->x.xR[i] = v + state->diffstep * state->s.xR[i];
                     state->PQ = 18; goto Pause; Resume18:
                     state->fp2 = state->f;
                     state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
                     state->repnfev += 4;
                  } else {
                     state->xm1 = v - state->diffstep * state->s.xR[i];
                     state->xp1 = v + state->diffstep * state->s.xR[i];
                     if (state->hasbndl.xB[i] && state->xm1 < state->bndl.xR[i]) {
                        state->xm1 = state->bndl.xR[i];
                     }
                     if (state->hasbndu.xB[i] && state->xp1 > state->bndu.xR[i]) {
                        state->xp1 = state->bndu.xR[i];
                     }
                     state->x.xR[i] = state->xm1;
                     state->PQ = 19; goto Pause; Resume19:
                     state->fm1 = state->f;
                     state->x.xR[i] = state->xp1;
                     state->PQ = 20; goto Pause; Resume20:
                     state->fp1 = state->f;
                     if (state->xm1 != state->xp1) {
                        state->g.xR[i] = (state->fp1 - state->fm1) / (state->xp1 - state->xm1);
                     } else {
                        state->g.xR[i] = 0.0;
                     }
                     state->repnfev += 2;
                  }
                  state->x.xR[i] = v;
               }
               state->needf = false;
               state->f = state->fbase;
            }
         // Back to MCSRCH
         //
         // NOTE: penalty term from correction is added to FN in order
         //       to penalize increase in infeasibility.
            smoothnessmonitorenqueuepoint1u(&state->smonitor, &state->s, &state->invs, &state->d, state->stp, &state->x, state->f, &state->g);
            state->fn = state->f + penaltyfactor * state->maxscaledgrad * penalty;
            ae_v_move(state->cgn.xR, 1, state->g.xR, 1, n);
            ae_v_move(state->ugn.xR, 1, state->g.xR, 1, n);
            sasconstraineddirection(&state->sas, &state->cgn);
            trimfunction(&state->fn, &state->cgn, n, state->trimthreshold);
         }
         ae_v_moveneg(state->bufsk.xyR[state->bufsize], 1, state->sas.xc.xR, 1, n);
         ae_v_moveneg(state->bufyk.xyR[state->bufsize], 1, state->cgc.xR, 1, n);
         ae_v_add(state->bufsk.xyR[state->bufsize], 1, state->xn.xR, 1, n);
         ae_v_add(state->bufyk.xyR[state->bufsize], 1, state->cgn.xR, 1, n);
         smoothnessmonitorfinalizelinesearch(&state->smonitor);
      // Check for presence of NAN/INF in function/gradient
         v = state->fn;
         for (i = 0; i < n; i++) {
            v = 0.1 * v + state->ugn.xR[i];
         }
         if (!isfinite(v)) {
         // Abnormal termination - infinities in function/gradient
            state->repterminationtype = -8;
            break;
         }
      // Handle possible failure of the line search or request for termination
         if (mcinfo != 1 && mcinfo != 5) {
         // We can not find step which decreases function value. We have
         // two possibilities:
         // (a) numerical properties of the function do not allow us to
         //     find good step.
         // (b) we are close to activation of some constraint, and it is
         //     so close that step which activates it leads to change in
         //     target function which is smaller than numerical noise.
         //
         // Optimization algorithm must be able to handle case (b), because
         // inability to handle it will cause failure when algorithm
         // started very close to boundary of the feasible area.
         //
         // In order to correctly handle such cases we allow limited amount
         // of small steps which increase function value.
            v = 0.0;
            for (i = 0; i < n; i++) {
               v += sqr(state->d.xR[i] * state->curstpmax / state->s.xR[i]);
            }
            v = sqrt(v);
            b = false;
            if (state->cidx >= 0 && v <= maxnonmonotoniclen && state->nonmonotoniccnt > 0) {
            // We try to enforce non-monotonic step:
            // * Stp    = CurStpMax
            // * MCINFO = 5
            // * XN     = XC+CurStpMax*D
            // * non-monotonic counter is decreased
            //
            // NOTE: UGN/CGN are not updated because step is so short that we assume that
            //       GN is approximately equal to GC.
            //
            // NOTE: prior to enforcing such step we check that it does not increase infeasibility
            //       of constraints beyond tolerable level
               v = state->curstpmax;
               ae_v_move(state->tmp0.xR, 1, state->sas.xc.xR, 1, n);
               ae_v_addd(state->tmp0.xR, 1, state->d.xR, 1, n, v);
               state->stp = state->curstpmax;
               mcinfo = 5;
               ae_v_move(state->xn.xR, 1, state->tmp0.xR, 1, n);
               state->nonmonotoniccnt--;
               b = true;
            }
            if (!b) {
            // Numerical properties of the function do not allow
            // us to solve problem. Here we have two possibilities:
            // * if it is "steepest descent" step, we can terminate
            //   algorithm because we are close to minimum
            // * if it is NOT "steepest descent" step, we should restart
            //   LBFGS iterations.
               if (state->steepestdescentstep) {
               // Algorithm is terminated
                  state->repterminationtype = 7;
                  break;
               } else {
               // Re-evaluate active set and restart LBFGS
                  break;
               }
            }
         }
         if (state->userterminationneeded) {
            break;
         }
      // Current point is updated:
      // * move XC/FC/GC to XP/FP/GP
      // * change current point remembered by SAS structure
      // * move XN/FN/GN to XC/FC/GC
      // * report current point and update iterations counter
      // * if MCINFO == 1, push new pair SK/YK to LBFGS buffer
         state->fp = state->fc;
         ae_v_move(state->xp.xR, 1, state->sas.xc.xR, 1, n);
         state->fc = state->fn;
         ae_v_move(state->cgc.xR, 1, state->cgn.xR, 1, n);
         ae_v_move(state->ugc.xR, 1, state->ugn.xR, 1, n);
         actstatus = sasmoveto(&state->sas, &state->xn, state->cidx >= 0 && state->stp >= state->activationstep, state->cidx, state->cval);
         if (state->xrep) {
            ae_v_move(state->x.xR, 1, state->sas.xc.xR, 1, n);
            state->xupdated = true, state->PQ = 21; goto Pause; Resume21: state->xupdated = false;
         }
         state->repinneriterationscount++;
         if (mcinfo == 1) {
         // Accept new LBFGS update given by Sk,Yk
            if (state->bufsize == m) {
            // Buffer is full, shift contents by one row
               for (i = 0; i < state->bufsize; i++) {
                  ae_v_move(state->bufsk.xyR[i], 1, state->bufsk.xyR[i + 1], 1, n);
                  ae_v_move(state->bufyk.xyR[i], 1, state->bufyk.xyR[i + 1], 1, n);
               }
               for (i = 0; i < state->bufsize - 1; i++) {
                  state->bufrho.xR[i] = state->bufrho.xR[i + 1];
                  state->buftheta.xR[i] = state->buftheta.xR[i + 1];
               }
            } else {
            // Buffer is not full, increase buffer size by 1
               state->bufsize++;
            }
            v = ae_v_dotproduct(state->bufyk.xyR[state->bufsize - 1], 1, state->bufsk.xyR[state->bufsize - 1], 1, n);
            vv = ae_v_dotproduct(state->bufyk.xyR[state->bufsize - 1], 1, state->bufyk.xyR[state->bufsize - 1], 1, n);
            if (v == 0.0 || vv == 0.0) {
            // Strange internal error in LBFGS - either YK == 0
            // (which should not have been) or (SK,YK) == 0 (again,
            // unexpected). It should not take place because
            // MCINFO == 1, which signals "good" step. But just
            // to be sure we have special branch of code which
            // restarts LBFGS
               break;
            }
            state->bufrho.xR[state->bufsize - 1] = 1.0 / v;
            ae_assert(state->bufsize <= m, "MinBLEIC: internal error");
         // Update length of the good step
            v = 0.0;
            vv = 0.0;
            for (i = 0; i < n; i++) {
               v += sqr((state->sas.xc.xR[i] - state->xp.xR[i]) / state->s.xR[i]);
               vv += sqr(state->sas.xc.xR[i] - state->xp.xR[i]);
            }
            state->lastgoodstep = sqrt(vv);
            minbleic_updateestimateofgoodstep(&state->lastscaledgoodstep, sqrt(v));
         }
      // Check stopping criteria
      //
      // Step size and function-based stopping criteria are tested only
      // for step which satisfies Wolfe conditions and is the first step of
      // LBFGS (subsequent steps may accumulate active constraints thus
      // they should NOT be used for stopping; step size or function change
      // may be small when constrained, but these constraints may be
      // deactivated by the subsequent steps).
      //
      // MaxIts-based stopping condition is checked for all kinds of steps.
         if (mcinfo == 1 && state->steepestdescentstep) {
         // Step is small enough
            v = 0.0;
            for (i = 0; i < n; i++) {
               v += sqr((state->sas.xc.xR[i] - state->xp.xR[i]) / state->s.xR[i]);
            }
            v = sqrt(v);
            if (v <= state->epsx) {
               state->repterminationtype = 2;
               break;
            }
         // Function change is small enough
            if (NearAtR(state->fp, state->fc, state->epsf * rmax2(fabs(state->fc), rmax2(fabs(state->fp), 1.0)))) {
               state->repterminationtype = 1;
               break;
            }
         }
         if (state->maxits > 0 && state->repinneriterationscount >= state->maxits) {
            state->repterminationtype = 5;
            break;
         }
      // Clear "steepest descent" flag.
         state->steepestdescentstep = false;
      // Smooth reset (LBFGS memory model is refreshed) or hard restart:
      // * LBFGS model is refreshed, if line search was performed with activation of constraints
      // * algorithm is restarted if scaled gradient decreased below GDecay
         if (actstatus >= 0) {
            state->bufsize = 0;
            continue;
         }
         v = 0.0;
         for (i = 0; i < n; i++) {
            v += sqr(state->cgc.xR[i] * state->s.xR[i]);
         }
         if (sqrt(v) < gdecay * ginit) {
            break;
         }
      }
      if (state->userterminationneeded) {
      // User requested termination
         state->repterminationtype = 8;
         break;
      }
      if (state->repterminationtype != 0) {
      // Algorithm terminated
         break;
      }
   // Decrease decay coefficient. Subsequent L-BFGS stages will
   // have more stringent stopping criteria.
      gdecay = rmax2(gdecay * decaycorrection, mindecay);
   }
   sasstopoptimization(&state->sas);
   state->repouteriterationscount = 1;
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This  function  activates/deactivates verification  of  the  user-supplied
// analytic gradient.
//
// Upon  activation  of  this  option  OptGuard  integrity  checker  performs
// numerical differentiation of your target function  at  the  initial  point
// (note: future versions may also perform check  at  the  final  point)  and
// compares numerical gradient with analytic one provided by you.
//
// If difference is too large, an error flag is set and optimization  session
// continues. After optimization session is over, you can retrieve the report
// which  stores  both  gradients  and  specific  components  highlighted  as
// suspicious by the OptGuard.
//
// The primary OptGuard report can be retrieved with minbleicoptguardresults().
//
// IMPORTANT: gradient check is a high-overhead option which  will  cost  you
//            about 3*N additional function evaluations. In many cases it may
//            cost as much as the rest of the optimization session.
//
//            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
//            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
//
// NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
//       does NOT interrupt optimization even if it discovers bad gradient.
//
// Inputs:
//     State       -   structure used to store algorithm state
//     TestStep    -   verification step used for numerical differentiation:
//                     * TestStep == 0 turns verification off
//                     * TestStep > 0 activates verification
//                     You should carefully choose TestStep. Value  which  is
//                     too large (so large that  function  behavior  is  non-
//                     cubic at this scale) will lead  to  false  alarms. Too
//                     short step will result in rounding  errors  dominating
//                     numerical derivative.
//
//                     You may use different step for different parameters by
//                     means of setting scale with minbleicsetscale().
//
// ==== EXPLANATION ====
//
// In order to verify gradient algorithm performs following steps:
//   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
//     where X[i] is i-th component of the initial point and S[i] is a  scale
//     of i-th parameter
//   * F(X) is evaluated at these trial points
//   * we perform one more evaluation in the middle point of the interval
//   * we  build  cubic  model using function values and derivatives at trial
//     points and we compare its prediction with actual value in  the  middle
//     point
// ALGLIB: Copyright 15.06.2014 by Sergey Bochkanov
// API: void minbleicoptguardgradient(const minbleicstate &state, const double teststep);
void minbleicoptguardgradient(minbleicstate *state, double teststep) {
   ae_assert(isfinite(teststep), "MinBLEICOptGuardGradient: TestStep contains NaN or INF");
   ae_assert(teststep >= 0.0, "MinBLEICOptGuardGradient: invalid argument TestStep(TestStep < 0)");
   state->teststep = teststep;
}

// This  function  activates/deactivates nonsmoothness monitoring  option  of
// the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
// solution process and tries to detect ill-posed problems, i.e. ones with:
// a) discontinuous target function (non-C0)
// b) nonsmooth     target function (non-C1)
//
// Smoothness monitoring does NOT interrupt optimization  even if it suspects
// that your problem is nonsmooth. It just sets corresponding  flags  in  the
// OptGuard report which can be retrieved after optimization is over.
//
// Smoothness monitoring is a moderate overhead option which often adds  less
// than 1% to the optimizer running time. Thus, you can use it even for large
// scale problems.
//
// NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
//       continuity violations.
//
//       First, minor errors are hard to  catch - say, a 0.0001 difference in
//       the model values at two sides of the gap may be due to discontinuity
//       of the model - or simply because the model has changed.
//
//       Second, C1-violations  are  especially  difficult  to  detect  in  a
//       noninvasive way. The optimizer usually  performs  very  short  steps
//       near the nonsmoothness, and differentiation  usually   introduces  a
//       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
//       discontinuity in the slope is due to real nonsmoothness or just  due
//       to numerical noise alone.
//
//       Our top priority was to avoid false positives, so in some rare cases
//       minor errors may went unnoticed (however, in most cases they can  be
//       spotted with restart from different initial point).
//
// Inputs:
//     state   -   algorithm state
//     level   -   monitoring level:
//                 * 0 - monitoring is disabled
//                 * 1 - noninvasive low-overhead monitoring; function values
//                       and/or gradients are recorded, but OptGuard does not
//                       try to perform additional evaluations  in  order  to
//                       get more information about suspicious locations.
//
// ==== EXPLANATION ====
//
// One major source of headache during optimization  is  the  possibility  of
// the coding errors in the target function/constraints (or their gradients).
// Such  errors   most   often   manifest   themselves  as  discontinuity  or
// nonsmoothness of the target/constraints.
//
// Another frequent situation is when you try to optimize something involving
// lots of min() and max() operations, i.e. nonsmooth target. Although not  a
// coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
// stop right after encountering nonsmoothness, well before reaching solution.
//
// OptGuard integrity checker helps you to catch such situations: it monitors
// function values/gradients being passed  to  the  optimizer  and  tries  to
// errors. Upon discovering suspicious pair of points it  raises  appropriate
// flag (and allows you to continue optimization). When optimization is done,
// you can study OptGuard result.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbleicoptguardsmoothness(const minbleicstate &state, const ae_int_t level);
// API: void minbleicoptguardsmoothness(const minbleicstate &state);
void minbleicoptguardsmoothness(minbleicstate *state, ae_int_t level) {
   ae_assert(level == 0 || level == 1, "MinBLEICOptGuardSmoothness: unexpected value of level parameter");
   state->smoothnessguardlevel = level;
}

// Results of OptGuard integrity check, should be called  after  optimization
// session is over.
//
// ==== PRIMARY REPORT ====
//
// OptGuard performs several checks which are intended to catch common errors
// in the implementation of nonlinear function/gradient:
// * incorrect analytic gradient
// * discontinuous (non-C0) target functions (constraints)
// * nonsmooth     (non-C1) target functions (constraints)
//
// Each of these checks is activated with appropriate function:
// * minbleicoptguardgradient() for gradient verification
// * minbleicoptguardsmoothness() for C0/C1 checks
//
// Following flags are set when these errors are suspected:
// * rep.badgradsuspected, and additionally:
//   * rep.badgradvidx for specific variable (gradient element) suspected
//   * rep.badgradxbase, a point where gradient is tested
//   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
//     single row in order to make  report  structure  compatible  with  more
//     complex optimizers like MinNLC or MinLM)
//   * rep.badgradnum,   reference    gradient    obtained    via   numerical
//     differentiation (stored as  2D matrix with single row in order to make
//     report structure compatible with more complex optimizers  like  MinNLC
//     or MinLM)
// * rep.nonc0suspected
// * rep.nonc1suspected
//
// ==== ADDITIONAL REPORTS/LOGS ====
//
// Several different tests are performed to catch C0/C1 errors, you can  find
// out specific test signaled error by looking to:
// * rep.nonc0test0positive, for non-C0 test #0
// * rep.nonc1test0positive, for non-C1 test #0
// * rep.nonc1test1positive, for non-C1 test #1
//
// Additional information (including line search logs)  can  be  obtained  by
// means of:
// * minbleicoptguardnonc1test0results()
// * minbleicoptguardnonc1test1results()
// which return detailed error reports, specific points where discontinuities
// were found, and so on.
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     rep     -   generic OptGuard report;  more  detailed  reports  can  be
//                 retrieved with other functions.
//
// NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
//       ones) are possible although unlikely.
//
//       The reason  is  that  you  need  to  make several evaluations around
//       nonsmoothness  in  order  to  accumulate  enough  information  about
//       function curvature. Say, if you start right from the nonsmooth point,
//       optimizer simply won't get enough data to understand what  is  going
//       wrong before it terminates due to abrupt changes in the  derivative.
//       It is also  possible  that  "unlucky"  step  will  move  us  to  the
//       termination too quickly.
//
//       Our current approach is to have less than 0.1%  false  negatives  in
//       our test examples  (measured  with  multiple  restarts  from  random
//       points), and to have exactly 0% false positives.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbleicoptguardresults(const minbleicstate &state, optguardreport &rep);
void minbleicoptguardresults(minbleicstate *state, optguardreport *rep) {
   SetObj(optguardreport, rep);
   smoothnessmonitorexportreport(&state->smonitor, rep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #0
//
// Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
// obtained during line searches and monitors  behavior  of  the  directional
// derivative estimate.
//
// This test is less powerful than test #1, but it does  not  depend  on  the
// gradient values and thus it is more robust against artifacts introduced by
// numerical differentiation.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #0 "strong" report
//     lngrep  -   C1 test #0 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbleicoptguardnonc1test0results(const minbleicstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep);
void minbleicoptguardnonc1test0results(minbleicstate *state, optguardnonc1test0report *strrep, optguardnonc1test0report *lngrep) {
   SetObj(optguardnonc1test0report, strrep);
   SetObj(optguardnonc1test0report, lngrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0lngrep, &state->lastscaleused, lngrep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #1
//
// Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
// gradient computed during line search.
//
// When precise analytic gradient is provided this test is more powerful than
// test #0  which  works  with  function  values  and  ignores  user-provided
// gradient.  However,  test  #0  becomes  more   powerful   when   numerical
// differentiation is employed (in such cases test #1 detects  higher  levels
// of numerical noise and becomes too conservative).
//
// This test also tells specific components of the gradient which violate  C1
// continuity, which makes it more informative than #0, which just tells that
// continuity is violated.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * vidx - is an index of the variable in [0,N) with nonsmooth derivative
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], g[] - arrays of length CNT which store step lengths and  gradient
//   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
//   vidx-th component of the gradient.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #1 "strong" report
//     lngrep  -   C1 test #1 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbleicoptguardnonc1test1results(const minbleicstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep);
void minbleicoptguardnonc1test1results(minbleicstate *state, optguardnonc1test1report *strrep, optguardnonc1test1report *lngrep) {
   SetObj(optguardnonc1test1report, strrep);
   SetObj(optguardnonc1test1report, lngrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1lngrep, &state->lastscaleused, lngrep);
}

// BLEIC results
//
// Buffered implementation of MinBLEICResults() which uses preallocated buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicresultsbuf(const minbleicstate &state, real_1d_array &x, minbleicreport &rep);
void minbleicresultsbuf(minbleicstate *state, RVector *x, minbleicreport *rep) {
   ae_int_t i;
   vectorsetlengthatleast(x, state->nmain);
   rep->iterationscount = state->repinneriterationscount;
   rep->inneriterationscount = state->repinneriterationscount;
   rep->outeriterationscount = state->repouteriterationscount;
   rep->nfev = state->repnfev;
   rep->varidx = state->repvaridx;
   rep->terminationtype = state->repterminationtype;
   if (state->repterminationtype > 0) {
      ae_v_move(x->xR, 1, state->sas.xc.xR, 1, state->nmain);
   } else {
      for (i = 0; i < state->nmain; i++) {
         x->xR[i] = NAN;
      }
   }
   rep->debugeqerr = state->repdebugeqerr;
   rep->debugfs = state->repdebugfs;
   rep->debugff = state->repdebugff;
   rep->debugdx = state->repdebugdx;
   rep->debugfeasqpits = state->repdebugfeasqpits;
   rep->debugfeasgpaits = state->repdebugfeasgpaits;
}

// BLEIC results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization report. You should check Rep.TerminationType
//                 in  order  to  distinguish  successful  termination  from
//                 unsuccessful one:
//                 * -8    internal integrity control  detected  infinite or
//                         NAN   values   in   function/gradient.   Abnormal
//                         termination signalled.
//                 * -3   inconsistent constraints. Feasible point is
//                        either nonexistent or too hard to find. Try to
//                        restart optimizer with better initial approximation
//                 *  1   relative function improvement is no more than EpsF.
//                 *  2   scaled step is no more than EpsX.
//                 *  4   scaled gradient norm is no more than EpsG.
//                 *  5   MaxIts steps was taken
//                 *  8   terminated by user who called minbleicrequesttermination().
//                        X contains point which was "current accepted"  when
//                        termination request was submitted.
//                 More information about fields of this  structure  can  be
//                 found in the comments on MinBLEICReport datatype.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicresults(const minbleicstate &state, real_1d_array &x, minbleicreport &rep);
void minbleicresults(minbleicstate *state, RVector *x, minbleicreport *rep) {
   SetVector(x);
   SetObj(minbleicreport, rep);
   minbleicresultsbuf(state, x, rep);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 08.10.2014 by Sergey Bochkanov
// API: void minbleicrequesttermination(const minbleicstate &state);
void minbleicrequesttermination(minbleicstate *state) {
   state->userterminationneeded = true;
}

// This subroutine finalizes internal structures after emergency  termination
// from State.LSStart report (see comments on MinBLEICState for more information).
//
// Inputs:
//     State   -   structure after exit from LSStart report
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
void minbleicemergencytermination(minbleicstate *state) {
   sasstopoptimization(&state->sas);
}

void minbleicstate_init(void *_p, bool make_automatic) {
   minbleicstate *p = (minbleicstate *)_p;
   sactiveset_init(&p->sas, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagh, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ugc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cgc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ugn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cgn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->cleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xstart, 0, DT_REAL, make_automatic);
   snnlssolver_init(&p->solver, make_automatic);
   ae_vector_init(&p->tmpprec, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->work, 0, DT_REAL, make_automatic);
   linminstate_init(&p->lstate, make_automatic);
   ae_matrix_init(&p->bufyk, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->bufsk, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufrho, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->buftheta, 0, DT_REAL, make_automatic);
   smoothnessmonitor_init(&p->smonitor, make_automatic);
   ae_vector_init(&p->lastscaleused, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->invs, 0, DT_REAL, make_automatic);
}

void minbleicstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minbleicstate *dst = (minbleicstate *)_dst;
   const minbleicstate *src = (const minbleicstate *)_src;
   dst->nmain = src->nmain;
   dst->nslack = src->nslack;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->xrep = src->xrep;
   dst->drep = src->drep;
   dst->stpmax = src->stpmax;
   dst->diffstep = src->diffstep;
   sactiveset_copy(&dst->sas, &src->sas, make_automatic);
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   dst->prectype = src->prectype;
   ae_vector_copy(&dst->diagh, &src->diagh, make_automatic);
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->needf = src->needf;
   dst->needfg = src->needfg;
   dst->xupdated = src->xupdated;
   dst->lsstart = src->lsstart;
   dst->steepestdescentstep = src->steepestdescentstep;
   dst->boundedstep = src->boundedstep;
   dst->userterminationneeded = src->userterminationneeded;
   dst->PQ = src->PQ;
   ae_vector_copy(&dst->ugc, &src->ugc, make_automatic);
   ae_vector_copy(&dst->cgc, &src->cgc, make_automatic);
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->ugn, &src->ugn, make_automatic);
   ae_vector_copy(&dst->cgn, &src->cgn, make_automatic);
   ae_vector_copy(&dst->xp, &src->xp, make_automatic);
   dst->fc = src->fc;
   dst->fn = src->fn;
   dst->fp = src->fp;
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_matrix_copy(&dst->cleic, &src->cleic, make_automatic);
   dst->nec = src->nec;
   dst->nic = src->nic;
   dst->lastgoodstep = src->lastgoodstep;
   dst->lastscaledgoodstep = src->lastscaledgoodstep;
   dst->maxscaledgrad = src->maxscaledgrad;
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repnfev = src->repnfev;
   dst->repvaridx = src->repvaridx;
   dst->repterminationtype = src->repterminationtype;
   dst->repdebugeqerr = src->repdebugeqerr;
   dst->repdebugfs = src->repdebugfs;
   dst->repdebugff = src->repdebugff;
   dst->repdebugdx = src->repdebugdx;
   dst->repdebugfeasqpits = src->repdebugfeasqpits;
   dst->repdebugfeasgpaits = src->repdebugfeasgpaits;
   ae_vector_copy(&dst->xstart, &src->xstart, make_automatic);
   snnlssolver_copy(&dst->solver, &src->solver, make_automatic);
   dst->fbase = src->fbase;
   dst->fm2 = src->fm2;
   dst->fm1 = src->fm1;
   dst->fp1 = src->fp1;
   dst->fp2 = src->fp2;
   dst->xm1 = src->xm1;
   dst->xp1 = src->xp1;
   dst->gm1 = src->gm1;
   dst->gp1 = src->gp1;
   dst->cidx = src->cidx;
   dst->cval = src->cval;
   ae_vector_copy(&dst->tmpprec, &src->tmpprec, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   dst->nfev = src->nfev;
   dst->mcstage = src->mcstage;
   dst->stp = src->stp;
   dst->curstpmax = src->curstpmax;
   dst->activationstep = src->activationstep;
   ae_vector_copy(&dst->work, &src->work, make_automatic);
   linminstate_copy(&dst->lstate, &src->lstate, make_automatic);
   dst->trimthreshold = src->trimthreshold;
   dst->nonmonotoniccnt = src->nonmonotoniccnt;
   ae_matrix_copy(&dst->bufyk, &src->bufyk, make_automatic);
   ae_matrix_copy(&dst->bufsk, &src->bufsk, make_automatic);
   ae_vector_copy(&dst->bufrho, &src->bufrho, make_automatic);
   ae_vector_copy(&dst->buftheta, &src->buftheta, make_automatic);
   dst->bufsize = src->bufsize;
   dst->teststep = src->teststep;
   dst->smoothnessguardlevel = src->smoothnessguardlevel;
   smoothnessmonitor_copy(&dst->smonitor, &src->smonitor, make_automatic);
   ae_vector_copy(&dst->lastscaleused, &src->lastscaleused, make_automatic);
   ae_vector_copy(&dst->invs, &src->invs, make_automatic);
}

void minbleicstate_free(void *_p, bool make_automatic) {
   minbleicstate *p = (minbleicstate *)_p;
   sactiveset_free(&p->sas, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->diagh, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   ae_vector_free(&p->ugc, make_automatic);
   ae_vector_free(&p->cgc, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->ugn, make_automatic);
   ae_vector_free(&p->cgn, make_automatic);
   ae_vector_free(&p->xp, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_matrix_free(&p->cleic, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->xstart, make_automatic);
   snnlssolver_free(&p->solver, make_automatic);
   ae_vector_free(&p->tmpprec, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->work, make_automatic);
   linminstate_free(&p->lstate, make_automatic);
   ae_matrix_free(&p->bufyk, make_automatic);
   ae_matrix_free(&p->bufsk, make_automatic);
   ae_vector_free(&p->bufrho, make_automatic);
   ae_vector_free(&p->buftheta, make_automatic);
   smoothnessmonitor_free(&p->smonitor, make_automatic);
   ae_vector_free(&p->lastscaleused, make_automatic);
   ae_vector_free(&p->invs, make_automatic);
}

void minbleicreport_init(void *_p, bool make_automatic) {
}

void minbleicreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minbleicreport *dst = (minbleicreport *)_dst;
   const minbleicreport *src = (const minbleicreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->varidx = src->varidx;
   dst->terminationtype = src->terminationtype;
   dst->debugeqerr = src->debugeqerr;
   dst->debugfs = src->debugfs;
   dst->debugff = src->debugff;
   dst->debugdx = src->debugdx;
   dst->debugfeasqpits = src->debugfeasqpits;
   dst->debugfeasgpaits = src->debugfeasgpaits;
   dst->inneriterationscount = src->inneriterationscount;
   dst->outeriterationscount = src->outeriterationscount;
}

void minbleicreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores nonlinear optimizer state.
// You should use functions provided by MinBLEIC subpackage to work with this
// object
DefClass(minbleicstate, DecVal(needf) DecVal(needfg) DecVal(xupdated) DecVal(f) DecVar(g) DecVar(x))

// This structure stores optimization report:
// * IterationsCount           number of iterations
// * NFEV                      number of gradient evaluations
// * TerminationType           termination type (see below)
//
// TERMINATION CODES
//
// TerminationType field contains completion code, which can be:
//   -8    internal integrity control detected  infinite  or  NAN  values  in
//         function/gradient. Abnormal termination signalled.
//   -3    inconsistent constraints. Feasible point is
//         either nonexistent or too hard to find. Try to
//         restart optimizer with better initial approximation
//    1    relative function improvement is no more than EpsF.
//    2    relative step is no more than EpsX.
//    4    gradient norm is no more than EpsG
//    5    MaxIts steps was taken
//    7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//    8    terminated by user who called minbleicrequesttermination(). X contains
//         point which was "current accepted" when  termination  request  was
//         submitted.
//
// ADDITIONAL FIELDS
//
// There are additional fields which can be used for debugging:
// * DebugEqErr                error in the equality constraints (2-norm)
// * DebugFS                   f, calculated at projection of initial point
//                             to the feasible set
// * DebugFF                   f, calculated at the final point
// * DebugDX                   |X_start-X_final|
DefClass(minbleicreport, DecVal(iterationscount) DecVal(nfev) DecVal(varidx) DecVal(terminationtype) DecVal(debugeqerr) DecVal(debugfs) DecVal(debugff) DecVal(debugdx) DecVal(debugfeasqpits) DecVal(debugfeasgpaits) DecVal(inneriterationscount) DecVal(outeriterationscount))

void minbleicsetbc(const minbleicstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetbc(ConstT(minbleicstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minbleicsetlc(const minbleicstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetlc(ConstT(minbleicstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbleicsetlc(const minbleicstate &state, const real_2d_array &c, const integer_1d_array &ct) {
   ae_int_t k = c.rows();
   if (k != ct.length()) ThrowError("Error while calling 'minbleicsetlc': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetlc(ConstT(minbleicstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#endif

void minbleicsetcond(const minbleicstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetcond(ConstT(minbleicstate, state), epsg, epsf, epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minbleicsetscale(const minbleicstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetscale(ConstT(minbleicstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minbleicsetprecdefault(const minbleicstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetprecdefault(ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}

void minbleicsetprecdiag(const minbleicstate &state, const real_1d_array &d) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetprecdiag(ConstT(minbleicstate, state), ConstT(ae_vector, d));
   alglib_impl::ae_state_clear();
}

void minbleicsetprecscale(const minbleicstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetprecscale(ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}

void minbleicsetxrep(const minbleicstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetxrep(ConstT(minbleicstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minbleicsetstpmax(const minbleicstate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetstpmax(ConstT(minbleicstate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void minbleicrestartfrom(const minbleicstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicrestartfrom(ConstT(minbleicstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minbleiccreate(const ae_int_t n, const real_1d_array &x, minbleicstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleiccreate(n, ConstT(ae_vector, x), ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbleiccreate(const real_1d_array &x, minbleicstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleiccreate(n, ConstT(ae_vector, x), ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minbleiccreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minbleicstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleiccreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbleiccreatef(const real_1d_array &x, const double diffstep, minbleicstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleiccreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}
#endif

bool minbleiciteration(const minbleicstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minbleiciteration(ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     func    -   callback which calculates function (or merit function)
//                 value func at given point x
//     grad    -   callback which calculates function (or merit function)
//                 value func and gradient grad at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. This function has two different implementations: one which  uses  exact
//    (analytical) user-supplied gradient,  and one which uses function value
//    only  and  numerically  differentiates  function  in  order  to  obtain
//    gradient.
//
//    Depending  on  the  specific  function  used to create optimizer object
//    (either  MinBLEICCreate() for analytical gradient or  MinBLEICCreateF()
//    for numerical differentiation) you should choose appropriate variant of
//    MinBLEICOptimize() - one  which  accepts  function  AND gradient or one
//    which accepts function ONLY.
//
//    Be careful to choose variant of MinBLEICOptimize() which corresponds to
//    your optimization scheme! Table below lists different  combinations  of
//    callback (function/gradient) passed to MinBLEICOptimize()  and specific
//    function used to create optimizer.
//
//                      |         USER PASSED TO MinBLEICOptimize()
//    CREATED WITH      |  function only   |  function and gradient
//    ------------------------------------------------------------
//    MinBLEICCreateF() |     work                FAIL
//    MinBLEICCreate()  |     FAIL                work
//
//    Here "FAIL" denotes inappropriate combinations  of  optimizer  creation
//    function  and  MinBLEICOptimize()  version.   Attemps   to   use   such
//    combination (for  example,  to  create optimizer with MinBLEICCreateF()
//    and  to  pass  gradient information to MinBLEICOptimize()) will lead to
//    exception being thrown. Either  you  did  not pass gradient when it WAS
//    needed or you passed gradient when it was NOT needed.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
void minbleicoptimize(minbleicstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "minbleicoptimize: func is NULL");
   while (alglib_impl::minbleiciteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minbleicoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minbleicoptimize(minbleicstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(grad != NULL, "minbleicoptimize: grad is NULL");
   while (alglib_impl::minbleiciteration(state.c_ptr()))
   BegPoll
      if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minbleicoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minbleicoptguardgradient(const minbleicstate &state, const double teststep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicoptguardgradient(ConstT(minbleicstate, state), teststep);
   alglib_impl::ae_state_clear();
}

void minbleicoptguardsmoothness(const minbleicstate &state, const ae_int_t level) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicoptguardsmoothness(ConstT(minbleicstate, state), level);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbleicoptguardsmoothness(const minbleicstate &state) {
   ae_int_t level = 1;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicoptguardsmoothness(ConstT(minbleicstate, state), level);
   alglib_impl::ae_state_clear();
}
#endif

void minbleicoptguardresults(const minbleicstate &state, optguardreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicoptguardresults(ConstT(minbleicstate, state), ConstT(optguardreport, rep));
   alglib_impl::ae_state_clear();
}

void minbleicoptguardnonc1test0results(const minbleicstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicoptguardnonc1test0results(ConstT(minbleicstate, state), ConstT(optguardnonc1test0report, strrep), ConstT(optguardnonc1test0report, lngrep));
   alglib_impl::ae_state_clear();
}

void minbleicoptguardnonc1test1results(const minbleicstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicoptguardnonc1test1results(ConstT(minbleicstate, state), ConstT(optguardnonc1test1report, strrep), ConstT(optguardnonc1test1report, lngrep));
   alglib_impl::ae_state_clear();
}

void minbleicresultsbuf(const minbleicstate &state, real_1d_array &x, minbleicreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicresultsbuf(ConstT(minbleicstate, state), ConstT(ae_vector, x), ConstT(minbleicreport, rep));
   alglib_impl::ae_state_clear();
}

void minbleicresults(const minbleicstate &state, real_1d_array &x, minbleicreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicresults(ConstT(minbleicstate, state), ConstT(ae_vector, x), ConstT(minbleicreport, rep));
   alglib_impl::ae_state_clear();
}

void minbleicrequesttermination(const minbleicstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicrequesttermination(ConstT(minbleicstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === QPBLEICSOLVER Package ===
// Depends on: MINBLEIC
namespace alglib_impl {
// This function initializes QPBLEICSettings structure with default settings.
//
// Newly created structure MUST be initialized by default settings  -  or  by
// copy of the already initialized structure.
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qpbleicloaddefaults(ae_int_t nmain, qpbleicsettings *s) {
   s->epsg = 0.0;
   s->epsf = 0.0;
   s->epsx = 0.000001;
   s->maxits = 0;
}

// This function initializes QPBLEICSettings  structure  with  copy  of  another,
// already initialized structure.
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qpbleiccopysettings(qpbleicsettings *src, qpbleicsettings *dst) {
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
}

// This function runs QPBLEIC solver; it returns after optimization   process
// was completed. Following QP problem is solved:
//
//     min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//
// subject to boundary constraints.
//
// Inputs:
//     AC          -   for dense problems (AKind == 0), A-term of CQM object
//                     contains system matrix. Other terms are unspecified
//                     and should not be referenced.
//     SparseAC    -   for sparse problems (AKind == 1
//     AKind       -   sparse matrix format:
//                     * 0 for dense matrix
//                     * 1 for sparse matrix
//     SparseUpper -   which triangle of SparseAC stores matrix  -  upper  or
//                     lower one (for dense matrices this  parameter  is  not
//                     actual).
//     AbsASum     -   SUM(|A[i,j]|)
//     AbsASum2    -   SUM(A[i,j]^2)
//     BC          -   linear term, array[NC]
//     BndLC       -   lower bound, array[NC]
//     BndUC       -   upper bound, array[NC]
//     SC          -   scale vector, array[NC]:
//                     * I-th element contains scale of I-th variable,
//                     * SC[I] > 0
//     XOriginC    -   origin term, array[NC]. Can be zero.
//     NC          -   number of variables in the  original  formulation  (no
//                     slack variables).
//     CLEICC      -   linear equality/inequality constraints. Present version
//                     of this function does NOT provide  publicly  available
//                     support for linear constraints. This feature  will  be
//                     introduced in the future versions of the function.
//     NEC, NIC    -   number of equality/inequality constraints.
//                     MUST BE ZERO IN THE CURRENT VERSION!!!
//     Settings    -   QPBLEICSettings object initialized by one of the initialization
//                     functions.
//     SState      -   object which stores temporaries:
//                     * if uninitialized object was passed, FirstCall parameter MUST
//                       be set to True; object will be automatically initialized by the
//                       function, and FirstCall will be set to False.
//                     * if FirstCall == False, it is assumed that this parameter was already
//                       initialized by previous call to this function with same
//                       problem dimensions (variable count N).
//     FirstCall   -   whether it is first call of this function for this specific
//                     instance of SState, with this number of variables N specified.
//     XS          -   initial point, array[NC]
//
// Outputs:
//     XS          -   last point
//     FirstCall   -   uncondtionally set to False
//     TerminationType-termination type:
//                     *
//                     *
//                     *
// ALGLIB: Copyright 14.05.2011 by Sergey Bochkanov
void qpbleicoptimize(convexquadraticmodel *a, sparsematrix *sparsea, ae_int_t akind, bool sparseaupper, double absasum, double absasum2, RVector *b, RVector *bndl, RVector *bndu, RVector *s, RVector *xorigin, ae_int_t n, RMatrix *cleic, ae_int_t nec, ae_int_t nic, qpbleicsettings *settings, qpbleicbuffers *sstate, bool *firstcall, RVector *xs, ae_int_t *terminationtype) {
   ae_int_t i;
   double d2;
   double d1;
   double d0;
   double v;
   double v0;
   double v1;
   double md;
   double mx;
   double mb;
   ae_int_t d1est;
   ae_int_t d2est;
   *terminationtype = 0;
   ae_assert(akind == 0 || akind == 1, "QPBLEICOptimize: unexpected AKind");
   sstate->repinneriterationscount = 0;
   sstate->repouteriterationscount = 0;
   *terminationtype = 0;
// Prepare solver object, if needed
   if (*firstcall) {
      minbleiccreate(n, xs, &sstate->solver);
      *firstcall = false;
   }
// Prepare max(|B|)
   mb = 0.0;
   for (i = 0; i < n; i++) {
      mb = rmax2(mb, fabs(b->xR[i]));
   }
// Temporaries
   vectorsetlengthatleast(&sstate->tmpi, nec + nic);
   vectorsetlengthatleast(&sstate->tmp0, n);
   vectorsetlengthatleast(&sstate->tmp1, n);
   for (i = 0; i < nec; i++) {
      sstate->tmpi.xZ[i] = 0;
   }
   for (i = 0; i < nic; i++) {
      sstate->tmpi.xZ[nec + i] = -1;
   }
   minbleicsetlc(&sstate->solver, cleic, &sstate->tmpi, nec + nic);
   minbleicsetbc(&sstate->solver, bndl, bndu);
   minbleicsetdrep(&sstate->solver, true);
   minbleicsetcond(&sstate->solver, minrealnumber, 0.0, 0.0, settings->maxits);
   minbleicsetscale(&sstate->solver, s);
   minbleicsetprecscale(&sstate->solver);
   for (minbleicrestartfrom(&sstate->solver, xs); minbleiciteration(&sstate->solver); )
      if (sstate->solver.lsstart) { // Line search started
      // Iteration counters:
      // * inner iterations count is increased on every line search
      // * outer iterations count is increased only at steepest descent line search
         sstate->repinneriterationscount++;
         if (sstate->solver.steepestdescentstep) {
            sstate->repouteriterationscount++;
         }
      // Build quadratic model of F along descent direction:
      //
      //     F(x+alpha*d) = D2*alpha^2 + D1*alpha + D0
      //
      // Calculate estimates of linear and quadratic term
      // (term magnitude is compared with magnitude of numerical errors)
         d0 = sstate->solver.f;
         d1 = ae_v_dotproduct(sstate->solver.d.xR, 1, sstate->solver.g.xR, 1, n);
         d2 = 0.0;
         if (akind == 0) {
            d2 = cqmxtadx2(a, &sstate->solver.d, &sstate->tmp0);
         }
         if (akind == 1) {
            sparsesmv(sparsea, sparseaupper, &sstate->solver.d, &sstate->tmp0);
            d2 = 0.0;
            for (i = 0; i < n; i++) {
               d2 += sstate->solver.d.xR[i] * sstate->tmp0.xR[i];
            }
            d2 *= 0.5;
         }
         mx = 0.0;
         md = 0.0;
         for (i = 0; i < n; i++) {
            mx = rmax2(mx, fabs(sstate->solver.x.xR[i]));
            md = rmax2(md, fabs(sstate->solver.d.xR[i]));
         }
         estimateparabolicmodel(absasum, absasum2, mx, mb, md, d1, d2, &d1est, &d2est);
      // Tests for "normal" convergence.
      //
      // This line search may be started from steepest descent
      // stage (stage 2) or from L-BFGS stage (stage 3) of the
      // BLEIC algorithm. Depending on stage type, different
      // checks are performed.
      //
      // Say, L-BFGS stage is an equality-constrained refinement
      // stage of BLEIC. This stage refines current iterate
      // under "frozen" equality constraints. We can terminate
      // iterations at this stage only when we encounter
      // unconstrained direction of negative curvature. In all
      // other cases (say, when constrained gradient is zero)
      // we should not terminate algorithm because everything may
      // change after de-activating presently active constraints.
      //
      // Tests for convergence are performed only at "steepest descent" stage
      // of the BLEIC algorithm, and only when function is non-concave
      // (D2 is positive or approximately zero) along direction D.
      //
      // NOTE: we do not test iteration count (MaxIts) here, because
      //       this stopping condition is tested by BLEIC itself.
         if (sstate->solver.steepestdescentstep && d2est >= 0) {
            if (d1est >= 0) {
            // "Emergency" stopping condition: D is non-descent direction.
            // Sometimes it is possible because of numerical noise in the
            // target function.
               *terminationtype = 4;
               for (i = 0; i < n; i++) {
                  xs->xR[i] = sstate->solver.x.xR[i];
               }
               break;
            }
            if (d2est > 0) {
            // Stopping condition #4 - gradient norm is small:
            //
            // 1. rescale State.Solver.D and State.Solver.G according to
            //    current scaling, store results to Tmp0 and Tmp1.
            // 2. Normalize Tmp0 (scaled direction vector).
            // 3. compute directional derivative (in scaled variables),
            //    which is equal to DOTPRODUCT(Tmp0,Tmp1).
               v = 0.0;
               for (i = 0; i < n; i++) {
                  sstate->tmp0.xR[i] = sstate->solver.d.xR[i] / s->xR[i];
                  sstate->tmp1.xR[i] = sstate->solver.g.xR[i] * s->xR[i];
                  v += sqr(sstate->tmp0.xR[i]);
               }
               ae_assert(v > 0.0, "QPBLEICOptimize: inernal errror (scaled direction is zero)");
               v = 1.0 / sqrt(v);
               ae_v_muld(sstate->tmp0.xR, 1, n, v);
               v = ae_v_dotproduct(sstate->tmp0.xR, 1, sstate->tmp1.xR, 1, n);
               if (SmallAtR(v, settings->epsg)) {
                  *terminationtype = 4;
                  for (i = 0; i < n; i++) {
                     xs->xR[i] = sstate->solver.x.xR[i];
                  }
                  break;
               }
            // Stopping condition #1 - relative function improvement is small:
            //
            // 1. calculate steepest descent step:   V  == -D1/(2*D2)
            // 2. calculate function change:         V1 == D2*V^2 + D1*V
            // 3. stop if function change is small enough
               v = -d1 / (2.0 * d2);
               v1 = d2 * v * v + d1 * v;
               if (SmallAtR(v1, settings->epsf * rmax2(d0, 1.0))) {
                  *terminationtype = 1;
                  for (i = 0; i < n; i++) {
                     xs->xR[i] = sstate->solver.x.xR[i];
                  }
                  break;
               }
            // Stopping condition #2 - scaled step is small:
            //
            // 1. calculate step multiplier V0 (step itself is D*V0)
            // 2. calculate scaled step length V
            // 3. stop if step is small enough
               v0 = -d1 / (2.0 * d2);
               v = 0.0;
               for (i = 0; i < n; i++) {
                  v += sqr(v0 * sstate->solver.d.xR[i] / s->xR[i]);
               }
               if (sqrt(v) <= settings->epsx) {
                  *terminationtype = 2;
                  for (i = 0; i < n; i++) {
                     xs->xR[i] = sstate->solver.x.xR[i];
                  }
                  break;
               }
            }
         }
      // Test for unconstrained direction of negative curvature
         if ((d2est < 0 || d2est == 0 && d1est < 0) && !sstate->solver.boundedstep) {
         // Function is unbounded from below:
         // * function will decrease along D, i.e. either:
         //   * D2 < 0
         //   * D2 == 0 and D1 < 0
         // * step is unconstrained
         //
         // If these conditions are true, we abnormally terminate QP
         // algorithm with return code -4 (we can do so at any stage
         // of BLEIC - whether it is L-BFGS or steepest descent one).
            *terminationtype = -4;
            for (i = 0; i < n; i++) {
               xs->xR[i] = sstate->solver.x.xR[i];
            }
            break;
         }
      // Suggest new step (only if D1 is negative far away from zero,
      // D2 is positive far away from zero).
         if (d1est < 0 && d2est > 0) {
            sstate->solver.stp = safeminposrv(-d1, 2.0 * d2, sstate->solver.curstpmax);
         }
      } else if (sstate->solver.needfg) { // Gradient evaluation
         for (i = 0; i < n; i++) {
            sstate->tmp0.xR[i] = sstate->solver.x.xR[i] - xorigin->xR[i];
         }
         if (akind == 0) {
            cqmadx(a, &sstate->tmp0, &sstate->tmp1);
         }
         if (akind == 1) {
            sparsesmv(sparsea, sparseaupper, &sstate->tmp0, &sstate->tmp1);
         }
         v0 = ae_v_dotproduct(sstate->tmp0.xR, 1, sstate->tmp1.xR, 1, n);
         v1 = ae_v_dotproduct(sstate->tmp0.xR, 1, b->xR, 1, n);
         sstate->solver.f = 0.5 * v0 + v1;
         ae_v_move(sstate->solver.g.xR, 1, sstate->tmp1.xR, 1, n);
         ae_v_add(sstate->solver.g.xR, 1, b->xR, 1, n);
      }
   if (*terminationtype == 0) {
   // BLEIC optimizer was terminated by one of its inner stopping
   // conditions. Usually it is iteration counter (if such
   // stopping condition was specified by user).
      minbleicresultsbuf(&sstate->solver, xs, &sstate->solverrep);
      *terminationtype = sstate->solverrep.terminationtype;
   } else {
   // BLEIC optimizer was terminated in "emergency" mode by QP
   // solver.
   //
   // NOTE: such termination is "emergency" only when viewed from
   //       BLEIC's position. QP solver sees such termination as
   //       routine one, triggered by QP's stopping criteria.
      minbleicemergencytermination(&sstate->solver);
   }
}

void qpbleicsettings_init(void *_p, bool make_automatic) {
}

void qpbleicsettings_copy(void *_dst, const void *_src, bool make_automatic) {
   qpbleicsettings *dst = (qpbleicsettings *)_dst;
   const qpbleicsettings *src = (const qpbleicsettings *)_src;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
}

void qpbleicsettings_free(void *_p, bool make_automatic) {
}

void qpbleicbuffers_init(void *_p, bool make_automatic) {
   qpbleicbuffers *p = (qpbleicbuffers *)_p;
   minbleicstate_init(&p->solver, make_automatic);
   minbleicreport_init(&p->solverrep, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpi, 0, DT_INT, make_automatic);
}

void qpbleicbuffers_copy(void *_dst, const void *_src, bool make_automatic) {
   qpbleicbuffers *dst = (qpbleicbuffers *)_dst;
   const qpbleicbuffers *src = (const qpbleicbuffers *)_src;
   minbleicstate_copy(&dst->solver, &src->solver, make_automatic);
   minbleicreport_copy(&dst->solverrep, &src->solverrep, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->tmpi, &src->tmpi, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
}

void qpbleicbuffers_free(void *_p, bool make_automatic) {
   qpbleicbuffers *p = (qpbleicbuffers *)_p;
   minbleicstate_free(&p->solver, make_automatic);
   minbleicreport_free(&p->solverrep, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->tmpi, make_automatic);
}
} // end of namespace alglib_impl

// === VIPMSOLVER Package ===
// Depends on: (Solvers) DIRECTDENSESOLVERS
// Depends on: MINLBFGS, CQMODELS, LPQPSERV
namespace alglib_impl {
// Sets linear/quadratic terms for QP-IPM solver
//
// If you initialized solver with VIPMInitDenseWithSlacks(), NMain below is a
// number of non-slack variables. In other cases, NMain == N.
//
// Inputs:
//     State               -   instance initialized with one of the initialization
//                             functions
//     DenseH              -   if HKind == 0: array[NMain,NMain], dense quadratic term
//                             (either upper or lower triangle)
//     SparseH             -   if HKind == 1: array[NMain,NMain], sparse quadratic term
//                             (either upper or lower triangle)
//     HKind               -   0 or 1, quadratic term format
//     IsUpper             -   whether dense/sparse H contains lower or upper
//                             triangle of the quadratic term
//     C                   -   array[N], linear term
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipmsetquadraticlinear(vipmstate *state, RMatrix *denseh, sparsematrix *sparseh, ae_int_t hkind, bool isupper, RVector *c) {
   ae_int_t nmain;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t j0;
   ae_int_t j1;
   double v;
   double vv;
   ae_int_t nnz;
   ae_int_t offs;
   nmain = state->nmain;
   n = state->n;
   ae_assert(hkind == 0 || hkind == 1, "VIPMSetQuadraticLinear: incorrect HKind");
   ae_assert(isfinitevector(c, n), "VIPMSetQuadraticLinear: C contains infinite or NaN elements");
   ae_assert(state->factorizationtype == 0 || state->factorizationtype == 1, "VIPMSetQuadraticLinear: unexpected factorization type");
// Set problem info, reset factorization flag
   state->islinear = false;
   state->factorizationpresent = false;
   state->factorizationpoweredup = false;
// Linear term
   vectorsetlengthatleast(&state->c, n);
   rvectorcopy(n, c, 0, &state->c, 0);
// Quadratic term and normalization
//
// NOTE: we perform integrity check for inifinities/NANs by
//       computing sum of all matrix elements and checking its
//       value for being finite. It is a bit faster than checking
//       each element individually.
   state->hkind = -1;
   state->targetscale = 1.0;
   if (state->factorizationtype == 0) {
   // Quadratic term is stored in dense format: either copy dense
   // term of densify sparse one
      state->hkind = 0;
      matrixsetlengthatleast(&state->denseh, nmain, nmain);
      if (hkind == 0) {
      // Copy dense quadratic term
         if (isupper) {
            rmatrixtranspose(nmain, nmain, denseh, 0, 0, &state->denseh, 0, 0);
         } else {
            rmatrixcopy(nmain, nmain, denseh, 0, 0, &state->denseh, 0, 0);
         }
      }
      if (hkind == 1) {
      // Extract sparse quadratic term
         ae_assert(sparseh->matrixtype == 1, "VIPMSetQuadraticLinear: unexpected sparse matrix format");
         ae_assert(sparseh->m == nmain, "VIPMSetQuadraticLinear: unexpected sparse matrix size");
         ae_assert(sparseh->n == nmain, "VIPMSetQuadraticLinear: unexpected sparse matrix size");
         for (i = 0; i < nmain; i++) {
            for (j = 0; j <= i; j++) {
               state->denseh.xyR[i][j] = 0.0;
            }
         }
         for (i = 0; i < nmain; i++) {
         // diagonal element
            if (sparseh->didx.xZ[i] != sparseh->uidx.xZ[i]) {
               state->denseh.xyR[i][i] = sparseh->vals.xR[sparseh->didx.xZ[i]];
            }
         // Off-diagonal elements
            if (isupper) {
            // superdiagonal elements are moved to subdiagonal part
               j0 = sparseh->uidx.xZ[i];
               j1 = sparseh->ridx.xZ[i + 1] - 1;
               for (j = j0; j <= j1; j++) {
                  state->denseh.xyR[sparseh->idx.xZ[j]][i] = sparseh->vals.xR[j];
               }
            } else {
            // subdiagonal elements are moved to subdiagonal part
               j0 = sparseh->ridx.xZ[i];
               j1 = sparseh->didx.xZ[i] - 1;
               for (j = j0; j <= j1; j++) {
                  state->denseh.xyR[i][sparseh->idx.xZ[j]] = sparseh->vals.xR[j];
               }
            }
         }
      }
      vv = 0.0;
      for (i = 0; i < nmain; i++) {
         for (j = 0; j <= i; j++) {
            vv += state->denseh.xyR[i][j];
         }
      }
      ae_assert(isfinite(vv), "VIPMSetQuadraticLinear: DenseH contains infinite or NaN values!");
      scaledenseqpinplace(&state->denseh, false, nmain, &state->c, n, &state->scl);
      state->targetscale = normalizedenseqpinplace(&state->denseh, false, nmain, &state->c, n);
      state->isdiagonalh = false;
   }
   if (state->factorizationtype == 1) {
      ae_assert(nmain == n, "VIPMSetQuadraticLinear: critical integrity check failed, NMain != N");
   // Quadratic term is stored in sparse format: either sparsify dense
   // term or copy the sparse one
      state->hkind = 1;
      state->sparseh.matrixtype = 1;
      state->sparseh.m = n;
      state->sparseh.n = n;
      if (hkind == 0) {
      // Sparsify dense term
         nnz = 0;
         for (i = 0; i < n; i++) {
            nnz++;
            if (isupper) {
               j0 = i + 1;
               j1 = n - 1;
            } else {
               j0 = 0;
               j1 = i - 1;
            }
            for (j = j0; j <= j1; j++) {
               if (denseh->xyR[i][j] != 0.0) {
                  nnz++;
               }
            }
         }
         vectorsetlengthatleast(&state->sparseh.ridx, n + 1);
         vectorsetlengthatleast(&state->sparseh.idx, nnz);
         vectorsetlengthatleast(&state->sparseh.vals, nnz);
         state->sparseh.ridx.xZ[0] = 0;
         offs = 0;
         vv = 0.0;
         for (i = 0; i < n; i++) {
         // Off-diagonal elements are copied only when nonzero
            if (!isupper) {
               for (j = 0; j < i; j++) {
                  if (denseh->xyR[i][j] != 0.0) {
                     v = denseh->xyR[i][j];
                     state->sparseh.idx.xZ[offs] = j;
                     state->sparseh.vals.xR[offs] = v;
                     vv += v;
                     offs++;
                  }
               }
            }
         // Diagonal element is always copied
            v = denseh->xyR[i][i];
            state->sparseh.idx.xZ[offs] = i;
            state->sparseh.vals.xR[offs] = v;
            vv += v;
            offs++;
         // Off-diagonal elements are copied only when nonzero
            if (isupper) {
               for (j = i + 1; j < n; j++) {
                  if (denseh->xyR[i][j] != 0.0) {
                     v = denseh->xyR[i][j];
                     state->sparseh.idx.xZ[offs] = j;
                     state->sparseh.vals.xR[offs] = v;
                     vv += v;
                     offs++;
                  }
               }
            }
         // Finalize row
            state->sparseh.ridx.xZ[i + 1] = offs;
         }
         ae_assert(isfinite(vv), "VIPMSetQuadraticLinear: DenseH contains infinite or NaN values!");
         ae_assert(offs == nnz, "VIPMSetQuadraticLinear: integrity check failed");
         sparsecreatecrsinplace(&state->sparseh);
      }
      if (hkind == 1) {
      // Copy sparse quadratic term, but make sure that we have diagonal elements
      // present (we add diagonal if it is not present)
         ae_assert(sparseh->matrixtype == 1, "VIPMSetQuadraticLinear: unexpected sparse matrix format");
         ae_assert(sparseh->m == n, "VIPMSetQuadraticLinear: unexpected sparse matrix size");
         ae_assert(sparseh->n == n, "VIPMSetQuadraticLinear: unexpected sparse matrix size");
         vectorsetlengthatleast(&state->sparseh.ridx, n + 1);
         vectorsetlengthatleast(&state->sparseh.idx, sparseh->ridx.xZ[n] + n);
         vectorsetlengthatleast(&state->sparseh.vals, sparseh->ridx.xZ[n] + n);
         state->sparseh.ridx.xZ[0] = 0;
         offs = 0;
         vv = 0.0;
         for (i = 0; i < n; i++) {
         // Copy subdiagonal elements (if needed)
            if (!isupper) {
               j0 = sparseh->ridx.xZ[i];
               j1 = sparseh->didx.xZ[i] - 1;
               for (k = j0; k <= j1; k++) {
                  v = sparseh->vals.xR[k];
                  state->sparseh.idx.xZ[offs] = sparseh->idx.xZ[k];
                  state->sparseh.vals.xR[offs] = v;
                  vv += v;
                  offs++;
               }
            }
         // Diagonal element is always copied
            v = 0.0;
            if (sparseh->uidx.xZ[i] != sparseh->didx.xZ[i]) {
               v = sparseh->vals.xR[sparseh->didx.xZ[i]];
            }
            state->sparseh.idx.xZ[offs] = i;
            state->sparseh.vals.xR[offs] = v;
            vv += v;
            offs++;
         // Copy superdiagonal elements (if needed)
            if (isupper) {
               j0 = sparseh->uidx.xZ[i];
               j1 = sparseh->ridx.xZ[i + 1] - 1;
               for (k = j0; k <= j1; k++) {
                  v = sparseh->vals.xR[k];
                  state->sparseh.idx.xZ[offs] = sparseh->idx.xZ[k];
                  state->sparseh.vals.xR[offs] = v;
                  vv += v;
                  offs++;
               }
            }
         // Finalize row
            state->sparseh.ridx.xZ[i + 1] = offs;
         }
         ae_assert(isfinite(vv), "VIPMSetQuadraticLinear: SparseH contains infinite or NaN values!");
         ae_assert(offs <= state->sparseh.vals.cnt && offs <= state->sparseh.idx.cnt, "VIPMSetQuadraticLinear: integrity check failed");
         sparsecreatecrsinplace(&state->sparseh);
      }
      if (isupper) {
         sparsecopytransposecrsbuf(&state->sparseh, &state->tmpsparse0);
         sparsecopybuf(&state->tmpsparse0, &state->sparseh);
      }
   // Finalize
      scalesparseqpinplace(&state->scl, n, &state->sparseh, &state->tmpr2, &state->dummyr, 0, &state->c);
      state->targetscale = normalizesparseqpinplace(&state->sparseh, false, &state->tmpr2, &state->dummyr, 0, &state->c, n);
      state->isdiagonalh = state->sparseh.ridx.xZ[n] == n;
   }
   ae_assert(state->hkind >= 0, "VIPMSetQuadraticLinear: integrity check failed");
}

// Sets constraints for QP-IPM solver
//
// Inputs:
//     State               -   instance initialized with one of the initialization
//                             functions
//     BndL, BndU          -   lower and upper bound. BndL[] can be -INF,
//                             BndU[] can be +INF.
//     SparseA             -   sparse constraint matrix, CRS format
//     MSparse             -   number of sparse constraints
//     DenseA              -   array[MDense,N], dense part of the constraints
//     MDense              -   number of dense constraints
//     CL, CU              -   lower and upper bounds for constraints, first
//                             MSparse are bounds for sparse part, following
//                             MDense ones are bounds for dense part,
//                             MSparse+MDense in total.
//                             -INF <= CL[I] <= CU[I] <= +INF.
//
// This function throws exception if constraints have inconsistent bounds, i.e.
// either BndL[I] > BndU[I] or CL[I] > CU[I]. In all other cases it succeeds.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipmsetconstraints(vipmstate *state, RVector *bndl, RVector *bndu, sparsematrix *sparsea, ae_int_t msparse, RMatrix *densea, ae_int_t mdense, RVector *cl, RVector *cu) {
   ae_int_t m;
   ae_int_t n;
   ae_int_t nmain;
   ae_int_t nslack;
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   ae_int_t k;
   ae_int_t offsmain;
   ae_int_t offscombined;
   double vs;
   double v;
   n = state->n;
   nmain = state->nmain;
   nslack = n - nmain;
   ae_assert(mdense >= 0, "VIPMSetConstraints: MDense < 0");
   ae_assert(msparse >= 0, "VIPMSetConstraints: MSparse < 0");
   ae_assert(apservisfinitematrix(densea, mdense, n), "VIPMSetConstraints: DenseA contains infinite or NaN values!");
   ae_assert(msparse == 0 || sparsea->matrixtype == 1, "VIPMSetConstraints: non-CRS constraint matrix!");
   ae_assert(msparse == 0 || sparsea->m == msparse && sparsea->n == n, "VIPMSetConstraints: constraint matrix has incorrect size");
   ae_assert(cl->cnt >= mdense + msparse, "VIPMSetConstraints: CL is too short!");
   ae_assert(cu->cnt >= mdense + msparse, "VIPMSetConstraints: CU is too short!");
// Reset factorization flag
   state->factorizationpresent = false;
   state->factorizationpoweredup = false;
// Box constraints
   vectorsetlengthatleast(&state->bndl, n);
   vectorsetlengthatleast(&state->bndu, n);
   vectorsetlengthatleast(&state->rawbndl, n);
   vectorsetlengthatleast(&state->rawbndu, n);
   vectorsetlengthatleast(&state->hasbndl, n);
   vectorsetlengthatleast(&state->hasbndu, n);
   for (i = 0; i < n; i++) {
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
      ae_assert(!(state->hasbndl.xB[i] && state->hasbndu.xB[i] && bndl->xR[i] > bndu->xR[i]), "VIPMInitDenseQuadratic: inconsistent range for box constraints");
      state->bndl.xR[i] = bndl->xR[i];
      state->bndu.xR[i] = bndu->xR[i];
      state->rawbndl.xR[i] = bndl->xR[i];
      state->rawbndu.xR[i] = bndu->xR[i];
   }
   scaleshiftbcinplace(&state->scl, &state->xorigin, &state->bndl, &state->bndu, n);
// Linear constraints (full matrices)
   m = mdense + msparse;
   vectorsetlengthatleast(&state->b, m);
   vectorsetlengthatleast(&state->r, m);
   vectorsetlengthatleast(&state->ascales, m);
   vectorsetlengthatleast(&state->aflips, m);
   vectorsetlengthatleast(&state->hasr, m);
   matrixsetlengthatleast(&state->denseafull, mdense, n);
   if (msparse > 0) {
      sparsecopytocrsbuf(sparsea, &state->sparseafull);
   }
   if (mdense > 0) {
      rmatrixcopy(mdense, n, densea, 0, 0, &state->denseafull, 0, 0);
   }
   for (i = 0; i < m; i++) {
      ae_assert(isfinite(cl->xR[i]) || isneginf(cl->xR[i]), "VIPMInitDenseQuadratic: CL is not finite number or -INF");
      ae_assert(isfinite(cu->xR[i]) || isposinf(cu->xR[i]), "VIPMInitDenseQuadratic: CU is not finite number or +INF");
   // Store range
      if (isfinite(cl->xR[i]) || isfinite(cu->xR[i])) {
      // Non-degenerate constraint, at least one of bounds is present
         if (isfinite(cl->xR[i])) {
            ae_assert(!isfinite(cu->xR[i]) || cu->xR[i] >= cl->xR[i], "VIPMInitDenseQuadratic: inconsistent range (right-hand side) for linear constraint");
            if (isfinite(cu->xR[i])) {
            // We have both CL and CU, i.e. CL <= A*x <= CU.
            //
            // It can be either equality constraint (no slacks) or range constraint
            // (two pairs of slacks variables).
            //
            // Try to arrange things in such a way that |CU| >= |CL| (it can be done
            // by multiplication by -1 and boundaries swap).
            //
            // Having |CU| >= |CL| will allow us to drop huge irrelevant bound CU,
            // if we find it irrelevant during computations. Due to limitations
            // of our slack variable substitution, it can be done only for CU.
               if (fabs(cu->xR[i]) >= fabs(cl->xR[i])) {
                  state->b.xR[i] = cl->xR[i];
                  state->r.xR[i] = cu->xR[i] - cl->xR[i];
                  state->hasr.xB[i] = true;
                  state->aflips.xB[i] = false;
                  vs = 1.0;
               } else {
                  state->b.xR[i] = -cu->xR[i];
                  state->r.xR[i] = cu->xR[i] - cl->xR[i];
                  state->hasr.xB[i] = true;
                  state->aflips.xB[i] = true;
                  vs = -1.0;
               }
            } else {
            // Only lower bound: CL <= A*x.
            //
            // One pair of slack variables added.
               state->b.xR[i] = cl->xR[i];
               state->r.xR[i] = +INFINITY;
               state->hasr.xB[i] = false;
               state->aflips.xB[i] = false;
               vs = 1.0;
            }
         } else {
         // Only upper bound: A*x <= CU
         //
         // One pair of slack variables added.
            state->b.xR[i] = -cu->xR[i];
            state->r.xR[i] = +INFINITY;
            state->hasr.xB[i] = false;
            state->aflips.xB[i] = true;
            vs = -1.0;
         }
      } else {
      // Degenerate constraint -inf <= Ax <= +inf.
      // Generate dummy formulation.
         state->b.xR[i] = -1.0;
         state->r.xR[i] = 2.0;
         state->hasr.xB[i] = true;
         state->aflips.xB[i] = false;
         vs = 0.0;
      }
   // Store matrix row and its scaling coefficient
      if (i < msparse) {
         j0 = state->sparseafull.ridx.xZ[i];
         j1 = state->sparseafull.ridx.xZ[i + 1] - 1;
         for (j = j0; j <= j1; j++) {
            state->sparseafull.vals.xR[j] *= vs;
         }
      } else {
         for (j = 0; j < n; j++) {
            state->denseafull.xyR[i - msparse][j] *= vs;
         }
      }
      state->ascales.xR[i] = vs;
   }
   scaleshiftmixedbrlcinplace(&state->scl, &state->xorigin, n, &state->sparseafull, msparse, &state->denseafull, mdense, &state->b, &state->r);
   normalizemixedbrlcinplace(&state->sparseafull, msparse, &state->denseafull, mdense, &state->b, &state->r, n, true, &state->tmp0, true);
   for (i = 0; i < m; i++) {
      state->ascales.xR[i] *= state->tmp0.xR[i];
   }
   state->mdense = mdense;
   state->msparse = msparse;
// Separate main and slack parts of the constraint matrices
   vectorsetlengthatleast(&state->tmpi, nslack);
   for (i = 0; i < nslack; i++) {
      state->tmpi.xZ[i] = 0;
   }
   state->combinedaslack.m = mdense + msparse;
   state->combinedaslack.n = nslack;
   vectorsetlengthatleast(&state->combinedaslack.ridx, mdense + msparse + 1);
   vectorsetlengthatleast(&state->combinedaslack.idx, nslack);
   vectorsetlengthatleast(&state->combinedaslack.vals, nslack);
   state->combinedaslack.ridx.xZ[0] = 0;
   state->sparseamain.m = msparse;
   state->sparseamain.n = nmain;
   if (msparse > 0) {
      vectorsetlengthatleast(&state->sparseamain.ridx, msparse + 1);
      vectorsetlengthatleast(&state->sparseamain.idx, sparsea->ridx.xZ[msparse]);
      vectorsetlengthatleast(&state->sparseamain.vals, sparsea->ridx.xZ[msparse]);
      state->sparseamain.ridx.xZ[0] = 0;
      for (i = 0; i < msparse; i++) {
         offsmain = state->sparseamain.ridx.xZ[i];
         offscombined = state->combinedaslack.ridx.xZ[i];
         j0 = state->sparseafull.ridx.xZ[i];
         j1 = state->sparseafull.ridx.xZ[i + 1] - 1;
         for (j = j0; j <= j1; j++) {
            v = state->sparseafull.vals.xR[j];
            k = state->sparseafull.idx.xZ[j];
            if (k < nmain) {
               state->sparseamain.idx.xZ[offsmain] = k;
               state->sparseamain.vals.xR[offsmain] = v;
               offsmain++;
            } else {
               ae_assert(state->tmpi.xZ[k - nmain] == 0, "VIPMSetConstraints: slack column contains more than one nonzero element");
               state->combinedaslack.idx.xZ[offscombined] = k - nmain;
               state->combinedaslack.vals.xR[offscombined] = v;
               state->tmpi.xZ[k - nmain]++;
               offscombined++;
            }
         }
         state->sparseamain.ridx.xZ[i + 1] = offsmain;
         state->combinedaslack.ridx.xZ[i + 1] = offscombined;
      }
   }
   sparsecreatecrsinplace(&state->sparseamain);
   if (mdense > 0) {
      matrixsetlengthatleast(&state->denseamain, mdense, nmain);
      rmatrixcopy(mdense, nmain, &state->denseafull, 0, 0, &state->denseamain, 0, 0);
      for (i = 0; i < mdense; i++) {
         offscombined = state->combinedaslack.ridx.xZ[msparse + i];
         for (k = nmain; k < n; k++) {
            if (state->denseafull.xyR[i][k] != 0.0) {
               ae_assert(state->tmpi.xZ[k - nmain] == 0, "VIPMSetConstraints: slack column contains more than one nonzero element");
               state->combinedaslack.idx.xZ[offscombined] = k - nmain;
               state->combinedaslack.vals.xR[offscombined] = state->denseafull.xyR[i][k];
               state->tmpi.xZ[k - nmain]++;
               offscombined++;
            }
         }
         state->combinedaslack.ridx.xZ[msparse + i + 1] = offscombined;
      }
   }
   sparsecreatecrsinplace(&state->combinedaslack);
}

// Sets stopping criteria for QP-IPM solver.
//
// You can set all epsilon-values to one small value, about 0.000001.
//
// Inputs:
//     State               -   instance initialized with one of the initialization
//                             functions
//     EpsP                -   maximum primal error allowed in the  solution,
//                             EpsP >= 0. Zero will be  automatically  replaced
//                             by recommended default value,  which is  equal
//                             to 10*sqrt(Epsilon) in the current version
//     EpsD                -   maximum  dual  error allowed in the  solution,
//                             EpsP >= 0. Zero will be  automatically  replaced
//                             by recommended default value,  which is  equal
//                             to 10*sqrt(Epsilon) in the current version
//     EpsGap              -   maximum  duality gap allowed in the  solution,
//                             EpsP >= 0. Zero will be  automatically  replaced
//                             by recommended default value,  which is  equal
//                             to 10*sqrt(Epsilon) in the current version
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipmsetcond(vipmstate *state, double epsp, double epsd, double epsgap) {
   double sml;
   ae_assert(isfinite(epsp) && epsp >= 0.0, "VIPMSetCond: EpsP is infinite or negative");
   ae_assert(isfinite(epsd) && epsd >= 0.0, "VIPMSetCond: EpsD is infinite or negative");
   ae_assert(isfinite(epsgap) && epsgap >= 0.0, "VIPMSetCond: EpsP is infinite or negative");
   sml = sqrt(machineepsilon);
   state->epsp = coalesce(epsp, sml);
   state->epsd = coalesce(epsd, sml);
   state->epsgap = coalesce(epsgap, sml);
}

// Initializes QP-IPM state and prepares it to receive quadratic/linear terms
// and constraints.
//
// The solver is configured to work internally with factorization FType
//
// Inputs:
//     State       -   solver  state  to  be configured; previously allocated
//                     memory is reused as much as possible
//     S           -   scale vector, array[N]:
//                     * I-th element contains scale of I-th variable,
//                     * S[I] > 0
//     XOrigin     -   origin term, array[N]. Can be zero. The solver solves
//                     problem of the form
//
//                     >
//                     > min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//                     >
//
//                     The terms A and b (as well as constraints) will be
//                     specified later with separate calls.
//     FType       -   factorization type:
//                     * 0 for dense NxN factorization (normal equations)
//                     * 1 for sparse (N+M)x(N+M) factorization
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_vipminit(vipmstate *state, RVector *s, RVector *xorigin, ae_int_t n, ae_int_t nmain, ae_int_t ftype) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t nslack;
   ae_assert(n >= 1, "VIPMInit: N < 1");
   ae_assert(isfinitevector(s, n), "VIPMInit: S contains infinite or NaN elements");
   ae_assert(isfinitevector(xorigin, n), "VIPMInit: XOrigin contains infinite or NaN elements");
   ae_assert(ftype == 0 || ftype == 1, "VIPMInit: unexpected FType");
   ae_assert(nmain >= 1, "VIPMInit: NMain < 1");
   ae_assert(nmain <= n, "VIPMInit: NMain > N");
   nslack = n - nmain;
// Problem metrics, settings and type
   state->n = n;
   state->nmain = nmain;
   state->islinear = true;
   state->factorizationtype = ftype;
   state->factorizationpresent = false;
   state->factorizationpoweredup = false;
   vipmsetcond(state, 0.0, 0.0, 0.0);
   state->slacksforequalityconstraints = true;
// Reports
   state->repiterationscount = 0;
   state->repncholesky = 0;
// Scale and origin
   vectorsetlengthatleast(&state->scl, n);
   vectorsetlengthatleast(&state->invscl, n);
   vectorsetlengthatleast(&state->xorigin, n);
   for (i = 0; i < n; i++) {
      ae_assert(s->xR[i] > 0.0, "VIPMInit: S[i] is non-positive");
      state->scl.xR[i] = s->xR[i];
      state->invscl.xR[i] = 1.0 / s->xR[i];
      state->xorigin.xR[i] = xorigin->xR[i];
   }
   state->targetscale = 1.0;
// Linear and quadratic terms - default value
   vectorsetlengthatleast(&state->c, n);
   for (i = 0; i < n; i++) {
      state->c.xR[i] = 0.0;
   }
   state->hkind = -1;
   if (ftype == 0) {
   // Dense quadratic term
      matrixsetlengthatleast(&state->denseh, nmain, nmain);
      for (i = 0; i < nmain; i++) {
         for (j = 0; j <= i; j++) {
            state->denseh.xyR[i][j] = 0.0;
         }
      }
      state->hkind = 0;
      state->isdiagonalh = false;
   }
   if (ftype == 1) {
   // Sparse quadratic term
      state->sparseh.matrixtype = 1;
      state->sparseh.m = n;
      state->sparseh.n = n;
      state->sparseh.ninitialized = n;
      vectorsetlengthatleast(&state->sparseh.idx, n);
      vectorsetlengthatleast(&state->sparseh.vals, n);
      vectorsetlengthatleast(&state->sparseh.ridx, n + 1);
      for (i = 0; i < n; i++) {
         state->sparseh.idx.xZ[i] = i;
         state->sparseh.vals.xR[i] = 0.0;
         state->sparseh.ridx.xZ[i] = i;
      }
      state->sparseh.ridx.xZ[n] = n;
      sparsecreatecrsinplace(&state->sparseh);
      state->hkind = 1;
      state->isdiagonalh = true;
   }
   ae_assert(state->hkind >= 0, "VIPMInit: integrity check failed");
// Box constraints - default values
   vectorsetlengthatleast(&state->bndl, n);
   vectorsetlengthatleast(&state->bndu, n);
   vectorsetlengthatleast(&state->hasbndl, n);
   vectorsetlengthatleast(&state->hasbndu, n);
   for (i = 0; i < n; i++) {
      state->hasbndl.xB[i] = false;
      state->hasbndu.xB[i] = false;
      state->bndl.xR[i] = -INFINITY;
      state->bndu.xR[i] = +INFINITY;
   }
// Linear constraints - empty
   state->mdense = 0;
   state->msparse = 0;
   state->combinedaslack.m = 0;
   state->combinedaslack.n = nslack;
   state->sparseamain.m = 0;
   state->sparseamain.n = nmain;
   sparsecreatecrsinplace(&state->sparseamain);
   sparsecreatecrsinplace(&state->combinedaslack);
}

// Initializes QP-IPM state and prepares it to receive quadratic/linear terms
// and constraints.
//
// The solver is configured to work internally with dense NxN  factorization,
// no matter what exactly is passed - dense or sparse matrices.
//
// Inputs:
//     State       -   solver  state  to  be configured; previously allocated
//                     memory is reused as much as possible
//     S           -   scale vector, array[N]:
//                     * I-th element contains scale of I-th variable,
//                     * S[I] > 0
//     XOrigin     -   origin term, array[N]. Can be zero. The solver solves
//                     problem of the form
//
//                     >
//                     > min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//                     >
//
//                     The terms A and b (as well as constraints) will be
//                     specified later with separate calls.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipminitdense(vipmstate *state, RVector *s, RVector *xorigin, ae_int_t n) {
   ae_assert(n >= 1, "VIPMInitDense: N < 1");
   ae_assert(isfinitevector(s, n), "VIPMInitDense: S contains infinite or NaN elements");
   ae_assert(isfinitevector(xorigin, n), "VIPMInitDense: XOrigin contains infinite or NaN elements");
   vipmsolver_vipminit(state, s, xorigin, n, n, 0);
}

// Initializes QP-IPM state and prepares it to receive quadratic/linear terms
// and constraints.
//
// The solver is configured to work internally with dense NxN problem divided
// into two distinct parts - "main" and slack one:
// * dense quadratic term  is  a  NMain*NMain  matrix  (NMain <= N),  quadratic
//   coefficients are zero for variables outside of [0,NMain) range)
// * linear term is general vector of length N
// * linear constraints have special structure for variable with  indexes  in
//   [NMain,N) range: at most one element per column can be nonzero.
//
// This mode is intended for problems arising during SL1QP nonlinear programming.
//
// Inputs:
//     State       -   solver  state  to  be configured; previously allocated
//                     memory is reused as much as possible
//     S           -   scale vector, array[N]:
//                     * I-th element contains scale of I-th variable,
//                     * S[I] > 0
//     XOrigin     -   origin term, array[N]. Can be zero. The solver solves
//                     problem of the form
//
//                     >
//                     > min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//                     >
//
//                     The terms A and b (as well as constraints) will be
//                     specified later with separate calls.
//     NMain       -   number of "main" variables, 1 <= NMain <= N
//     N           -   total number of variables including slack ones
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipminitdensewithslacks(vipmstate *state, RVector *s, RVector *xorigin, ae_int_t nmain, ae_int_t n) {
   ae_assert(nmain >= 1, "VIPMInitDense: NMain < 1");
   ae_assert(n >= 1, "VIPMInitDense: N < 1");
   ae_assert(nmain <= n, "VIPMInitDense: NMain > N");
   ae_assert(isfinitevector(s, n), "VIPMInitDense: S contains infinite or NaN elements");
   ae_assert(isfinitevector(xorigin, n), "VIPMInitDense: XOrigin contains infinite or NaN elements");
   vipmsolver_vipminit(state, s, xorigin, n, nmain, 0);
}

// Initializes QP-IPM state and prepares it to receive quadratic/linear terms
// and constraints.
//
// The  solver  is configured  to  work  internally  with  sparse (N+M)x(N+M)
// factorization no matter what exactly is passed - dense or sparse matrices.
// Dense quadratic term will be sparsified prior to storage.
//
// Inputs:
//     State       -   solver  state  to  be configured; previously allocated
//                     memory is reused as much as possible
//     S           -   scale vector, array[N]:
//                     * I-th element contains scale of I-th variable,
//                     * S[I] > 0
//     XOrigin     -   origin term, array[N]. Can be zero. The solver solves
//                     problem of the form
//                     >
//                     > min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//                     >
//                     The terms A and b (as well as constraints) will be
//                     specified later with separate calls.
//     N           -   total number of variables, N >= 1
//
// This optimization mode assumes that no slack variables is present.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipminitsparse(vipmstate *state, RVector *s, RVector *xorigin, ae_int_t n) {
   ae_assert(n >= 1, "VIPMInitSparse: N < 1");
   ae_assert(isfinitevector(s, n), "VIPMInitSparse: S contains infinite or NaN elements");
   ae_assert(isfinitevector(xorigin, n), "VIPMInitSparse: XOrigin contains infinite or NaN elements");
   vipmsolver_vipminit(state, s, xorigin, n, n, 1);
}

// Allocates place for variables of IPM and fills by zeros.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_varsinitbyzero(vipmvars *vstate, ae_int_t n, ae_int_t m) {
   ae_assert(n >= 1, "VarsInitByZero: N < 1");
   ae_assert(m >= 0, "VarsInitByZero: M < 0");
   vstate->n = n;
   vstate->m = m;
   rsetallocv(n, 0.0, &vstate->x);
   rsetallocv(n, 0.0, &vstate->g);
   rsetallocv(n, 0.0, &vstate->t);
   rsetallocv(n, 0.0, &vstate->z);
   rsetallocv(n, 0.0, &vstate->s);
   rsetallocv(m, 0.0, &vstate->y);
   rsetallocv(m, 0.0, &vstate->w);
   rsetallocv(m, 0.0, &vstate->p);
   rsetallocv(m, 0.0, &vstate->v);
   rsetallocv(m, 0.0, &vstate->q);
}

// Allocates place for variables of IPM and fills them by values of
// the source
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_varsinitfrom(vipmvars *vstate, vipmvars *vsrc) {
   ae_int_t n;
   ae_int_t m;
   n = vsrc->n;
   m = vsrc->m;
   ae_assert(n >= 1, "VarsInitFrom: N < 1");
   ae_assert(m >= 0, "VarsInitFrom: M < 0");
   vstate->n = n;
   vstate->m = m;
   rcopyallocv(n, &vsrc->x, &vstate->x);
   rcopyallocv(n, &vsrc->g, &vstate->g);
   rcopyallocv(n, &vsrc->t, &vstate->t);
   rcopyallocv(n, &vsrc->z, &vstate->z);
   rcopyallocv(n, &vsrc->s, &vstate->s);
   rcopyallocv(m, &vsrc->y, &vstate->y);
   rcopyallocv(m, &vsrc->w, &vstate->w);
   rcopyallocv(m, &vsrc->p, &vstate->p);
   rcopyallocv(m, &vsrc->v, &vstate->v);
   rcopyallocv(m, &vsrc->q, &vstate->q);
}

// Adds to variables direction vector times step length. Different
// lengths are used for primal and dual steps.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_varsaddstep(vipmvars *vstate, vipmvars *vdir, double stpp, double stpd) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t m;
   n = vstate->n;
   m = vstate->m;
   ae_assert(n >= 1, "VarsAddStep: N < 1");
   ae_assert(m >= 0, "VarsAddStep: M < 0");
   ae_assert(n == vdir->n, "VarsAddStep: sizes mismatch");
   ae_assert(m == vdir->m, "VarsAddStep: sizes mismatch");
   for (i = 0; i < n; i++) {
      vstate->x.xR[i] += stpp * vdir->x.xR[i];
      vstate->g.xR[i] += stpp * vdir->g.xR[i];
      vstate->t.xR[i] += stpp * vdir->t.xR[i];
      vstate->z.xR[i] += stpd * vdir->z.xR[i];
      vstate->s.xR[i] += stpd * vdir->s.xR[i];
   }
   for (i = 0; i < m; i++) {
      vstate->w.xR[i] += stpp * vdir->w.xR[i];
      vstate->p.xR[i] += stpp * vdir->p.xR[i];
      vstate->y.xR[i] += stpd * vdir->y.xR[i];
      vstate->v.xR[i] += stpd * vdir->v.xR[i];
      vstate->q.xR[i] += stpd * vdir->q.xR[i];
   }
}

// Computes complementarity gap
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static double vipmsolver_varscomputecomplementaritygap(vipmvars *vstate) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t m;
   double result;
   n = vstate->n;
   m = vstate->m;
   result = 0.0;
   for (i = 0; i < n; i++) {
      result += vstate->z.xR[i] * vstate->g.xR[i] + vstate->s.xR[i] * vstate->t.xR[i];
   }
   for (i = 0; i < m; i++) {
      result += vstate->v.xR[i] * vstate->w.xR[i] + vstate->p.xR[i] * vstate->q.xR[i];
   }
   return result;
}

// Computes empirical value of the barrier parameter Mu
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static double vipmsolver_varscomputemu(vipmstate *state, vipmvars *vstate) {
   double result;
   result = 0.0;
   result += rdotv(vstate->n, &vstate->z, &vstate->g) + rdotv(vstate->n, &vstate->s, &vstate->t);
   result += rdotv(vstate->m, &vstate->v, &vstate->w) + rdotv(vstate->m, &vstate->p, &vstate->q);
   result /= coalesce(state->cntgz + state->cntts + state->cntwv + state->cntpq, 1.0);
   return result;
}

// Initializes reduced sparse system.
//
// Works only for sparse IPM.
// ALGLIB: Copyright 15.11.2021 by Sergey Bochkanov
static void vipmsolver_reducedsysteminit(vipmreducedsparsesystem *s, vipmstate *solver) {
   ae_int_t ntotal;
   ae_int_t nnzmax;
   ae_int_t factldlt;
   ae_int_t permpriorityamd;
   ae_int_t offs;
   ae_int_t rowoffs;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t k0;
   ae_int_t k1;
   ae_int_t sumcoldeg;
   ae_int_t sumrowdeg;
   ae_assert(solver->factorizationtype == 1, "ReducedSystemInit: unexpected factorization type");
   ae_assert(solver->hkind == 1, "ReducedSystemInit: unexpected HKind");
   ntotal = solver->n + solver->mdense + solver->msparse;
   s->ntotal = ntotal;
   allocv(ntotal, &s->effectivediag);
// Determine maximum amount of memory required to store sparse matrices
   nnzmax = solver->sparseh.ridx.xZ[solver->n];
   if (solver->msparse > 0) {
      nnzmax += solver->sparseafull.ridx.xZ[solver->msparse];
   }
   if (solver->mdense > 0) {
      nnzmax += solver->n * solver->mdense;
   }
   nnzmax += ntotal;
// Default DIAG and DAMP terms
   rsetallocv(ntotal, 0.0, &s->diagterm);
   rsetallocv(ntotal, 0.0, &s->dampterm);
// Prepare lower triangle of template KKT matrix (KKT system without D and E
// terms being added to diagonals)
   s->rawsystem.m = ntotal;
   s->rawsystem.n = ntotal;
   vectorsetlengthatleast(&s->rawsystem.idx, nnzmax);
   vectorsetlengthatleast(&s->rawsystem.vals, nnzmax);
   vectorsetlengthatleast(&s->rawsystem.ridx, ntotal + 1);
   s->rawsystem.ridx.xZ[0] = 0;
   offs = 0;
   rowoffs = 0;
   sumcoldeg = 0;
   sumrowdeg = 0;
   isetallocv(solver->n, 0, &s->coldegrees);
   isetallocv(solver->msparse + solver->mdense, 0, &s->rowdegrees);
   bsetallocv(solver->n, true, &s->isdiagonal);
   for (i = 0; i < solver->n; i++) {
      ae_assert(solver->sparseh.didx.xZ[i] + 1 == solver->sparseh.uidx.xZ[i], "ReducedSystemInit: critical integrity check failed for diagonal of H");
      if (!solver->isfrozen.xB[i]) {
      // Entire row is not frozen, but some of its entries can be.
      // Output non-frozen offdiagonal entries.
         k0 = solver->sparseh.ridx.xZ[i];
         k1 = solver->sparseh.didx.xZ[i] - 1;
         for (k = k0; k <= k1; k++) {
            j = solver->sparseh.idx.xZ[k];
            if (!solver->isfrozen.xB[j]) {
               s->rawsystem.idx.xZ[offs] = j;
               s->rawsystem.vals.xR[offs] = -solver->sparseh.vals.xR[k];
               s->isdiagonal.xB[i] = false;
               s->isdiagonal.xB[j] = false;
               s->coldegrees.xZ[i]++;
               s->coldegrees.xZ[j]++;
               sumcoldeg += 2;
               offs++;
            }
         }
      // Output diagonal entry (it is always not frozen)
         s->rawsystem.idx.xZ[offs] = i;
         s->rawsystem.vals.xR[offs] = -solver->sparseh.vals.xR[solver->sparseh.didx.xZ[i]];
         offs++;
      } else {
      // Entire row is frozen, output just -1
         s->rawsystem.idx.xZ[offs] = i;
         s->rawsystem.vals.xR[offs] = -1.0;
         offs++;
      }
      rowoffs++;
      s->rawsystem.ridx.xZ[rowoffs] = offs;
   }
   for (i = 0; i < solver->msparse; i++) {
      k0 = solver->sparseafull.ridx.xZ[i];
      k1 = solver->sparseafull.ridx.xZ[i + 1] - 1;
      for (k = k0; k <= k1; k++) {
         j = solver->sparseafull.idx.xZ[k];
         if (!solver->isfrozen.xB[j]) {
            s->rawsystem.idx.xZ[offs] = j;
            s->rawsystem.vals.xR[offs] = solver->sparseafull.vals.xR[k];
            s->rowdegrees.xZ[i]++;
            s->coldegrees.xZ[j]++;
            sumcoldeg++;
            sumrowdeg++;
            offs++;
         }
      }
      s->rawsystem.idx.xZ[offs] = rowoffs;
      s->rawsystem.vals.xR[offs] = 0.0;
      offs++;
      rowoffs++;
      s->rawsystem.ridx.xZ[rowoffs] = offs;
   }
   for (i = 0; i < solver->mdense; i++) {
      for (k = 0; k < solver->n; k++) {
         if (solver->denseafull.xyR[i][k] != 0.0 && !solver->isfrozen.xB[k]) {
            s->rawsystem.idx.xZ[offs] = k;
            s->rawsystem.vals.xR[offs] = solver->denseafull.xyR[i][k];
            s->rowdegrees.xZ[solver->msparse + i]++;
            s->coldegrees.xZ[k]++;
            sumcoldeg++;
            sumrowdeg++;
            offs++;
         }
      }
      s->rawsystem.idx.xZ[offs] = rowoffs;
      s->rawsystem.vals.xR[offs] = 0.0;
      offs++;
      rowoffs++;
      s->rawsystem.ridx.xZ[rowoffs] = offs;
   }
   ae_assert(rowoffs == ntotal, "ReducedSystemInit: critical integrity check failed");
   ae_assert(offs <= nnzmax, "ReducedSystemInit: critical integrity check failed");
   sparsecreatecrsinplace(&s->rawsystem);
// Prepare reordering
   isetallocv(ntotal, 0, &s->priorities);
// Perform factorization analysis using sparsity pattern (but not numerical values)
   factldlt = 1;
   permpriorityamd = 3;
   if (!spsymmanalyze(&s->rawsystem, &s->priorities, 0.0, factldlt, permpriorityamd, &s->analysis)) {
      ae_assert(false, "ReducedSystemInit: critical integrity check failed, symbolically degenerate KKT system encountered");
   }
}

// Computes factorization of A+Diag+Damp, where A is an internally stored KKT
// matrix and Diag and Damp are user-supplied diagonal terms.
//
// The Diag term is assumed to be a "true" modification of the system, and
// Damp is assumed to be a small damping factor. The difference is that the
// damping factor is added during the factorization, but not accounted for
// during the iterative refinement stage, i.e. we factor A+Diag+Damp, but aim
// to solve A+Diag.
//
// ModEps and BadChol are user supplied tolerances for modified Cholesky/LDLT.
//
// Returns True on success, False on LDLT failure.
//
// On success outputs diagonal reproduction error ErrSq, and sum of squared
// diagonal elements SumSq
// ALGLIB: Copyright 15.11.2021 by Sergey Bochkanov
static bool vipmsolver_reducedsystemfactorizewithaddends(vipmreducedsparsesystem *s, RVector *diag, RVector *damp, double modeps, double badchol, double *sumsq, double *errsq) {
   ae_int_t ntotal;
   ae_int_t i;
   bool result;
   *sumsq = 0.0;
   *errsq = 0.0;
   ntotal = s->ntotal;
   rcopyv(ntotal, diag, &s->diagterm);
   rcopyv(ntotal, damp, &s->dampterm);
   for (i = 0; i < ntotal; i++) {
      s->effectivediag.xR[i] = s->rawsystem.vals.xR[s->rawsystem.didx.xZ[i]] + diag->xR[i] + damp->xR[i];
   }
   spsymmreloaddiagonal(&s->analysis, &s->effectivediag);
   result = true;
   spsymmsetmodificationstrategy(&s->analysis, 1, modeps, badchol, 0.0, 0.0);
   if (spsymmfactorize(&s->analysis)) {
   // Compute diagonal reproduction error
      spsymmdiagerr(&s->analysis, sumsq, errsq);
   } else {
      *sumsq = 0.0;
      *errsq = 0.0;
      result = false;
   }
   return result;
}

// Solve reduced KKT system, replacing right part by its solution.
// ALGLIB: Copyright 15.11.2021 by Sergey Bochkanov
static void vipmsolver_reducedsystemsolve(vipmreducedsparsesystem *s, RVector *b) {
   const ae_int_t maxrefinementits = 5;
   ae_int_t iteridx;
   double bnrm2;
   double relerr;
   double prevrelerr;
// Perform initial solution
   rcopyallocv(s->ntotal, b, &s->tmpb);
   spsymmsolve(&s->analysis, b);
// Trace residual and relative error
   bnrm2 = rmax2(rdotv2(s->ntotal, &s->tmpb), 1.0);
   sparsesmv(&s->rawsystem, false, b, &s->tmprhs);
   rmuladdv(s->ntotal, b, &s->diagterm, &s->tmprhs);
   rmulv(s->ntotal, -1.0, &s->tmprhs);
   raddv(s->ntotal, 1.0, &s->tmpb, &s->tmprhs);
   relerr = sqrt(rdotv2(s->ntotal, &s->tmprhs) / bnrm2);
// Perform iterative refinement, if necessary
   prevrelerr = 1.0E50;
   iteridx = 0;
   while (iteridx < maxrefinementits && relerr > 10.0 * machineepsilon && relerr < 0.5 * prevrelerr) {
   // Compute correction and update solution
      rcopyallocv(s->ntotal, &s->tmprhs, &s->tmpcorr);
      spsymmsolve(&s->analysis, &s->tmpcorr);
      raddv(s->ntotal, 1.0, &s->tmpcorr, b);
   // Recompute residual
      sparsesmv(&s->rawsystem, false, b, &s->tmprhs);
      rmuladdv(s->ntotal, b, &s->diagterm, &s->tmprhs);
      rmulv(s->ntotal, -1.0, &s->tmprhs);
      raddv(s->ntotal, 1.0, &s->tmpb, &s->tmprhs);
      prevrelerr = relerr;
      relerr = sqrt(rdotv2(s->ntotal, &s->tmprhs) / bnrm2);
      iteridx++;
   }
}

// Computes target function 0.5*x'*H*x+c'*x
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static double vipmsolver_vipmtarget(vipmstate *state, RVector *x) {
   ae_int_t n;
   ae_int_t nmain;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t j0;
   ae_int_t j1;
   double v;
   double result;
   n = state->n;
   nmain = state->nmain;
   ae_assert(state->hkind == 0 || state->hkind == 1, "VIPMTarget: unexpected HKind");
   result = 0.0;
// Dense
   if (state->hkind == 0) {
      for (i = 0; i < nmain; i++) {
         for (j = 0; j < i; j++) {
            result += x->xR[i] * state->denseh.xyR[i][j] * x->xR[j];
         }
         result += 0.5 * x->xR[i] * x->xR[i] * state->denseh.xyR[i][i];
      }
      for (i = 0; i < n; i++) {
         result += state->c.xR[i] * x->xR[i];
      }
      return result;
   }
// Sparse
   if (state->hkind == 1) {
      for (i = 0; i < n; i++) {
         result += state->c.xR[i] * x->xR[i];
         j0 = state->sparseh.ridx.xZ[i];
         j1 = state->sparseh.didx.xZ[i] - 1;
         for (k = j0; k <= j1; k++) {
            v = state->sparseh.vals.xR[k];
            j = state->sparseh.idx.xZ[k];
            result += v * x->xR[i] * x->xR[j];
         }
         ae_assert(state->sparseh.uidx.xZ[i] != state->sparseh.didx.xZ[i], "VIPMTarget: sparse diagonal not found");
         v = state->sparseh.vals.xR[state->sparseh.didx.xZ[i]];
         result += 0.5 * v * x->xR[i] * x->xR[i];
      }
      return result;
   }
   return result;
}

// Computes
//
//     Y = alpha*A*x + beta*Y
//
// where A is constraint matrix, X is user-specified source, Y is target.
//
// Beta can be zero (in this case original contents of Y is ignored).
// If Beta is nonzero, we expect that Y contains preallocated array.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_multiplygeax(vipmstate *state, double alpha, RVector *x, ae_int_t offsx, double beta, RVector *y, ae_int_t offsax) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t mdense;
   ae_int_t msparse;
   n = state->n;
   m = state->mdense + state->msparse;
   mdense = state->mdense;
   msparse = state->msparse;
   if (beta == 0.0) {
      allocv(offsax + m, y);
   } else {
      ae_assert(y->cnt >= offsax + m, "MultiplyGEAX: Y is too short");
   }
   if (msparse > 0) {
      sparsegemv(&state->sparseafull, alpha, 0, x, offsx, beta, y, offsax);
   }
   if (mdense > 0) {
      rmatrixgemv(mdense, n, alpha, &state->denseafull, 0, 0, 0, x, offsx, beta, y, offsax + msparse);
   }
}

// Computes
//
//     Y = alpha*A'*x + beta*Y
//
// where A is constraint matrix, X is user-specified source, Y is target.
//
// Beta can be zero, in this case we automatically reallocate target if it is
// too short (but do NOT reallocate it if its size is large enough).
// If Beta is nonzero, we expect that Y contains preallocated array.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_multiplygeatx(vipmstate *state, double alpha, RVector *x, ae_int_t offsx, double beta, RVector *y, ae_int_t offsy) {
   ae_int_t n;
   ae_int_t mdense;
   ae_int_t msparse;
   n = state->n;
   mdense = state->mdense;
   msparse = state->msparse;
   if (beta == 0.0) {
      allocv(offsy + n, y);
      rsetvx(n, 0.0, y, offsy);
   } else {
      ae_assert(y->cnt >= offsy + n, "MultiplyGEATX: Y is too short");
      rmulvx(n, beta, y, offsy);
   }
   if (msparse > 0) {
      sparsegemv(&state->sparseafull, alpha, 1, x, offsx, 1.0, y, offsy);
   }
   if (mdense > 0) {
      rmatrixgemv(n, mdense, alpha, &state->denseafull, 0, 0, 1, x, offsx + msparse, 1.0, y, offsy);
   }
}

// Computes H*x, does not support advanced functionality of GEAX/GEATX
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_multiplyhx(vipmstate *state, RVector *x, RVector *hx) {
   ae_int_t n;
   ae_int_t nmain;
   ae_int_t i;
   n = state->n;
   nmain = state->nmain;
   vectorsetlengthatleast(hx, n);
   ae_assert(state->hkind == 0 || state->hkind == 1, "VIPMMultiplyHX: unexpected HKind");
   if (state->hkind == 0) {
      rmatrixsymv(nmain, 1.0, &state->denseh, 0, 0, false, x, 0, 0.0, hx, 0);
      for (i = nmain; i < n; i++) {
         hx->xR[i] = 0.0;
      }
      for (i = 0; i < n; i++) {
         hx->xR[i] += x->xR[i] * state->diagr.xR[i];
      }
   }
   if (state->hkind == 1) {
      ae_assert(state->sparseh.n == n && state->sparseh.m == n, "VIPMMultiplyHX: sparse H has incorrect size");
      if (state->isdiagonalh) {
      // H is known to be diagonal, much faster code can be used
         rcopyv(n, &state->diagr, hx);
         raddv(n, 1.0, &state->sparseh.vals, hx);
         rmergemulv(n, x, hx);
      } else {
      // H is a general sparse matrix, use generic sparse matrix-vector multiply
         sparsesmv(&state->sparseh, false, x, hx);
         for (i = 0; i < n; i++) {
            hx->xR[i] += x->xR[i] * state->diagr.xR[i];
         }
      }
   }
}

// Computes products H*x, A*x, A^T*y
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_vipmmultiply(vipmstate *state, RVector *x, RVector *y, RVector *hx, RVector *ax, RVector *aty) {
   vipmsolver_multiplygeax(state, 1.0, x, 0, 0.0, ax, 0);
   vipmsolver_multiplygeatx(state, 1.0, y, 0, 0.0, aty, 0);
   vipmsolver_multiplyhx(state, x, hx);
}

// This function performs factorization of modified KKT system
//
//     (                        |                 )
//     ( -(H+alpha0*D+alpha1*I) |       A^T       )
//     (                        |                 )
//     (------------------------|-----------------)
//     (                        |                 )
//     (           A            | beta0*E+beta1*I )
//     (                        |                 )
//
// where:
// * H is an NxN quadratic term
// * A is an MxN matrix of linear constraint
// * alpha0, alpha1, beta0, beta1 are nonnegative scalars
// * D and E are diagonal matrices with nonnegative entries (which are ignored
//   if alpha0 and beta0 are zero - arrays are not referenced at all)
// * I is an NxN or MxM identity matrix
//
// Additionally, regularizing term
//
//     (        |        )
//     ( -reg*I |        )
//     (        |        )
//     (--------|--------)
//     (        |        )
//     (        | +reg*I )
//     (        |        )
//
// is added to the entire KKT system prior to factorization in order to
// improve its numerical stability.
//
// Returns True on success, False on falure of factorization (it is recommended
// to increase regularization parameter and try one more time).
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static bool vipmsolver_vipmfactorize(vipmstate *state, double alpha0, RVector *d, double beta0, RVector *e, double alpha11, double beta11, double modeps, double dampeps) {
   ae_int_t n;
   ae_int_t nmain;
   ae_int_t nslack;
   ae_int_t m;
   ae_int_t mdense;
   ae_int_t msparse;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t k0;
   ae_int_t k1;
   ae_int_t ka;
   ae_int_t kb;
   ae_int_t ja;
   ae_int_t jb;
   double va;
   double vb;
   double v;
   double vv;
   double badchol;
   double sumsq;
   double errsq;
   bool result;
   ae_assert(isfinite(alpha0) && alpha0 >= 0.0, "VIPMFactorize: Alpha0 is infinite or negative");
   ae_assert(isfinite(alpha11) && alpha11 >= 0.0, "VIPMFactorize: Alpha1 is infinite or negative");
   ae_assert(isfinite(beta0) && beta0 >= 0.0, "VIPMFactorize: Beta0 is infinite or negative");
   ae_assert(isfinite(beta11) && beta11 >= 0.0, "VIPMFactorize: Beta1 is infinite or negative");
   ae_assert(state->factorizationtype == 0 || state->factorizationtype == 1, "VIPMFactorize: unexpected factorization type");
   ae_assert(state->factorizationpoweredup, "VIPMFactorize: critical integrity check failed (no powerup stage)");
   n = state->n;
   nmain = state->nmain;
   nslack = n - nmain;
   m = state->mdense + state->msparse;
   mdense = state->mdense;
   msparse = state->msparse;
   state->factorizationpresent = false;
   badchol = 1.0E50;
   result = true;
// Dense NxN normal equations approach
   if (state->factorizationtype == 0) {
   // A problem formulation with possible slacks.
   //
   // ==== A FORMULATION WITHOUT FROZEN VARIABLES ====
   //
   // We have to solve following system:
   //
   //     [ -(H+Dh+Rh)         Ah'  ] [ Xh ]   [ Bh ]
   //     [          -(Dz+Rz)  Az'  ] [ Xz ] = [ Bz ]
   //     [   Ah     Az         E   ] [ Y  ]   [ By ]
   //
   // with Xh being NMain-dimensional vector, Xz being NSlack-dimensional vector, constraint
   // matrix A being divided into non-slack and slack parts Ah and Az (and Ah, in turn, being
   // divided into sparse and dense parts), Rh and Rz being diagonal regularization matrix,
   // Y being M-dimensional vector.
   //
   // NOTE: due to definition of slack variables following holds: for any diagonal matrix W
   //       a product Az*W*Az' is a diagonal matrix.
   //
   // From the second line we get
   //
   //     Xz = inv(Dz+Rz)*Az'*y - inv(Dz+Rz)*Bz
   //        = inv(Dz+Rz)*Az'*y - BzWave
   //
   // Using this value for Zx, third line gives us
   //
   //     Y  = inv(E+Az*inv(Dz+Rz)*Az')*(By+Az*BzWave-Ah*Xh)
   //        = inv(EWave)*(ByWave-Ah*Xh)
   //        with EWave = E+Az*inv(Dz+Rz)*Az' and ByWave = By+Az*BzWave
   //
   // Finally, first line gives us
   //
   //     Xh = -inv(H+Dh+Rh+Ah'*inv(EWave)*Ah)*(Bh-Ah'*inv(EWave)*ByWave)
   //        = -inv(HWave)*BhWave
   //        with HWave = H+Dh+Rh+Ah'*inv(EWave)*Ah and BhWave = Bh-Ah'*inv(EWave)*ByWave
   //
   // In order to prepare factorization we need to compute:
   // (a) diagonal matrices Dh, Rh, Dz and Rz (and precomputed inverse of Dz+Rz)
   // (b) EWave
   // (c) HWave
   //
   // ==== SPECIAL HANDLING OF FROZEN VARIABLES ====
   //
   // Frozen variables result in zero steps, i.e. zero components of Xh and Xz.
   // It could be implemented by explicit modification of KKT system (zeroing out
   // columns/rows of KKT matrix, rows of right part, putting 1's to diagonal).
   //
   // However, it is possible to do without actually modifying quadratic term and
   // constraints:
   // * freezing elements of Xz can be implemented by zeroing out corresponding
   //   columns of inv(Dz+Rz) because Az always appears in computations along with diagonal Dz+Rz.
   // * freezing elements of Xh is a bit more complex - it needs:
   //   * zeroing out columns/rows of HWave and setting up unit diagonal prior to solving for Xh
   //   * explicitly zeroing out computed elements of Xh prior to computing Y and Xz
      vectorsetlengthatleast(&state->factregdhrh, nmain);
      vectorsetlengthatleast(&state->factinvregdzrz, nslack);
      for (i = 0; i < n; i++) {
         v = 0.0;
         if (alpha0 > 0.0) {
            v += alpha0 * d->xR[i];
         }
         if (alpha11 > 0.0) {
            v += alpha11;
         }
         v += state->diagr.xR[i];
         v += dampeps;
         ae_assert(v > 0.0, "VIPMFactorize: integrity check failed, degenerate diagonal matrix");
         if (i >= nmain) {
            if (!state->isfrozen.xB[i]) {
               state->factinvregdzrz.xR[i - nmain] = 1.0 / v;
            } else {
               state->factinvregdzrz.xR[i - nmain] = 0.0;
            }
         } else {
            state->factregdhrh.xR[i] = v;
         }
      }
   // Now we are ready to compute EWave
      vectorsetlengthatleast(&state->factregewave, m);
      for (i = 0; i < m; i++) {
      // Compute diagonal element of E
         v = 0.0;
         if (beta0 > 0.0) {
            v += beta0 * e->xR[i];
         }
         if (beta11 > 0.0) {
            v += beta11;
         }
         v += dampeps;
         ae_assert(v > 0.0, "VIPMFactorize: integrity check failed, degenerate diagonal matrix");
      // Compute diagonal modification Az*inv(Dz)*Az'
         k0 = state->combinedaslack.ridx.xZ[i];
         k1 = state->combinedaslack.ridx.xZ[i + 1] - 1;
         for (k = k0; k <= k1; k++) {
            vv = state->combinedaslack.vals.xR[k];
            v += vv * vv * state->factinvregdzrz.xR[state->combinedaslack.idx.xZ[k]];
         }
      // Save EWave
         state->factregewave.xR[i] = v;
      }
   // Now we are ready to compute HWave:
   // * store H
   // * add Dh
   // * add Ah'*inv(EWave)*Ah
      matrixsetlengthatleast(&state->factdensehaug, nmain, nmain);
      ae_assert(state->hkind == 0, "VIPMFactorize: unexpected HKind");
      rmatrixcopy(nmain, nmain, &state->denseh, 0, 0, &state->factdensehaug, 0, 0);
      for (i = 0; i < nmain; i++) {
         state->factdensehaug.xyR[i][i] += state->factregdhrh.xR[i];
      }
      if (msparse > 0) {
      // Handle sparse part of Ah in Ah'*inv(EWave)*Ah
         for (i = 0; i < msparse; i++) {
            v = 1.0 / state->factregewave.xR[i];
            k0 = state->sparseamain.ridx.xZ[i];
            k1 = state->sparseamain.ridx.xZ[i + 1] - 1;
            for (ka = k0; ka <= k1; ka++) {
               ja = state->sparseamain.idx.xZ[ka];
               va = state->sparseamain.vals.xR[ka];
               for (kb = k0; kb <= ka; kb++) {
                  jb = state->sparseamain.idx.xZ[kb];
                  vb = state->sparseamain.vals.xR[kb];
                  state->factdensehaug.xyR[ja][jb] += v * va * vb;
               }
            }
         }
      }
      if (mdense > 0) {
      // Handle dense part of Ah in Ah'*inv(EWave)*Ah
         matrixsetlengthatleast(&state->tmpr2, mdense, nmain);
         rmatrixcopy(mdense, nmain, &state->denseamain, 0, 0, &state->tmpr2, 0, 0);
         for (i = 0; i < mdense; i++) {
            v = 1.0 / sqrt(state->factregewave.xR[msparse + i]);
            for (j = 0; j < nmain; j++) {
               state->tmpr2.xyR[i][j] *= v;
            }
         }
         rmatrixsyrk(nmain, mdense, 1.0, &state->tmpr2, 0, 0, 2, 1.0, &state->factdensehaug, 0, 0, false);
      }
   // Zero out rows/cols of HWave corresponding to frozen variables, set up unit diagonal
      rsetallocv(nmain, 1.0, &state->tmp0);
      for (i = 0; i < nmain; i++) {
         if (state->isfrozen.xB[i]) {
            state->tmp0.xR[i] = 0.0;
         }
      }
      for (i = 0; i < nmain; i++) {
         if (state->isfrozen.xB[i]) {
         // Entire row is nullified except for diagonal element
            rsetr(i + 1, 0.0, &state->factdensehaug, i);
            state->factdensehaug.xyR[i][i] = 1.0;
         } else {
         // Only some components are nullified
            rmergemulvr(i + 1, &state->tmp0, &state->factdensehaug, i);
         }
      }
   // Compute Cholesky factorization of HWave
      if (!spdmatrixcholesky(&state->factdensehaug, nmain, false)) {
         result = false;
         return result;
      }
      v = 0.0;
      for (i = 0; i < nmain; i++) {
         v += state->factdensehaug.xyR[i][i];
      }
      if (!isfinite(v) || v > badchol) {
         result = false;
         return result;
      }
      state->factorizationpresent = true;
   }
// Sparse (M+N)x(M+N) factorization
   if (state->factorizationtype == 1) {
   // Generate reduced KKT matrix
      allocv(n + m, &state->facttmpdiag);
      allocv(n + m, &state->facttmpdamp);
      for (i = 0; i < n; i++) {
         vv = 0.0;
         if (alpha0 > 0.0) {
            vv += alpha0 * d->xR[i];
         }
         if (alpha11 > 0.0) {
            vv += alpha11;
         }
         vv += state->diagr.xR[i];
         state->facttmpdiag.xR[i] = -vv;
         state->facttmpdamp.xR[i] = -dampeps;
         ae_assert(vv > 0.0, "VIPMFactorize: integrity check failed, degenerate diagonal matrix");
      }
      for (i = 0; i < msparse + mdense; i++) {
         vv = 0.0;
         if (beta0 > 0.0) {
            vv += beta0 * e->xR[i];
         }
         if (beta11 > 0.0) {
            vv += beta11;
         }
         state->facttmpdiag.xR[n + i] = vv;
         state->facttmpdamp.xR[n + i] = dampeps;
         ae_assert(vv > 0.0, "VIPMFactorize: integrity check failed, degenerate diagonal matrix");
      }
   // Perform factorization
   // Perform additional integrity check: LDLT should reproduce diagonal of initial KKT system with good precision
      if (!vipmsolver_reducedsystemfactorizewithaddends(&state->reducedsparsesystem, &state->facttmpdiag, &state->facttmpdamp, modeps, badchol, &sumsq, &errsq)) {
         result = false;
         return result;
      }
      if (sqrt(errsq / (1.0 + sumsq)) > sqrt(machineepsilon)) {
         result = false;
         return result;
      }
      state->factorizationpresent = true;
   }
// Done, integrity control
   ae_assert(state->factorizationpresent, "VIPMFactorize: integrity check failed");
   state->repncholesky++;
   return result;
}

// A  low-level  function  which  solves  KKT  system  whose  regularized (!)
// factorization was prepared by VIPMFactorize(). No iterative refinement  is
// performed.
//
// On input, right-hand-side is stored in DeltaXY; on output, solution replaces
// DeltaXY.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_solvereducedkktsystem(vipmstate *state, RVector *deltaxy) {
   ae_int_t n;
   ae_int_t nmain;
   ae_int_t nslack;
   ae_int_t m;
   ae_int_t mdense;
   ae_int_t msparse;
   ae_int_t i;
   ae_assert(state->factorizationpresent, "VIPMSolve: integrity check failed - factorization is not present");
   ae_assert(state->factorizationtype == 0 || state->factorizationtype == 1, "VIPMSolve: unexpected factorization type");
   n = state->n;
   nmain = state->nmain;
   nslack = n - nmain;
   m = state->mdense + state->msparse;
   mdense = state->mdense;
   msparse = state->msparse;
// Dense solving
   if (state->factorizationtype == 0) {
   // Compute
   //
   //     BzWave = inv(Dz+Rz)*Bz
   //     ByWave = By+Az*BzWave
   //     BhWave = Bh-Ah'*inv(EWave)*ByWave
      for (i = 0; i < nslack; i++) {
         deltaxy->xR[nmain + i] *= state->factinvregdzrz.xR[i];
      }
      sparsegemv(&state->combinedaslack, 1.0, 0, deltaxy, nmain, 1.0, deltaxy, n);
      vectorsetlengthatleast(&state->tmp1, m);
      for (i = 0; i < m; i++) {
         state->tmp1.xR[i] = deltaxy->xR[n + i] / state->factregewave.xR[i];
      }
      sparsegemv(&state->sparseamain, -1.0, 1, &state->tmp1, 0, 1.0, deltaxy, 0);
      rmatrixgemv(nmain, mdense, -1.0, &state->denseamain, 0, 0, 1, &state->tmp1, msparse, 1.0, deltaxy, 0);
   // Compute Xh = -inv(HWave)*BhWave.
   // Zero out components corresponding to frozen variables.
      for (i = 0; i < nmain; i++) {
         deltaxy->xR[i] = -deltaxy->xR[i];
      }
      rmatrixtrsv(nmain, &state->factdensehaug, 0, 0, false, false, 0, deltaxy, 0);
      rmatrixtrsv(nmain, &state->factdensehaug, 0, 0, false, false, 1, deltaxy, 0);
      for (i = 0; i < n; i++) {
         if (state->isfrozen.xB[i]) {
            deltaxy->xR[i] = 0.0;
         }
      }
   // Compute Y = inv(EWave)*(ByWave-Ah*Xh)
      sparsegemv(&state->sparseamain, -1.0, 0, deltaxy, 0, 1.0, deltaxy, n);
      rmatrixgemv(mdense, nmain, -1.0, &state->denseamain, 0, 0, 0, deltaxy, 0, 1.0, deltaxy, n + msparse);
      for (i = 0; i < m; i++) {
         deltaxy->xR[n + i] /= state->factregewave.xR[i];
      }
   // Compute Xz = -(BzWave - inv(Dz+Rz)*Az'*y)
      vectorsetlengthatleast(&state->tmp0, nslack);
      for (i = 0; i < nslack; i++) {
         state->tmp0.xR[i] = 0.0;
      }
      sparsegemv(&state->combinedaslack, 1.0, 1, deltaxy, n, 1.0, &state->tmp0, 0);
      for (i = 0; i < nslack; i++) {
         deltaxy->xR[nmain + i] = -(deltaxy->xR[nmain + i] - state->factinvregdzrz.xR[i] * state->tmp0.xR[i]);
      }
   // Done
      return;
   }
// Sparse solving
   if (state->factorizationtype == 1) {
      vipmsolver_reducedsystemsolve(&state->reducedsparsesystem, deltaxy);
      for (i = 0; i < n; i++) {
         if (state->isfrozen.xB[i]) {
            deltaxy->xR[i] = 0.0;
         }
      }
      return;
   }
//
   ae_assert(false, "VIPMSolve: integrity check failed - unexpected factorization");
}

// This function "powers up" factorization, i.e. prepares some important
// temporaries. It should be called once prior to the first call to
// VIPMInitialPoint() or VIPMFactorize().
//
// Parameter:
//     RegFree     -   regularization for free variables;
//                     good value sqrt(MachineEpsilon)
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_vipmpowerup(vipmstate *state, double regfree) {
   const double initslackval = 100.0;
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   double v;
   double vrhs;
   double priorcoeff;
   double initprimslack;
   double initdualslack;
   double maxinitialnoncentrality;
   double maxinitialimbalance;
   double mu0;
   double mumin;
   bool success;
   ae_assert(state->factorizationtype == 0 || state->factorizationtype == 1, "VIPMPowerUp: unexpected factorization type");
   n = state->n;
   m = state->mdense + state->msparse;
   ae_assert(!state->factorizationpoweredup, "VIPMPowerUp: repeated call");
   maxinitialnoncentrality = 0.000001;
   maxinitialimbalance = 0.000001;
// Set up information about presence of slack variables.
// Decide which components of X should be frozen.
// Compute diagonal regularization matrix R.
   bcopyallocv(n, &state->hasbndl, &state->hasgz);
   bcopyallocv(n, &state->hasbndu, &state->hasts);
   bsetallocv(n, false, &state->isfrozen);
   rsetallocv(n, 0.0, &state->diagr);
   vipmsolver_varsinitbyzero(&state->current, n, m);
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
         state->isfrozen.xB[i] = true;
         state->hasgz.xB[i] = false;
         state->hasts.xB[i] = false;
         state->current.x.xR[i] = state->bndl.xR[i];
      }
      if (!state->hasbndl.xB[i] && !state->hasbndu.xB[i]) {
         state->diagr.xR[i] = regfree;
      }
   }
   allocv(m, &state->haspq);
   allocv(m, &state->haswv);
   for (i = 0; i < m; i++) {
      state->haswv.xB[i] = state->slacksforequalityconstraints || !state->hasr.xB[i] || state->r.xR[i] > 0.0;
      state->haspq.xB[i] = state->hasr.xB[i] && state->haswv.xB[i];
   }
   state->cntgz = 0;
   state->cntts = 0;
   state->cntwv = 0;
   state->cntpq = 0;
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         state->cntgz++;
      }
      if (state->hasts.xB[i]) {
         state->cntts++;
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
         state->cntwv++;
      }
      if (state->haspq.xB[i]) {
         state->cntpq++;
      }
   }
// Special initialization for sparse version
   if (state->factorizationtype == 1) {
      vipmsolver_reducedsysteminit(&state->reducedsparsesystem, state);
   }
   state->factorizationpoweredup = true;
// Set up initial values of primal and dual variables X and Y by solving
// modified KKT system which tries to enforce linear constraints (ignoring
// box constraints for a while) subject to minimization of additional prior
// term which moves solution towards some interior point.
//
// Here we expect that State.Current.X contains zeros in non-fixed variables
// and their fixed values for fixed ones.
   priorcoeff = 1.0;
   success = vipmsolver_vipmfactorize(state, 0.0, &state->diagddr, 0.0, &state->diagder, priorcoeff, priorcoeff, machineepsilon, machineepsilon);
   ae_assert(success, "VIPMInitialPoint: impossible failure of LDLT factorization");
   vipmsolver_multiplyhx(state, &state->current.x, &state->tmp0);
   vipmsolver_multiplygeax(state, 1.0, &state->current.x, 0, 0.0, &state->tmp1, 0);
   allocv(n + m, &state->deltaxy);
   for (i = 0; i < n; i++) {
      state->deltaxy.xR[i] = state->c.xR[i] + state->tmp0.xR[i];
   }
   for (i = 0; i < m; i++) {
   // We need to specify target right-hand sides for constraints.
   //
   // Ether zero, b or b+r is used (depending on presence of r and
   // magnitudes of b and b+r, and subject to current state of frozen
   // variables).
      vrhs = state->b.xR[i] - state->tmp1.xR[i];
      if (state->hasr.xB[i]) {
      // Range constraint b <= Ax <= b+r
         if (vrhs >= 0.0) {
         // 0 <= b <= b+r, select target at lower bound
            v = vrhs;
         } else {
         // b <= 0, b+r can have any sign.
         // Select zero target if possible, if not - one with smallest absolute value.
            v = rmin2(vrhs + state->r.xR[i], 0.0);
         }
      } else {
      // Single-sided constraint Ax >= b.
      // Select zero target if possible, if not - one with smallest absolute value.
         v = rmax2(vrhs, 0.0);
      }
      state->deltaxy.xR[n + i] = v;
   }
   vipmsolver_solvereducedkktsystem(state, &state->deltaxy);
   for (i = 0; i < n; i++) {
      if (!state->isfrozen.xB[i]) {
         state->current.x.xR[i] = state->deltaxy.xR[i];
      }
   }
   for (i = 0; i < m; i++) {
      state->current.y.xR[i] = state->deltaxy.xR[n + i];
   }
// Set up slacks according to our own heuristic
   initprimslack = rmax2(initslackval, rmaxabsv(n, &state->current.x));
   initdualslack = rmax2(initslackval, rmaxabsv(m, &state->current.y));
   vipmsolver_multiplygeax(state, 1.0, &state->current.x, 0, 0.0, &state->tmpax, 0);
   mu0 = 1.0;
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         state->current.g.xR[i] = rmax2(fabs(state->current.x.xR[i] - state->bndl.xR[i]), initprimslack);
         state->current.z.xR[i] = rmax2(state->current.g.xR[i] * maxinitialimbalance, initdualslack);
         mu0 = rmax2(mu0, state->current.g.xR[i] * state->current.z.xR[i]);
      }
      if (state->hasts.xB[i]) {
         state->current.t.xR[i] = rmax2(fabs(state->current.x.xR[i] - state->bndu.xR[i]), initprimslack);
         state->current.s.xR[i] = rmax2(state->current.t.xR[i] * maxinitialimbalance, initdualslack);
         mu0 = rmax2(mu0, state->current.t.xR[i] * state->current.s.xR[i]);
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
         state->current.w.xR[i] = rmax2(fabs(state->tmpax.xR[i] - state->b.xR[i]), initprimslack);
         state->current.v.xR[i] = rmax3(state->current.w.xR[i] * maxinitialimbalance, fabs(state->current.y.xR[i]), initslackval);
         mu0 = rmax2(mu0, state->current.w.xR[i] * state->current.v.xR[i]);
      }
      if (state->haspq.xB[i]) {
         state->current.p.xR[i] = rmax2(fabs(state->r.xR[i] - state->current.w.xR[i]), initprimslack);
         state->current.q.xR[i] = rmax3(state->current.p.xR[i] * maxinitialimbalance, fabs(state->current.y.xR[i]), initslackval);
         mu0 = rmax2(mu0, state->current.p.xR[i] * state->current.q.xR[i]);
      }
   }
// Additional shift to ensure that initial point is not too non-centered
   mumin = mu0 * maxinitialnoncentrality;
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i] && state->current.g.xR[i] * state->current.z.xR[i] < mumin) {
         v = sqrt(mumin / (state->current.g.xR[i] * state->current.z.xR[i]));
         state->current.g.xR[i] *= v;
         state->current.z.xR[i] *= v;
      }
      if (state->hasts.xB[i] && state->current.t.xR[i] * state->current.s.xR[i] < mumin) {
         v = sqrt(mumin / (state->current.t.xR[i] * state->current.s.xR[i]));
         state->current.t.xR[i] *= v;
         state->current.s.xR[i] *= v;
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i] && state->current.w.xR[i] * state->current.v.xR[i] < mumin) {
         v = sqrt(mumin / (state->current.w.xR[i] * state->current.v.xR[i]));
         state->current.w.xR[i] *= v;
         state->current.v.xR[i] *= v;
      }
      if (state->haspq.xB[i] && state->current.p.xR[i] * state->current.q.xR[i] < mumin) {
         v = sqrt(mumin / (state->current.p.xR[i] * state->current.q.xR[i]));
         state->current.p.xR[i] *= v;
         state->current.q.xR[i] *= v;
      }
   }
// Almost done.
}

// Generates precomputed temporary  vectors  and  KKT  factorization  at  the
// beginning of the current iteration.
//
// This function uses representation of  KKT  system  inspired  by  Vanderbei
// slack variable approach, but with additional regularization being  applied
// all along computations.
//
// On successful factorization returns True; on failure returns False - it is
// recommended to increase regularization parameter and try one more time.
//
// --- DESCRIPTION ----------------------------------------------------------
//
// Initial KKT system proposed by Vanderbei has following structure:
//
//     (1) -DS*deltaT - I*deltaS                       = -mu/T + s + DELTAT*DELTAS/T = -GammaS
//     (2) -DZ*deltaG - I*deltaZ                       = -mu/G + z + DELTAG*DELTAZ/G = -GammaZ
//     (3) -DQ*deltaP - I*deltaQ                       = -mu/P + q + DELTAP*DELTAQ/P = -GammaQ
//     (4) -DW*deltaV - I*deltaW                       = -mu/V + w + DELTAV*DELTAW/V = -GammaW
//     (5)  -I*deltaY - I*deltaQ + I*deltaV            = y-q+v                       =  Beta
//     (6)  -H*deltaX +A'*deltaY + I*deltaZ - I*deltaS = c-A'*y-z+s+H*x              =  Sigma
//     (7)   A*deltaX - I*deltaW                       = b-A*x+w                     =  Rho
//     (8)   I*deltaX - I*deltaG                       = l-x+g                       =  Nu
//     (9)  -I*deltaX - I*deltaT                       = -u+x+t                      = -Tau
//     (10) -I*deltaW - I*deltaP                       = -r+w+p                      = -Alpha
//
// where
//
//     DS = diag(S/T)
//     DZ = diag(Z/G)
//     DQ = diag(Q/P)
//     DW = diag(W/V)
//
// This linear system is actually  symmetric  indefinite  one,  that  can  be
// regularized by modifying equations (5), (6),  (7), (8), (9), (10):
//
//     (5)       -I*deltaY - I*deltaQ + I*deltaV -REG*deltaW == y+q-v+REG*w          ==  Beta
//     (6) -(H+REG)*deltaX +A'*deltaY + I*deltaZ - I*deltaS  == c-A'*y-z+s+(H+REG)*x ==  Sigma
//     (7)        A*deltaX - I*deltaW            +REG*deltaY == b-A*x+w-REG*y        ==  Rho
//     (8)        I*deltaX - I*deltaG            +REG*deltaZ == l-x+g-REG*z          ==  Nu
//     (9)       -I*deltaX - I*deltaT            +REG*deltaS == -u+x+t-REG*s         == -Tau
//     (10)      -I*deltaW - I*deltaP            +REG*deltaQ == -r+w+p-REG*q         == -Alpha
//
// NOTE: regularizing equations (5)-(10) seems to be beneficial because their
//       coefficients are well-normalized, usually having unit scale. Contrary
//       to that, equations (1)-(4) are wildly nonnormalized, and regularization
//       ruins algorithm convergence.
//
// From (1), (2), (3) and (4) we obtain
//
//     deltaT = (GammaS-I*deltaS)/DS
//     deltaG = (GammaZ-I*deltaZ)/DZ
//     deltaP = (GammaQ-I*deltaQ)/DQ
//     deltaV = (GammaW-I*deltaW)/DW
//
// and substitute them to equations to obtain
//
//     (5)   -I*deltaY - I*deltaQ      - (inv(DW)+REG)*deltaW =    Beta-inv(DW)*GammaW  =  BetaCap
//     (8)    I*deltaX                 + (inv(DZ)+REG)*deltaZ =      Nu+inv(DZ)*GammaZ  =  NuCap
//     (9)   -I*deltaX                 + (inv(DS)+REG)*deltaS =   -(Tau-inv(DS)*GammaS) = -TauCap
//     (10)  -I*deltaW                 + (inv(DQ)+REG)*deltaQ = -(Alpha-inv(DQ)*GammaQ) = -AlphaCap
//     (6)   A'*deltaY + I*deltaZ - I*deltaS - (H+REG)*deltaX = c-A'*y-z+s+(H+REG)*x    =  Sigma
//     (7)  REG*deltaY + A*deltaX - I*deltaW                  = b-A*x+w-REG*y           =  Rho
//
// then, we obtain (here IRI stands for Invert-Regularize-Invert)
//
//     DQIRI  = inv(inv(DQ)+REG)
//     DZIRI  = inv(inv(DZ)+REG)
//     DSIRI  = inv(inv(DS)+REG)
//
//     deltaQ = (I*deltaW-AlphaCap)*DQIRI
//     deltaZ =    (NuCap-I*deltaX)*DZIRI
//     deltaS =   (I*deltaX-TauCap)*DSIRI
//
//     DWIR   = inv(DW)+REG
//
// and after substitution
//
//     (5)   -I*deltaY        - (DQIRI+DWIR)*deltaW = BetaCap-DQIRI*AlphaCap
//     (6)   A'*deltaY - (H+REG+DSIRI+DZIRI)*deltaX = Sigma-DSIRI*TauCap-DZIRI*NuCap
//     (7)  REG*deltaY + A*deltaX - I*deltaW        = Rho
//
// finally, we obtain
//
//     DE     = inv(DQIRI+DWIR)
//     DER    = DE+REG
//     DDR    = DSIRI+DZIRI+REG
//     deltaW = -(BetaCap-DQIRI*AlphaCap+I*deltaY)*DE
//
// and after substitution
//
//     (6)  -(H+DDR)*deltaX +  A'*deltaY = Sigma-DSIRI*TauCap-DZIRI*NuCap
//     (7)         A*deltaX + DER*deltaY = Rho-DE*(BetaCap-DQIRI*AlphaCap)
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static bool vipmsolver_vipmprecomputenewtonfactorization(vipmstate *state, vipmvars *v0, double regeps, double modeps, double dampeps, double dampfree) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   bool result;
   n = state->n;
   m = state->mdense + state->msparse;
   rsetallocv(n, 0.0, &state->diagdz);
   rsetallocv(n, 0.0, &state->diagdzi);
   rsetallocv(n, 0.0, &state->diagdziri);
   rsetallocv(n, 0.0, &state->diagds);
   rsetallocv(n, 0.0, &state->diagdsi);
   rsetallocv(n, 0.0, &state->diagdsiri);
   rsetallocv(m, 0.0, &state->diagdw);
   rsetallocv(m, 0.0, &state->diagdwi);
   rsetallocv(m, 0.0, &state->diagdwir);
   rsetallocv(m, 0.0, &state->diagdq);
   rsetallocv(m, 0.0, &state->diagdqi);
   rsetallocv(m, 0.0, &state->diagdqiri);
   allocv(n, &state->diagddr);
   allocv(m, &state->diagde);
   allocv(m, &state->diagder);
// Handle temporary matrices arising due to box constraints
   for (i = 0; i < n; i++) {
   // Lower bound: G*inv(Z) and Z*inv(G)
      if (state->hasgz.xB[i]) {
         ae_assert(v0->g.xR[i] > 0.0 && v0->z.xR[i] > 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - G[i] <= 0 or Z[i] <= 0");
         state->diagdz.xR[i] = v0->z.xR[i] / v0->g.xR[i];
         state->diagdzi.xR[i] = 1.0 / state->diagdz.xR[i];
         state->diagdziri.xR[i] = 1.0 / (state->diagdzi.xR[i] + regeps);
      } else {
         ae_assert(v0->g.xR[i] == 0.0 && v0->z.xR[i] == 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - G[i] != 0 or Z[i] != 0 for absent lower bound");
      }
   // Upper bound: T*inv(S) and S*inv(T)
      if (state->hasts.xB[i]) {
         ae_assert(v0->t.xR[i] > 0.0 && v0->s.xR[i] > 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - T[i] <= 0 or S[i] <= 0");
         state->diagds.xR[i] = v0->s.xR[i] / v0->t.xR[i];
         state->diagdsi.xR[i] = 1.0 / state->diagds.xR[i];
         state->diagdsiri.xR[i] = 1.0 / (state->diagdsi.xR[i] + regeps);
      } else {
         ae_assert(v0->t.xR[i] == 0.0 && v0->s.xR[i] == 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - T[i] != 0 or S[i] != 0 for absent upper bound");
      }
   // Diagonal term D
      state->diagddr.xR[i] = state->diagdziri.xR[i] + state->diagdsiri.xR[i] + regeps;
      if (!state->hasgz.xB[i] && !state->hasts.xB[i]) {
         state->diagddr.xR[i] += dampfree;
      }
   }
// Handle temporary matrices arising due to linear constraints: with lower bound B[]
// or with lower and upper bounds.
   for (i = 0; i < m; i++) {
   // Lower bound
      if (state->haswv.xB[i]) {
         ae_assert(v0->v.xR[i] > 0.0 && v0->w.xR[i] > 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - V[i] <= 0 or W[i] <= 0");
         state->diagdw.xR[i] = v0->w.xR[i] / v0->v.xR[i];
         state->diagdwi.xR[i] = 1.0 / state->diagdw.xR[i];
         state->diagdwir.xR[i] = state->diagdwi.xR[i] + regeps;
      } else {
         ae_assert(v0->v.xR[i] == 0.0 && v0->w.xR[i] == 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - V[i] != 0 or W[i] != 0 for linear equality constraint");
      }
   // Upper bound
      if (state->haspq.xB[i]) {
         ae_assert(v0->p.xR[i] > 0.0 && v0->q.xR[i] > 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - P[i] <= 0 or Q[i] <= 0");
         state->diagdq.xR[i] = v0->q.xR[i] / v0->p.xR[i];
         state->diagdqi.xR[i] = 1.0 / state->diagdq.xR[i];
         state->diagdqiri.xR[i] = 1.0 / (state->diagdqi.xR[i] + regeps);
      } else {
         ae_assert(v0->p.xR[i] == 0.0 && v0->q.xR[i] == 0.0, "VIPMPrecomputeNewtonFactorization: integrity failure - P[i] != 0 or Q[i] != 0 for absent linear constraint");
      }
   // Diagonal term E
      if (state->haswv.xB[i] || state->haspq.xB[i]) {
         state->diagde.xR[i] = 1.0 / (state->diagdwir.xR[i] + state->diagdqiri.xR[i]);
      } else {
         state->diagde.xR[i] = 0.0;
      }
      state->diagder.xR[i] = state->diagde.xR[i] + regeps;
   }
// Perform factorization
   result = vipmsolver_vipmfactorize(state, 1.0, &state->diagddr, 1.0, &state->diagder, 0.0, 0.0, modeps, dampeps);
   return result;
}

// Solves KKT system stored in VIPMState with user-passed RHS.
// Sol must be preallocated VIPMVars object whose initial values are ignored.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_solvekktsystem(vipmstate *state, vipmrighthandside *rhs, vipmvars *sol) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   n = state->n;
   m = state->mdense + state->msparse;
// Compute elimination temporaries
//
// RhsAlphaCap  = RhsAlpha - InvDQ*GammaQ
// RhsNuCap     = RhsNu    + InvDZ*GammaZ
// RhsTauCap    = RhsTau   - InvDS*GammaS
// RhsBetaCap   = RhsBeta  - InvDW*GammaW
   allocv(n, &state->rhsnucap);
   allocv(n, &state->rhstaucap);
   allocv(m, &state->rhsbetacap);
   allocv(m, &state->rhsalphacap);
   rcopynegmuladdv(m, &state->diagdqi, &rhs->gammaq, &rhs->alpha, &state->rhsalphacap);
   rcopymuladdv(n, &state->diagdzi, &rhs->gammaz, &rhs->nu, &state->rhsnucap);
   rcopynegmuladdv(n, &state->diagdsi, &rhs->gammas, &rhs->tau, &state->rhstaucap);
   rcopynegmuladdv(m, &state->diagdwi, &rhs->gammaw, &rhs->beta, &state->rhsbetacap);
// Solve reduced KKT system
   vectorsetlengthatleast(&state->deltaxy, n + m);
   for (i = 0; i < n; i++) {
      state->deltaxy.xR[i] = rhs->sigma.xR[i] - state->diagdziri.xR[i] * state->rhsnucap.xR[i] - state->diagdsiri.xR[i] * state->rhstaucap.xR[i];
   }
   for (i = 0; i < m; i++) {
      state->deltaxy.xR[n + i] = rhs->rho.xR[i] - state->diagde.xR[i] * (state->rhsbetacap.xR[i] - state->diagdqiri.xR[i] * state->rhsalphacap.xR[i]);
   }
   vipmsolver_solvereducedkktsystem(state, &state->deltaxy);
// Perform backsubstitution
   for (i = 0; i < n; i++) {
      sol->x.xR[i] = state->deltaxy.xR[i];
      sol->s.xR[i] = state->diagdsiri.xR[i] * (sol->x.xR[i] - state->rhstaucap.xR[i]);
      sol->z.xR[i] = state->diagdziri.xR[i] * (state->rhsnucap.xR[i] - sol->x.xR[i]);
      sol->g.xR[i] = state->diagdzi.xR[i] * (rhs->gammaz.xR[i] - sol->z.xR[i]);
      sol->t.xR[i] = state->diagdsi.xR[i] * (rhs->gammas.xR[i] - sol->s.xR[i]);
   }
   for (i = 0; i < m; i++) {
      sol->y.xR[i] = state->deltaxy.xR[n + i];
      sol->w.xR[i] = -state->diagde.xR[i] * (state->rhsbetacap.xR[i] - state->diagdqiri.xR[i] * state->rhsalphacap.xR[i] + sol->y.xR[i]);
      sol->q.xR[i] = state->diagdqiri.xR[i] * (sol->w.xR[i] - state->rhsalphacap.xR[i]);
      sol->v.xR[i] = state->diagdwi.xR[i] * (rhs->gammaw.xR[i] - sol->w.xR[i]);
      sol->p.xR[i] = state->diagdqi.xR[i] * (rhs->gammaq.xR[i] - sol->q.xR[i]);
   }
}

// Compute right-hand side for KKT system.
//
// Inputs:
//     State           -   IPM state
//     V0              -   current point (used to compute RHS)
//     MuEstimate      -   estimate of Mu (can be zero)
//     DirEstimate     -   estimate of delta's (can be zero)
//
// Outputs:
//     Rhs             -   RHS
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_rhscompute(vipmstate *state, vipmvars *v0, double muestimate, vipmvars *direstimate, vipmrighthandside *rhs, double reg) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   n = state->n;
   m = state->mdense + state->msparse;
// Allocate
   vectorsetlengthatleast(&rhs->sigma, n);
   vectorsetlengthatleast(&rhs->nu, n);
   vectorsetlengthatleast(&rhs->tau, n);
   vectorsetlengthatleast(&rhs->gammaz, n);
   vectorsetlengthatleast(&rhs->gammas, n);
   vectorsetlengthatleast(&rhs->gammaw, m);
   vectorsetlengthatleast(&rhs->gammaq, m);
   rsetallocv(m, 0.0, &rhs->beta);
   rsetallocv(m, 0.0, &rhs->rho);
   rsetallocv(m, 0.0, &rhs->alpha);
// Compute products H*x, A*x, A^T*y
// We compute these products in one location for the sake of simplicity.
   vipmsolver_vipmmultiply(state, &v0->x, &v0->y, &state->tmphx, &state->tmpax, &state->tmpaty);
// Compute right-hand side:
// Rho      = b - A*x + w
// Nu       = l - x + g
// Tau      = u - x - t
// Alpha    = r - w - p
// Sigma    = c - A^T*y - z + s + (H+REG)*x
// Beta     = y + q - v
   for (i = 0; i < m; i++) {
      rhs->rho.xR[i] = state->b.xR[i] - state->tmpax.xR[i] - reg * v0->y.xR[i];
      if (state->haswv.xB[i]) {
      // Inequality/range constraint
         rhs->rho.xR[i] += v0->w.xR[i];
      } else {
      // Equality constraint without slack variables, W[i] == 0
         ae_assert(v0->w.xR[i] == 0.0, "RhsCompute: W[i] != 0 for linear equality constraint");
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
      // Lower bound is present
         rhs->nu.xR[i] = state->bndl.xR[i] - v0->x.xR[i] + v0->g.xR[i] - reg * v0->z.xR[i];
      } else {
      // Lower bound is absent, g[i] = 0
         ae_assert(v0->g.xR[i] == 0.0, "RhsCompute: G[i] != 0 for absent constraint");
         rhs->nu.xR[i] = 0.0;
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasts.xB[i]) {
      // Upper bound is present
         rhs->tau.xR[i] = state->bndu.xR[i] - v0->x.xR[i] - v0->t.xR[i] + reg * v0->s.xR[i];
      } else {
      // Upper bound is absent, t[i] = 0
         ae_assert(v0->t.xR[i] == 0.0, "RhsCompute: T[i] != 0 for absent constraint");
         rhs->tau.xR[i] = 0.0;
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haspq.xB[i]) {
         rhs->alpha.xR[i] = state->r.xR[i] - v0->w.xR[i] - v0->p.xR[i] + reg * v0->q.xR[i];
      }
   }
   for (i = 0; i < n; i++) {
      if (!state->isfrozen.xB[i]) {
         rhs->sigma.xR[i] = state->c.xR[i] - state->tmpaty.xR[i] + state->tmphx.xR[i] + reg * v0->x.xR[i];
         if (state->hasgz.xB[i]) {
            rhs->sigma.xR[i] -= v0->z.xR[i];
         }
         if (state->hasts.xB[i]) {
            rhs->sigma.xR[i] += v0->s.xR[i];
         }
      } else {
         rhs->sigma.xR[i] = 0.0;
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
         rhs->beta.xR[i] += v0->y.xR[i] - v0->v.xR[i] + reg * v0->w.xR[i];
      }
      if (state->haspq.xB[i]) {
         rhs->beta.xR[i] += v0->q.xR[i];
      }
   }
// Compute right-hand side:
// GammaZ   = mu*inv(G)*e - z - inv(G)*DELTAG*deltaZ
// GammaW   = mu*inv(V)*e - w - inv(V)*DELTAV*deltaW
// GammaS   = mu*inv(T)*e - s - inv(T)*DELTAT*deltaS
// GammaQ   = mu*inv(P)*e - q - inv(P)*DELTAP*deltaQ
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         ae_assert(v0->g.xR[i] > 0.0, "RhsCompute: G[i] <= 0");
         rhs->gammaz.xR[i] = muestimate / v0->g.xR[i] - v0->z.xR[i] - direstimate->g.xR[i] * direstimate->z.xR[i] / v0->g.xR[i];
      } else {
         ae_assert(v0->g.xR[i] == 0.0, "RhsCompute: G[i] != 0 for absent constraint");
         ae_assert(v0->z.xR[i] == 0.0, "RhsCompute: Z[i] != 0 for absent constraint");
         rhs->gammaz.xR[i] = 0.0;
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
      // Inequality/range constraint
         ae_assert(v0->v.xR[i] > 0.0, "RhsCompute: V[i] <= 0");
         rhs->gammaw.xR[i] = muestimate / v0->v.xR[i] - v0->w.xR[i] - direstimate->v.xR[i] * direstimate->w.xR[i] / v0->v.xR[i];
      } else {
      // Equality constraint
         ae_assert(v0->v.xR[i] == 0.0, "RhsCompute: V[i] != 0 for equality constraint");
         ae_assert(v0->w.xR[i] == 0.0, "RhsCompute: W[i] != 0 for equality constraint");
         rhs->gammaw.xR[i] = 0.0;
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasts.xB[i]) {
      // Upper bound is present
         ae_assert(v0->t.xR[i] > 0.0, "RhsCompute: T[i] <= 0");
         rhs->gammas.xR[i] = muestimate / v0->t.xR[i] - v0->s.xR[i] - direstimate->t.xR[i] * direstimate->s.xR[i] / v0->t.xR[i];
      } else {
      // Upper bound is absent
         ae_assert(v0->t.xR[i] == 0.0, "RhsCompute: T[i] != 0 for absent constraint");
         ae_assert(v0->s.xR[i] == 0.0, "RhsCompute: S[i] != 0 for absent constraint");
         rhs->gammas.xR[i] = 0.0;
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haspq.xB[i]) {
         ae_assert(v0->p.xR[i] > 0.0, "RhsCompute: P[i] <= 0");
         rhs->gammaq.xR[i] = muestimate / v0->p.xR[i] - v0->q.xR[i] - direstimate->p.xR[i] * direstimate->q.xR[i] / v0->p.xR[i];
      } else {
         ae_assert(v0->p.xR[i] == 0.0, "RhsCompute: P[i] != 0 for absent range");
         ae_assert(v0->q.xR[i] == 0.0, "RhsCompute: Q[i] != 0 for absent range");
         rhs->gammaq.xR[i] = 0.0;
      }
   }
}

// Subtracts KKT*cand from already computed RHS.
//
// A pair of RhsCompute/RhsSubtract calls results in  residual  being  loaded
// into the RHS structure.
//
// Inputs:
//     State           -   IPM state
//     V0              -   current point (used to compute RHS)
//     MuEstimate      -   estimate of Mu (can be zero)
//     DirEstimate     -   estimate of delta's (can be zero)
//     ResidualFrom    -   whether we want to compute RHS or residual computed
//                         using VDCandidate
//     VDCandidate     -   solution candidate
//
// Outputs:
//     Rhs             -   either RHS or residual RHS-KKT*Cand
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_rhssubtract(vipmstate *state, vipmrighthandside *rhs, vipmvars *v0, vipmvars *vdcandidate, double reg) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   n = state->n;
   m = state->mdense + state->msparse;
   vipmsolver_vipmmultiply(state, &vdcandidate->x, &vdcandidate->y, &state->tmphx, &state->tmpax, &state->tmpaty);
// Residual for Rho, Nu, Tau, Alpha, Sigma, Beta
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
         rhs->rho.xR[i] -= state->tmpax.xR[i] - vdcandidate->w.xR[i] + reg * vdcandidate->y.xR[i];
      } else {
         rhs->rho.xR[i] -= state->tmpax.xR[i] + reg * vdcandidate->y.xR[i];
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         rhs->nu.xR[i] -= vdcandidate->x.xR[i] - vdcandidate->g.xR[i] + reg * vdcandidate->z.xR[i];
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasts.xB[i]) {
         rhs->tau.xR[i] -= vdcandidate->x.xR[i] + vdcandidate->t.xR[i] - reg * vdcandidate->s.xR[i];
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haspq.xB[i]) {
         rhs->alpha.xR[i] -= vdcandidate->w.xR[i] + vdcandidate->p.xR[i] - reg * vdcandidate->q.xR[i];
      }
   }
   for (i = 0; i < n; i++) {
      if (!state->isfrozen.xB[i]) {
         rhs->sigma.xR[i] -= state->tmpaty.xR[i] - state->tmphx.xR[i] - reg * vdcandidate->x.xR[i];
         if (state->hasgz.xB[i]) {
            rhs->sigma.xR[i] -= vdcandidate->z.xR[i];
         }
         if (state->hasts.xB[i]) {
            rhs->sigma.xR[i] += vdcandidate->s.xR[i];
         }
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
         rhs->beta.xR[i] -= -vdcandidate->y.xR[i] + vdcandidate->v.xR[i] - reg * vdcandidate->w.xR[i];
      }
      if (state->haspq.xB[i]) {
         rhs->beta.xR[i] += vdcandidate->q.xR[i];
      }
   }
// Residual for GammaZ, GammaW, GammaS, GammaQ
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         rhs->gammaz.xR[i] -= v0->z.xR[i] / v0->g.xR[i] * vdcandidate->g.xR[i] + vdcandidate->z.xR[i];
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haswv.xB[i]) {
         rhs->gammaw.xR[i] -= v0->w.xR[i] / v0->v.xR[i] * vdcandidate->v.xR[i] + vdcandidate->w.xR[i];
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasts.xB[i]) {
         rhs->gammas.xR[i] -= v0->s.xR[i] / v0->t.xR[i] * vdcandidate->t.xR[i] + vdcandidate->s.xR[i];
      }
   }
   for (i = 0; i < m; i++) {
      if (state->haspq.xB[i]) {
         rhs->gammaq.xR[i] -= v0->q.xR[i] / v0->p.xR[i] * vdcandidate->p.xR[i] + vdcandidate->q.xR[i];
      }
   }
}

// Computes sum of squared primal terms of RHS
//
// Inputs:
//     Rhs             -   RHS structure
//     N, M            -   problem metrics
//
// Result:
//     sum(sqr()) computed over primal terms (Rho, Nu, Tau, Alpha)
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_rhsprimal2(vipmrighthandside *rhs, ae_int_t n, ae_int_t m) {
   double result;
   result = 0.0;
   result += rdotv2(m, &rhs->rho);
   result += rdotv2(n, &rhs->nu);
   result += rdotv2(n, &rhs->tau);
   result += rdotv2(m, &rhs->alpha);
   return result;
}

// Computes sum of squared dual terms of RHS
//
// Inputs:
//     Rhs             -   RHS structure
//     N, M            -   problem metrics
//
// Result:
//     sum(sqr()) computed over dual terms (Sigma, Beta)
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_rhsdual2(vipmrighthandside *rhs, ae_int_t n, ae_int_t m) {
   double result;
   result = 0.0;
   result += rdotv2(n, &rhs->sigma);
   result += rdotv2(m, &rhs->beta);
   return result;
}

// Computes inf-norm of primal terms of RHS
//
// Inputs:
//     Rhs             -   RHS structure
//     N, M            -   problem metrics
//
// Result:
//     max(abs()) computed over primal terms (Rho, Nu, Tau, Alpha)
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_rhsprimalinf(vipmrighthandside *rhs, ae_int_t n, ae_int_t m) {
   double result;
   result = 0.0;
   result = rmax2(result, rmaxabsv(m, &rhs->rho));
   result = rmax2(result, rmaxabsv(n, &rhs->nu));
   result = rmax2(result, rmaxabsv(n, &rhs->tau));
   result = rmax2(result, rmaxabsv(m, &rhs->alpha));
   return result;
}

// Computes inf-norm of dual terms of RHS
//
// Inputs:
//     Rhs             -   RHS structure
//     N, M            -   problem metrics
//
// Result:
//     max(abs()) computed over dual terms (Sigma, Beta)
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_rhsdualinf(vipmrighthandside *rhs, ae_int_t n, ae_int_t m) {
   double result;
   result = 0.0;
   result = rmax2(result, rmaxabsv(n, &rhs->sigma));
   result = rmax2(result, rmaxabsv(m, &rhs->beta));
   return result;
}

// Computes maximum over complementarity slackness terms of RHS
//
// Inputs:
//     Rhs             -   RHS structure
//     N, M            -   problem metrics
//
// Result:
//     max(abs()) computed over complementarity terms (GammaZ, GammaS, GammaW, GammaQ)
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_rhscompl2(vipmrighthandside *rhs, ae_int_t n, ae_int_t m) {
   double result;
   result = 0.0;
   result += rdotv2(n, &rhs->gammaz);
   result += rdotv2(n, &rhs->gammas);
   result += rdotv2(m, &rhs->gammaw);
   result += rdotv2(m, &rhs->gammaq);
   return result;
}

// Compute VIPM step by solving KKT system.
//
// VDResult must be preallocated VIPMVars object  whose  initial  values  are
// ignored.
//
// Returns False on failure to compute step direction with reasonable accuracy
// (it is advised to terminate iterations immediately).
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static bool vipmsolver_vipmcomputestepdirection(vipmstate *state, vipmvars *v0, double muestimate, vipmvars *vdestimate, vipmvars *vdresult, double reg, bool isdampepslarge) {
   ae_int_t n;
   ae_int_t m;
   double vrhsprim2;
   double vrhsdual2;
   double vrhscmpl2;
   double vresprim2;
   double vresdual2;
   double vrescmpl2;
   double vrhspriminf;
   double vrhsdualinf;
   double vrespriminf;
   double vresdualinf;
   double badres;
   double verybadres;
   double residualgrowth;
   bool primaldestabilized;
   bool dualdestabilized;
   bool result;
   n = state->n;
   m = state->mdense + state->msparse;
   badres = 1.01;
   verybadres = 1000.0;
   result = true;
// Solve KKT system with right-hand sides coming from primal, dual
// and complementary slackness conditions. Analyze solution,
// terminate immediately if primal/dual residuals are way too high.
   vipmsolver_rhscompute(state, v0, muestimate, vdestimate, &state->rhs, reg);
   vrhsprim2 = vipmsolver_rhsprimal2(&state->rhs, n, m);
   vrhsdual2 = vipmsolver_rhsdual2(&state->rhs, n, m);
   vrhscmpl2 = vipmsolver_rhscompl2(&state->rhs, n, m);
   vrhspriminf = vipmsolver_rhsprimalinf(&state->rhs, n, m);
   vrhsdualinf = vipmsolver_rhsdualinf(&state->rhs, n, m);
   vipmsolver_solvekktsystem(state, &state->rhs, vdresult);
   vipmsolver_rhssubtract(state, &state->rhs, v0, vdresult, reg);
   vresprim2 = vipmsolver_rhsprimal2(&state->rhs, n, m);
   vresdual2 = vipmsolver_rhsdual2(&state->rhs, n, m);
   vrescmpl2 = vipmsolver_rhscompl2(&state->rhs, n, m);
   vrespriminf = vipmsolver_rhsprimalinf(&state->rhs, n, m);
   vresdualinf = vipmsolver_rhsdualinf(&state->rhs, n, m);
   primaldestabilized = vrhspriminf <= state->epsp && vrespriminf >= rmax2(verybadres * vrhspriminf, state->epsp);
   dualdestabilized = vrhsdualinf <= state->epsd && vresdualinf >= rmax2(verybadres * vrhsdualinf, state->epsd);
   residualgrowth = sqrt((vresprim2 + vresdual2 + vrescmpl2) / coalesce(vrhsprim2 + vrhsdual2 + vrhscmpl2, 1.0));
   if ((primaldestabilized || dualdestabilized) && residualgrowth > 0.01 * sqrt(machineepsilon) && !isdampepslarge) {
      result = false;
      return result;
   }
   if (residualgrowth > badres) {
      result = false;
      return result;
   }
   return result;
}

// This function estimates primal and dual step lengths (subject to step
// decay parameter, which should be in [0,1] range).
//
// Current version returns same step lengths for primal and dual steps.
//
// Inputs:
//     State               -   solver state
//     V0                  -   current point (we ignore one stored in State.Current)
//     VS                  -   step direction
//     StepDecay           -   decay parameter, the step is multiplied by this
//                             coefficient. 1.0 corresponds to full step
//                             length being returned. Values in (0,1] range.
//     SeparateStep        -   separate step for primal and dual vars
//
// Outputs:
//     AlphaP              -   primal step (after applying decay coefficient)
//     AlphaD              -   dual   step (after applying decay coefficient)
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_vipmcomputesteplength(vipmstate *state, vipmvars *v0, vipmvars *vs, double stepdecay, bool separatestep, double *alphap, double *alphad) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   double alpha;
   *alphap = 0.0;
   *alphad = 0.0;
   n = state->n;
   m = state->mdense + state->msparse;
   ae_assert(n == v0->n && m == v0->m, "VIPMComputeStepLength: sizes mismatch");
   *alphap = 1.0;
   *alphad = 1.0;
   for (i = 0; i < n; i++) {
   // Primal
      if (vs->g.xR[i] < 0.0) {
         *alphap = safeminposrv(v0->g.xR[i], -vs->g.xR[i], *alphap);
      }
      if (vs->t.xR[i] < 0.0) {
         *alphap = safeminposrv(v0->t.xR[i], -vs->t.xR[i], *alphap);
      }
   // Dual
      if (vs->z.xR[i] < 0.0) {
         *alphad = safeminposrv(v0->z.xR[i], -vs->z.xR[i], *alphad);
      }
      if (vs->s.xR[i] < 0.0) {
         *alphad = safeminposrv(v0->s.xR[i], -vs->s.xR[i], *alphad);
      }
   }
   for (i = 0; i < m; i++) {
   // Primal
      if (vs->w.xR[i] < 0.0) {
         *alphap = safeminposrv(v0->w.xR[i], -vs->w.xR[i], *alphap);
      }
      if (vs->p.xR[i] < 0.0) {
         *alphap = safeminposrv(v0->p.xR[i], -vs->p.xR[i], *alphap);
      }
   // Dual
      if (vs->v.xR[i] < 0.0) {
         *alphad = safeminposrv(v0->v.xR[i], -vs->v.xR[i], *alphad);
      }
      if (vs->q.xR[i] < 0.0) {
         *alphad = safeminposrv(v0->q.xR[i], -vs->q.xR[i], *alphad);
      }
   }
// Separate step or joint step?
   if (separatestep) {
   // Separate step on primal/dual
      *alphap *= stepdecay;
      *alphad *= stepdecay;
   } else {
   // Because we may solve QP problem, step length has to be same for primal and dual variables
      alpha = rmin2(*alphap, *alphad);
      *alphap = stepdecay * alpha;
      *alphad = stepdecay * alpha;
   }
}

// This function performs IPM step, updates  iteration  counts  and  performs
// following additional checks:
// * it monitors status of box/linear constraints  and  smoothly  drops  ones
//   with too large bounds (a variable or linear sum is well below constraint
//   bound for several iterations)
//
// Inputs:
//     State               -   solver state
//     AlphaP              -   primal step to perform
//     AlphaD              -   dual   step to perform
// ALGLIB: Copyright 01.08.2020 by Sergey Bochkanov
static void vipmsolver_vipmperformstep(vipmstate *state, double alphap, double alphad) {
// Perform step
   vipmsolver_varsaddstep(&state->current, &state->deltacorr, alphap, alphad);
// Update iterations count
   state->repiterationscount++;
}

// Compute primal/dual errors and complementarity gap
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
static void vipmsolver_computeerrors(vipmstate *state, double *errp2, double *errd2, double *errpinf, double *errdinf, double *egap) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   ae_int_t cntp2;
   ae_int_t cntd2;
   double v;
   *errp2 = 0.0;
   *errd2 = 0.0;
   *errpinf = 0.0;
   *errdinf = 0.0;
   *egap = 0.0;
   n = state->n;
   m = state->mdense + state->msparse;
// Compute primal and dual infeasibilities
   vipmsolver_vipmmultiply(state, &state->current.x, &state->current.y, &state->tmphx, &state->tmpax, &state->tmpaty);
   cntp2 = 0;
   *errp2 = 0.0;
   *errpinf = 0.0;
   for (i = 0; i < m; i++) {
      v = state->tmpax.xR[i] - state->current.w.xR[i] - state->b.xR[i];
      *errp2 += v * v;
      *errpinf = rmax2(*errpinf, fabs(v));
      cntp2++;
      if (state->haspq.xB[i]) {
         v = state->current.w.xR[i] + state->current.p.xR[i] - state->r.xR[i];
         *errp2 += v * v;
         *errpinf = rmax2(*errpinf, fabs(v));
         cntp2++;
      }
   }
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         v = state->current.x.xR[i] - state->current.g.xR[i] - state->bndl.xR[i];
         *errp2 += v * v;
         *errpinf = rmax2(*errpinf, fabs(v));
         cntp2++;
      }
      if (state->hasts.xB[i]) {
         v = state->current.x.xR[i] + state->current.t.xR[i] - state->bndu.xR[i];
         *errp2 += v * v;
         *errpinf = rmax2(*errpinf, fabs(v));
         cntp2++;
      }
   }
   *errp2 = sqrt(*errp2 / coalesce(cntp2, 1.0));
   cntd2 = 0;
   *errd2 = 0.0;
   *errdinf = 0.0;
   for (i = 0; i < n; i++) {
      if (!state->isfrozen.xB[i]) {
         v = state->tmphx.xR[i] + state->c.xR[i] - state->tmpaty.xR[i];
         if (state->hasgz.xB[i]) {
            v -= state->current.z.xR[i];
         }
         if (state->hasts.xB[i]) {
            v += state->current.s.xR[i];
         }
         *errd2 += v * v;
         *errdinf = rmax2(*errdinf, fabs(v));
         cntd2++;
      }
   }
   for (i = 0; i < m; i++) {
      v = 0.0;
      if (state->haswv.xB[i]) {
         v = state->current.y.xR[i] - state->current.v.xR[i];
      }
      if (state->haspq.xB[i]) {
         v += state->current.q.xR[i];
      }
      *errd2 += v * v;
      *errdinf = rmax2(*errdinf, fabs(v));
      if (state->haswv.xB[i] || state->haspq.xB[i]) {
         cntd2++;
      }
   }
   *errd2 = sqrt(*errd2 / coalesce(cntd2, 1.0));
   *egap = vipmsolver_varscomputecomplementaritygap(&state->current) / (1.0 + fabs(vipmsolver_vipmtarget(state, &state->current.x)));
}

// Performs integrity checks for current point and step
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static void vipmsolver_runintegritychecks(vipmstate *state, vipmvars *v0, vipmvars *vd, double alphap, double alphad) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   n = state->n;
   m = state->mdense + state->msparse;
   ae_assert(isfinite(alphap) && alphap >= 0.0, "[VIPM]RunIntegrityChecks: bad AlphaP");
   ae_assert(isfinite(alphad) && alphad >= 0.0, "[VIPM]RunIntegrityChecks: bad AlphaD");
   for (i = 0; i < n; i++) {
      if (state->hasgz.xB[i]) {
         ae_assert(!state->isfrozen.xB[i], "[VIPM]RunIntegrityChecks: integrity failure - X[I] is frozen");
         ae_assert(v0->g.xR[i] > 0.0 && v0->z.xR[i] > 0.0, "[VIPM]RunIntegrityChecks: integrity failure - G[i] <= 0 or Z[i] <= 0");
      } else {
         ae_assert(v0->g.xR[i] == 0.0 && v0->z.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - G[i] != 0 or Z[i] != 0 for absent lower bound");
         ae_assert(vd->g.xR[i] == 0.0 && vd->z.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - G[i] != 0 or Z[i] != 0 for absent lower bound");
      }
      if (state->hasts.xB[i]) {
         ae_assert(!state->isfrozen.xB[i], "[VIPM]RunIntegrityChecks: integrity failure - X[I] is frozen");
         ae_assert(v0->t.xR[i] > 0.0 && v0->s.xR[i] > 0.0, "[VIPM]RunIntegrityChecks: integrity failure - T[i] <= 0 or S[i] <= 0");
      } else {
         ae_assert(v0->t.xR[i] == 0.0 && v0->s.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - T[i] != 0 or S[i] != 0 for absent upper bound");
         ae_assert(vd->t.xR[i] == 0.0 && vd->s.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - T[i] != 0 or S[i] != 0 for absent upper bound");
      }
   }
   for (i = 0; i < m; i++) {
      ae_assert(state->haswv.xB[i] || !state->haspq.xB[i], "[VIPM]RunIntegrityChecks: inconsistent HasWV/HasPQ");
      if (state->haswv.xB[i]) {
         ae_assert(v0->v.xR[i] > 0.0 && v0->w.xR[i] > 0.0, "[VIPM]RunIntegrityChecks: integrity failure - V[i] <= 0 or W[i] <= 0");
      } else {
         ae_assert(v0->v.xR[i] == 0.0 && v0->w.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - V[i] != 0 or W[i] != 0 for linear equality constraint");
         ae_assert(vd->v.xR[i] == 0.0 && vd->w.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - V[i] != 0 or W[i] != 0 for linear equality constraint");
      }
      if (state->haspq.xB[i]) {
         ae_assert(v0->p.xR[i] > 0.0 && v0->q.xR[i] > 0.0, "[VIPM]RunIntegrityChecks: integrity failure - P[i] <= 0 or Q[i] <= 0");
      } else {
         ae_assert(v0->p.xR[i] == 0.0 && v0->q.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - P[i] != 0 or Q[i] != 0 for absent range of linear constraint");
         ae_assert(vd->p.xR[i] == 0.0 && vd->q.xR[i] == 0.0, "[VIPM]RunIntegrityChecks: integrity failure - P[i] != 0 or Q[i] != 0 for absent range of linear constraint");
      }
   }
}

#if 0 //(@) Not used.
// Computes minimum nonzero value of the vector. Returns 0 if all components
// are nonpositive.
//
// Inputs:
//     X               -   vector
//     N               -   length
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_minnz(RVector *x, ae_int_t n) {
   ae_int_t i;
   bool nz;
   double result;
   result = 0.0;
   nz = false;
   for (i = 0; i < n; i++) {
      if (x->xR[i] > 0.0) {
         if (!nz) {
            result = x->xR[i];
            nz = true;
         } else {
            result = rmin2(result, x->xR[i]);
         }
      }
   }
   return result;
}

// Computes minimum product of nonzero components.
// Returns 0 if all components are nonpositive.
//
// Inputs:
//     X               -   vector
//     Y               -   vector
//     N               -   length
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_minprodnz(RVector *x, RVector *y, ae_int_t n) {
   ae_int_t i;
   bool nz;
   double result;
   result = 0.0;
   nz = false;
   for (i = 0; i < n; i++) {
      if (x->xR[i] > 0.0 && y->xR[i] > 0.0) {
         if (!nz) {
            result = x->xR[i] * y->xR[i];
            nz = true;
         } else {
            result = rmin2(result, x->xR[i] * y->xR[i]);
         }
      }
   }
   return result;
}

// Computes maximum product of nonzero components.
// Returns 0 if all components are nonpositive.
//
// Inputs:
//     X               -   vector
//     Y               -   vector
//     N               -   length
// ALGLIB: Copyright 01.11.2020 by Sergey Bochkanov
static double vipmsolver_maxprodnz(RVector *x, RVector *y, ae_int_t n) {
   ae_int_t i;
   bool nz;
   double result;
   result = 0.0;
   nz = false;
   for (i = 0; i < n; i++) {
      if (x->xR[i] > 0.0 && y->xR[i] > 0.0) {
         if (!nz) {
            result = x->xR[i] * y->xR[i];
            nz = true;
         } else {
            result = rmax2(result, x->xR[i] * y->xR[i]);
         }
      }
   }
   return result;
}
#endif

// Solve QP problem.
//
// Inputs:
//     State               -   solver instance
//     DropBigBounds       -   If True, algorithm may drop box and linear constraints
//                             with huge bound values that destabilize algorithm.
//
// Outputs:
//     XS                  -   array[N], solution
//     LagBC               -   array[N], Lagrange multipliers for box constraints
//     LagLC               -   array[M], Lagrange multipliers for linear constraints
//     TerminationType     -   completion code, positive values for success,
//                             negative for failures (XS constrains best point
//                             found so far):
//                             * -2    the task is either unbounded or infeasible;
//                                     the IPM solver has difficulty distinguishing between these two.
//                             * +1    stopping criteria are met
//                             * +7    stopping criteria are too stringent
//
// Result:
//
// This function ALWAYS returns something  meaningful in XS, LagBC, LagLC -
// either solution or the best point so far, even for negative TerminationType.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
void vipmoptimize(vipmstate *state, bool dropbigbounds, RVector *xs, RVector *lagbc, RVector *laglc, ae_int_t *terminationtype) {
   const ae_int_t maxipmits = 200;
   const double steplengthdecay = 0.95, stagnationdelta = 0.99999;
   const double primalinfeasible1 = 0.001, dualinfeasible1 = 0.001;
   const double bigy = 100000000.0, ygrowth = 1000000.0;
   const ae_int_t phase0length = 10;
   const ae_int_t itersfortoostringentcond = 25;
   const ae_int_t minitersbeforedroppingbounds = 3, minitersbeforeinfeasible = 3;
   const ae_int_t minitersbeforestagnation = 5, minitersbeforeeworststagnation = 50;
   const ae_int_t primalstagnationlen = 5, dualstagnationlen = 7;
   const double bigconstrxtol = 0.00001, bigconstrmag = 1000.0;
   const double minitersbeforesafeguards = 5.0, badsteplength = 0.001;
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   ae_int_t iteridx;
   double mu;
   double muaff;
   double sigma;
   double alphaaffp;
   double alphaaffd;
   double alphap;
   double alphad;
   ae_int_t primalstagnationcnt;
   ae_int_t dualstagnationcnt;
   double regeps;
   double regeps0;
   double regeps1;
   double dampeps;
   double safedampeps;
   double modeps;
   double maxdampeps;
   double regfree;
   double dampfree;
   ae_int_t droppedbounds;
   double primalxscale;
   double errp2;
   double errd2;
   double errpinf;
   double errdinf;
   double preverrp2;
   double preverrd2;
   double errgap;
   double eprimal;
   double edual;
   double egap;
   double mumin;
   double mustop;
   double y0nrm;
   double bady;
   double mxprimal;
   double mxdeltaprimal;
   ae_int_t bestiteridx;
   double besterr;
   double besteprimal;
   double bestedual;
   bool loadbest;
   *terminationtype = 0;
   n = state->n;
   m = state->mdense + state->msparse;
// Prepare outputs
   rsetallocv(n, 0.0, xs);
   rsetallocv(n, 0.0, lagbc);
   rsetallocv(m, 0.0, laglc);
// Some integrity checks:
// * we need PrimalStagnationLen < DualStagnationLen in order to be able to correctly
//   detect infeasible instances (stagnated dual error is present in both infeasible
//   and unbounded instances, so we should check for primal stagnation a few iters
//   before checking for dual stagnation)
   ae_assert(primalstagnationlen < dualstagnationlen, "VIPM: critical integrity failure - incorrect configuration parameters");
// Prepare regularization coefficients:
// * RegEps - one that is applied to initial (5N+5M)x(5N+5M) KKT system. This one has to be
//   small because it perturbs solution returned by the algorithm. Essential in order to
//   avoid stalling at extremely large points.
// * ModEps - small modification applied to LDLT decomposition in order to preserve sign
//   of diagonal elements
// * DampEps - damping coefficient for damped Newton step. Comes along with SafeDampEps
//   (threshold value when some safeguards are turned off in order to preserve convergence
//   speed) and MaxDampEps - threshold value when we consider problem overregularized and stop.
// * DampFree - additional damping coefficient for free variables
   regfree = pow(machineepsilon, 0.75);
   dampfree = 0.0;
   regeps0 = sqrt(machineepsilon);
   regeps1 = 10.0 * machineepsilon;
   regeps = regeps0;
   modeps = (100.0 + sqrt(n)) * machineepsilon;
   dampeps = 10.0 * machineepsilon;
   safedampeps = sqrt(machineepsilon);
   maxdampeps = sqrt(sqrt(machineepsilon));
// Set up initial state
   state->repiterationscount = 0;
   state->repncholesky = 0;
   mustop = (100.0 + sqrt(n)) * machineepsilon;
   mumin = 0.01 * mustop;
   vipmsolver_vipmpowerup(state, regfree);
   vipmsolver_varsinitfrom(&state->best, &state->current);
   vipmsolver_varsinitbyzero(&state->zerovars, n, m);
   vipmsolver_varsinitbyzero(&state->deltaaff, n, m);
   vipmsolver_varsinitbyzero(&state->deltacorr, n, m);
   bestiteridx = -1;
   besterr = maxrealnumber;
   besteprimal = maxrealnumber;
   bestedual = maxrealnumber;
   y0nrm = 0.0;
   y0nrm = rmax2(y0nrm, rmaxabsv(m, &state->current.y));
   y0nrm = rmax2(y0nrm, rmaxabsv(m, &state->current.v));
   y0nrm = rmax2(y0nrm, rmaxabsv(m, &state->current.q));
   y0nrm = rmax2(y0nrm, rmaxabsv(n, &state->current.z));
   y0nrm = rmax2(y0nrm, rmaxabsv(n, &state->current.s));
// Start iteration
   loadbest = true;
   primalstagnationcnt = 0;
   dualstagnationcnt = 0;
   *terminationtype = 7;
   errp2 = maxrealnumber;
   errd2 = maxrealnumber;
   for (iteridx = 0; iteridx < maxipmits; iteridx++) {
      regeps = iteridx < phase0length ? regeps0 : regeps1;
   // Check regularization status, terminate if overregularized
      if (dampeps >= maxdampeps) {
         *terminationtype = 7;
         break;
      }
   // Precompute factorization
   //
   // NOTE: we use "solver" regularization coefficient at this moment
      if (!vipmsolver_vipmprecomputenewtonfactorization(state, &state->current, regeps, modeps, dampeps, dampfree)) {
      // KKT factorization failed.
      // Increase regularization parameter and skip this iteration.
         dampeps *= 10.0;
         continue;
      }
   // Compute Mu
      mu = vipmsolver_varscomputemu(state, &state->current);
   // Compute affine scaling step for Mehrotra's predictor-corrector algorithm
      if (!vipmsolver_vipmcomputestepdirection(state, &state->current, 0.0, &state->zerovars, &state->deltaaff, regeps, dampeps >= safedampeps)) {
      // Affine scaling step failed due to numerical errors.
      // Increase regularization parameter and skip this iteration.
         dampeps *= 10.0;
         continue;
      }
      vipmsolver_vipmcomputesteplength(state, &state->current, &state->deltaaff, steplengthdecay, false, &alphaaffp, &alphaaffd);
   // Compute MuAff and centering parameter
      vipmsolver_varsinitfrom(&state->trial, &state->current);
      vipmsolver_varsaddstep(&state->trial, &state->deltaaff, alphaaffp, alphaaffd);
      muaff = vipmsolver_varscomputemu(state, &state->trial);
      sigma = rmin2(pow((muaff + mumin) / (mu + mumin), 3.0), 1.0);
      ae_assert(isfinite(sigma) && sigma <= 1.0, "VIPMOptimize: critical integrity check failed for Sigma (infinite or greater than 1)");
   // Compute corrector step
      if (!vipmsolver_vipmcomputestepdirection(state, &state->current, sigma * mu + mumin, &state->deltaaff, &state->deltacorr, regeps, dampeps >= safedampeps)) {
      // Affine scaling step failed due to numerical errors.
      // Increase regularization parameter and skip this iteration.
         dampeps *= 10.0;
         continue;
      }
      vipmsolver_vipmcomputesteplength(state, &state->current, &state->deltacorr, steplengthdecay, false, &alphap, &alphad);
      if (iteridx >= minitersbeforesafeguards && (alphap <= badsteplength || alphad <= badsteplength)) {
      // Affine scaling step failed due to numerical errors.
      // Increase regularization parameter and skip this iteration.
         dampeps *= 10.0;
         continue;
      }
   // Perform a step
      vipmsolver_runintegritychecks(state, &state->current, &state->deltacorr, alphap, alphad);
      vipmsolver_vipmperformstep(state, alphap, alphad);
   // Check for excessive bounds (one that are so large that they are both irrelevant
   // and destabilizing due to their magnitude)
      if (dropbigbounds && iteridx >= minitersbeforedroppingbounds) {
         ae_assert(10.0 * bigconstrmag <= 1.0 / bigconstrxtol, "VIPMOptimize: integrity check failed (incorrect BigConstr settings)");
         droppedbounds = 0;
      // Determine variable and step scales.
      // Both quantities are bounded from below by 1.0
         mxprimal = 1.0;
         mxprimal = rmax2(mxprimal, rmaxabsv(n, &state->current.x));
         mxprimal = rmax2(mxprimal, rmaxabsv(n, &state->current.g));
         mxprimal = rmax2(mxprimal, rmaxabsv(n, &state->current.t));
         mxprimal = rmax2(mxprimal, rmaxabsv(m, &state->current.w));
         mxprimal = rmax2(mxprimal, rmaxabsv(m, &state->current.p));
         mxdeltaprimal = 1.0;
         mxdeltaprimal = rmax2(mxdeltaprimal, alphap * rmaxabsv(n, &state->deltacorr.x));
         mxdeltaprimal = rmax2(mxdeltaprimal, alphap * rmaxabsv(n, &state->deltacorr.g));
         mxdeltaprimal = rmax2(mxdeltaprimal, alphap * rmaxabsv(n, &state->deltacorr.t));
         mxdeltaprimal = rmax2(mxdeltaprimal, alphap * rmaxabsv(m, &state->deltacorr.w));
         mxdeltaprimal = rmax2(mxdeltaprimal, alphap * rmaxabsv(m, &state->deltacorr.p));
      // If changes in primal variables are small enough, try dropping too large bounds
         if (mxdeltaprimal < mxprimal * bigconstrxtol) {
         // Drop irrelevant box constraints
            primalxscale = 1.0;
            primalxscale = rmax2(primalxscale, rmaxabsv(n, &state->current.x));
            for (i = 0; i < n; i++) {
               if (state->hasbndl.xB[i] && state->hasgz.xB[i] && !SmallAtR(state->bndl.xR[i], bigconstrmag * primalxscale)) {
                  state->hasgz.xB[i] = false;
                  state->current.g.xR[i] = 0.0;
                  state->current.z.xR[i] = 0.0;
                  state->cntgz--;
                  droppedbounds++;
               }
               if (state->hasbndu.xB[i] && state->hasts.xB[i] && !SmallAtR(state->bndu.xR[i], bigconstrmag * primalxscale)) {
                  state->hasts.xB[i] = false;
                  state->current.t.xR[i] = 0.0;
                  state->current.s.xR[i] = 0.0;
                  state->cntts--;
                  droppedbounds++;
               }
            }
         // Drop irrelevant linear constraints. Due to specifics of the solver
         // we can drop only right part part of b <= Ax <= b+r.
         //
         // We can't drop b <= A from b <= A <= b+r because it impossible with our choice of
         // slack variables. Usually we do not need to do so because we reorder constraints
         // during initialization in such a way that |b+r| > |b| and because typical
         // applications do not have excessively large lower AND upper bound (user may
         // specify large value for 'absent' bound, but usually he does not mark both bounds as absent).
            vipmsolver_multiplygeax(state, 1.0, &state->current.x, 0, 0.0, &state->tmpax, 0);
            primalxscale = 1.0;
            primalxscale = rmax2(primalxscale, rmaxabsv(n, &state->current.x));
            primalxscale = rmax2(primalxscale, rmaxabsv(m, &state->tmpax));
            for (i = 0; i < m; i++) {
               if (state->hasr.xB[i] && state->haspq.xB[i] && !SmallAtR(state->b.xR[i] + state->r.xR[i], bigconstrmag * primalxscale) && SmallR(state->b.xR[i], bigconstrmag * primalxscale)) {
                  ae_assert(state->haswv.xB[i] && state->haspq.xB[i], "VIPMOptimize: unexpected integrity check failure (4y64)");
                  state->haspq.xB[i] = false;
                  state->current.p.xR[i] = 0.0;
                  state->current.q.xR[i] = 0.0;
                  state->cntpq--;
                  droppedbounds++;
               }
            }
         }
      }
   // Check stopping criteria
   // * primal and dual stagnation are checked only when following criteria are met:
   //   1) Mu is smaller than 1 (we already converged close enough)
   //   2) we performed more than MinItersBeforeStagnation iterations
      preverrp2 = errp2;
      preverrd2 = errd2;
      vipmsolver_computeerrors(state, &errp2, &errd2, &errpinf, &errdinf, &errgap);
      mu = vipmsolver_varscomputemu(state, &state->current);
      egap = errgap;
      eprimal = errpinf;
      edual = errdinf;
      if (rmax3(egap, eprimal, edual) < besterr) {
      // Save best point found so far
         vipmsolver_varsinitfrom(&state->best, &state->current);
         bestiteridx = iteridx;
         besterr = rmax3(egap, eprimal, edual);
         besteprimal = eprimal;
         bestedual = edual;
      }
      if (bestiteridx > 0 && iteridx > bestiteridx + minitersbeforeeworststagnation) {
         break;
      }
      if (egap <= state->epsgap && errp2 >= stagnationdelta * preverrp2 && errpinf >= primalinfeasible1 && iteridx >= minitersbeforestagnation) {
         primalstagnationcnt++;
         if (primalstagnationcnt >= primalstagnationlen) {
            break;
         }
      } else {
         primalstagnationcnt = 0;
      }
      if (egap <= state->epsgap && errd2 >= stagnationdelta * preverrd2 && errdinf >= dualinfeasible1 && iteridx >= minitersbeforestagnation) {
         dualstagnationcnt++;
         if (dualstagnationcnt >= dualstagnationlen) {
            break;
         }
      } else {
         dualstagnationcnt = 0;
      }
      if (mu <= mustop && iteridx >= itersfortoostringentcond) {
         *terminationtype = 7;
         break;
      }
      if (egap <= state->epsgap && eprimal <= state->epsp && edual <= state->epsd) {
         *terminationtype = 1;
         loadbest = false;
         break;
      }
      bady = bigy;
      bady = rmax2(bady, ygrowth * y0nrm);
      bady = rmax2(bady, ygrowth * rmaxabsv(n, &state->current.x));
      bady = rmax2(bady, ygrowth * rmaxabsv(n, &state->current.g));
      bady = rmax2(bady, ygrowth * rmaxabsv(n, &state->current.t));
      bady = rmax2(bady, ygrowth * rmaxabsv(m, &state->current.w));
      bady = rmax2(bady, ygrowth * rmaxabsv(m, &state->current.p));
      if (rmaxabsv(m, &state->current.y) >= bady && iteridx >= minitersbeforeinfeasible) {
         break;
      }
   }
// Load best point, perform some checks
   if (loadbest) {
   // Load best point
      vipmsolver_varsinitfrom(&state->current, &state->best);
   // If no error flags were set yet, check solution quality
      bady = bigy;
      bady = rmax2(bady, ygrowth * y0nrm);
      bady = rmax2(bady, ygrowth * rmaxabsv(n, &state->current.x));
      bady = rmax2(bady, ygrowth * rmaxabsv(n, &state->current.g));
      bady = rmax2(bady, ygrowth * rmaxabsv(n, &state->current.t));
      bady = rmax2(bady, ygrowth * rmaxabsv(m, &state->current.w));
      bady = rmax2(bady, ygrowth * rmaxabsv(m, &state->current.p));
      if (*terminationtype > 0 && rmaxabsv(m, &state->current.y) >= bady) {
         *terminationtype = -2;
      }
      if (*terminationtype > 0 && besteprimal >= primalinfeasible1) {
         *terminationtype = -2;
      }
      if (*terminationtype > 0 && bestedual >= dualinfeasible1) {
         *terminationtype = -2;
      }
   }
// Output
   vipmsolver_multiplyhx(state, &state->current.x, &state->tmp0);
   raddv(n, 1.0, &state->c, &state->tmp0);
   vipmsolver_multiplygeatx(state, -1.0, &state->current.y, 0, 1.0, &state->tmp0, 0);
   for (i = 0; i < n; i++) {
      if (state->isfrozen.xB[i]) {
      // I-th variable is frozen, use its frozen value.
      // By the definition, I-th Lagrangian multiplier is an I-th component of Lagrangian gradient
         xs->xR[i] = state->current.x.xR[i];
         lagbc->xR[i] = -state->tmp0.xR[i];
      } else {
         xs->xR[i] = state->current.x.xR[i];
         lagbc->xR[i] = 0.0;
         if (state->hasgz.xB[i]) {
            lagbc->xR[i] -= state->current.z.xR[i];
         }
         if (state->hasts.xB[i]) {
            lagbc->xR[i] += state->current.s.xR[i];
         }
      }
   }
   for (i = 0; i < m; i++) {
      laglc->xR[i] = -state->current.y.xR[i];
   }
// Unscale point and Lagrange multipliers
   unscaleunshiftpointbc(&state->scl, &state->xorigin, &state->rawbndl, &state->rawbndu, &state->bndl, &state->bndu, &state->hasbndl, &state->hasbndu, xs, n);
   for (i = 0; i < n; i++) {
      lagbc->xR[i] *= state->targetscale / state->scl.xR[i];
   }
   for (i = 0; i < m; i++) {
      laglc->xR[i] *= state->targetscale / coalesce(state->ascales.xR[i], 1.0);
   }
}

void vipmvars_init(void *_p, bool make_automatic) {
   vipmvars *p = (vipmvars *)_p;
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->w, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->t, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->p, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->y, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->z, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->v, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->q, 0, DT_REAL, make_automatic);
}

void vipmvars_copy(void *_dst, const void *_src, bool make_automatic) {
   vipmvars *dst = (vipmvars *)_dst;
   const vipmvars *src = (const vipmvars *)_src;
   dst->n = src->n;
   dst->m = src->m;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   ae_vector_copy(&dst->w, &src->w, make_automatic);
   ae_vector_copy(&dst->t, &src->t, make_automatic);
   ae_vector_copy(&dst->p, &src->p, make_automatic);
   ae_vector_copy(&dst->y, &src->y, make_automatic);
   ae_vector_copy(&dst->z, &src->z, make_automatic);
   ae_vector_copy(&dst->v, &src->v, make_automatic);
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->q, &src->q, make_automatic);
}

void vipmvars_free(void *_p, bool make_automatic) {
   vipmvars *p = (vipmvars *)_p;
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   ae_vector_free(&p->w, make_automatic);
   ae_vector_free(&p->t, make_automatic);
   ae_vector_free(&p->p, make_automatic);
   ae_vector_free(&p->y, make_automatic);
   ae_vector_free(&p->z, make_automatic);
   ae_vector_free(&p->v, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->q, make_automatic);
}

void vipmreducedsparsesystem_init(void *_p, bool make_automatic) {
   vipmreducedsparsesystem *p = (vipmreducedsparsesystem *)_p;
   sparsematrix_init(&p->rawsystem, make_automatic);
   ae_vector_init(&p->effectivediag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->isdiagonal, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->rowdegrees, 0, DT_INT, make_automatic);
   ae_vector_init(&p->coldegrees, 0, DT_INT, make_automatic);
   spcholanalysis_init(&p->analysis, make_automatic);
   ae_vector_init(&p->priorities, 0, DT_INT, make_automatic);
   ae_vector_init(&p->diagterm, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dampterm, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmprhs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpcorr, 0, DT_REAL, make_automatic);
}

void vipmreducedsparsesystem_copy(void *_dst, const void *_src, bool make_automatic) {
   vipmreducedsparsesystem *dst = (vipmreducedsparsesystem *)_dst;
   const vipmreducedsparsesystem *src = (const vipmreducedsparsesystem *)_src;
   sparsematrix_copy(&dst->rawsystem, &src->rawsystem, make_automatic);
   ae_vector_copy(&dst->effectivediag, &src->effectivediag, make_automatic);
   ae_vector_copy(&dst->isdiagonal, &src->isdiagonal, make_automatic);
   ae_vector_copy(&dst->rowdegrees, &src->rowdegrees, make_automatic);
   ae_vector_copy(&dst->coldegrees, &src->coldegrees, make_automatic);
   dst->ntotal = src->ntotal;
   spcholanalysis_copy(&dst->analysis, &src->analysis, make_automatic);
   ae_vector_copy(&dst->priorities, &src->priorities, make_automatic);
   ae_vector_copy(&dst->diagterm, &src->diagterm, make_automatic);
   ae_vector_copy(&dst->dampterm, &src->dampterm, make_automatic);
   ae_vector_copy(&dst->tmpb, &src->tmpb, make_automatic);
   ae_vector_copy(&dst->tmprhs, &src->tmprhs, make_automatic);
   ae_vector_copy(&dst->tmpcorr, &src->tmpcorr, make_automatic);
}

void vipmreducedsparsesystem_free(void *_p, bool make_automatic) {
   vipmreducedsparsesystem *p = (vipmreducedsparsesystem *)_p;
   sparsematrix_free(&p->rawsystem, make_automatic);
   ae_vector_free(&p->effectivediag, make_automatic);
   ae_vector_free(&p->isdiagonal, make_automatic);
   ae_vector_free(&p->rowdegrees, make_automatic);
   ae_vector_free(&p->coldegrees, make_automatic);
   spcholanalysis_free(&p->analysis, make_automatic);
   ae_vector_free(&p->priorities, make_automatic);
   ae_vector_free(&p->diagterm, make_automatic);
   ae_vector_free(&p->dampterm, make_automatic);
   ae_vector_free(&p->tmpb, make_automatic);
   ae_vector_free(&p->tmprhs, make_automatic);
   ae_vector_free(&p->tmpcorr, make_automatic);
}

void vipmrighthandside_init(void *_p, bool make_automatic) {
   vipmrighthandside *p = (vipmrighthandside *)_p;
   ae_vector_init(&p->sigma, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->beta, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rho, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tau, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->alpha, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gammaz, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gammas, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gammaw, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gammaq, 0, DT_REAL, make_automatic);
}

void vipmrighthandside_copy(void *_dst, const void *_src, bool make_automatic) {
   vipmrighthandside *dst = (vipmrighthandside *)_dst;
   const vipmrighthandside *src = (const vipmrighthandside *)_src;
   ae_vector_copy(&dst->sigma, &src->sigma, make_automatic);
   ae_vector_copy(&dst->beta, &src->beta, make_automatic);
   ae_vector_copy(&dst->rho, &src->rho, make_automatic);
   ae_vector_copy(&dst->nu, &src->nu, make_automatic);
   ae_vector_copy(&dst->tau, &src->tau, make_automatic);
   ae_vector_copy(&dst->alpha, &src->alpha, make_automatic);
   ae_vector_copy(&dst->gammaz, &src->gammaz, make_automatic);
   ae_vector_copy(&dst->gammas, &src->gammas, make_automatic);
   ae_vector_copy(&dst->gammaw, &src->gammaw, make_automatic);
   ae_vector_copy(&dst->gammaq, &src->gammaq, make_automatic);
}

void vipmrighthandside_free(void *_p, bool make_automatic) {
   vipmrighthandside *p = (vipmrighthandside *)_p;
   ae_vector_free(&p->sigma, make_automatic);
   ae_vector_free(&p->beta, make_automatic);
   ae_vector_free(&p->rho, make_automatic);
   ae_vector_free(&p->nu, make_automatic);
   ae_vector_free(&p->tau, make_automatic);
   ae_vector_free(&p->alpha, make_automatic);
   ae_vector_free(&p->gammaz, make_automatic);
   ae_vector_free(&p->gammas, make_automatic);
   ae_vector_free(&p->gammaw, make_automatic);
   ae_vector_free(&p->gammaq, make_automatic);
}

void vipmstate_init(void *_p, bool make_automatic) {
   vipmstate *p = (vipmstate *)_p;
   ae_vector_init(&p->scl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->invscl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xorigin, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->c, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->denseh, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparseh, make_automatic);
   ae_vector_init(&p->diagr, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->denseafull, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->denseamain, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparseafull, make_automatic);
   sparsematrix_init(&p->sparseamain, make_automatic);
   sparsematrix_init(&p->combinedaslack, make_automatic);
   ae_vector_init(&p->ascales, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->aflips, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->b, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->r, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasr, 0, DT_BOOL, make_automatic);
   vipmvars_init(&p->current, make_automatic);
   vipmvars_init(&p->best, make_automatic);
   vipmvars_init(&p->trial, make_automatic);
   vipmvars_init(&p->deltaaff, make_automatic);
   vipmvars_init(&p->deltacorr, make_automatic);
   ae_vector_init(&p->isfrozen, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasgz, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasts, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->haswv, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->haspq, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->diagdz, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdzi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdziri, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagds, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdsi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdsiri, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdw, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdwi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdwir, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdq, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdqi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagdqiri, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagddr, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagde, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagder, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->factdensehaug, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->factregdhrh, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->factinvregdzrz, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->factregewave, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->facttmpdiag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->facttmpdamp, 0, DT_REAL, make_automatic);
   vipmreducedsparsesystem_init(&p->reducedsparsesystem, make_automatic);
   vipmrighthandside_init(&p->rhs, make_automatic);
   ae_vector_init(&p->rhsalphacap, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rhsbetacap, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rhsnucap, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rhstaucap, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->deltaxy, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmphx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpax, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpaty, 0, DT_REAL, make_automatic);
   vipmvars_init(&p->zerovars, make_automatic);
   ae_vector_init(&p->dummyr, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpy, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp2, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmpr2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmplaggrad, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpi, 0, DT_INT, make_automatic);
   sparsematrix_init(&p->tmpsparse0, make_automatic);
}

void vipmstate_copy(void *_dst, const void *_src, bool make_automatic) {
   vipmstate *dst = (vipmstate *)_dst;
   const vipmstate *src = (const vipmstate *)_src;
   dst->slacksforequalityconstraints = src->slacksforequalityconstraints;
   dst->n = src->n;
   dst->nmain = src->nmain;
   dst->epsp = src->epsp;
   dst->epsd = src->epsd;
   dst->epsgap = src->epsgap;
   dst->islinear = src->islinear;
   ae_vector_copy(&dst->scl, &src->scl, make_automatic);
   ae_vector_copy(&dst->invscl, &src->invscl, make_automatic);
   ae_vector_copy(&dst->xorigin, &src->xorigin, make_automatic);
   dst->targetscale = src->targetscale;
   ae_vector_copy(&dst->c, &src->c, make_automatic);
   ae_matrix_copy(&dst->denseh, &src->denseh, make_automatic);
   sparsematrix_copy(&dst->sparseh, &src->sparseh, make_automatic);
   ae_vector_copy(&dst->diagr, &src->diagr, make_automatic);
   dst->hkind = src->hkind;
   dst->isdiagonalh = src->isdiagonalh;
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->rawbndl, &src->rawbndl, make_automatic);
   ae_vector_copy(&dst->rawbndu, &src->rawbndu, make_automatic);
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_matrix_copy(&dst->denseafull, &src->denseafull, make_automatic);
   ae_matrix_copy(&dst->denseamain, &src->denseamain, make_automatic);
   sparsematrix_copy(&dst->sparseafull, &src->sparseafull, make_automatic);
   sparsematrix_copy(&dst->sparseamain, &src->sparseamain, make_automatic);
   sparsematrix_copy(&dst->combinedaslack, &src->combinedaslack, make_automatic);
   ae_vector_copy(&dst->ascales, &src->ascales, make_automatic);
   ae_vector_copy(&dst->aflips, &src->aflips, make_automatic);
   ae_vector_copy(&dst->b, &src->b, make_automatic);
   ae_vector_copy(&dst->r, &src->r, make_automatic);
   ae_vector_copy(&dst->hasr, &src->hasr, make_automatic);
   dst->mdense = src->mdense;
   dst->msparse = src->msparse;
   vipmvars_copy(&dst->current, &src->current, make_automatic);
   vipmvars_copy(&dst->best, &src->best, make_automatic);
   vipmvars_copy(&dst->trial, &src->trial, make_automatic);
   vipmvars_copy(&dst->deltaaff, &src->deltaaff, make_automatic);
   vipmvars_copy(&dst->deltacorr, &src->deltacorr, make_automatic);
   ae_vector_copy(&dst->isfrozen, &src->isfrozen, make_automatic);
   ae_vector_copy(&dst->hasgz, &src->hasgz, make_automatic);
   ae_vector_copy(&dst->hasts, &src->hasts, make_automatic);
   ae_vector_copy(&dst->haswv, &src->haswv, make_automatic);
   ae_vector_copy(&dst->haspq, &src->haspq, make_automatic);
   dst->cntgz = src->cntgz;
   dst->cntts = src->cntts;
   dst->cntwv = src->cntwv;
   dst->cntpq = src->cntpq;
   dst->repiterationscount = src->repiterationscount;
   dst->repncholesky = src->repncholesky;
   dst->factorizationtype = src->factorizationtype;
   dst->factorizationpoweredup = src->factorizationpoweredup;
   dst->factorizationpresent = src->factorizationpresent;
   ae_vector_copy(&dst->diagdz, &src->diagdz, make_automatic);
   ae_vector_copy(&dst->diagdzi, &src->diagdzi, make_automatic);
   ae_vector_copy(&dst->diagdziri, &src->diagdziri, make_automatic);
   ae_vector_copy(&dst->diagds, &src->diagds, make_automatic);
   ae_vector_copy(&dst->diagdsi, &src->diagdsi, make_automatic);
   ae_vector_copy(&dst->diagdsiri, &src->diagdsiri, make_automatic);
   ae_vector_copy(&dst->diagdw, &src->diagdw, make_automatic);
   ae_vector_copy(&dst->diagdwi, &src->diagdwi, make_automatic);
   ae_vector_copy(&dst->diagdwir, &src->diagdwir, make_automatic);
   ae_vector_copy(&dst->diagdq, &src->diagdq, make_automatic);
   ae_vector_copy(&dst->diagdqi, &src->diagdqi, make_automatic);
   ae_vector_copy(&dst->diagdqiri, &src->diagdqiri, make_automatic);
   ae_vector_copy(&dst->diagddr, &src->diagddr, make_automatic);
   ae_vector_copy(&dst->diagde, &src->diagde, make_automatic);
   ae_vector_copy(&dst->diagder, &src->diagder, make_automatic);
   ae_matrix_copy(&dst->factdensehaug, &src->factdensehaug, make_automatic);
   ae_vector_copy(&dst->factregdhrh, &src->factregdhrh, make_automatic);
   ae_vector_copy(&dst->factinvregdzrz, &src->factinvregdzrz, make_automatic);
   ae_vector_copy(&dst->factregewave, &src->factregewave, make_automatic);
   ae_vector_copy(&dst->facttmpdiag, &src->facttmpdiag, make_automatic);
   ae_vector_copy(&dst->facttmpdamp, &src->facttmpdamp, make_automatic);
   vipmreducedsparsesystem_copy(&dst->reducedsparsesystem, &src->reducedsparsesystem, make_automatic);
   vipmrighthandside_copy(&dst->rhs, &src->rhs, make_automatic);
   ae_vector_copy(&dst->rhsalphacap, &src->rhsalphacap, make_automatic);
   ae_vector_copy(&dst->rhsbetacap, &src->rhsbetacap, make_automatic);
   ae_vector_copy(&dst->rhsnucap, &src->rhsnucap, make_automatic);
   ae_vector_copy(&dst->rhstaucap, &src->rhstaucap, make_automatic);
   ae_vector_copy(&dst->deltaxy, &src->deltaxy, make_automatic);
   ae_vector_copy(&dst->tmphx, &src->tmphx, make_automatic);
   ae_vector_copy(&dst->tmpax, &src->tmpax, make_automatic);
   ae_vector_copy(&dst->tmpaty, &src->tmpaty, make_automatic);
   vipmvars_copy(&dst->zerovars, &src->zerovars, make_automatic);
   ae_vector_copy(&dst->dummyr, &src->dummyr, make_automatic);
   ae_vector_copy(&dst->tmpy, &src->tmpy, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->tmp2, &src->tmp2, make_automatic);
   ae_matrix_copy(&dst->tmpr2, &src->tmpr2, make_automatic);
   ae_vector_copy(&dst->tmplaggrad, &src->tmplaggrad, make_automatic);
   ae_vector_copy(&dst->tmpi, &src->tmpi, make_automatic);
   sparsematrix_copy(&dst->tmpsparse0, &src->tmpsparse0, make_automatic);
}

void vipmstate_free(void *_p, bool make_automatic) {
   vipmstate *p = (vipmstate *)_p;
   ae_vector_free(&p->scl, make_automatic);
   ae_vector_free(&p->invscl, make_automatic);
   ae_vector_free(&p->xorigin, make_automatic);
   ae_vector_free(&p->c, make_automatic);
   ae_matrix_free(&p->denseh, make_automatic);
   sparsematrix_free(&p->sparseh, make_automatic);
   ae_vector_free(&p->diagr, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->rawbndl, make_automatic);
   ae_vector_free(&p->rawbndu, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_matrix_free(&p->denseafull, make_automatic);
   ae_matrix_free(&p->denseamain, make_automatic);
   sparsematrix_free(&p->sparseafull, make_automatic);
   sparsematrix_free(&p->sparseamain, make_automatic);
   sparsematrix_free(&p->combinedaslack, make_automatic);
   ae_vector_free(&p->ascales, make_automatic);
   ae_vector_free(&p->aflips, make_automatic);
   ae_vector_free(&p->b, make_automatic);
   ae_vector_free(&p->r, make_automatic);
   ae_vector_free(&p->hasr, make_automatic);
   vipmvars_free(&p->current, make_automatic);
   vipmvars_free(&p->best, make_automatic);
   vipmvars_free(&p->trial, make_automatic);
   vipmvars_free(&p->deltaaff, make_automatic);
   vipmvars_free(&p->deltacorr, make_automatic);
   ae_vector_free(&p->isfrozen, make_automatic);
   ae_vector_free(&p->hasgz, make_automatic);
   ae_vector_free(&p->hasts, make_automatic);
   ae_vector_free(&p->haswv, make_automatic);
   ae_vector_free(&p->haspq, make_automatic);
   ae_vector_free(&p->diagdz, make_automatic);
   ae_vector_free(&p->diagdzi, make_automatic);
   ae_vector_free(&p->diagdziri, make_automatic);
   ae_vector_free(&p->diagds, make_automatic);
   ae_vector_free(&p->diagdsi, make_automatic);
   ae_vector_free(&p->diagdsiri, make_automatic);
   ae_vector_free(&p->diagdw, make_automatic);
   ae_vector_free(&p->diagdwi, make_automatic);
   ae_vector_free(&p->diagdwir, make_automatic);
   ae_vector_free(&p->diagdq, make_automatic);
   ae_vector_free(&p->diagdqi, make_automatic);
   ae_vector_free(&p->diagdqiri, make_automatic);
   ae_vector_free(&p->diagddr, make_automatic);
   ae_vector_free(&p->diagde, make_automatic);
   ae_vector_free(&p->diagder, make_automatic);
   ae_matrix_free(&p->factdensehaug, make_automatic);
   ae_vector_free(&p->factregdhrh, make_automatic);
   ae_vector_free(&p->factinvregdzrz, make_automatic);
   ae_vector_free(&p->factregewave, make_automatic);
   ae_vector_free(&p->facttmpdiag, make_automatic);
   ae_vector_free(&p->facttmpdamp, make_automatic);
   vipmreducedsparsesystem_free(&p->reducedsparsesystem, make_automatic);
   vipmrighthandside_free(&p->rhs, make_automatic);
   ae_vector_free(&p->rhsalphacap, make_automatic);
   ae_vector_free(&p->rhsbetacap, make_automatic);
   ae_vector_free(&p->rhsnucap, make_automatic);
   ae_vector_free(&p->rhstaucap, make_automatic);
   ae_vector_free(&p->deltaxy, make_automatic);
   ae_vector_free(&p->tmphx, make_automatic);
   ae_vector_free(&p->tmpax, make_automatic);
   ae_vector_free(&p->tmpaty, make_automatic);
   vipmvars_free(&p->zerovars, make_automatic);
   ae_vector_free(&p->dummyr, make_automatic);
   ae_vector_free(&p->tmpy, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->tmp2, make_automatic);
   ae_matrix_free(&p->tmpr2, make_automatic);
   ae_vector_free(&p->tmplaggrad, make_automatic);
   ae_vector_free(&p->tmpi, make_automatic);
   sparsematrix_free(&p->tmpsparse0, make_automatic);
}
} // end of namespace alglib_impl

// === MINQP Package ===
// Depends on: QPDENSEAULSOLVER, QPBLEICSOLVER, VIPMSOLVER
namespace alglib_impl {
// This function tells solver to use BLEIC-based algorithm and sets  stopping
// criteria for the algorithm.
//
// This algorithm is intended for large-scale  problems,  possibly nonconvex,
// with small number of general linear constraints. Feasible initial point is
// essential for good performance.
//
// IMPORTANT: when DENSE-IPM (or DENSE-AUL for  nonconvex  problems)  solvers
//            are applicable, their performance is much better than  that  of
//            BLEIC-QP.
//            We recommend  you to use BLEIC only when other solvers can  not
//            be used.
//
// ALGORITHM FEATURES:
//
// * supports dense and sparse QP problems
// * supports box and general linear equality/inequality constraints
// * can solve all types of problems  (convex,  semidefinite,  nonconvex)  as
//   long as they are bounded from below under constraints.
//   Say, it is possible to solve "min{-x^2} subject to -1 <= x <= +1".
//   Of course, global  minimum  is found only  for  positive  definite   and
//   semidefinite  problems.  As  for indefinite ones - only local minimum is
//   found.
//
// ALGORITHM OUTLINE:
//
// * BLEIC-QP solver is just a driver function for MinBLEIC solver; it solves
//   quadratic  programming   problem   as   general   linearly   constrained
//   optimization problem, which is solved by means of BLEIC solver  (part of
//   ALGLIB, active set method).
//
// ALGORITHM LIMITATIONS:
// * This algorithm is inefficient on  problems with hundreds  and  thousands
//   of general inequality constraints and infeasible initial point.  Initial
//   feasibility detection stage may take too long on such constraint sets.
//   Consider using DENSE-IPM or DENSE-AUL instead.
// * unlike QuickQP solver, this algorithm does not perform Newton steps  and
//   does not use Level 3 BLAS. Being general-purpose active set  method,  it
//   can activate constraints only one-by-one. Thus, its performance is lower
//   than that of QuickQP.
// * its precision is also a bit  inferior  to  that  of   QuickQP.  BLEIC-QP
//   performs only LBFGS steps (no Newton steps), which are good at detecting
//   neighborhood of the solution, buy needs many iterations to find solution
//   with more than 6 digits of precision.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsG    -   >= 0
//                 The  subroutine  finishes  its  work   if   the  condition
//                 |v| < EpsG is satisfied, where:
//                 * |.| means Euclidian norm
//                 * v - scaled constrained gradient vector, v[i] == g[i]*s[i]
//                 * g - gradient
//                 * s - scaling coefficients set by MinQPSetScale()
//     EpsF    -   >= 0
//                 The  subroutine  finishes its work if exploratory steepest
//                 descent  step  on  k+1-th iteration  satisfies   following
//                 condition:  |F(k+1)-F(k)| <= EpsF*max{|F(k)|,|F(k+1)|,1}
//     EpsX    -   >= 0
//                 The  subroutine  finishes its work if exploratory steepest
//                 descent  step  on  k+1-th iteration  satisfies   following
//                 condition:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - step vector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinQPSetScale()
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited. NOTE: this  algorithm uses  LBFGS
//                 iterations,  which  are  relatively  cheap,  but   improve
//                 function value only a bit. So you will need many iterations
//                 to converge - from 0.1*N to 10*N, depending  on  problem's
//                 condition number.
//
// IT IS VERY IMPORTANT TO CALL MinQPSetScale() WHEN YOU USE THIS  ALGORITHM
// BECAUSE ITS STOPPING CRITERIA ARE SCALE-DEPENDENT!
//
// Passing EpsG == 0, EpsF == 0 and EpsX == 0 and MaxIts == 0 (simultaneously) will lead
// to automatic stopping criterion selection (presently it is  small    step
// length, but it may change in the future versions of ALGLIB).
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetalgobleic(const minqpstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits);
void minqpsetalgobleic(minqpstate *state, double epsg, double epsf, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsg), "MinQPSetAlgoBLEIC: EpsG is not finite number");
   ae_assert(epsg >= 0.0, "MinQPSetAlgoBLEIC: negative EpsG");
   ae_assert(isfinite(epsf), "MinQPSetAlgoBLEIC: EpsF is not finite number");
   ae_assert(epsf >= 0.0, "MinQPSetAlgoBLEIC: negative EpsF");
   ae_assert(isfinite(epsx), "MinQPSetAlgoBLEIC: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinQPSetAlgoBLEIC: negative EpsX");
   ae_assert(maxits >= 0, "MinQPSetAlgoBLEIC: negative MaxIts!");
   state->algokind = 2;
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->qpbleicsettingsuser.epsg = epsg;
   state->qpbleicsettingsuser.epsf = epsf;
   state->qpbleicsettingsuser.epsx = epsx;
   state->qpbleicsettingsuser.maxits = maxits;
}

// This function tells QP solver to use DENSE-AUL algorithm and sets stopping
// criteria for the algorithm.
//
// This  algorithm  is  intended  for  non-convex problems with moderate  (up
// to several thousands) variable count and arbitrary number  of  constraints
// which are either (a) effectively convexified under constraints or (b) have
// unique solution even with nonconvex target.
//
// IMPORTANT: when DENSE-IPM solver is applicable, its performance is usually
//            much better than that of DENSE-AUL.
//            We recommend  you to use DENSE-AUL only when other solvers  can
//            not be used.
//
// ALGORITHM FEATURES:
//
// * supports  box  and  dense/sparse  general   linear   equality/inequality
//   constraints
// * convergence is theoretically proved for positive-definite  (convex)   QP
//   problems. Semidefinite and non-convex problems can be solved as long  as
//   they  are   bounded  from  below  under  constraints,  although  without
//   theoretical guarantees.
//
// ALGORITHM OUTLINE:
//
// * this  algorithm   is   an   augmented   Lagrangian   method  with  dense
//   preconditioner (hence  its  name).
// * it performs several outer iterations in order to refine  values  of  the
//   Lagrange multipliers. Single outer  iteration  is  a  solution  of  some
//   unconstrained optimization problem: first  it  performs  dense  Cholesky
//   factorization of the Hessian in order to build preconditioner  (adaptive
//   regularization is applied to enforce positive  definiteness),  and  then
//   it uses L-BFGS optimizer to solve optimization problem.
// * typically you need about 5-10 outer iterations to converge to solution
//
// ALGORITHM LIMITATIONS:
//
// * because dense Cholesky driver is used, this algorithm has O(N^2)  memory
//   requirements and O(OuterIterations*N^3) minimum running time.  From  the
//   practical  point  of  view,  it  limits  its  applicability  by  several
//   thousands of variables.
//   From  the  other  side,  variables  count  is  the most limiting factor,
//   and dependence on constraint count is  much  more  lower. Assuming  that
//   constraint matrix is sparse, it may handle tens of thousands  of general
//   linear constraints.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsX    -   >= 0, stopping criteria for inner optimizer.
//                 Inner  iterations  are  stopped  when  step  length  (with
//                 variable scaling being applied) is less than EpsX.
//                 See  minqpsetscale()  for  more  information  on  variable
//                 scaling.
//     Rho     -   penalty coefficient, Rho > 0:
//                 * large enough  that  algorithm  converges  with   desired
//                   precision.
//                 * not TOO large to prevent ill-conditioning
//                 * recommended values are 100, 1000 or 10000
//     ItsCnt  -   number of outer iterations:
//                 * recommended values: 10-15 (although  in  most  cases  it
//                   converges within 5 iterations, you may need a  few  more
//                   to be sure).
//                 * ItsCnt == 0 means that small number of outer iterations  is
//                   automatically chosen (10 iterations in current version).
//                 * ItsCnt == 1 means that AUL algorithm performs just as usual
//                   penalty method.
//                 * ItsCnt > 1 means that  AUL  algorithm  performs  specified
//                   number of outer iterations
//
// IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
// BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
//
// NOTE: Passing  EpsX == 0  will  lead  to  automatic  step  length  selection
//       (specific step length chosen may change in the future  versions  of
//       ALGLIB, so it is better to specify step length explicitly).
// ALGLIB: Copyright 20.08.2016 by Sergey Bochkanov
// API: void minqpsetalgodenseaul(const minqpstate &state, const double epsx, const double rho, const ae_int_t itscnt);
void minqpsetalgodenseaul(minqpstate *state, double epsx, double rho, ae_int_t itscnt) {
   ae_assert(isfinite(epsx), "MinQPSetAlgoDenseAUL: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinQPSetAlgoDenseAUL: negative EpsX");
   ae_assert(isfinite(rho), "MinQPSetAlgoDenseAUL: Rho is not finite number");
   ae_assert(rho > 0.0, "MinQPSetAlgoDenseAUL: non-positive Rho");
   ae_assert(itscnt >= 0, "MinQPSetAlgoDenseAUL: negative ItsCnt!");
   state->algokind = 4;
   if (epsx == 0.0) {
      epsx = 0.00000001;
   }
   if (itscnt == 0) {
      itscnt = 10;
   }
   state->qpdenseaulsettingsuser.epsx = epsx;
   state->qpdenseaulsettingsuser.outerits = itscnt;
   state->qpdenseaulsettingsuser.rho = rho;
}

// This function tells QP solver to  use  DENSE-IPM  QP  algorithm  and  sets
// stopping criteria for the algorithm.
//
// This  algorithm  is  intended  for convex and semidefinite  problems  with
// moderate (up to several thousands) variable count and arbitrary number  of
// constraints.
//
// IMPORTANT: this algorithm won't work for nonconvex problems, use DENSE-AUL
//            or BLEIC-QP instead. If you try to  run  DENSE-IPM  on  problem
//            with  indefinite  matrix  (matrix having  at least one negative
//            eigenvalue) then depending on circumstances it may  either  (a)
//            stall at some  arbitrary  point,  or  (b)  throw  exception  on
//            failure of Cholesky decomposition.
//
// ALGORITHM FEATURES:
//
// * supports  box  and  dense/sparse  general   linear   equality/inequality
//   constraints
//
// ALGORITHM OUTLINE:
//
// * this  algorithm  is  our implementation  of  interior  point  method  as
//   formulated by  R.J.Vanderbei, with minor modifications to the  algorithm
//   (damped Newton directions are extensively used)
// * like all interior point methods, this algorithm  tends  to  converge  in
//   roughly same number of iterations (between 15 and 50) independently from
//   the problem dimensionality
//
// ALGORITHM LIMITATIONS:
//
// * because dense Cholesky driver is used, for  N-dimensional  problem  with
//   M dense constaints this algorithm has O(N^2+N*M) memory requirements and
//   O(N^3+N*M^2) running time.
//   Having sparse constraints with Z nonzeros per row  relaxes  storage  and
//   running time down to O(N^2+M*Z) and O(N^3+N*Z^2)
//   From the practical  point  of  view,  it  limits  its  applicability  by
//   several thousands of variables.
//   From  the  other  side,  variables  count  is  the most limiting factor,
//   and dependence on constraint count is  much  more  lower. Assuming  that
//   constraint matrix is sparse, it may handle tens of thousands  of general
//   linear constraints.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     Eps     -   >= 0, stopping criteria. The algorithm stops  when   primal
//                 and dual infeasiblities as well as complementarity gap are
//                 less than Eps.
//
// IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
// BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
//
// NOTE: Passing EpsX == 0 will lead to automatic selection of small epsilon.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
// API: void minqpsetalgodenseipm(const minqpstate &state, const double eps);
void minqpsetalgodenseipm(minqpstate *state, double eps) {
   ae_assert(isfinite(eps), "MinQPSetAlgoDenseIPM: Eps is not finite number");
   ae_assert(eps >= 0.0, "MinQPSetAlgoDenseIPM: negative Eps");
   state->algokind = 5;
   state->veps = eps;
}

// This function tells QP solver to  use  SPARSE-IPM  QP algorithm  and  sets
// stopping criteria for the algorithm.
//
// This  algorithm  is  intended  for convex and semidefinite  problems  with
// large  variable  and  constraint  count  and  sparse  quadratic  term  and
// constraints. It is possible to have  some  limited  set  of  dense  linear
// constraints - they will be handled separately by dense BLAS - but the more
// dense constraints you have, the more time solver needs.
//
// IMPORTANT: internally this solver performs large  and  sparse  (N+M)x(N+M)
//            triangular factorization. So it expects both quadratic term and
//            constraints to be highly sparse. However, its  running  time is
//            influenced by BOTH fill factor and sparsity pattern.
//
//            Generally we expect that no more than few nonzero  elements per
//            row are present. However different sparsity patterns may result
//            in completely different running  times  even  given  same  fill
//            factor.
//
//            In many cases this algorithm outperforms DENSE-IPM by order  of
//            magnitude. However, in some cases you may  get  better  results
//            with DENSE-IPM even when solving sparse task.
//
// IMPORTANT: this algorithm won't work for nonconvex problems, use DENSE-AUL
//            or BLEIC-QP instead. If you try to  run  DENSE-IPM  on  problem
//            with  indefinite  matrix  (matrix having  at least one negative
//            eigenvalue) then depending on circumstances it may  either  (a)
//            stall at some  arbitrary  point,  or  (b)  throw  exception  on
//            failure of Cholesky decomposition.
//
// ALGORITHM FEATURES:
//
// * supports  box  and  dense/sparse  general   linear   equality/inequality
//   constraints
// * specializes on large-scale sparse problems
//
// ALGORITHM OUTLINE:
//
// * this  algorithm  is  our implementation  of  interior  point  method  as
//   formulated by  R.J.Vanderbei, with minor modifications to the  algorithm
//   (damped Newton directions are extensively used)
// * like all interior point methods, this algorithm  tends  to  converge  in
//   roughly same number of iterations (between 15 and 50) independently from
//   the problem dimensionality
//
// ALGORITHM LIMITATIONS:
//
// * this algorithm may handle moderate number  of dense constraints, usually
//   no more than a thousand of dense ones without losing its efficiency.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     Eps     -   >= 0, stopping criteria. The algorithm stops  when   primal
//                 and dual infeasiblities as well as complementarity gap are
//                 less than Eps.
//
// IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
// BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
//
// NOTE: Passing EpsX == 0 will lead to automatic selection of small epsilon.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
// API: void minqpsetalgosparseipm(const minqpstate &state, const double eps);
void minqpsetalgosparseipm(minqpstate *state, double eps) {
   ae_assert(isfinite(eps), "MinQPSetAlgoSparseIPM: Eps is not finite number");
   ae_assert(eps >= 0.0, "MinQPSetAlgoSparseIPM: negative Eps");
   state->algokind = 6;
   state->veps = eps;
}

// This function tells solver to use QuickQP  algorithm:  special  extra-fast
// algorithm for problems with box-only constrants. It may  solve  non-convex
// problems as long as they are bounded from below under constraints.
//
// ALGORITHM FEATURES:
// * several times faster than DENSE-IPM when running on box-only problem
// * utilizes accelerated methods for activation of constraints.
// * supports dense and sparse QP problems
// * supports ONLY box constraints; general linear constraints are NOT
//   supported by this solver
// * can solve all types of problems  (convex,  semidefinite,  nonconvex)  as
//   long as they are bounded from below under constraints.
//   Say, it is possible to solve "min{-x^2} subject to -1 <= x <= +1".
//   In convex/semidefinite case global minimum  is  returned,  in  nonconvex
//   case - algorithm returns one of the local minimums.
//
// ALGORITHM OUTLINE:
//
// * algorithm  performs  two kinds of iterations: constrained CG  iterations
//   and constrained Newton iterations
// * initially it performs small number of constrained CG  iterations,  which
//   can efficiently activate/deactivate multiple constraints
// * after CG phase algorithm tries to calculate Cholesky  decomposition  and
//   to perform several constrained Newton steps. If  Cholesky  decomposition
//   failed (matrix is indefinite even under constraints),  we  perform  more
//   CG iterations until we converge to such set of constraints  that  system
//   matrix becomes  positive  definite.  Constrained  Newton  steps  greatly
//   increase convergence speed and precision.
// * algorithm interleaves CG and Newton iterations which  allows  to  handle
//   indefinite matrices (CG phase) and quickly converge after final  set  of
//   constraints is found (Newton phase). Combination of CG and Newton phases
//   is called "outer iteration".
// * it is possible to turn off Newton  phase  (beneficial  for  semidefinite
//   problems - Cholesky decomposition will fail too often)
//
// ALGORITHM LIMITATIONS:
//
// * algorithm does not support general  linear  constraints;  only  box ones
//   are supported
// * Cholesky decomposition for sparse problems  is  performed  with  Skyline
//   Cholesky solver, which is intended for low-profile matrices. No profile-
//   reducing reordering of variables is performed in this version of ALGLIB.
// * problems with near-zero negative eigenvalues (or exacty zero  ones)  may
//   experience about 2-3x performance penalty. The reason is  that  Cholesky
//   decomposition can not be performed until we identify directions of  zero
//   and negative curvature and activate corresponding boundary constraints -
//   but we need a lot of trial and errors because these directions  are hard
//   to notice in the matrix spectrum.
//   In this case you may turn off Newton phase of algorithm.
//   Large negative eigenvalues  are  not  an  issue,  so  highly  non-convex
//   problems can be solved very efficiently.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsG    -   >= 0
//                 The  subroutine  finishes  its  work   if   the  condition
//                 |v| < EpsG is satisfied, where:
//                 * |.| means Euclidian norm
//                 * v - scaled constrained gradient vector, v[i] == g[i]*s[i]
//                 * g - gradient
//                 * s - scaling coefficients set by MinQPSetScale()
//     EpsF    -   >= 0
//                 The  subroutine  finishes its work if exploratory steepest
//                 descent  step  on  k+1-th iteration  satisfies   following
//                 condition:  |F(k+1)-F(k)| <= EpsF*max{|F(k)|,|F(k+1)|,1}
//     EpsX    -   >= 0
//                 The  subroutine  finishes its work if exploratory steepest
//                 descent  step  on  k+1-th iteration  satisfies   following
//                 condition:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - step vector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinQPSetScale()
//     MaxOuterIts-maximum number of OUTER iterations.  One  outer  iteration
//                 includes some amount of CG iterations (from 5 to  ~N)  and
//                 one or several (usually small amount) Newton steps.  Thus,
//                 one outer iteration has high cost, but can greatly  reduce
//                 funcation value.
//                 Use 0 if you do not want to limit number of outer iterations.
//     UseNewton-  use Newton phase or not:
//                 * Newton phase improves performance of  positive  definite
//                   dense problems (about 2 times improvement can be observed)
//                 * can result in some performance penalty  on  semidefinite
//                   or slightly negative definite  problems  -  each  Newton
//                   phase will bring no improvement (Cholesky failure),  but
//                   still will require computational time.
//                 * if you doubt, you can turn off this  phase  -  optimizer
//                   will retain its most of its high speed.
//
// IT IS VERY IMPORTANT TO CALL MinQPSetScale() WHEN YOU USE THIS  ALGORITHM
// BECAUSE ITS STOPPING CRITERIA ARE SCALE-DEPENDENT!
//
// Passing EpsG == 0, EpsF == 0 and EpsX == 0 and MaxIts == 0 (simultaneously) will lead
// to automatic stopping criterion selection (presently it is  small    step
// length, but it may change in the future versions of ALGLIB).
// ALGLIB: Copyright 22.05.2014 by Sergey Bochkanov
// API: void minqpsetalgoquickqp(const minqpstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxouterits, const bool usenewton);
void minqpsetalgoquickqp(minqpstate *state, double epsg, double epsf, double epsx, ae_int_t maxouterits, bool usenewton) {
   ae_assert(isfinite(epsg), "MinQPSetAlgoQuickQP: EpsG is not finite number");
   ae_assert(epsg >= 0.0, "MinQPSetAlgoQuickQP: negative EpsG");
   ae_assert(isfinite(epsf), "MinQPSetAlgoQuickQP: EpsF is not finite number");
   ae_assert(epsf >= 0.0, "MinQPSetAlgoQuickQP: negative EpsF");
   ae_assert(isfinite(epsx), "MinQPSetAlgoQuickQP: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinQPSetAlgoQuickQP: negative EpsX");
   ae_assert(maxouterits >= 0, "MinQPSetAlgoQuickQP: negative MaxOuterIts!");
   state->algokind = 3;
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxouterits == 0) {
      epsx = 0.000001;
   }
   state->qqpsettingsuser.maxouterits = maxouterits;
   state->qqpsettingsuser.epsg = epsg;
   state->qqpsettingsuser.epsf = epsf;
   state->qqpsettingsuser.epsx = epsx;
   state->qqpsettingsuser.cnphase = usenewton;
}

// CONSTRAINED QUADRATIC PROGRAMMING
// The subroutine creates QP optimizer. After initial creation,  it  contains
// default optimization problem with zero quadratic and linear terms  and  no
// constraints.
//
// In order to actually solve something you should:
// * set cost vector with minqpsetlinearterm()
// * set variable bounds with minqpsetbc() or minqpsetbcall()
// * specify constraint matrix with one of the following functions:
//   * modern API:
//     * minqpsetlc2()       for sparse two-sided constraints AL <= A*x <= AU
//     * minqpsetlc2dense()  for dense  two-sided constraints AL <= A*x <= AU
//     * minqpsetlc2mixed()  for mixed  two-sided constraints AL <= A*x <= AU
//     * minqpaddlc2dense()  to add one dense row to the dense constraint submatrix
//     * minqpaddlc2()       to add one sparse row to the sparse constraint submatrix
//     * minqpaddlc2sparsefromdense() to add one sparse row (passed as a dense array) to the sparse constraint submatrix
//   * legacy API:
//     * minqpsetlc()        for dense one-sided equality/inequality constraints
//     * minqpsetlcsparse()  for sparse one-sided equality/inequality constraints
//     * minqpsetlcmixed()   for mixed dense/sparse one-sided equality/inequality constraints
// * choose appropriate QP solver and set it  and  its stopping  criteria  by
//   means of minqpsetalgo??????() function
// * call minqpoptimize() to run the solver and  minqpresults()  to  get  the
//   solution vector and additional information.
//
// Following solvers are recommended for convex and semidefinite problems:
// * QuickQP for dense problems with box-only constraints (or no constraints
//   at all)
// * DENSE-IPM-QP for  convex  or  semidefinite  problems  with   medium  (up
//   to several thousands) variable count, dense/sparse  quadratic  term  and
//   any number  (up  to  many  thousands)  of  dense/sparse  general  linear
//   constraints
// * SPARSE-IPM-QP for convex  or  semidefinite  problems  with   large (many
//   thousands) variable count, sparse quadratic term AND linear constraints.
//
// If your problem happens to be nonconvex,  but  either  (a) is  effectively
// convexified under constraints,  or  (b)  has  unique  solution  even  with
// nonconvex target, then you can use:
// * QuickQP for dense nonconvex problems with box-only constraints
// * DENSE-AUL-QP  for   dense   nonconvex   problems  which  are effectively
//   convexified under constraints with up to several thousands of  variables
//   and any (small or large) number of general linear constraints
// * QP-BLEIC for dense/sparse problems with small (up to  several  hundreds)
//   number of general linear  constraints  and  arbitrarily  large  variable
//   count.
//
// Inputs:
//     N       -   problem size
//
// Outputs:
//     State   -   optimizer with zero quadratic/linear terms
//                 and no constraints
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpcreate(const ae_int_t n, minqpstate &state);
void minqpcreate(ae_int_t n, minqpstate *state) {
   ae_int_t i;
   SetObj(minqpstate, state);
   ae_assert(n >= 1, "MinQPCreate: N < 1");
// initialize QP solver
   state->n = n;
   state->mdense = 0;
   state->msparse = 0;
   state->repterminationtype = 0;
   state->absamax = 1.0;
   state->absasum = 1.0;
   state->absasum2 = 1.0;
   state->akind = 0;
   state->sparseaupper = false;
   cqminit(n, &state->a);
   ae_vector_set_length(&state->b, n);
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->havebndl, n);
   ae_vector_set_length(&state->havebndu, n);
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->startx, n);
   ae_vector_set_length(&state->xorigin, n);
   ae_vector_set_length(&state->xs, n);
   vectorsetlengthatleast(&state->replagbc, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = -INFINITY;
      state->bndu.xR[i] = +INFINITY;
      state->havebndl.xB[i] = false;
      state->havebndu.xB[i] = false;
      state->b.xR[i] = 0.0;
      state->startx.xR[i] = 0.0;
      state->xorigin.xR[i] = 0.0;
      state->s.xR[i] = 1.0;
      state->replagbc.xR[i] = 0.0;
   }
   state->stype = 0;
   state->havex = false;
   minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
   qqploaddefaults(n, &state->qqpsettingsuser);
   qpbleicloaddefaults(n, &state->qpbleicsettingsuser);
   qpdenseaulloaddefaults(n, &state->qpdenseaulsettingsuser);
   state->qpbleicfirstcall = true;
   state->dbgskipconstraintnormalization = false;
   state->veps = 0.0;
}

// Fast version of MinQPSetLinearTerm(), which doesn't check its arguments.
// For internal use only.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
void minqpsetlineartermfast(minqpstate *state, RVector *b) {
   ae_v_move(state->b.xR, 1, b->xR, 1, state->n);
}

// This function sets linear term for QP solver.
//
// By default, linear term is zero.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     B       -   linear term, array[N].
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetlinearterm(const minqpstate &state, const real_1d_array &b);
void minqpsetlinearterm(minqpstate *state, RVector *b) {
   ae_int_t n;
   n = state->n;
   ae_assert(b->cnt >= n, "MinQPSetLinearTerm: Length(B) < N");
   ae_assert(isfinitevector(b, n), "MinQPSetLinearTerm: B contains infinite or NaN elements");
   minqpsetlineartermfast(state, b);
}

// Fast version of MinQPSetQuadraticTerm(), which doesn't check its arguments.
//
// It accepts additional parameter - shift S, which allows to "shift"  matrix
// A by adding s*I to A. S must be positive (although it is not checked).
//
// For internal use only.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
void minqpsetquadratictermfast(minqpstate *state, RMatrix *a, bool isupper, double s) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   double v;
   ae_int_t j0;
   ae_int_t j1;
   n = state->n;
   state->akind = 0;
   cqmseta(&state->a, a, isupper, 1.0);
   if (s > 0.0) {
      vectorsetlengthatleast(&state->tmp0, n);
      for (i = 0; i < n; i++) {
         state->tmp0.xR[i] = a->xyR[i][i] + s;
      }
      cqmrewritedensediagonal(&state->a, &state->tmp0);
   }
// Estimate norm of A
// (it will be used later in the quadratic penalty function)
   state->absamax = 0.0;
   state->absasum = 0.0;
   state->absasum2 = 0.0;
   for (i = 0; i < n; i++) {
      if (isupper) {
         j0 = i;
         j1 = n - 1;
      } else {
         j0 = 0;
         j1 = i;
      }
      for (j = j0; j <= j1; j++) {
         v = fabs(a->xyR[i][j]);
         state->absamax = rmax2(state->absamax, v);
         state->absasum += v;
         state->absasum2 += v * v;
      }
   }
}

// This  function  sets  dense  quadratic  term  for  QP solver. By  default,
// quadratic term is zero.
//
// IMPORTANT:
//
// This solver minimizes following  function:
//     f(x) = 0.5*x'*A*x + b'*x.
// Note that quadratic term has 0.5 before it. So if  you  want  to  minimize
//     f(x) = x^2 + x
// you should rewrite your problem as follows:
//     f(x) = 0.5*(2*x^2) + x
// and your matrix A will be equal to [[2.0]], not to [[1.0]]
//
// Inputs:
//     State   -   structure which stores algorithm state
//     A       -   matrix, array[N,N]
//     IsUpper -   (optional) storage type:
//                 * if True, symmetric matrix  A  is  given  by  its  upper
//                   triangle, and the lower triangle isn't used
//                 * if False, symmetric matrix  A  is  given  by  its lower
//                   triangle, and the upper triangle isn't used
//                 * if not given, both lower and upper  triangles  must  be
//                   filled.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetquadraticterm(const minqpstate &state, const real_2d_array &a, const bool isupper);
// API: void minqpsetquadraticterm(const minqpstate &state, const real_2d_array &a);
void minqpsetquadraticterm(minqpstate *state, RMatrix *a, bool isupper) {
   ae_int_t n;
   n = state->n;
   ae_assert(a->rows >= n, "MinQPSetQuadraticTerm: Rows(A) < N");
   ae_assert(a->cols >= n, "MinQPSetQuadraticTerm: Cols(A) < N");
   ae_assert(isfinitertrmatrix(a, n, isupper), "MinQPSetQuadraticTerm: A contains infinite or NaN elements");
   minqpsetquadratictermfast(state, a, isupper, 0.0);
}

// This  function  sets  sparse  quadratic  term  for  QP solver. By default,
// quadratic  term  is  zero.  This  function  overrides  previous  calls  to
// minqpsetquadraticterm() or minqpsetquadratictermsparse().
//
// NOTE: dense solvers like DENSE-AUL-QP or DENSE-IPM-QP  will  convert  this
//       matrix to dense storage anyway.
//
// IMPORTANT:
//
// This solver minimizes following  function:
//     f(x) = 0.5*x'*A*x + b'*x.
// Note that quadratic term has 0.5 before it. So if  you  want  to  minimize
//     f(x) = x^2 + x
// you should rewrite your problem as follows:
//     f(x) = 0.5*(2*x^2) + x
// and your matrix A will be equal to [[2.0]], not to [[1.0]]
//
// Inputs:
//     State   -   structure which stores algorithm state
//     A       -   matrix, array[N,N]
//     IsUpper -   (optional) storage type:
//                 * if True, symmetric matrix  A  is  given  by  its  upper
//                   triangle, and the lower triangle isn't used
//                 * if False, symmetric matrix  A  is  given  by  its lower
//                   triangle, and the upper triangle isn't used
//                 * if not given, both lower and upper  triangles  must  be
//                   filled.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetquadratictermsparse(const minqpstate &state, const sparsematrix &a, const bool isupper);
void minqpsetquadratictermsparse(minqpstate *state, sparsematrix *a, bool isupper) {
   ae_int_t n;
   ae_int_t t0;
   ae_int_t t1;
   ae_int_t i;
   ae_int_t j;
   double v;
   n = state->n;
   ae_assert(sparsegetnrows(a) == n, "MinQPSetQuadraticTermSparse: Rows(A) != N");
   ae_assert(sparsegetncols(a) == n, "MinQPSetQuadraticTermSparse: Cols(A) != N");
   sparsecopytocrsbuf(a, &state->sparsea);
   state->sparseaupper = isupper;
   state->akind = 1;
// Estimate norm of A
// (it will be used later in the quadratic penalty function)
   state->absamax = 0.0;
   state->absasum = 0.0;
   state->absasum2 = 0.0;
   t0 = 0;
   t1 = 0;
   while (sparseenumerate(a, &t0, &t1, &i, &j, &v)) {
      if (i == j) {
      // Diagonal terms are counted only once
         state->absamax = rmax2(state->absamax, v);
         state->absasum += v;
         state->absasum2 += v * v;
      }
      if (isupper ? j > i : j < i) {
      // Offdiagonal terms are counted twice
         state->absamax = rmax2(state->absamax, v);
         state->absasum += 2.0 * v;
         state->absasum2 += 2.0 * v * v;
      }
   }
}

// Fast version of MinQPSetStartingPoint(), which doesn't check its arguments.
// For internal use only.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
void minqpsetstartingpointfast(minqpstate *state, RVector *x) {
   ae_int_t n;
   n = state->n;
   ae_v_move(state->startx.xR, 1, x->xR, 1, n);
   state->havex = true;
}

// This function sets starting point for QP solver. It is useful to have good
// initial approximation to the solution, because it will increase  speed  of
// convergence and identification of active constraints.
//
// NOTE: interior point solvers ignore initial point provided by user.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     X       -   starting point, array[N].
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetstartingpoint(const minqpstate &state, const real_1d_array &x);
void minqpsetstartingpoint(minqpstate *state, RVector *x) {
   ae_int_t n;
   n = state->n;
   ae_assert(x->cnt >= n, "MinQPSetStartingPoint: Length(B) < N");
   ae_assert(isfinitevector(x, n), "MinQPSetStartingPoint: X contains infinite or NaN elements");
   minqpsetstartingpointfast(state, x);
}

// Fast version of MinQPSetOrigin(), which doesn't check its arguments.
// For internal use only.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
void minqpsetoriginfast(minqpstate *state, RVector *xorigin) {
   ae_int_t n;
   n = state->n;
   ae_v_move(state->xorigin.xR, 1, xorigin->xR, 1, n);
}

// This  function sets origin for QP solver. By default, following QP program
// is solved:
//
//     min(0.5*x'*A*x+b'*x)
//
// This function allows to solve different problem:
//
//     min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
//
// Specification of non-zero origin affects function being minimized, but not
// constraints. Box and  linear  constraints  are  still  calculated  without
// origin.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     XOrigin -   origin, array[N].
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetorigin(const minqpstate &state, const real_1d_array &xorigin);
void minqpsetorigin(minqpstate *state, RVector *xorigin) {
   ae_int_t n;
   n = state->n;
   ae_assert(xorigin->cnt >= n, "MinQPSetOrigin: Length(B) < N");
   ae_assert(isfinitevector(xorigin, n), "MinQPSetOrigin: B contains infinite or NaN elements");
   minqpsetoriginfast(state, xorigin);
}

// This function sets scaling coefficients.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison  with  tolerances)  and  as
// preconditioner.
//
// Scale of the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the
//    function
//
// If you do not know how to choose scales of your variables, you can:
// * read www.alglib.net/optimization/scaling.php article
// * use minqpsetscaleautodiag(), which calculates scale  using  diagonal  of
//   the  quadratic  term:  S  is  set to 1/sqrt(diag(A)), which works well
//   sometimes.
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minqpsetscale(const minqpstate &state, const real_1d_array &s);
void minqpsetscale(minqpstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinQPSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinQPSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinQPSetScale: S contains zero elements");
   }
   for (i = 0; i < state->n; i++) {
      state->s.xR[i] = fabs(s->xR[i]);
   }
   state->stype = 0;
}

// This function sets automatic evaluation of variable scaling.
//
// IMPORTANT: this function works only for  matrices  with positive  diagonal
//            elements! Zero or negative elements will  result  in  -9  error
//            code  being  returned.  Specify  scale  vector  manually   with
//            minqpsetscale() in such cases.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison  with  tolerances)  and  as
// preconditioner.
//
// The  best  way  to  set  scaling  is  to manually specify variable scales.
// However, sometimes you just need quick-and-dirty solution  -  either  when
// you perform fast prototyping, or when you know your problem well  and  you
// are 100% sure that this quick solution is robust enough in your case.
//
// One such solution is to evaluate scale of I-th variable as 1/sqrt(A[i,i]),
// where A[i,i] is an I-th diagonal element of the quadratic term.
//
// Such approach works well sometimes, but you have to be careful here.
//
// Inputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 26.12.2017 by Sergey Bochkanov
// API: void minqpsetscaleautodiag(const minqpstate &state);
void minqpsetscaleautodiag(minqpstate *state) {
   state->stype = 1;
}

// This function sets box constraints for QP solver
//
// Box constraints are inactive by default (after  initial  creation).  After
// being  set,  they are  preserved until explicitly overwritten with another
// minqpsetbc()  or  minqpsetbcall()  call,  or  partially  overwritten  with
// minqpsetbci() call.
//
// Following types of constraints are supported:
//
//     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
//     fixed variable      x[i] == Bnd[i]          BndL[i] == BndU[i]
//     lower bound         BndL[i] <= x[i]         BndU[i] == +INF
//     upper bound         x[i] <= BndU[i]         BndL[i] == -INF
//     range               BndL[i] <= x[i] <= BndU[i]  ...
//     free variable       -                       BndL[i] == -INF, BndU[i] == +INF
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF (latter is recommended because
//                 it will allow solver to use better algorithm).
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF (latter is recommended because
//                 it will allow solver to use better algorithm).
//
// NOTE: infinite values can be specified by means of Double.PositiveInfinity
//       and  Double.NegativeInfinity  (in  C#)  and  +INFINITY   and
//       -INFINITY (in C++).
//
// NOTE: you may replace infinities by very small/very large values,  but  it
//       is not recommended because large numbers may introduce large numerical
//       errors in the algorithm.
//
// NOTE: if constraints for all variables are same you may use minqpsetbcall()
//       which allows to specify constraints without using arrays.
//
// NOTE: BndL > BndU will result in QP problem being recognized as infeasible.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetbc(const minqpstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minqpsetbc(minqpstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(bndl->cnt >= n, "MinQPSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinQPSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinQPSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinQPSetBC: BndU contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->havebndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->havebndu.xB[i] = isfinite(bndu->xR[i]);
   }
}

// This function sets box constraints for QP solver (all variables  at  once,
// same constraints for all variables)
//
// Box constraints are inactive by default (after  initial  creation).  After
// being  set,  they are  preserved until explicitly overwritten with another
// minqpsetbc()  or  minqpsetbcall()  call,  or  partially  overwritten  with
// minqpsetbci() call.
//
// Following types of constraints are supported:
//
//     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
//     fixed variable      x[i] == Bnd             BndL == BndU
//     lower bound         BndL <= x[i]            BndU == +INF
//     upper bound         x[i] <= BndU            BndL == -INF
//     range               BndL <= x[i] <= BndU    ...
//     free variable       -                       BndL == -INF, BndU == +INF
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bound, same for all variables
//     BndU    -   upper bound, same for all variables
//
// NOTE: infinite values can be specified by means of Double.PositiveInfinity
//       and  Double.NegativeInfinity  (in  C#)  and  +INFINITY   and
//       -INFINITY (in C++).
//
// NOTE: you may replace infinities by very small/very large values,  but  it
//       is not recommended because large numbers may introduce large numerical
//       errors in the algorithm.
//
// NOTE: BndL > BndU will result in QP problem being recognized as infeasible.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetbcall(const minqpstate &state, const double bndl, const double bndu);
void minqpsetbcall(minqpstate *state, double bndl, double bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(isfinite(bndl) || isneginf(bndl), "MinQPSetBCAll: BndL is NAN or +INF");
   ae_assert(isfinite(bndu) || isposinf(bndu), "MinQPSetBCAll: BndU is NAN or -INF");
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = bndl;
      state->bndu.xR[i] = bndu;
      state->havebndl.xB[i] = isfinite(bndl);
      state->havebndu.xB[i] = isfinite(bndu);
   }
}

// This function sets box constraints for I-th variable (other variables are
// not modified).
//
// Following types of constraints are supported:
//
//     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
//     fixed variable      x[i] == Bnd             BndL == BndU
//     lower bound         BndL <= x[i]            BndU == +INF
//     upper bound         x[i] <= BndU            BndL == -INF
//     range               BndL <= x[i] <= BndU    ...
//     free variable       -                       BndL == -INF, BndU == +INF
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bound
//     BndU    -   upper bound
//
// NOTE: infinite values can be specified by means of Double.PositiveInfinity
//       and  Double.NegativeInfinity  (in  C#)  and  +INFINITY   and
//       -INFINITY (in C++).
//
// NOTE: you may replace infinities by very small/very large values,  but  it
//       is not recommended because large numbers may introduce large numerical
//       errors in the algorithm.
//
// NOTE: BndL > BndU will result in QP problem being recognized as infeasible.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpsetbci(const minqpstate &state, const ae_int_t i, const double bndl, const double bndu);
void minqpsetbci(minqpstate *state, ae_int_t i, double bndl, double bndu) {
   ae_assert(i >= 0 && i < state->n, "MinQPSetBCi: I is outside of [0,N)");
   ae_assert(isfinite(bndl) || isneginf(bndl), "MinQPSetBCi: BndL is NAN or +INF");
   ae_assert(isfinite(bndu) || isposinf(bndu), "MinQPSetBCi: BndU is NAN or -INF");
   state->bndl.xR[i] = bndl;
   state->bndu.xR[i] = bndu;
   state->havebndl.xB[i] = isfinite(bndl);
   state->havebndu.xB[i] = isfinite(bndu);
}

// This function sets mixed linear constraints, which include a set of  dense
// rows, and a set of sparse rows.
//
// This  function  overrides  results  of  previous  calls  to  minqpsetlc(),
// minqpsetlcsparse() and minqpsetlcmixed().
//
// This function may be useful if constraint matrix includes large number  of
// both types of rows - dense and sparse. If you have just a few sparse rows,
// you  may  represent  them  in  dense  format  without losing  performance.
// Similarly, if you have just a few dense rows, you may store them in sparse
// format with almost same performance.
//
// Inputs:
//     State   -   structure previously allocated with MinQPCreate call.
//     SparseC -   linear constraints, sparse  matrix with dimensions EXACTLY
//                 EQUAL TO [SparseK,N+1].  Each  row  of  C  represents  one
//                 constraint, either equality or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     SparseCT-   type of sparse constraints, array[K]:
//                 * if SparseCT[i] > 0, then I-th constraint is SparseC[i,*]*x >= SparseC[i,n+1]
//                 * if SparseCT[i] == 0, then I-th constraint is SparseC[i,*]*x  = SparseC[i,n+1]
//                 * if SparseCT[i] < 0, then I-th constraint is SparseC[i,*]*x <= SparseC[i,n+1]
//     SparseK -   number of sparse equality/inequality constraints, K >= 0
//     DenseC  -   dense linear constraints, array[K,N+1].
//                 Each row of DenseC represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of DenseC (including right part) must be finite.
//     DenseCT -   type of constraints, array[K]:
//                 * if DenseCT[i] > 0, then I-th constraint is DenseC[i,*]*x >= DenseC[i,n+1]
//                 * if DenseCT[i] == 0, then I-th constraint is DenseC[i,*]*x  = DenseC[i,n+1]
//                 * if DenseCT[i] < 0, then I-th constraint is DenseC[i,*]*x <= DenseC[i,n+1]
//     DenseK  -   number of equality/inequality constraints, DenseK >= 0
//
// NOTE 1: linear (non-box) constraints  are  satisfied only approximately  -
//         there always exists some violation due  to  numerical  errors  and
//         algorithmic limitations (BLEIC-QP solver is most  precise,  AUL-QP
//         solver is less precise).
//
// NOTE 2: due to backward compatibility reasons SparseC can be  larger  than
//         [SparseK,N+1]. In this case only leading  [SparseK,N+1]  submatrix
//         will be  used.  However,  the  rest  of  ALGLIB  has  more  strict
//         requirements on the input size, so we recommend you to pass sparse
//         term whose size exactly matches algorithm expectations.
// ALGLIB: Copyright 22.08.2016 by Sergey Bochkanov
// API: void minqpsetlcmixed(const minqpstate &state, const sparsematrix &sparsec, const integer_1d_array &sparsect, const ae_int_t sparsek, const real_2d_array &densec, const integer_1d_array &densect, const ae_int_t densek);
void minqpsetlcmixed(minqpstate *state, sparsematrix *sparsec, ZVector *sparsect, ae_int_t sparsek, RMatrix *densec, ZVector *densect, ae_int_t densek) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   double v;
   ae_int_t t0;
   ae_int_t t1;
   ae_int_t nnz;
   EnFrame();
   NewZVector(srcidx, 0);
   NewZVector(dstidx, 0);
   NewRVector(s, 0);
   NewZVector(rs, 0);
   NewZVector(eoffs, 0);
   NewZVector(roffs, 0);
   NewRVector(v2, 0);
   NewZVector(eidx, 0);
   NewRVector(eval, 0);
   n = state->n;
// First, check for errors in the inputs
   ae_assert(densek >= 0, "MinQPSetLCMixed: K < 0");
   ae_assert(densek == 0 || densec->cols > n, "MinQPSetLCMixed: Cols(C) <= N");
   ae_assert(densec->rows >= densek, "MinQPSetLCMixed: Rows(DenseC) < DenseK");
   ae_assert(densect->cnt >= densek, "MinQPSetLCMixed: Length(DenseCT) < DenseK");
   ae_assert(apservisfinitematrix(densec, densek, n + 1), "MinQPSetLCMixed: C contains infinite or NaN values!");
   ae_assert(sparsek >= 0, "MinQPSetLCMixed: SparseK < 0");
   ae_assert(sparsek == 0 || sparsegetncols(sparsec) > n, "MinQPSetLCMixed: Cols(SparseC) <= N");
   ae_assert(sparsek == 0 || sparsegetnrows(sparsec) >= sparsek, "MinQPSetLCMixed: Rows(SparseC) < SparseK");
   ae_assert(sparsect->cnt >= sparsek, "MinQPSetLCMixed: Length(SparseCT) < SparseK");
// Allocate place for Lagrange multipliers, fill by zero
   vectorsetlengthatleast(&state->replaglc, densek + sparsek);
   for (i = 0; i < densek + sparsek; i++) {
      state->replaglc.xR[i] = 0.0;
   }
// Init
   ae_vector_set_length(&state->cl, densek + sparsek);
   ae_vector_set_length(&state->cu, densek + sparsek);
   state->mdense = densek;
   state->msparse = sparsek;
   if (sparsek > 0) {
   // Evaluate row sizes for new storage
      ae_vector_set_length(&rs, sparsek);
      for (i = 0; i < sparsek; i++) {
         rs.xZ[i] = 0;
      }
      t0 = 0;
      t1 = 0;
      nnz = 0;
      while (sparseenumerate(sparsec, &t0, &t1, &i, &j, &v)) {
         if (i > sparsek - 1 || j > n - 1) {
            continue;
         }
         ae_assert(isfinite(v), "MinQPSetLCSparse: C contains infinite or NAN values");
         nnz++;
         rs.xZ[i]++;
      }
   // Prepare new sparse CRS storage, copy leading SparseK*N submatrix into the storage
      for (i = 0; i < sparsek; i++) {
         state->cl.xR[i] = 0.0;
         state->cu.xR[i] = 0.0;
      }
      state->sparsec.m = sparsek;
      state->sparsec.n = n;
      vectorsetlengthatleast(&state->sparsec.ridx, sparsek + 1);
      vectorsetlengthatleast(&state->sparsec.idx, nnz);
      vectorsetlengthatleast(&state->sparsec.vals, nnz);
      ae_vector_set_length(&eoffs, sparsek + 1);
      state->sparsec.ridx.xZ[0] = 0;
      eoffs.xZ[0] = 0;
      for (i = 1; i <= sparsek; i++) {
         state->sparsec.ridx.xZ[i] = state->sparsec.ridx.xZ[i - 1] + rs.xZ[i - 1];
         eoffs.xZ[i] = state->sparsec.ridx.xZ[i];
      }
      t0 = 0;
      t1 = 0;
      while (sparseenumerate(sparsec, &t0, &t1, &i, &j, &v)) {
         if (i > sparsek - 1 || j > n) {
            continue;
         }
         if (j < n) {
         // Copy left part of constraint
            j0 = eoffs.xZ[i];
            state->sparsec.idx.xZ[j0] = j;
            state->sparsec.vals.xR[j0] = v;
            eoffs.xZ[i] = j0 + 1;
         } else {
         // Handle right part of the constraint
            state->cl.xR[i] = v;
            state->cu.xR[i] = v;
         }
      }
      for (i = 0; i < sparsek; i++) {
         ae_assert(eoffs.xZ[i] == state->sparsec.ridx.xZ[i + 1], "MinQP: critical integrity check failed (sparse copying)");
      }
      sparsecreatecrsinplace(&state->sparsec);
      for (i = 0; i < sparsek; i++) {
         if (sparsect->xZ[i] > 0) {
            state->cu.xR[i] = +INFINITY;
         }
         if (sparsect->xZ[i] < 0) {
            state->cl.xR[i] = -INFINITY;
         }
      }
   }
   if (densek > 0) {
   // Copy dense constraints
      matrixsetlengthatleast(&state->densec, densek, n);
      for (i = 0; i < densek; i++) {
         for (j = 0; j < n; j++) {
            state->densec.xyR[i][j] = densec->xyR[i][j];
         }
         if (densect->xZ[i] > 0) {
            state->cl.xR[sparsek + i] = densec->xyR[i][n];
            state->cu.xR[sparsek + i] = +INFINITY;
            continue;
         }
         if (densect->xZ[i] < 0) {
            state->cl.xR[sparsek + i] = -INFINITY;
            state->cu.xR[sparsek + i] = densec->xyR[i][n];
            continue;
         }
         state->cl.xR[sparsek + i] = densec->xyR[i][n];
         state->cu.xR[sparsek + i] = densec->xyR[i][n];
      }
   }
   DeFrame();
}

// This function provides legacy API for specification of mixed  dense/sparse
// linear constraints.
//
// New conventions used by ALGLIB since release  3.16.0  state  that  set  of
// sparse constraints comes first,  followed  by  set  of  dense  ones.  This
// convention is essential when you talk about things like order of  Lagrange
// multipliers.
//
// However, legacy API accepted mixed  constraints  in  reverse  order.  This
// function is here to simplify situation with code relying on legacy API. It
// simply accepts constraints in one order (old) and passes them to new  API,
// now in correct order.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
// API: void minqpsetlcmixedlegacy(const minqpstate &state, const real_2d_array &densec, const integer_1d_array &densect, const ae_int_t densek, const sparsematrix &sparsec, const integer_1d_array &sparsect, const ae_int_t sparsek);
void minqpsetlcmixedlegacy(minqpstate *state, RMatrix *densec, ZVector *densect, ae_int_t densek, sparsematrix *sparsec, ZVector *sparsect, ae_int_t sparsek) {
   minqpsetlcmixed(state, sparsec, sparsect, sparsek, densec, densect, densek);
}

// This function sets sparse linear constraints for QP optimizer.
//
// This  function  overrides  results  of  previous  calls  to  minqpsetlc(),
// minqpsetlcsparse() and minqpsetlcmixed().  After  call  to  this  function
// all non-box constraints are dropped, and you have only  those  constraints
// which were specified in the present call.
//
// If you want  to  specify  mixed  (with  dense  and  sparse  terms)  linear
// constraints, you should call minqpsetlcmixed().
//
// Inputs:
//     State   -   structure previously allocated with MinQPCreate call.
//     C       -   linear  constraints,  sparse  matrix  with  dimensions  at
//                 least [K,N+1]. If matrix has  larger  size,  only  leading
//                 Kx(N+1) rectangle is used.
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n+1]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n+1]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n+1]
//     K       -   number of equality/inequality constraints, K >= 0
//
// NOTE 1: linear (non-bound) constraints are satisfied only approximately  -
//         there always exists some violation due  to  numerical  errors  and
//         algorithmic limitations (BLEIC-QP solver is most  precise,  AUL-QP
//         solver is less precise).
// ALGLIB: Copyright 22.08.2016 by Sergey Bochkanov
// API: void minqpsetlcsparse(const minqpstate &state, const sparsematrix &c, const integer_1d_array &ct, const ae_int_t k);
void minqpsetlcsparse(minqpstate *state, sparsematrix *c, ZVector *ct, ae_int_t k) {
   EnFrame();
   NewRMatrix(dummyc, 0, 0);
   NewZVector(dummyct, 0);
   minqpsetlcmixed(state, c, ct, k, &dummyc, &dummyct, 0);
   DeFrame();
}

// This function sets dense linear constraints for QP optimizer.
//
// This  function  overrides  results  of  previous  calls  to  minqpsetlc(),
// minqpsetlcsparse() and minqpsetlcmixed().  After  call  to  this  function
// all non-box constraints are dropped, and you have only  those  constraints
// which were specified in the present call.
//
// If you want  to  specify  mixed  (with  dense  and  sparse  terms)  linear
// constraints, you should call minqpsetlcmixed().
//
// Inputs:
//     State   -   structure previously allocated with MinQPCreate call.
//     C       -   linear constraints, array[K,N+1].
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n+1]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n+1]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n+1]
//     K       -   number of equality/inequality constraints, K >= 0:
//                 * if given, only leading K elements of C/CT are used
//                 * if not given, automatically determined from sizes of C/CT
//
// NOTE 1: linear (non-bound) constraints are satisfied only approximately  -
//         there always exists some violation due  to  numerical  errors  and
//         algorithmic limitations (BLEIC-QP solver is most  precise,  AUL-QP
//         solver is less precise).
// ALGLIB: Copyright 19.06.2012 by Sergey Bochkanov
// API: void minqpsetlc(const minqpstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k);
// API: void minqpsetlc(const minqpstate &state, const real_2d_array &c, const integer_1d_array &ct);
void minqpsetlc(minqpstate *state, RMatrix *c, ZVector *ct, ae_int_t k) {
   EnFrame();
   NewObj(sparsematrix, dummyc);
   NewZVector(dummyct, 0);
   minqpsetlcmixed(state, &dummyc, &dummyct, 0, c, ct, k);
   DeFrame();
}

// This  function  sets  two-sided linear  constraints  AL <= A*x <= AU  with
// mixed constraining matrix A including sparse part (first SparseK rows) and
// dense part (last DenseK rows). Recommended for large-scale problems.
//
// This  function  overwrites  linear  (non-box)  constraints set by previous
// calls (if such calls were made).
//
// This function may be useful if constraint matrix includes large number  of
// both types of rows - dense and sparse. If you have just a few sparse rows,
// you  may  represent  them  in  dense  format  without losing  performance.
// Similarly, if you have just a few dense rows, you may store them in sparse
// format with almost same performance.
//
// Inputs:
//     State   -   structure previously allocated with minqpcreate() call.
//     SparseA -   sparse matrix with size [K,N] (exactly!).
//                 Each row of A represents one general linear constraint.
//                 A can be stored in any sparse storage format.
//     SparseK -   number of sparse constraints, SparseK >= 0
//     DenseA  -   linear constraints, array[K,N], set of dense constraints.
//                 Each row of A represents one general linear constraint.
//     DenseK  -   number of dense constraints, DenseK >= 0
//     AL, AU  -   lower and upper bounds, array[SparseK+DenseK], with former
//                 SparseK elements corresponding to sparse constraints,  and
//                 latter DenseK elements corresponding to dense constraints;
//                 * AL[i] == AU[i] => equality constraint Ai*x
//                 * AL[i] < AU[i]  => two-sided constraint AL[i] <= Ai*x <= AU[i]
//                 * AL[i] == -INF  => one-sided constraint Ai*x <= AU[i]
//                 * AU[i] == +INF  => one-sided constraint AL[i] <= Ai*x
//                 * AL[i] == -INF, AU[i] == +INF => constraint is ignored
//     K       -   number  of equality/inequality constraints, K >= 0.  If  K == 0
//                 is specified, A, AL, AU are ignored.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
// API: void minqpsetlc2mixed(const minqpstate &state, const sparsematrix &sparsea, const ae_int_t ksparse, const real_2d_array &densea, const ae_int_t kdense, const real_1d_array &al, const real_1d_array &au);
void minqpsetlc2mixed(minqpstate *state, sparsematrix *sparsea, ae_int_t ksparse, RMatrix *densea, ae_int_t kdense, RVector *al, RVector *au) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   n = state->n;
   m = kdense + ksparse;
// Check input arguments
   ae_assert(ksparse >= 0, "MinQPSetLC2Mixed: KSparse < 0");
   ae_assert(ksparse == 0 || sparsegetncols(sparsea) == n, "MinQPSetLC2: Cols(SparseA) != N");
   ae_assert(ksparse == 0 || sparsegetnrows(sparsea) == ksparse, "MinQPSetLC2: Rows(SparseA) != K");
   ae_assert(kdense >= 0, "MinQPSetLC2Mixed: KDense < 0");
   ae_assert(kdense == 0 || densea->cols >= n, "MinQPSetLC2Mixed: Cols(DenseA) < N");
   ae_assert(kdense == 0 || densea->rows >= kdense, "MinQPSetLC2Mixed: Rows(DenseA) < K");
   ae_assert(apservisfinitematrix(densea, kdense, n), "MinQPSetLC2Mixed: DenseA contains infinite or NaN values!");
   ae_assert(al->cnt >= kdense + ksparse, "MinQPSetLC2Mixed: Length(AL) < K");
   ae_assert(au->cnt >= kdense + ksparse, "MinQPSetLC2Mixed: Length(AU) < K");
   for (i = 0; i < m; i++) {
      ae_assert(isfinite(al->xR[i]) || isneginf(al->xR[i]), "MinQPSetLC2Mixed: AL contains NAN or +INF");
      ae_assert(isfinite(au->xR[i]) || isposinf(au->xR[i]), "MinQPSetLC2Mixed: AU contains NAN or -INF");
   }
// Allocate place for Lagrange multipliers, fill by zero
   vectorsetlengthatleast(&state->replaglc, kdense + ksparse);
   for (i = 0; i < kdense + ksparse; i++) {
      state->replaglc.xR[i] = 0.0;
   }
// Quick exit if needed
   if (m == 0) {
      state->mdense = 0;
      state->msparse = 0;
      return;
   }
// Prepare
   vectorsetlengthatleast(&state->cl, m);
   vectorsetlengthatleast(&state->cu, m);
   for (i = 0; i < m; i++) {
      state->cl.xR[i] = al->xR[i];
      state->cu.xR[i] = au->xR[i];
   }
   state->mdense = kdense;
   state->msparse = ksparse;
// Copy dense and sparse terms
   if (ksparse > 0) {
      sparsecopytocrsbuf(sparsea, &state->sparsec);
   }
   if (kdense > 0) {
      matrixsetlengthatleast(&state->densec, kdense, n);
      rmatrixcopy(kdense, n, densea, 0, 0, &state->densec, 0, 0);
   }
}

// This function sets two-sided linear constraints AL <= A*x <= AU with dense
// constraint matrix A.
//
// NOTE: knowing  that  constraint  matrix  is  dense  helps  some QP solvers
//       (especially modern IPM method) to utilize efficient  dense  Level  3
//       BLAS for dense parts of the problem. If your problem has both  dense
//       and sparse constraints, you  can  use  minqpsetlc2mixed()  function,
//       which will result in dense algebra being applied to dense terms, and
//       sparse sparse linear algebra applied to sparse terms.
//
// Inputs:
//     State   -   structure previously allocated with minqpcreate() call.
//     A       -   linear constraints, array[K,N]. Each row of  A  represents
//                 one  constraint. One-sided  inequality   constraints, two-
//                 sided inequality  constraints,  equality  constraints  are
//                 supported (see below)
//     AL, AU  -   lower and upper bounds, array[K];
//                 * AL[i] == AU[i] => equality constraint Ai*x
//                 * AL[i] < AU[i]  => two-sided constraint AL[i] <= Ai*x <= AU[i]
//                 * AL[i] == -INF  => one-sided constraint Ai*x <= AU[i]
//                 * AU[i] == +INF  => one-sided constraint AL[i] <= Ai*x
//                 * AL[i] == -INF, AU[i] == +INF => constraint is ignored
//     K       -   number of equality/inequality constraints,  K >= 0;  if  not
//                 given, inferred from sizes of A, AL, AU.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
// API: void minqpsetlc2dense(const minqpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k);
// API: void minqpsetlc2dense(const minqpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au);
void minqpsetlc2dense(minqpstate *state, RMatrix *a, RVector *al, RVector *au, ae_int_t k) {
   minqpsetlc2mixed(state, &state->dummysparse, 0, a, k, al, au);
}

// This  function  sets  two-sided linear  constraints  AL <= A*x <= AU  with
// sparse constraining matrix A. Recommended for large-scale problems.
//
// This  function  overwrites  linear  (non-box)  constraints set by previous
// calls (if such calls were made).
//
// Inputs:
//     State   -   structure previously allocated with minqpcreate() call.
//     A       -   sparse matrix with size [K,N] (exactly!).
//                 Each row of A represents one general linear constraint.
//                 A can be stored in any sparse storage format.
//     AL, AU  -   lower and upper bounds, array[K];
//                 * AL[i] == AU[i] => equality constraint Ai*x
//                 * AL[i] < AU[i]  => two-sided constraint AL[i] <= Ai*x <= AU[i]
//                 * AL[i] == -INF  => one-sided constraint Ai*x <= AU[i]
//                 * AU[i] == +INF  => one-sided constraint AL[i] <= Ai*x
//                 * AL[i] == -INF, AU[i] == +INF => constraint is ignored
//     K       -   number  of equality/inequality constraints, K >= 0.  If  K == 0
//                 is specified, A, AL, AU are ignored.
// ALGLIB: Copyright 01.11.2019 by Sergey Bochkanov
// API: void minqpsetlc2(const minqpstate &state, const sparsematrix &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k);
void minqpsetlc2(minqpstate *state, sparsematrix *a, RVector *al, RVector *au, ae_int_t k) {
   minqpsetlc2mixed(state, a, k, &state->dummyr2, 0, al, au);
}

// This function appends two-sided linear constraint  AL <= A*x <= AU  to the
// matrix of currently present dense constraints.
//
// Inputs:
//     State   -   structure previously allocated with minqpcreate() call.
//     A       -   linear constraint coefficient, array[N], right side is NOT
//                 included.
//     AL, AU  -   lower and upper bounds;
//                 * AL == AU   => equality constraint Ai*x
//                 * AL < AU    => two-sided constraint AL <= A*x <= AU
//                 * AL == -INF => one-sided constraint Ai*x <= AU
//                 * AU == +INF => one-sided constraint AL <= Ai*x
//                 * AL == -INF, AU == +INF => constraint is ignored
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minqpaddlc2dense(const minqpstate &state, const real_1d_array &a, const double al, const double au);
void minqpaddlc2dense(minqpstate *state, RVector *a, double al, double au) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(a->cnt >= n, "MinQPAddLC2Dense: Length(A) < N");
   ae_assert(isfinitevector(a, n), "MinQPAddLC2Dense: A contains infinite or NaN values!");
   ae_assert(isfinite(al) || isneginf(al), "MinQPAddLC2Dense: AL is NAN or +INF");
   ae_assert(isfinite(au) || isposinf(au), "MinQPAddLC2Dense: AU is NAN or -INF");
   rvectorgrowto(&state->cl, state->msparse + state->mdense + 1);
   rvectorgrowto(&state->cu, state->msparse + state->mdense + 1);
   rvectorgrowto(&state->replaglc, state->msparse + state->mdense + 1);
   rmatrixgrowrowsto(&state->densec, state->mdense + 1, n);
   for (i = 0; i < n; i++) {
      state->densec.xyR[state->mdense][i] = a->xR[i];
   }
   state->cl.xR[state->msparse + state->mdense] = al;
   state->cu.xR[state->msparse + state->mdense] = au;
   state->replaglc.xR[state->msparse + state->mdense] = 0.0;
   state->mdense++;
}

// This function appends two-sided linear constraint  AL <= A*x <= AU  to the
// list of currently present sparse constraints.
//
// Constraint is passed in compressed format: as list of non-zero entries  of
// coefficient vector A. Such approach is more efficient than  dense  storage
// for highly sparse constraint vectors.
//
// Inputs:
//     State   -   structure previously allocated with minqpcreate() call.
//     IdxA    -   array[NNZ], indexes of non-zero elements of A:
//                 * can be unsorted
//                 * can include duplicate indexes (corresponding entries  of
//                   ValA[] will be summed)
//     ValA    -   array[NNZ], values of non-zero elements of A
//     NNZ     -   number of non-zero coefficients in A
//     AL, AU  -   lower and upper bounds;
//                 * AL == AU   => equality constraint A*x
//                 * AL < AU    => two-sided constraint AL <= A*x <= AU
//                 * AL == -INF => one-sided constraint A*x <= AU
//                 * AU == +INF => one-sided constraint AL <= A*x
//                 * AL == -INF, AU == +INF => constraint is ignored
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minqpaddlc2(const minqpstate &state, const integer_1d_array &idxa, const real_1d_array &vala, const ae_int_t nnz, const double al, const double au);
void minqpaddlc2(minqpstate *state, ZVector *idxa, RVector *vala, ae_int_t nnz, double al, double au) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t offs;
   ae_int_t offsdst;
   ae_int_t n;
   ae_int_t didx;
   ae_int_t uidx;
   n = state->n;
// Check inputs
   ae_assert(nnz >= 0, "MinQPAddLC2: NNZ < 0");
   ae_assert(idxa->cnt >= nnz, "MinQPAddLC2: Length(IdxA) < NNZ");
   ae_assert(vala->cnt >= nnz, "MinQPAddLC2: Length(ValA) < NNZ");
   for (i = 0; i < nnz; i++) {
      ae_assert(idxa->xZ[i] >= 0 && idxa->xZ[i] < n, "MinQPAddLC2: IdxA contains indexes outside of [0,N) range");
   }
   ae_assert(isfinitevector(vala, nnz), "MinQPAddLC2: ValA contains infinite or NaN values!");
   ae_assert(isfinite(al) || isneginf(al), "MinQPAddLC2: AL is NAN or +INF");
   ae_assert(isfinite(au) || isposinf(au), "MinQPAddLC2: AU is NAN or -INF");
// If M == 0, it means that A is uninitialized.
// Prepare sparse matrix structure
   if (state->msparse == 0) {
      state->sparsec.matrixtype = 1;
      state->sparsec.m = 0;
      state->sparsec.n = n;
      state->sparsec.ninitialized = 0;
      vectorsetlengthatleast(&state->sparsec.ridx, 1);
      state->sparsec.ridx.xZ[0] = 0;
   }
   ae_assert(state->sparsec.matrixtype == 1 && state->sparsec.m == state->msparse, "MinQPAddLC2: integrity check failed!");
// Reallocate inequality bounds
   rvectorgrowto(&state->cl, state->msparse + state->mdense + 1);
   rvectorgrowto(&state->cu, state->msparse + state->mdense + 1);
   rvectorgrowto(&state->replaglc, state->msparse + state->mdense + 1);
   for (i = state->msparse + state->mdense; i > state->msparse; i--) {
      state->cl.xR[i] = state->cl.xR[i - 1];
      state->cu.xR[i] = state->cu.xR[i - 1];
      state->replaglc.xR[i] = state->replaglc.xR[i - 1];
   }
   state->cl.xR[state->msparse] = al;
   state->cu.xR[state->msparse] = au;
   state->replaglc.xR[state->msparse] = 0.0;
// Reallocate sparse storage
   offs = state->sparsec.ridx.xZ[state->msparse];
   ivectorgrowto(&state->sparsec.idx, offs + nnz);
   rvectorgrowto(&state->sparsec.vals, offs + nnz);
   ivectorgrowto(&state->sparsec.didx, state->msparse + 1);
   ivectorgrowto(&state->sparsec.uidx, state->msparse + 1);
   ivectorgrowto(&state->sparsec.ridx, state->msparse + 2);
// If NNZ == 0, perform quick and simple row append.
   if (nnz == 0) {
      state->sparsec.didx.xZ[state->msparse] = state->sparsec.ridx.xZ[state->msparse];
      state->sparsec.uidx.xZ[state->msparse] = state->sparsec.ridx.xZ[state->msparse];
      state->sparsec.ridx.xZ[state->msparse + 1] = state->sparsec.ridx.xZ[state->msparse];
      state->sparsec.m++;
      state->msparse++;
      return;
   }
// Now we are sure that SparseC contains properly initialized sparse
// matrix (or some appropriate dummy for M == 0) and we have NNZ > 0
// (no need to care about degenerate cases).
//
// Append rows to SparseC:
// * append data
// * sort in place
// * merge duplicate indexes
// * compute DIdx and UIdx
//
   for (i = 0; i < nnz; i++) {
      state->sparsec.idx.xZ[offs + i] = idxa->xZ[i];
      state->sparsec.vals.xR[offs + i] = vala->xR[i];
   }
   tagsortmiddleir(&state->sparsec.idx, &state->sparsec.vals, nnz, offs);
   offsdst = offs;
   for (i = 1; i < nnz; i++) {
      if (state->sparsec.idx.xZ[offsdst] != state->sparsec.idx.xZ[offs + i]) {
         offsdst++;
         state->sparsec.idx.xZ[offsdst] = state->sparsec.idx.xZ[offs + i];
         state->sparsec.vals.xR[offsdst] = state->sparsec.vals.xR[offs + i];
      } else {
         state->sparsec.vals.xR[offsdst] += state->sparsec.vals.xR[offs + i];
      }
   }
   nnz = offsdst - offs + 1;
   uidx = -1;
   didx = -1;
   for (j = offs; j <= offsdst; j++) {
      k = state->sparsec.idx.xZ[j];
      if (k == state->msparse) {
         didx = j;
      } else {
         if (k > state->msparse && uidx == -1) {
            uidx = j;
            break;
         }
      }
   }
   if (uidx == -1) {
      uidx = offsdst + 1;
   }
   if (didx == -1) {
      didx = uidx;
   }
   state->sparsec.didx.xZ[state->msparse] = didx;
   state->sparsec.uidx.xZ[state->msparse] = uidx;
   state->sparsec.ridx.xZ[state->msparse + 1] = offsdst + 1;
   state->sparsec.ninitialized = state->sparsec.ridx.xZ[state->msparse + 1];
   state->sparsec.m++;
   state->msparse++;
}

// This function appends two-sided linear constraint  AL <= A*x <= AU  to the
// list of currently present sparse constraints.
//
// Constraint vector A is  passed  as  a  dense  array  which  is  internally
// sparsified by this function.
//
// Inputs:
//     State   -   structure previously allocated with minqpcreate() call.
//     DA      -   array[N], constraint vector
//     AL, AU  -   lower and upper bounds;
//                 * AL == AU   => equality constraint A*x
//                 * AL < AU    => two-sided constraint AL <= A*x <= AU
//                 * AL == -INF => one-sided constraint A*x <= AU
//                 * AU == +INF => one-sided constraint AL <= A*x
//                 * AL == -INF, AU == +INF => constraint is ignored
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minqpaddlc2sparsefromdense(const minqpstate &state, const real_1d_array &da, const double al, const double au);
void minqpaddlc2sparsefromdense(minqpstate *state, RVector *da, double al, double au) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t nzi;
   ae_int_t offs;
   ae_int_t n;
   ae_int_t nnz;
   ae_int_t didx;
   ae_int_t uidx;
   n = state->n;
// Check inputs
   ae_assert(da->cnt >= n, "MinQPAddLC2SparseFromDense: Length(DA) < N");
   ae_assert(isfinitevector(da, n), "MinQPAddLC2SparseFromDense: DA contains infinities/NANs");
   ae_assert(isfinite(al) || isneginf(al), "MinQPAddLC2SparseFromDense: AL is NAN or +INF");
   ae_assert(isfinite(au) || isposinf(au), "MinQPAddLC2SparseFromDense: AU is NAN or -INF");
// If M == 0, it means that A is uninitialized.
// Prepare sparse matrix structure
   if (state->msparse == 0) {
      state->sparsec.matrixtype = 1;
      state->sparsec.m = 0;
      state->sparsec.n = n;
      state->sparsec.ninitialized = 0;
      vectorsetlengthatleast(&state->sparsec.ridx, 1);
      state->sparsec.ridx.xZ[0] = 0;
   }
   ae_assert(state->sparsec.matrixtype == 1 && state->sparsec.m == state->msparse, "MinQPAddLC2SparseFromDense: integrity check failed!");
// Reallocate inequality bounds
   rvectorgrowto(&state->cl, state->msparse + state->mdense + 1);
   rvectorgrowto(&state->cu, state->msparse + state->mdense + 1);
   rvectorgrowto(&state->replaglc, state->msparse + state->mdense + 1);
   for (i = state->msparse + state->mdense; i > state->msparse; i--) {
      state->cl.xR[i] = state->cl.xR[i - 1];
      state->cu.xR[i] = state->cu.xR[i - 1];
      state->replaglc.xR[i] = state->replaglc.xR[i - 1];
   }
   state->cl.xR[state->msparse] = al;
   state->cu.xR[state->msparse] = au;
   state->replaglc.xR[state->msparse] = 0.0;
// Determine nonzeros count.
// Reallocate sparse storage.
   nnz = 0;
   for (i = 0; i < n; i++) {
      if (!(da->xR[i] == 0.0)) {
         nnz++;
      }
   }
   offs = state->sparsec.ridx.xZ[state->msparse];
   ivectorgrowto(&state->sparsec.idx, offs + nnz);
   rvectorgrowto(&state->sparsec.vals, offs + nnz);
   ivectorgrowto(&state->sparsec.didx, state->msparse + 1);
   ivectorgrowto(&state->sparsec.uidx, state->msparse + 1);
   ivectorgrowto(&state->sparsec.ridx, state->msparse + 2);
// If NNZ == 0, perform quick and simple row append.
   if (nnz == 0) {
      state->sparsec.didx.xZ[state->msparse] = state->sparsec.ridx.xZ[state->msparse];
      state->sparsec.uidx.xZ[state->msparse] = state->sparsec.ridx.xZ[state->msparse];
      state->sparsec.ridx.xZ[state->msparse + 1] = state->sparsec.ridx.xZ[state->msparse];
      state->sparsec.m++;
      state->msparse++;
      return;
   }
// Now we are sure that SparseC contains properly initialized sparse
// matrix (or some appropriate dummy for M == 0) and we have NNZ > 0
// (no need to care about degenerate cases).
//
// Append rows to SparseC:
// * append data
// * compute DIdx and UIdx
//
   nzi = 0;
   for (i = 0; i < n; i++) {
      if (!(da->xR[i] == 0.0)) {
         state->sparsec.idx.xZ[offs + nzi] = i;
         state->sparsec.vals.xR[offs + nzi] = da->xR[i];
         nzi++;
      }
   }
   uidx = -1;
   didx = -1;
   for (j = offs; j < offs + nnz; j++) {
      k = state->sparsec.idx.xZ[j];
      if (k == state->msparse) {
         didx = j;
      } else {
         if (k > state->msparse && uidx == -1) {
            uidx = j;
            break;
         }
      }
   }
   if (uidx == -1) {
      uidx = offs + nnz;
   }
   if (didx == -1) {
      didx = uidx;
   }
   state->sparsec.didx.xZ[state->msparse] = didx;
   state->sparsec.uidx.xZ[state->msparse] = uidx;
   state->sparsec.ridx.xZ[state->msparse + 1] = offs + nnz;
   state->sparsec.ninitialized = state->sparsec.ridx.xZ[state->msparse + 1];
   state->sparsec.m++;
   state->msparse++;
}

// This function solves quadratic programming problem.
//
// Prior to calling this function you should choose solver by means of one of
// the following functions:
//
// * minqpsetalgoquickqp()     - for QuickQP solver
// * minqpsetalgobleic()       - for BLEIC-QP solver
// * minqpsetalgodenseaul()    - for Dense-AUL-QP solver
// * minqpsetalgodenseipm()    - for Dense-IPM-QP solver
//
// These functions also allow you to control stopping criteria of the solver.
// If you did not set solver,  MinQP  subpackage  will  automatically  select
// solver for your problem and will run it with default stopping criteria.
//
// However, it is better to set explicitly solver and its stopping criteria.
//
// Inputs:
//     State   -   algorithm state
//
// You should use MinQPResults() function to access results after calls
// to this function.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// Special thanks to Elvira Illarionova for important suggestions on the linearly constrained QP algorithm.
// API: void minqpoptimize(const minqpstate &state);
void minqpoptimize(minqpstate *state) {
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   ae_int_t nbc;
   ae_int_t neq;
   ae_int_t nineq;
   ae_int_t curecpos;
   ae_int_t curicpos;
   n = state->n;
   m = state->mdense + state->msparse;
   state->repterminationtype = -5;
   state->repinneriterationscount = 0;
   state->repouteriterationscount = 0;
   state->repncholesky = 0;
   state->repnmv = 0;
// Zero-fill Lagrange multipliers (their initial value)
   for (i = 0; i < n; i++) {
      state->replagbc.xR[i] = 0.0;
   }
   for (i = 0; i < m; i++) {
      state->replaglc.xR[i] = 0.0;
   }
// Initial point:
// * if we have starting point in StartX, we just have to bound it
// * if we do not have StartX, deduce initial point from boundary constraints
   if (state->havex) {
      for (i = 0; i < n; i++) {
         state->xs.xR[i] = state->startx.xR[i];
         if (state->havebndl.xB[i] && state->xs.xR[i] < state->bndl.xR[i]) {
            state->xs.xR[i] = state->bndl.xR[i];
         }
         if (state->havebndu.xB[i] && state->xs.xR[i] > state->bndu.xR[i]) {
            state->xs.xR[i] = state->bndu.xR[i];
         }
      }
   } else {
      for (i = 0; i < n; i++) {
         if (state->havebndl.xB[i] && state->havebndu.xB[i]) {
            state->xs.xR[i] = 0.5 * (state->bndl.xR[i] + state->bndu.xR[i]);
            continue;
         }
         if (state->havebndl.xB[i]) {
            state->xs.xR[i] = state->bndl.xR[i];
            continue;
         }
         if (state->havebndu.xB[i]) {
            state->xs.xR[i] = state->bndu.xR[i];
            continue;
         }
         state->xs.xR[i] = 0.0;
      }
   }
// check correctness of constraints
   for (i = 0; i < n; i++) {
      if (state->havebndl.xB[i] && state->havebndu.xB[i]) {
         if (state->bndl.xR[i] > state->bndu.xR[i]) {
            state->repterminationtype = -3;
            return;
         }
      }
   }
// count number of bound and linear constraints
   nbc = 0;
   for (i = 0; i < n; i++) {
      if (state->havebndl.xB[i]) {
         nbc++;
      }
      if (state->havebndu.xB[i]) {
         nbc++;
      }
   }
// Effective scale
   vectorsetlengthatleast(&state->effectives, n);
   if (state->stype == 0) {
   // User scale (or default one)
      for (i = 0; i < n; i++) {
         state->effectives.xR[i] = state->s.xR[i];
      }
   } else {
      if (state->stype == 1) {
      // Diagonal is used for scaling:
      // * unpack
      // * convert to scale, return error on failure
         if (state->akind == 0) {
         // Unpack CQM structure
            cqmgetdiaga(&state->a, &state->effectives);
         } else {
            if (state->akind == 1) {
               for (i = 0; i < n; i++) {
                  state->effectives.xR[i] = sparseget(&state->sparsea, i, i);
               }
            } else {
               ae_assert(false, "MinQPOptimize: integrity check failed");
            }
         }
         for (i = 0; i < n; i++) {
            if (state->effectives.xR[i] <= 0.0) {
               state->repterminationtype = -9;
               return;
            }
            state->effectives.xR[i] = 1.0 / sqrt(state->effectives.xR[i]);
         }
      } else {
         ae_assert(false, "MinQPOptimize: integrity check failed");
      }
   }
// Solvers which can not handle new two-sided constraints need them to be
// converted into legacy equality/inequality one-sided format
   if (state->algokind == 2 || state->algokind == 4) {
   // Scan constraint left/right sides, count equality ones and one/two-sided inequality ones
      neq = 0;
      nineq = 0;
      for (i = 0; i < m; i++) {
         if (isfinite(state->cl.xR[i]) && isfinite(state->cu.xR[i]) && state->cl.xR[i] == state->cu.xR[i]) {
            neq++;
            continue;
         }
         if (isfinite(state->cl.xR[i])) {
            nineq++;
         }
         if (isfinite(state->cu.xR[i])) {
            nineq++;
         }
      }
   // Perform conversion
      matrixsetlengthatleast(&state->ecleic, neq + nineq, n + 1);
      vectorsetlengthatleast(&state->elagmlt, neq + nineq);
      vectorsetlengthatleast(&state->elagidx, neq + nineq);
      curecpos = 0;
      curicpos = neq;
      for (i = 0; i < m; i++) {
         if (isfinite(state->cl.xR[i]) && isfinite(state->cu.xR[i]) && state->cl.xR[i] == state->cu.xR[i]) {
         // Offload equality constraint
            if (i < state->msparse) {
               for (j = 0; j < n; j++) {
                  state->ecleic.xyR[curecpos][j] = 0.0;
               }
               j0 = state->sparsec.ridx.xZ[i];
               j1 = state->sparsec.ridx.xZ[i + 1] - 1;
               for (j = j0; j <= j1; j++) {
                  state->ecleic.xyR[curecpos][state->sparsec.idx.xZ[j]] = state->sparsec.vals.xR[j];
               }
            } else {
               for (j = 0; j < n; j++) {
                  state->ecleic.xyR[curecpos][j] = state->densec.xyR[i - state->msparse][j];
               }
            }
            state->ecleic.xyR[curecpos][n] = state->cu.xR[i];
            state->elagidx.xZ[curecpos] = i;
            state->elagmlt.xR[curecpos] = 1.0;
            curecpos++;
            continue;
         }
         if (isfinite(state->cl.xR[i])) {
         // Offload inequality constraint of the form CL <= C*x, convert it to -C*x <= -CL
            if (i < state->msparse) {
               for (j = 0; j < n; j++) {
                  state->ecleic.xyR[curicpos][j] = 0.0;
               }
               j0 = state->sparsec.ridx.xZ[i];
               j1 = state->sparsec.ridx.xZ[i + 1] - 1;
               for (j = j0; j <= j1; j++) {
                  state->ecleic.xyR[curicpos][state->sparsec.idx.xZ[j]] = -state->sparsec.vals.xR[j];
               }
            } else {
               for (j = 0; j < n; j++) {
                  state->ecleic.xyR[curicpos][j] = -state->densec.xyR[i - state->msparse][j];
               }
            }
            state->ecleic.xyR[curicpos][n] = -state->cl.xR[i];
            state->elagidx.xZ[curicpos] = i;
            state->elagmlt.xR[curicpos] = -1.0;
            curicpos++;
         }
         if (isfinite(state->cu.xR[i])) {
         // Offload inequality constraint of the form C*x <= CU
            if (i < state->msparse) {
               for (j = 0; j < n; j++) {
                  state->ecleic.xyR[curicpos][j] = 0.0;
               }
               j0 = state->sparsec.ridx.xZ[i];
               j1 = state->sparsec.ridx.xZ[i + 1] - 1;
               for (j = j0; j <= j1; j++) {
                  state->ecleic.xyR[curicpos][state->sparsec.idx.xZ[j]] = state->sparsec.vals.xR[j];
               }
            } else {
               for (j = 0; j < n; j++) {
                  state->ecleic.xyR[curicpos][j] = state->densec.xyR[i - state->msparse][j];
               }
            }
            state->ecleic.xyR[curicpos][n] = state->cu.xR[i];
            state->elagidx.xZ[curicpos] = i;
            state->elagmlt.xR[curicpos] = 1.0;
            curicpos++;
         }
      }
      ae_assert(curecpos == neq && curicpos == neq + nineq, "MinQPOptimize: critical integrity check failed (ECLEIC conversion)");
   // Run solvers
      if (state->algokind == 2) {
         qpbleicoptimize(&state->a, &state->sparsea, state->akind, state->sparseaupper, state->absasum, state->absasum2, &state->b, &state->bndl, &state->bndu, &state->effectives, &state->xorigin, n, &state->ecleic, neq, nineq, &state->qpbleicsettingsuser, &state->qpbleicbuf, &state->qpbleicfirstcall, &state->xs, &state->repterminationtype);
         state->repinneriterationscount = state->qpbleicbuf.repinneriterationscount;
         state->repouteriterationscount = state->qpbleicbuf.repouteriterationscount;
         return;
      }
      if (state->algokind == 4) {
         qpdenseauloptimize(&state->a, &state->sparsea, state->akind, state->sparseaupper, &state->b, &state->bndl, &state->bndu, &state->effectives, &state->xorigin, n, &state->ecleic, neq, nineq, &state->dummysparse, 0, 0, !state->dbgskipconstraintnormalization, &state->qpdenseaulsettingsuser, &state->qpdenseaulbuf, &state->xs, &state->replagbc, &state->elaglc, &state->repterminationtype);
         for (i = 0; i < neq + nineq; i++) {
            state->replaglc.xR[state->elagidx.xZ[i]] += state->elaglc.xR[i] * state->elagmlt.xR[i];
         }
         state->repinneriterationscount = state->qpdenseaulbuf.repinneriterationscount;
         state->repouteriterationscount = state->qpdenseaulbuf.repouteriterationscount;
         state->repncholesky = state->qpdenseaulbuf.repncholesky;
         return;
      }
      ae_assert(false, "MinQPOptimize: integrity check failed - unknown solver");
   }
// QuickQP solver
   if (state->algokind == 3) {
      if (state->mdense + state->msparse > 0) {
         state->repterminationtype = -5;
         return;
      }
      qqpoptimize(&state->a, &state->sparsea, &state->dummyr2, state->akind, state->sparseaupper, &state->b, &state->bndl, &state->bndu, &state->effectives, &state->xorigin, n, &state->qqpsettingsuser, &state->qqpbuf, &state->xs, &state->repterminationtype);
      state->repinneriterationscount = state->qqpbuf.repinneriterationscount;
      state->repouteriterationscount = state->qqpbuf.repouteriterationscount;
      state->repncholesky = state->qqpbuf.repncholesky;
      return;
   }
// QP-DENSE-IPM and QP-SPARSE-IPM solvers
   if (state->algokind == 5 || state->algokind == 6) {
   // Prepare working versions of constraints; these versions may be modified
   // when we detect that some bounds are irrelevant.
      rcopyallocv(n, &state->bndl, &state->wrkbndl);
      rcopyallocv(n, &state->bndu, &state->wrkbndu);
      if (state->msparse > 0) {
         sparsecopybuf(&state->sparsec, &state->wrksparsec);
      }
      if (state->mdense > 0) {
         rcopyallocm(state->mdense, n, &state->densec, &state->wrkdensec);
      }
      rcopyallocv(m, &state->cl, &state->wrkcl);
      rcopyallocv(m, &state->cu, &state->wrkcu);
   // Solve
      ae_assert(state->akind == 0 || state->akind == 1, "MinQPOptimize: unexpected AKind");
      if (state->akind == 0) {
         cqmgeta(&state->a, &state->tmpr2);
      }
      if (state->algokind == 5) {
         vipminitdense(&state->vsolver, &state->effectives, &state->xorigin, n);
      }
      if (state->algokind == 6) {
         vipminitsparse(&state->vsolver, &state->effectives, &state->xorigin, n);
      }
      vipmsetquadraticlinear(&state->vsolver, &state->tmpr2, &state->sparsea, state->akind, state->sparseaupper, &state->b);
      vipmsetconstraints(&state->vsolver, &state->wrkbndl, &state->wrkbndu, &state->wrksparsec, state->msparse, &state->wrkdensec, state->mdense, &state->wrkcl, &state->wrkcu);
      vipmsetcond(&state->vsolver, state->veps, state->veps, state->veps);
      vipmoptimize(&state->vsolver, true, &state->xs, &state->replagbc, &state->replaglc, &state->repterminationtype);
      state->repinneriterationscount = state->vsolver.repiterationscount;
      state->repouteriterationscount = state->repinneriterationscount;
      state->repncholesky = state->vsolver.repncholesky;
      return;
   }
// Integrity check failed - unknown solver
   ae_assert(false, "MinQPOptimize: integrity check failed - unknown solver");
}

// QP results
//
// Buffered implementation of MinQPResults() which uses preallocated  buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpresultsbuf(const minqpstate &state, real_1d_array &x, minqpreport &rep);
void minqpresultsbuf(minqpstate *state, RVector *x, minqpreport *rep) {
   ae_int_t i;
   ae_assert(state->xs.cnt >= state->n, "MinQPResultsBuf: integrity check failed");
   ae_assert(state->replagbc.cnt >= state->n, "MinQPResultsBuf: integrity check failed");
   ae_assert(state->replaglc.cnt >= state->mdense + state->msparse, "MinQPResultsBuf: integrity check failed");
   vectorsetlengthatleast(x, state->n);
   vectorsetlengthatleast(&rep->lagbc, state->n);
   vectorsetlengthatleast(&rep->laglc, state->mdense + state->msparse);
   for (i = 0; i < state->n; i++) {
      x->xR[i] = state->xs.xR[i];
      rep->lagbc.xR[i] = state->replagbc.xR[i];
   }
   for (i = 0; i < state->mdense + state->msparse; i++) {
      rep->laglc.xR[i] = state->replaglc.xR[i];
   }
   rep->inneriterationscount = state->repinneriterationscount;
   rep->outeriterationscount = state->repouteriterationscount;
   rep->nmv = state->repnmv;
   rep->ncholesky = state->repncholesky;
   rep->terminationtype = state->repterminationtype;
}

// QP solver results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution (on failure - the best point found
//                 so far).
//     Rep     -   optimization report, contains:
//                 * completion code in Rep.TerminationType (positive  values
//                   denote some kind of success, negative - failures)
//                 * Lagrange multipliers - for QP solvers which support them
//                 * other statistics
//                 See comments on minqpreport structure for more information
//
// Following completion codes are returned in Rep.TerminationType:
// * -9    failure of the automatic scale evaluation:  one  of  the  diagonal
//         elements of the quadratic term is non-positive.  Specify  variable
//         scales manually!
// * -5    inappropriate solver was used:
//         * QuickQP solver for problem with general linear constraints
// * -4    the function is unbounded from below even under constraints,
//         no meaningful minimum can be found.
// * -3    inconsistent constraints (or, maybe, feasible point is too hard to
//         find).
// * -2    IPM solver has difficulty finding primal/dual feasible point.
//         It is likely that the problem is either infeasible or unbounded,
//         but it is difficult to determine exact reason for termination.
//         X contains best point found so far.
// *  > 0  success
// *  7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minqpresults(const minqpstate &state, real_1d_array &x, minqpreport &rep);
void minqpresults(minqpstate *state, RVector *x, minqpreport *rep) {
   SetVector(x);
   SetObj(minqpreport, rep);
   minqpresultsbuf(state, x, rep);
}

// Internal function which allows to rewrite diagonal of quadratic term.
// For internal use only.
//
// This function can be used only when you have dense A and already made
// MinQPSetQuadraticTerm(Fast) call.
// ALGLIB: Copyright 16.01.2011 by Sergey Bochkanov
void minqprewritediagonal(minqpstate *state, RVector *s) {
   cqmrewritedensediagonal(&state->a, s);
}

void minqpstate_init(void *_p, bool make_automatic) {
   minqpstate *p = (minqpstate *)_p;
   qqpsettings_init(&p->qqpsettingsuser, make_automatic);
   qpbleicsettings_init(&p->qpbleicsettingsuser, make_automatic);
   qpdenseaulsettings_init(&p->qpdenseaulsettingsuser, make_automatic);
   convexquadraticmodel_init(&p->a, make_automatic);
   sparsematrix_init(&p->sparsea, make_automatic);
   ae_vector_init(&p->b, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->havebndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->havebndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->xorigin, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->startx, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->densec, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsec, make_automatic);
   ae_vector_init(&p->cl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->replagbc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->replaglc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->effectives, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->ecleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->elaglc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->elagmlt, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->elagidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->dummyr, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->dummyr2, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->dummysparse, make_automatic);
   ae_matrix_init(&p->tmpr2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wrkbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wrkbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wrkcl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wrkcu, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->wrkdensec, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->wrksparsec, make_automatic);
   qpbleicbuffers_init(&p->qpbleicbuf, make_automatic);
   qqpbuffers_init(&p->qqpbuf, make_automatic);
   qpdenseaulbuffers_init(&p->qpdenseaulbuf, make_automatic);
   vipmstate_init(&p->vsolver, make_automatic);
}

void minqpstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minqpstate *dst = (minqpstate *)_dst;
   const minqpstate *src = (const minqpstate *)_src;
   dst->n = src->n;
   qqpsettings_copy(&dst->qqpsettingsuser, &src->qqpsettingsuser, make_automatic);
   qpbleicsettings_copy(&dst->qpbleicsettingsuser, &src->qpbleicsettingsuser, make_automatic);
   qpdenseaulsettings_copy(&dst->qpdenseaulsettingsuser, &src->qpdenseaulsettingsuser, make_automatic);
   dst->veps = src->veps;
   dst->dbgskipconstraintnormalization = src->dbgskipconstraintnormalization;
   dst->algokind = src->algokind;
   dst->akind = src->akind;
   convexquadraticmodel_copy(&dst->a, &src->a, make_automatic);
   sparsematrix_copy(&dst->sparsea, &src->sparsea, make_automatic);
   dst->sparseaupper = src->sparseaupper;
   dst->absamax = src->absamax;
   dst->absasum = src->absasum;
   dst->absasum2 = src->absasum2;
   ae_vector_copy(&dst->b, &src->b, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   dst->stype = src->stype;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->havebndl, &src->havebndl, make_automatic);
   ae_vector_copy(&dst->havebndu, &src->havebndu, make_automatic);
   ae_vector_copy(&dst->xorigin, &src->xorigin, make_automatic);
   ae_vector_copy(&dst->startx, &src->startx, make_automatic);
   dst->havex = src->havex;
   ae_matrix_copy(&dst->densec, &src->densec, make_automatic);
   sparsematrix_copy(&dst->sparsec, &src->sparsec, make_automatic);
   ae_vector_copy(&dst->cl, &src->cl, make_automatic);
   ae_vector_copy(&dst->cu, &src->cu, make_automatic);
   dst->mdense = src->mdense;
   dst->msparse = src->msparse;
   ae_vector_copy(&dst->xs, &src->xs, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repncholesky = src->repncholesky;
   dst->repnmv = src->repnmv;
   dst->repterminationtype = src->repterminationtype;
   ae_vector_copy(&dst->replagbc, &src->replagbc, make_automatic);
   ae_vector_copy(&dst->replaglc, &src->replaglc, make_automatic);
   ae_vector_copy(&dst->effectives, &src->effectives, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_matrix_copy(&dst->ecleic, &src->ecleic, make_automatic);
   ae_vector_copy(&dst->elaglc, &src->elaglc, make_automatic);
   ae_vector_copy(&dst->elagmlt, &src->elagmlt, make_automatic);
   ae_vector_copy(&dst->elagidx, &src->elagidx, make_automatic);
   ae_vector_copy(&dst->dummyr, &src->dummyr, make_automatic);
   ae_matrix_copy(&dst->dummyr2, &src->dummyr2, make_automatic);
   sparsematrix_copy(&dst->dummysparse, &src->dummysparse, make_automatic);
   ae_matrix_copy(&dst->tmpr2, &src->tmpr2, make_automatic);
   ae_vector_copy(&dst->wrkbndl, &src->wrkbndl, make_automatic);
   ae_vector_copy(&dst->wrkbndu, &src->wrkbndu, make_automatic);
   ae_vector_copy(&dst->wrkcl, &src->wrkcl, make_automatic);
   ae_vector_copy(&dst->wrkcu, &src->wrkcu, make_automatic);
   ae_matrix_copy(&dst->wrkdensec, &src->wrkdensec, make_automatic);
   sparsematrix_copy(&dst->wrksparsec, &src->wrksparsec, make_automatic);
   dst->qpbleicfirstcall = src->qpbleicfirstcall;
   qpbleicbuffers_copy(&dst->qpbleicbuf, &src->qpbleicbuf, make_automatic);
   qqpbuffers_copy(&dst->qqpbuf, &src->qqpbuf, make_automatic);
   qpdenseaulbuffers_copy(&dst->qpdenseaulbuf, &src->qpdenseaulbuf, make_automatic);
   vipmstate_copy(&dst->vsolver, &src->vsolver, make_automatic);
}

void minqpstate_free(void *_p, bool make_automatic) {
   minqpstate *p = (minqpstate *)_p;
   qqpsettings_free(&p->qqpsettingsuser, make_automatic);
   qpbleicsettings_free(&p->qpbleicsettingsuser, make_automatic);
   qpdenseaulsettings_free(&p->qpdenseaulsettingsuser, make_automatic);
   convexquadraticmodel_free(&p->a, make_automatic);
   sparsematrix_free(&p->sparsea, make_automatic);
   ae_vector_free(&p->b, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->havebndl, make_automatic);
   ae_vector_free(&p->havebndu, make_automatic);
   ae_vector_free(&p->xorigin, make_automatic);
   ae_vector_free(&p->startx, make_automatic);
   ae_matrix_free(&p->densec, make_automatic);
   sparsematrix_free(&p->sparsec, make_automatic);
   ae_vector_free(&p->cl, make_automatic);
   ae_vector_free(&p->cu, make_automatic);
   ae_vector_free(&p->xs, make_automatic);
   ae_vector_free(&p->replagbc, make_automatic);
   ae_vector_free(&p->replaglc, make_automatic);
   ae_vector_free(&p->effectives, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_matrix_free(&p->ecleic, make_automatic);
   ae_vector_free(&p->elaglc, make_automatic);
   ae_vector_free(&p->elagmlt, make_automatic);
   ae_vector_free(&p->elagidx, make_automatic);
   ae_vector_free(&p->dummyr, make_automatic);
   ae_matrix_free(&p->dummyr2, make_automatic);
   sparsematrix_free(&p->dummysparse, make_automatic);
   ae_matrix_free(&p->tmpr2, make_automatic);
   ae_vector_free(&p->wrkbndl, make_automatic);
   ae_vector_free(&p->wrkbndu, make_automatic);
   ae_vector_free(&p->wrkcl, make_automatic);
   ae_vector_free(&p->wrkcu, make_automatic);
   ae_matrix_free(&p->wrkdensec, make_automatic);
   sparsematrix_free(&p->wrksparsec, make_automatic);
   qpbleicbuffers_free(&p->qpbleicbuf, make_automatic);
   qqpbuffers_free(&p->qqpbuf, make_automatic);
   qpdenseaulbuffers_free(&p->qpdenseaulbuf, make_automatic);
   vipmstate_free(&p->vsolver, make_automatic);
}

void minqpreport_init(void *_p, bool make_automatic) {
   minqpreport *p = (minqpreport *)_p;
   ae_vector_init(&p->lagbc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->laglc, 0, DT_REAL, make_automatic);
}

void minqpreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minqpreport *dst = (minqpreport *)_dst;
   const minqpreport *src = (const minqpreport *)_src;
   dst->inneriterationscount = src->inneriterationscount;
   dst->outeriterationscount = src->outeriterationscount;
   dst->nmv = src->nmv;
   dst->ncholesky = src->ncholesky;
   dst->terminationtype = src->terminationtype;
   ae_vector_copy(&dst->lagbc, &src->lagbc, make_automatic);
   ae_vector_copy(&dst->laglc, &src->laglc, make_automatic);
}

void minqpreport_free(void *_p, bool make_automatic) {
   minqpreport *p = (minqpreport *)_p;
   ae_vector_free(&p->lagbc, make_automatic);
   ae_vector_free(&p->laglc, make_automatic);
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores nonlinear optimizer state.
// You should use functions provided by MinQP subpackage to work with this
// object
DefClass(minqpstate, )

// This structure stores optimization report:
// * InnerIterationsCount      number of inner iterations
// * OuterIterationsCount      number of outer iterations
// * NCholesky                 number of Cholesky decomposition
// * NMV                       number of matrix-vector products
//                             (only products calculated as part of iterative
//                             process are counted)
// * TerminationType           completion code (see below)
// * LagBC                     Lagrange multipliers for box constraints,
//                             array[N], not filled by QP-BLEIC solver
// * LagLC                     Lagrange multipliers for linear constraints,
//                             array[MSparse+MDense], ignored by QP-BLEIC solver
//
// ==== COMPLETION CODES ====
//
// Completion codes:
// * -9    failure of the automatic scale evaluation:  one  of  the  diagonal
//         elements of the quadratic term is non-positive.  Specify  variable
//         scales manually!
// * -5    inappropriate solver was used:
//         * QuickQP solver for problem with general linear constraints (dense/sparse)
// * -4    BLEIC-QP or QuickQP solver found unconstrained direction
//         of negative curvature (function is unbounded from
//         below  even  under  constraints),  no  meaningful
//         minimum can be found.
// * -3    inconsistent constraints (or, maybe, feasible point is
//         too hard to find). If you are sure that constraints are feasible,
//         try to restart optimizer with better initial approximation.
// * -2    IPM solver has difficulty finding primal/dual feasible point.
//         It is likely that the problem is either infeasible or unbounded,
//         but it is difficult to determine exact reason for termination.
//         X contains best point found so far.
// *  1..4 successful completion
// *  5    MaxIts steps was taken
// *  7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//
// ==== LAGRANGE MULTIPLIERS ====
//
// Some  optimizers  report  values of  Lagrange  multipliers  on  successful
// completion (positive completion code):
// * DENSE-IPM-QP and SPARSE-IPM-QP return very precise Lagrange  multipliers
//   as determined during solution process.
// * DENSE-AUL-QP returns approximate Lagrange multipliers  (which  are  very
//   close to "true"  Lagrange  multipliers  except  for  overconstrained  or
//   degenerate problems)
//
// Two arrays of multipliers are returned:
// * LagBC is array[N] which is loaded with multipliers from box constraints;
//   LagBC[i] > 0 means that I-th constraint is at the upper bound, LagBC[I] < 0
//   means that I-th constraint is at the lower bound, LagBC[I] == 0 means  that
//   I-th box constraint is inactive.
// * LagLC is array[MSparse+MDense] which is  loaded  with  multipliers  from
//   general  linear  constraints  (former  MSparse  elements  corresponds to
//   sparse part of the constraint matrix, latter MDense are  for  the  dense
//   constraints, as was specified by user).
//   LagLC[i] > 0 means that the I-th constraint is at the upper bound,
//   LagLC[i] < 0 means that the I-th constraint is at the lower bound,
//   LagLC[i] == 0 means that the I-th linear constraint is inactive.
//
// On failure (or when optimizer does not support Lagrange multipliers) these
// arrays are zero-filled.
//
// It is expected that at solution the dual feasibility condition holds:
//
//     C+H*(Xs-X0) + SUM(Ei*LagBC[i],i = 0..n-1) + SUM(Ai*LagLC[i],i = 0..m-1) ~ 0
//
// where
// * C is a linear term
// * H is a quadratic term
// * Xs is a solution, and X0 is an origin term (zero by default)
// * Ei is a vector with 1.0 at position I and 0 in other positions
// * Ai is an I-th row of linear constraint matrix
//
// NOTE: methods  from  IPM  family  may  also  return  meaningful   Lagrange
//       multipliers  on  completion   with   code   -2   (infeasibility   or
//       unboundedness  detected).
DefClass(minqpreport, DecVal(inneriterationscount) DecVal(outeriterationscount) DecVal(nmv) DecVal(ncholesky) DecVal(terminationtype) DecVar(lagbc) DecVar(laglc))

void minqpsetalgobleic(const minqpstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetalgobleic(ConstT(minqpstate, state), epsg, epsf, epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minqpsetalgodenseaul(const minqpstate &state, const double epsx, const double rho, const ae_int_t itscnt) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetalgodenseaul(ConstT(minqpstate, state), epsx, rho, itscnt);
   alglib_impl::ae_state_clear();
}

void minqpsetalgodenseipm(const minqpstate &state, const double eps) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetalgodenseipm(ConstT(minqpstate, state), eps);
   alglib_impl::ae_state_clear();
}

void minqpsetalgosparseipm(const minqpstate &state, const double eps) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetalgosparseipm(ConstT(minqpstate, state), eps);
   alglib_impl::ae_state_clear();
}

void minqpsetalgoquickqp(const minqpstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxouterits, const bool usenewton) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetalgoquickqp(ConstT(minqpstate, state), epsg, epsf, epsx, maxouterits, usenewton);
   alglib_impl::ae_state_clear();
}

void minqpcreate(const ae_int_t n, minqpstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpcreate(n, ConstT(minqpstate, state));
   alglib_impl::ae_state_clear();
}

void minqpsetlinearterm(const minqpstate &state, const real_1d_array &b) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlinearterm(ConstT(minqpstate, state), ConstT(ae_vector, b));
   alglib_impl::ae_state_clear();
}

void minqpsetquadraticterm(const minqpstate &state, const real_2d_array &a, const bool isupper) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetquadraticterm(ConstT(minqpstate, state), ConstT(ae_matrix, a), isupper);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minqpsetquadraticterm(const minqpstate &state, const real_2d_array &a) {
   if (!alglib_impl::ae_is_symmetric(ConstT(ae_matrix, a))) ThrowError("'a' parameter is not symmetric matrix");
   bool isupper = false;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetquadraticterm(ConstT(minqpstate, state), ConstT(ae_matrix, a), isupper);
   alglib_impl::ae_state_clear();
}
#endif

void minqpsetquadratictermsparse(const minqpstate &state, const sparsematrix &a, const bool isupper) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetquadratictermsparse(ConstT(minqpstate, state), ConstT(sparsematrix, a), isupper);
   alglib_impl::ae_state_clear();
}

void minqpsetstartingpoint(const minqpstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetstartingpoint(ConstT(minqpstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minqpsetorigin(const minqpstate &state, const real_1d_array &xorigin) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetorigin(ConstT(minqpstate, state), ConstT(ae_vector, xorigin));
   alglib_impl::ae_state_clear();
}

void minqpsetscale(const minqpstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetscale(ConstT(minqpstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minqpsetscaleautodiag(const minqpstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetscaleautodiag(ConstT(minqpstate, state));
   alglib_impl::ae_state_clear();
}

void minqpsetbc(const minqpstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetbc(ConstT(minqpstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minqpsetbcall(const minqpstate &state, const double bndl, const double bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetbcall(ConstT(minqpstate, state), bndl, bndu);
   alglib_impl::ae_state_clear();
}

void minqpsetbci(const minqpstate &state, const ae_int_t i, const double bndl, const double bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetbci(ConstT(minqpstate, state), i, bndl, bndu);
   alglib_impl::ae_state_clear();
}

void minqpsetlcmixed(const minqpstate &state, const sparsematrix &sparsec, const integer_1d_array &sparsect, const ae_int_t sparsek, const real_2d_array &densec, const integer_1d_array &densect, const ae_int_t densek) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlcmixed(ConstT(minqpstate, state), ConstT(sparsematrix, sparsec), ConstT(ae_vector, sparsect), sparsek, ConstT(ae_matrix, densec), ConstT(ae_vector, densect), densek);
   alglib_impl::ae_state_clear();
}

void minqpsetlcmixedlegacy(const minqpstate &state, const real_2d_array &densec, const integer_1d_array &densect, const ae_int_t densek, const sparsematrix &sparsec, const integer_1d_array &sparsect, const ae_int_t sparsek) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlcmixedlegacy(ConstT(minqpstate, state), ConstT(ae_matrix, densec), ConstT(ae_vector, densect), densek, ConstT(sparsematrix, sparsec), ConstT(ae_vector, sparsect), sparsek);
   alglib_impl::ae_state_clear();
}

void minqpsetlcsparse(const minqpstate &state, const sparsematrix &c, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlcsparse(ConstT(minqpstate, state), ConstT(sparsematrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}

void minqpsetlc(const minqpstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlc(ConstT(minqpstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minqpsetlc(const minqpstate &state, const real_2d_array &c, const integer_1d_array &ct) {
   ae_int_t k = c.rows();
   if (k != ct.length()) ThrowError("Error while calling 'minqpsetlc': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlc(ConstT(minqpstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#endif

void minqpsetlc2mixed(const minqpstate &state, const sparsematrix &sparsea, const ae_int_t ksparse, const real_2d_array &densea, const ae_int_t kdense, const real_1d_array &al, const real_1d_array &au) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlc2mixed(ConstT(minqpstate, state), ConstT(sparsematrix, sparsea), ksparse, ConstT(ae_matrix, densea), kdense, ConstT(ae_vector, al), ConstT(ae_vector, au));
   alglib_impl::ae_state_clear();
}

void minqpsetlc2dense(const minqpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlc2dense(ConstT(minqpstate, state), ConstT(ae_matrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minqpsetlc2dense(const minqpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au) {
   ae_int_t k = a.rows();
   if (k != al.length() || k != au.length()) ThrowError("Error while calling 'minqpsetlc2dense': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlc2dense(ConstT(minqpstate, state), ConstT(ae_matrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), k);
   alglib_impl::ae_state_clear();
}
#endif

void minqpsetlc2(const minqpstate &state, const sparsematrix &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpsetlc2(ConstT(minqpstate, state), ConstT(sparsematrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), k);
   alglib_impl::ae_state_clear();
}

void minqpaddlc2dense(const minqpstate &state, const real_1d_array &a, const double al, const double au) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpaddlc2dense(ConstT(minqpstate, state), ConstT(ae_vector, a), al, au);
   alglib_impl::ae_state_clear();
}

void minqpaddlc2(const minqpstate &state, const integer_1d_array &idxa, const real_1d_array &vala, const ae_int_t nnz, const double al, const double au) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpaddlc2(ConstT(minqpstate, state), ConstT(ae_vector, idxa), ConstT(ae_vector, vala), nnz, al, au);
   alglib_impl::ae_state_clear();
}

void minqpaddlc2sparsefromdense(const minqpstate &state, const real_1d_array &da, const double al, const double au) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpaddlc2sparsefromdense(ConstT(minqpstate, state), ConstT(ae_vector, da), al, au);
   alglib_impl::ae_state_clear();
}

void minqpoptimize(const minqpstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpoptimize(ConstT(minqpstate, state));
   alglib_impl::ae_state_clear();
}

void minqpresultsbuf(const minqpstate &state, real_1d_array &x, minqpreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpresultsbuf(ConstT(minqpstate, state), ConstT(ae_vector, x), ConstT(minqpreport, rep));
   alglib_impl::ae_state_clear();
}

void minqpresults(const minqpstate &state, real_1d_array &x, minqpreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minqpresults(ConstT(minqpstate, state), ConstT(ae_vector, x), ConstT(minqpreport, rep));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === MINLM Package ===
// Depends on: MINQP
namespace alglib_impl {
static const double minlm_suspiciousnu = 16.0;

// This function sets stopping conditions for Levenberg-Marquardt optimization
// algorithm.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsX    -   >= 0
//                 The subroutine finishes its work if  on  k+1-th  iteration
//                 the condition |v| <= EpsX is fulfilled, where:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - ste pvector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinLMSetScale()
//                 Recommended values: 1E-9 ... 1E-12.
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations   is    unlimited.   Only   Levenberg-Marquardt
//                 iterations  are  counted  (L-BFGS/CG  iterations  are  NOT
//                 counted because their cost is very low compared to that of
//                 LM).
//
// Passing  EpsX == 0  and  MaxIts == 0  (simultaneously)  will  lead  to automatic
// stopping criterion selection (small EpsX).
//
// NOTE: it is not recommended to set large EpsX (say, 0.001). Because LM  is
//       a second-order method, it performs very precise steps anyway.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlmsetcond(const minlmstate &state, const double epsx, const ae_int_t maxits);
void minlmsetcond(minlmstate *state, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsx), "MinLMSetCond: EpsX is not finite number!");
   ae_assert(epsx >= 0.0, "MinLMSetCond: negative EpsX!");
   ae_assert(maxits >= 0, "MinLMSetCond: negative MaxIts!");
   if (epsx == 0.0 && maxits == 0) {
      epsx = 1.0E-9;
   }
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to MinLMOptimize(). Both Levenberg-Marquardt and internal  L-BFGS
// iterations are reported.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlmsetxrep(const minlmstate &state, const bool needxrep);
void minlmsetxrep(minlmstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This function sets maximum step length
//
// Inputs:
//     State   -   structure which stores algorithm state
//     StpMax  -   maximum step length, >= 0. Set StpMax to 0.0,  if you don't
//                 want to limit step length.
//
// Use this subroutine when you optimize target function which contains exp()
// or  other  fast  growing  functions,  and optimization algorithm makes too
// large  steps  which  leads  to overflow. This function allows us to reject
// steps  that  are  too  large  (and  therefore  expose  us  to the possible
// overflow) without actually calculating function value at the x+stp*d.
//
// NOTE: non-zero StpMax leads to moderate  performance  degradation  because
// intermediate  step  of  preconditioned L-BFGS optimization is incompatible
// with limits on step size.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minlmsetstpmax(const minlmstate &state, const double stpmax);
void minlmsetstpmax(minlmstate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinLMSetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinLMSetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// This function sets scaling coefficients for LM optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Generally, scale is NOT considered to be a form of preconditioner.  But LM
// optimizer is unique in that it uses scaling matrix both  in  the  stopping
// condition tests and as Marquardt damping factor.
//
// Proper scaling is very important for the algorithm performance. It is less
// important for the quality of results, but still has some influence (it  is
// easier  to  converge  when  variables  are  properly  scaled, so premature
// stopping is possible when very badly scalled variables are  combined  with
// relaxed stopping conditions).
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minlmsetscale(const minlmstate &state, const real_1d_array &s);
void minlmsetscale(minlmstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinLMSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinLMSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinLMSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// This function sets boundary constraints for LM optimizer
//
// Boundary constraints are inactive by default (after initial creation).
// They are preserved until explicitly turned off with another SetBC() call.
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF (latter is recommended because
//                 it will allow solver to use better algorithm).
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF (latter is recommended because
//                 it will allow solver to use better algorithm).
//
// NOTE 1: it is possible to specify BndL[i] == BndU[i]. In this case I-th
// variable will be "frozen" at X[i] == BndL[i] == BndU[i].
//
// NOTE 2: this solver has following useful properties:
// * bound constraints are always satisfied exactly
// * function is evaluated only INSIDE area specified by bound constraints
//   or at its boundary
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minlmsetbc(const minlmstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minlmsetbc(minlmstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(bndl->cnt >= n, "MinLMSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinLMSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinLMSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinLMSetBC: BndU contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->havebndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->havebndu.xB[i] = isfinite(bndu->xR[i]);
   }
}

// This function sets general linear constraints for LM optimizer
//
// Linear constraints are inactive by default (after initial creation).  They
// are preserved until explicitly turned off with another minlmsetlc() call.
//
// Inputs:
//     State   -   structure stores algorithm state
//     C       -   linear constraints, array[K,N+1].
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n+1]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n+1]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n+1]
//     K       -   number of equality/inequality constraints, K >= 0:
//                 * if given, only leading K elements of C/CT are used
//                 * if not given, automatically determined from sizes of C/CT
//
// IMPORTANT: if you have linear constraints, it is strongly  recommended  to
//            set scale of variables with minlmsetscale(). QP solver which is
//            used to calculate linearly constrained steps heavily relies  on
//            good scaling of input problems.
//
// IMPORTANT: solvers created with minlmcreatefgh()  do  not  support  linear
//            constraints.
//
// NOTE: linear  (non-bound)  constraints are satisfied only approximately  -
//       there  always  exists some violation due  to  numerical  errors  and
//       algorithmic limitations.
//
// NOTE: general linear constraints  add  significant  overhead  to  solution
//       process. Although solver performs roughly same amount of  iterations
//       (when compared  with  similar  box-only  constrained  problem), each
//       iteration   now    involves  solution  of  linearly  constrained  QP
//       subproblem, which requires ~3-5 times more Cholesky  decompositions.
//       Thus, if you can reformulate your problem in such way  this  it  has
//       only box constraints, it may be beneficial to do so.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minlmsetlc(const minlmstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k);
// API: void minlmsetlc(const minlmstate &state, const real_2d_array &c, const integer_1d_array &ct);
void minlmsetlc(minlmstate *state, RMatrix *c, ZVector *ct, ae_int_t k) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
// First, check for errors in the inputs
   ae_assert(k >= 0, "MinLMSetLC: K < 0");
   ae_assert(c->cols > n || k == 0, "MinLMSetLC: Cols(C) <= N");
   ae_assert(c->rows >= k, "MinLMSetLC: Rows(C) < K");
   ae_assert(ct->cnt >= k, "MinLMSetLC: Length(CT) < K");
   ae_assert(apservisfinitematrix(c, k, n + 1), "MinLMSetLC: C contains infinite or NaN values!");
// Handle zero K
   if (k == 0) {
      state->nec = 0;
      state->nic = 0;
      return;
   }
// Equality constraints are stored first, in the upper
// NEC rows of State.CLEIC matrix. Inequality constraints
// are stored in the next NIC rows.
//
// NOTE: we convert inequality constraints to the form
// A*x <= b before copying them.
   matrixsetlengthatleast(&state->cleic, k, n + 1);
   state->nec = 0;
   state->nic = 0;
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] == 0) {
         ae_v_move(state->cleic.xyR[state->nec], 1, c->xyR[i], 1, n + 1);
         state->nec++;
      }
   }
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] != 0) {
         if (ct->xZ[i] > 0) {
            ae_v_moveneg(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         } else {
            ae_v_move(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         }
         state->nic++;
      }
   }
}

// This function is used to change acceleration settings
//
// You can choose between three acceleration strategies:
// * AccType == 0, no acceleration.
// * AccType == 1, secant updates are used to update quadratic model after  each
//   iteration. After fixed number of iterations (or after  model  breakdown)
//   we  recalculate  quadratic  model  using  analytic  Jacobian  or  finite
//   differences. Number of secant-based iterations depends  on  optimization
//   settings: about 3 iterations - when we have analytic Jacobian, up to 2*N
//   iterations - when we use finite differences to calculate Jacobian.
//
// AccType == 1 is recommended when Jacobian  calculation  cost is prohibitively
// high (several Mx1 function vector calculations  followed  by  several  NxN
// Cholesky factorizations are faster than calculation of one M*N  Jacobian).
// It should also be used when we have no Jacobian, because finite difference
// approximation takes too much time to compute.
//
// Table below list  optimization  protocols  (XYZ  protocol  corresponds  to
// MinLMCreateXYZ) and acceleration types they support (and use by  default).
//
// ACCELERATION TYPES SUPPORTED BY OPTIMIZATION PROTOCOLS:
//
// protocol    0   1   comment
// V           +   +
// VJ          +   +
// FGH         +
//
// DEFAULT VALUES:
//
// protocol    0   1   comment
// V               x   without acceleration it is so slooooooooow
// VJ          x
// FGH         x
//
// NOTE: this  function should be called before optimization. Attempt to call
// it during algorithm iterations may result in unexpected behavior.
//
// NOTE: attempt to call this function with unsupported protocol/acceleration
// combination will result in exception being thrown.
// ALGLIB: Copyright 14.10.2010 by Sergey Bochkanov
// API: void minlmsetacctype(const minlmstate &state, const ae_int_t acctype);
void minlmsetacctype(minlmstate *state, ae_int_t acctype) {
   const ae_int_t smallmodelage = 3;
   ae_assert(acctype == 0 || acctype == 1 || acctype == 2, "MinLMSetAccType: incorrect AccType!");
   if (acctype == 2) {
      acctype = 0;
   }
   if (acctype == 0) {
      state->maxmodelage = 0;
      state->makeadditers = false;
      return;
   }
   if (acctype == 1) {
      ae_assert(state->hasfi, "MinLMSetAccType: AccType == 1 is incompatible with current protocol!");
      if (state->algomode == 0) {
         state->maxmodelage = 2 * state->n;
      } else {
         state->maxmodelage = smallmodelage;
      }
      state->makeadditers = false;
      return;
   }
}

// This  subroutine  restarts  LM  algorithm from new point. All optimization
// parameters are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure used for reverse communication previously
//                 allocated with MinLMCreateXXX call.
//     X       -   new starting point.
// ALGLIB: Copyright 30.07.2010 by Sergey Bochkanov
// API: void minlmrestartfrom(const minlmstate &state, const real_1d_array &x);
void minlmrestartfrom(minlmstate *state, RVector *x) {
   ae_assert(x->cnt >= state->n, "MinLMRestartFrom: Length(X) < N!");
   ae_assert(isfinitevector(x, state->n), "MinLMRestartFrom: X contains infinite or NaN values!");
   ae_v_move(state->xbase.xR, 1, x->xR, 1, state->n);
   state->PQ = -1;
}

// Prepare internal structures (except for RComm).
//
// Note: M must be zero for FGH mode, non-zero for V/VJ/FJ/FGJ mode.
static void minlm_lmprepare(ae_int_t n, ae_int_t m, bool havegrad, minlmstate *state) {
   const ae_int_t additers = 5;
   ae_int_t i;
   smoothnessmonitorinit(&state->smonitor, &state->s, 0, 0, false);
   if (n <= 0 || m < 0) {
      return;
   }
   if (havegrad) {
      ae_vector_set_length(&state->g, n);
   }
   if (m != 0) {
      ae_matrix_set_length(&state->j, m, n);
      ae_vector_set_length(&state->fi, m);
      ae_vector_set_length(&state->fibase, m);
      ae_vector_set_length(&state->deltaf, m);
      ae_vector_set_length(&state->fm1, m);
      ae_vector_set_length(&state->fp1, m);
      ae_vector_set_length(&state->fc1, m);
      ae_vector_set_length(&state->gm1, m);
      ae_vector_set_length(&state->gp1, m);
      ae_vector_set_length(&state->gc1, m);
   } else {
      ae_matrix_set_length(&state->h, n, n);
   }
   ae_vector_set_length(&state->x, n);
   ae_vector_set_length(&state->deltax, n);
   ae_matrix_set_length(&state->quadraticmodel, n, n);
   ae_vector_set_length(&state->xbase, n);
   ae_vector_set_length(&state->gbase, n);
   ae_vector_set_length(&state->xdir, n);
   ae_vector_set_length(&state->tmp0, n);
// prepare internal L-BFGS
   for (i = 0; i < n; i++) {
      state->x.xR[i] = 0.0;
   }
   minlbfgscreate(n, imin2(additers, n), &state->x, &state->internalstate);
   minlbfgssetcond(&state->internalstate, 0.0, 0.0, 0.0, imin2(additers, n));
// Prepare internal QP solver
   minqpcreate(n, &state->qpstate);
   minqpsetalgoquickqp(&state->qpstate, 0.0, 0.0, coalesce(0.01 * state->epsx, 1.0E-12), 10, true);
// Prepare boundary constraints
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->havebndl, n);
   ae_vector_set_length(&state->havebndu, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = -INFINITY;
      state->havebndl.xB[i] = false;
      state->bndu.xR[i] = +INFINITY;
      state->havebndu.xB[i] = false;
   }
// Prepare scaling matrix
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->lastscaleused, n);
   for (i = 0; i < n; i++) {
      state->s.xR[i] = 1.0;
      state->lastscaleused.xR[i] = 1.0;
   }
// Prepare linear constraints
   state->nec = 0;
   state->nic = 0;
}

// IMPROVED LEVENBERG-MARQUARDT METHOD
// FOR NON-LINEAR LEAST SQUARES OPTIMIZATION
// This function is used to find minimum of function which is represented  as
// sum of squares:
//     F(x) = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
// using value of function vector f[] and Jacobian of f[].
//
// REQUIREMENTS:
// This algorithm will request following information during its operation:
//
// * function vector f[] at given point X
// * function vector f[] and Jacobian of f[] (simultaneously) at given point
//
// There are several overloaded versions of  MinLMOptimize()  function  which
// correspond  to  different LM-like optimization algorithms provided by this
// unit. You should choose version which accepts fvec()  and jac() callbacks.
// First  one  is used to calculate f[] at given point, second one calculates
// f[] and Jacobian df[i]/dx[j].
//
// You can try to initialize MinLMState structure with VJ  function and  then
// use incorrect version  of  MinLMOptimize()  (for  example,  version  which
// works  with  general  form function and does not provide Jacobian), but it
// will  lead  to  exception  being  thrown  after first attempt to calculate
// Jacobian.
//
// USAGE:
// 1. User initializes algorithm state with MinLMCreateVJ() call
// 2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
//    other functions
// 3. User calls MinLMOptimize() function which  takes algorithm  state   and
//    callback functions.
// 4. User calls MinLMResults() to get solution
// 5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
//    with same N/M but another starting point and/or another function.
//    MinLMRestartFrom() allows to reuse already initialized structure.
//
// Inputs:
//     N       -   dimension, N > 1
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     M       -   number of functions f[i]
//     X       -   initial solution, array[0..N-1]
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. you may tune stopping conditions with MinLMSetCond() function
// 2. if target function contains exp() or other fast growing functions,  and
//    optimization algorithm makes too large steps which leads  to  overflow,
//    use MinLMSetStpMax() function to bound algorithm's steps.
// ALGLIB: Copyright 30.03.2009 by Sergey Bochkanov
// API: void minlmcreatevj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state);
// API: void minlmcreatevj(const ae_int_t m, const real_1d_array &x, minlmstate &state);
void minlmcreatevj(ae_int_t n, ae_int_t m, RVector *x, minlmstate *state) {
   SetObj(minlmstate, state);
   ae_assert(n >= 1, "MinLMCreateVJ: N < 1!");
   ae_assert(m >= 1, "MinLMCreateVJ: M < 1!");
   ae_assert(x->cnt >= n, "MinLMCreateVJ: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinLMCreateVJ: X contains infinite or NaN values!");
// initialize, check parameters
   state->teststep = 0.0;
   state->n = n;
   state->m = m;
   state->algomode = 1;
   state->hasf = false;
   state->hasfi = true;
   state->hasg = false;
// second stage of initialization
   minlmsetacctype(state, 0);
   minlmsetcond(state, 0.0, 0);
   minlm_lmprepare(n, m, false, state);
   minlmsetxrep(state, false);
   minlmsetstpmax(state, 0.0);
   minlmrestartfrom(state, x);
}

// IMPROVED LEVENBERG-MARQUARDT METHOD
// FOR NON-LINEAR LEAST SQUARES OPTIMIZATION
// This function is used to find minimum of function which is represented  as
// sum of squares:
//     F(x) = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
// using value of function vector f[] only. Finite differences  are  used  to
// calculate Jacobian.
//
// REQUIREMENTS:
// This algorithm will request following information during its operation:
// * function vector f[] at given point X
//
// There are several overloaded versions of  MinLMOptimize()  function  which
// correspond  to  different LM-like optimization algorithms provided by this
// unit. You should choose version which accepts fvec() callback.
//
// You can try to initialize MinLMState structure with VJ  function and  then
// use incorrect version  of  MinLMOptimize()  (for  example,  version  which
// works with general form function and does not accept function vector), but
// it will  lead  to  exception being thrown after first attempt to calculate
// Jacobian.
//
// USAGE:
// 1. User initializes algorithm state with MinLMCreateV() call
// 2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
//    other functions
// 3. User calls MinLMOptimize() function which  takes algorithm  state   and
//    callback functions.
// 4. User calls MinLMResults() to get solution
// 5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
//    with same N/M but another starting point and/or another function.
//    MinLMRestartFrom() allows to reuse already initialized structure.
//
// Inputs:
//     N       -   dimension, N > 1
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     M       -   number of functions f[i]
//     X       -   initial solution, array[0..N-1]
//     DiffStep-   differentiation step, > 0
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// See also MinLMIteration, MinLMResults.
//
// NOTES:
// 1. you may tune stopping conditions with MinLMSetCond() function
// 2. if target function contains exp() or other fast growing functions,  and
//    optimization algorithm makes too large steps which leads  to  overflow,
//    use MinLMSetStpMax() function to bound algorithm's steps.
// ALGLIB: Copyright 30.03.2009 by Sergey Bochkanov
// API: void minlmcreatev(const ae_int_t n, const ae_int_t m, const real_1d_array &x, const double diffstep, minlmstate &state);
// API: void minlmcreatev(const ae_int_t m, const real_1d_array &x, const double diffstep, minlmstate &state);
void minlmcreatev(ae_int_t n, ae_int_t m, RVector *x, double diffstep, minlmstate *state) {
   SetObj(minlmstate, state);
   ae_assert(isfinite(diffstep), "MinLMCreateV: DiffStep is not finite!");
   ae_assert(diffstep > 0.0, "MinLMCreateV: DiffStep <= 0!");
   ae_assert(n >= 1, "MinLMCreateV: N < 1!");
   ae_assert(m >= 1, "MinLMCreateV: M < 1!");
   ae_assert(x->cnt >= n, "MinLMCreateV: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinLMCreateV: X contains infinite or NaN values!");
// Initialize
   state->teststep = 0.0;
   state->n = n;
   state->m = m;
   state->algomode = 0;
   state->hasf = false;
   state->hasfi = true;
   state->hasg = false;
   state->diffstep = diffstep;
// Second stage of initialization
   minlmsetacctype(state, 1);
   minlmsetcond(state, 0.0, 0);
   minlm_lmprepare(n, m, false, state);
   minlmsetxrep(state, false);
   minlmsetstpmax(state, 0.0);
   minlmrestartfrom(state, x);
}

// LEVENBERG-MARQUARDT-LIKE METHOD FOR NON-LINEAR OPTIMIZATION
// This  function  is  used  to  find  minimum  of general form (not "sum-of-
// -squares") function
//     F = F(x[0], ..., x[n-1])
// using  its  gradient  and  Hessian.  Levenberg-Marquardt modification with
// L-BFGS pre-optimization and internal pre-conditioned  L-BFGS  optimization
// after each Levenberg-Marquardt step is used.
//
// REQUIREMENTS:
// This algorithm will request following information during its operation:
//
// * function value F at given point X
// * F and gradient G (simultaneously) at given point X
// * F, G and Hessian H (simultaneously) at given point X
//
// There are several overloaded versions of  MinLMOptimize()  function  which
// correspond  to  different LM-like optimization algorithms provided by this
// unit. You should choose version which accepts func(),  grad()  and  hess()
// function pointers. First pointer is used to calculate F  at  given  point,
// second  one  calculates  F(x)  and  grad F(x),  third one calculates F(x),
// grad F(x), hess F(x).
//
// You can try to initialize MinLMState structure with FGH-function and  then
// use incorrect version of MinLMOptimize() (for example, version which  does
// not provide Hessian matrix), but it will lead to  exception  being  thrown
// after first attempt to calculate Hessian.
//
// USAGE:
// 1. User initializes algorithm state with MinLMCreateFGH() call
// 2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
//    other functions
// 3. User calls MinLMOptimize() function which  takes algorithm  state   and
//    pointers (delegates, etc.) to callback functions.
// 4. User calls MinLMResults() to get solution
// 5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
//    with same N but another starting point and/or another function.
//    MinLMRestartFrom() allows to reuse already initialized structure.
//
// Inputs:
//     N       -   dimension, N > 1
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   initial solution, array[0..N-1]
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. you may tune stopping conditions with MinLMSetCond() function
// 2. if target function contains exp() or other fast growing functions,  and
//    optimization algorithm makes too large steps which leads  to  overflow,
//    use MinLMSetStpMax() function to bound algorithm's steps.
// ALGLIB: Copyright 30.03.2009 by Sergey Bochkanov
// API: void minlmcreatefgh(const ae_int_t n, const real_1d_array &x, minlmstate &state);
// API: void minlmcreatefgh(const real_1d_array &x, minlmstate &state);
void minlmcreatefgh(ae_int_t n, RVector *x, minlmstate *state) {
   SetObj(minlmstate, state);
   ae_assert(n >= 1, "MinLMCreateFGH: N < 1!");
   ae_assert(x->cnt >= n, "MinLMCreateFGH: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinLMCreateFGH: X contains infinite or NaN values!");
// initialize
   state->teststep = 0.0;
   state->n = n;
   state->m = 0;
   state->algomode = 2;
   state->hasf = true;
   state->hasfi = false;
   state->hasg = true;
// init2
   minlmsetacctype(state, 2);
   minlmsetcond(state, 0.0, 0);
   minlm_lmprepare(n, 0, true, state);
   minlmsetxrep(state, false);
   minlmsetstpmax(state, 0.0);
   minlmrestartfrom(state, x);
}

// This is obsolete function.
//
// Since ALGLIB 3.3 it is equivalent to MinLMCreateVJ().
// ALGLIB: Copyright 30.03.2009 by Sergey Bochkanov
// API: void minlmcreatevgj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state);
// API: void minlmcreatevgj(const ae_int_t m, const real_1d_array &x, minlmstate &state);
void minlmcreatevgj(ae_int_t n, ae_int_t m, RVector *x, minlmstate *state) {
   SetObj(minlmstate, state);
   minlmcreatevj(n, m, x, state);
}

// This function is considered obsolete since ALGLIB 3.1.0 and is present for
// backward  compatibility  only.  We  recommend  to use MinLMCreateVJ, which
// provides similar, but more consistent and feature-rich interface.
// ALGLIB: Copyright 30.03.2009 by Sergey Bochkanov
// API: void minlmcreatefj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state);
// API: void minlmcreatefj(const ae_int_t m, const real_1d_array &x, minlmstate &state);
void minlmcreatefj(ae_int_t n, ae_int_t m, RVector *x, minlmstate *state) {
   SetObj(minlmstate, state);
   ae_assert(n >= 1, "MinLMCreateFJ: N < 1!");
   ae_assert(m >= 1, "MinLMCreateFJ: M < 1!");
   ae_assert(x->cnt >= n, "MinLMCreateFJ: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinLMCreateFJ: X contains infinite or NaN values!");
// initialize
   state->teststep = 0.0;
   state->n = n;
   state->m = m;
   state->algomode = 1;
   state->hasf = true;
   state->hasfi = false;
   state->hasg = false;
// init 2
   minlmsetacctype(state, 0);
   minlmsetcond(state, 0.0, 0);
   minlm_lmprepare(n, m, true, state);
   minlmsetxrep(state, false);
   minlmsetstpmax(state, 0.0);
   minlmrestartfrom(state, x);
}

// This is obsolete function.
//
// Since ALGLIB 3.3 it is equivalent to MinLMCreateFJ().
// ALGLIB: Copyright 30.03.2009 by Sergey Bochkanov
// API: void minlmcreatefgj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state);
// API: void minlmcreatefgj(const ae_int_t m, const real_1d_array &x, minlmstate &state);
void minlmcreatefgj(ae_int_t n, ae_int_t m, RVector *x, minlmstate *state) {
   SetObj(minlmstate, state);
   minlmcreatefj(n, m, x, state);
}

// Increases lambda, returns False when there is a danger of overflow
static bool minlm_increaselambda(double *lambdav, double *nu) {
   const double lambdaup = 2.0;
   double lnlambda;
   double lnnu;
   double lnlambdaup;
   double lnmax;
   bool result;
   result = false;
   lnlambda = log(*lambdav);
   lnlambdaup = log(lambdaup);
   lnnu = log(*nu);
   lnmax = log(maxrealnumber);
   if (lnlambda + lnlambdaup + lnnu > 0.25 * lnmax) {
      return result;
   }
   if (lnnu + log(2.0) > lnmax) {
      return result;
   }
   *lambdav *= lambdaup * *nu;
   *nu *= 2.0;
   result = true;
   return result;
}

// Decreases lambda, but leaves it unchanged when there is danger of underflow.
static void minlm_decreaselambda(double *lambdav, double *nu) {
   const double lambdadown = 0.33;
   *nu = 1.0;
   if (log(*lambdav) + log(lambdadown) < log(minrealnumber)) {
      *lambdav = minrealnumber;
   } else {
      *lambdav *= lambdadown;
   }
}

// This function compares actual decrease vs predicted decrease  and  updates
// LambdaV/Nu accordingly.
//
// Inputs:
//     QuadraticModel      -   array[N,N], full Hessian matrix of quadratic
//                             model at deltaX == 0
//     GBase               -   array[N], gradient at deltaX == 0
//     FBase               -   F(deltaX == 0)
//     N                   -   size
//     DeltaX              -   step vector
//     FNew                -   new function value
//     LambdaV             -   lambda-value, updated on exit
//     Nu                  -   Nu-multiplier, updated on exit
//
// On exit it returns:
// * Result == 0  - if we have to continue iterations
// * Result != 0 - if termination with completion code Result is requested
// ALGLIB: Copyright 17.02.2017 by Sergey Bochkanov
static ae_int_t minlm_checkdecrease(RMatrix *quadraticmodel, RVector *gbase, double fbase, ae_int_t n, RVector *deltax, double fnew, double *lambdav, double *nu) {
   ae_int_t i;
   double v;
   double t;
   double predicteddecrease;
   double actualdecrease;
   ae_int_t result;
   result = 0;
   t = 0.0;
   for (i = 0; i < n; i++) {
      v = ae_v_dotproduct(quadraticmodel->xyR[i], 1, deltax->xR, 1, n);
      t += deltax->xR[i] * gbase->xR[i] + 0.5 * deltax->xR[i] * v;
   }
   predicteddecrease = -t;
   actualdecrease = -(fnew - fbase);
   if (predicteddecrease <= 0.0) {
      result = 7;
      return result;
   }
   v = actualdecrease / predicteddecrease;
   if (v < 0.1) {
      if (!minlm_increaselambda(lambdav, nu)) {
      // Lambda is too large, we have to break iterations.
         result = 7;
         return result;
      }
   }
   if (v > 0.5) {
      minlm_decreaselambda(lambdav, nu);
   }
   return result;
}

// This  function  initializes  step finder object  with  problem  statement;
// model  parameters  specified  during  this  call  should not (and can not)
// change during object lifetime (although it is  possible  to  re-initialize
// object with different settings).
//
// This function reuses internally allocated objects as much as possible.
//
// In addition to initializing step finder, this function enforces feasibility
// in initial point X passed to this function. It is important that LM iteration
// starts from feasible point and performs feasible steps;
//
// Return Value:
//     True for successful initialization
//     False for inconsistent constraints; you should not use step finder if
//     it returned False.
static bool minlm_minlmstepfinderinit(minlmstepfinder *state, ae_int_t n, ae_int_t m, ae_int_t maxmodelage, bool hasfi, RVector *xbase, RVector *bndl, RVector *bndu, RMatrix *cleic, ae_int_t nec, ae_int_t nic, RVector *s, double stpmax, double epsx) {
   ae_int_t i;
   bool result;
   state->n = n;
   state->m = m;
   state->maxmodelage = maxmodelage;
   state->hasfi = hasfi;
   state->stpmax = stpmax;
   state->epsx = epsx;
// Allocate temporaries, create QP solver, select QP algorithm
   vectorsetlengthatleast(&state->bndl, n);
   vectorsetlengthatleast(&state->bndu, n);
   vectorsetlengthatleast(&state->s, n);
   vectorsetlengthatleast(&state->havebndl, n);
   vectorsetlengthatleast(&state->havebndu, n);
   vectorsetlengthatleast(&state->x, n);
   vectorsetlengthatleast(&state->xbase, n);
   vectorsetlengthatleast(&state->tmp0, n);
   vectorsetlengthatleast(&state->modeldiag, n);
   vectorsetlengthatleast(&state->tmpct, nec + nic);
   vectorsetlengthatleast(&state->xdir, n);
   if (hasfi) {
      vectorsetlengthatleast(&state->fi, m);
      vectorsetlengthatleast(&state->fibase, m);
   }
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinLM: integrity check failed");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinLM: integrity check failed");
      state->bndl.xR[i] = bndl->xR[i];
      state->havebndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->havebndu.xB[i] = isfinite(bndu->xR[i]);
      state->s.xR[i] = s->xR[i];
   }
   for (i = 0; i < nec; i++) {
      state->tmpct.xZ[i] = 0;
   }
   for (i = 0; i < nic; i++) {
      state->tmpct.xZ[nec + i] = -1;
   }
   minqpcreate(n, &state->qpstate);
   if (nec + nic == 0) {
      minqpsetalgoquickqp(&state->qpstate, 0.0, 0.0, coalesce(0.01 * epsx, 1.0E-12), 10, true);
   } else {
      minqpsetalgodenseaul(&state->qpstate, coalesce(0.01 * epsx, 1.0E-12), 100.0, 10);
   }
   minqpsetbc(&state->qpstate, bndl, bndu);
   minqpsetlc(&state->qpstate, cleic, &state->tmpct, nec + nic);
   minqpsetscale(&state->qpstate, s);
// Check feasibility of constraints:
// * check/enforce box constraints (straightforward)
// * prepare QP subproblem which return us a feasible point
   result = true;
   for (i = 0; i < n; i++) {
      if (state->havebndl.xB[i] && state->havebndu.xB[i] && state->bndl.xR[i] > state->bndu.xR[i]) {
         result = false;
         return result;
      }
      if (state->havebndl.xB[i] && xbase->xR[i] < state->bndl.xR[i]) {
         xbase->xR[i] = state->bndl.xR[i];
      }
      if (state->havebndu.xB[i] && xbase->xR[i] > state->bndu.xR[i]) {
         xbase->xR[i] = state->bndu.xR[i];
      }
   }
   if (nec + nic > 0) {
   // Well, we have linear constraints... let's use heavy machinery.
   //
   // We will modify QP solver state below, but everything will be
   // restored in MinLMStepFinderStart().
      sparsecreate(n, n, n, &state->tmpsp);
      for (i = 0; i < n; i++) {
         sparseset(&state->tmpsp, i, i, 0.5);
         state->tmp0.xR[i] = 0.0;
      }
      minqpsetstartingpointfast(&state->qpstate, xbase);
      minqpsetoriginfast(&state->qpstate, xbase);
      minqpsetlineartermfast(&state->qpstate, &state->tmp0);
      minqpsetquadratictermsparse(&state->qpstate, &state->tmpsp, true);
      minqpoptimize(&state->qpstate);
      minqpresultsbuf(&state->qpstate, xbase, &state->qprep);
   }
   return result;
}

// This function prepares LM step search session.
static void minlm_minlmstepfinderstart(minlmstepfinder *state, RMatrix *quadraticmodel, RVector *gbase, double fbase, RVector *xbase, RVector *fibase, ae_int_t modelage) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   state->PQ = -1;
   state->modelage = modelage;
   state->fbase = fbase;
   if (state->hasfi) {
      for (i = 0; i < state->m; i++) {
         state->fibase.xR[i] = fibase->xR[i];
      }
   }
   for (i = 0; i < n; i++) {
      state->xbase.xR[i] = xbase->xR[i];
      state->modeldiag.xR[i] = quadraticmodel->xyR[i][i];
   }
   minqpsetstartingpointfast(&state->qpstate, xbase);
   minqpsetoriginfast(&state->qpstate, xbase);
   minqpsetlineartermfast(&state->qpstate, gbase);
   minqpsetquadratictermfast(&state->qpstate, quadraticmodel, true, 0.0);
}

// This function runs LM step search session.
//
// Find value of Levenberg-Marquardt damping parameter which:
// * leads to positive definite damped model
// * within bounds specified by StpMax
// * generates step which decreases function value
//
// After this block IFlag is set to:
// * -8:	if infinities/NANs were detected in function values/gradient
// * -3:	if constraints are infeasible
// * -2:	if model update is needed (either Lambda growth is too large
//		or step is too short, but we can't rely on model and stop iterations)
// * -1:	if model is fresh, Lambda have grown too large, termination is needed
// *  0:	if everything is OK, continue iterations
// * > 0:	successful completion (step size is small enough)
//
// State.Nu can have any value on enter, but after exit it is set to 1.0
static bool minlm_minlmstepfinderiteration(minlmstepfinder *state, double *lambdav, double *nu, RVector *xnew, RVector *deltax, bool *deltaxready, RVector *deltaf, bool *deltafready, ae_int_t *iflag, double *fnew, ae_int_t *ncholesky) {
   AutoS ae_int_t i;
   AutoS bool bflag;
   AutoS double v;
   AutoS ae_int_t n;
   AutoS ae_int_t m;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume0; case 1: goto Resume1;
      default: goto Exit;
   }
Spawn:
   n = state->n;
   m = state->m;
   state->needfi = state->needf = false;
   while (true) {
      *deltaxready = false;
      *deltafready = false;
   // Do we need model update?
      if (state->modelage > 0 && *nu >= minlm_suspiciousnu) {
         *iflag = -2;
         break;
      }
   // Setup quadratic solver and solve quadratic programming problem.
   // After problem is solved we'll try to bound step by StpMax
   // (Lambda will be increased if step size is too large).
   //
   // We use BFlag variable to indicate that we have to increase Lambda.
   // If it is False, we will try to increase Lambda and move to new iteration.
      bflag = true;
      for (i = 0; i < n; i++) {
         state->tmp0.xR[i] = state->modeldiag.xR[i] + *lambdav / sqr(state->s.xR[i]);
      }
      minqprewritediagonal(&state->qpstate, &state->tmp0);
      minqpoptimize(&state->qpstate);
      minqpresultsbuf(&state->qpstate, xnew, &state->qprep);
      *ncholesky += state->qprep.ncholesky;
      if (state->qprep.terminationtype == -3) {
      // Infeasible constraints
         *iflag = -3;
         break;
      }
      if (state->qprep.terminationtype == -4 || state->qprep.terminationtype == -5) {
      // Unconstrained direction of negative curvature was detected
         if (!minlm_increaselambda(lambdav, nu)) {
            *iflag = -1;
            break;
         }
         continue;
      }
      ae_assert(state->qprep.terminationtype > 0, "MinLM: unexpected completion code from QP solver");
      ae_v_move(state->xdir.xR, 1, xnew->xR, 1, n);
      ae_v_sub(state->xdir.xR, 1, state->xbase.xR, 1, n);
      v = 0.0;
      for (i = 0; i < n; i++) {
         v += sqr(state->xdir.xR[i] / state->s.xR[i]);
      }
      if (isfinite(v)) {
         v = sqrt(v);
         if (state->stpmax > 0.0 && v > state->stpmax) {
            bflag = false;
         }
      } else {
         bflag = false;
      }
      if (!bflag) {
      // Solution failed:
      // try to increase lambda to make matrix positive definite and continue.
         if (!minlm_increaselambda(lambdav, nu)) {
            *iflag = -1;
            break;
         }
         continue;
      }
   // Step in State.XDir and it is bounded by StpMax.
   //
   // We should check stopping conditions on step size here.
   // DeltaX, which is used for secant updates, is initialized here.
   //
   // This code is a bit tricky because sometimes XDir != 0, but
   // it is so small that XDir + XBase == XBase (in finite precision
   // arithmetics). So we set DeltaX to XBase, then
   // add XDir, and then subtract XBase to get exact value of
   // DeltaX.
   //
   // Step length is estimated using DeltaX.
   //
   // NOTE: stopping conditions are tested
   // for fresh models only (ModelAge == 0)
      ae_v_move(deltax->xR, 1, xnew->xR, 1, n);
      ae_v_sub(deltax->xR, 1, state->xbase.xR, 1, n);
      *deltaxready = true;
      v = 0.0;
      for (i = 0; i < n; i++) {
         v += sqr(deltax->xR[i] / state->s.xR[i]);
      }
      v = sqrt(v);
      if (v <= state->epsx) {
         if (state->modelage == 0) {
         // Step is too short, model is fresh and we can rely on it.
         // Terminating.
            *iflag = 2;
            break;
         } else {
         // Step is suspiciously short, but model is not fresh
         // and we can't rely on it.
            *iflag = -2;
            break;
         }
      }
   // Let's evaluate new step:
   // a) if we have Fi vector, we evaluate it using RComm, and
   //    then we manually calculate State.F as sum of squares of Fi[]
   // b) if we have F value, we just evaluate it through RComm interface
   //
   // We prefer (a) because we may need Fi vector for additional
   // iterations
      ae_v_move(state->x.xR, 1, xnew->xR, 1, n);
      if (state->hasfi) {
         state->needfi = true, state->PQ = 0; goto Pause; Resume0: state->needfi = false;
         v = ae_v_dotproduct(state->fi.xR, 1, state->fi.xR, 1, m);
         *fnew = v;
         ae_v_move(deltaf->xR, 1, state->fi.xR, 1, m);
         ae_v_sub(deltaf->xR, 1, state->fibase.xR, 1, m);
         *deltafready = true;
      } else {
         state->needf = true, state->PQ = 1; goto Pause; Resume1: state->needf = false;
         *fnew = state->f;
      }
      if (!isfinite(*fnew)) {
      // Integrity check failed, break!
         *iflag = -8;
         break;
      } else if (*fnew >= state->fbase) {
      // Increase lambda and continue
         if (!minlm_increaselambda(lambdav, nu)) {
            *iflag = -1;
            break;
         }
      } else {
      // We've found our step!
         *iflag = 0;
         break;
      }
   }
   *nu = 1.0;
   ae_assert(*iflag >= -3 && *iflag <= 0 || *iflag == -8 || *iflag > 0, "MinLM: internal integrity check failed!");
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions minlmoptimize() listed below.
// ALGLIB: Copyright 10.03.2009 by Sergey Bochkanov
// API: bool minlmiteration(const minlmstate &state);
// API: void minlmoptimize(minlmstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minlmoptimize(minlmstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minlmoptimize(minlmstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*hess)(const real_1d_array &x, double &func, real_1d_array &grad, real_2d_array &hess, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minlmoptimize(minlmstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minlmoptimize(minlmstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minlmiteration(minlmstate *state) {
   AutoS ae_int_t n;
   AutoS ae_int_t m;
   AutoS bool bflag;
   AutoS ae_int_t iflag;
   AutoS double v;
   AutoS double s;
   AutoS double t;
   AutoS double fnew;
   AutoS ae_int_t i;
   AutoS ae_int_t k;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14; case 15: goto Resume15;
      case 16: goto Resume16; case 17: goto Resume17; case 18: goto Resume18; case 19: goto Resume19;
      case 20: goto Resume20; case 21: goto Resume21; case 22: goto Resume22; case 23: goto Resume23;
      case 24: goto Resume24; case 25: goto Resume25; case 26: goto Resume26; case 27: goto Resume27;
      default: goto Exit;
   }
Spawn:
// prepare
   n = state->n;
   m = state->m;
   state->xupdated = state->needfi = state->needfij = state->needfgh = state->needfg = state->needf = false;
   state->repiterationscount = 0;
   state->repterminationtype = 0;
   state->repnfunc = 0;
   state->repnjac = 0;
   state->repngrad = 0;
   state->repnhess = 0;
   state->repncholesky = 0;
   state->userterminationneeded = false;
   if (m > 0) {
      smoothnessmonitorinit(&state->smonitor, &state->s, n, m, false);
   }
   for (i = 0; i < n; i++) {
      state->lastscaleused.xR[i] = state->s.xR[i];
   }
// Prepare LM step finder and enforce/check feasibility of constraints
   if (!minlm_minlmstepfinderinit(&state->finderstate, n, m, state->maxmodelage, state->hasfi, &state->xbase, &state->bndl, &state->bndu, &state->cleic, state->nec, state->nic, &state->s, state->stpmax, state->epsx)) {
      state->repterminationtype = -3;
      goto Exit;
   }
// set constraints for obsolete QP solver
   minqpsetbc(&state->qpstate, &state->bndl, &state->bndu);
// Check correctness of the analytic Jacobian
   if (state->algomode == 1 && state->teststep > 0.0) {
      ae_assert(m > 0, "MinLM: integrity check failed");
      while (smoothnessmonitorcheckgradientatx0(&state->smonitor, &state->xbase, &state->s, &state->bndl, &state->bndu, true, state->teststep)) {
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->smonitor.x.xR[i];
         }
         state->needfij = true, state->PQ = 0; goto Pause; Resume00: state->needfij = false;
         for (i = 0; i < m; i++) {
            state->smonitor.fi.xR[i] = state->fi.xR[i];
            for (k = 0; k < n; k++) {
               state->smonitor.j.xyR[i][k] = state->j.xyR[i][k];
            }
         }
      }
   }
// Initial report of current point
//
// Note 1: we rewrite State.X twice because
// user may accidentally change it after first call.
//
// Note 2: we set NeedF or NeedFI depending on what
// information about function we have.
   if (state->xrep) {
      ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
      if (state->hasf) {
         state->needf = true, state->PQ = 1; goto Pause; Resume01: state->needf = false;
      } else {
         ae_assert(state->hasfi, "MinLM: internal error 2!");
         state->needfi = true, state->PQ = 2; goto Pause; Resume02: state->needfi = false;
         v = ae_v_dotproduct(state->fi.xR, 1, state->fi.xR, 1, m);
         state->f = v;
      }
      state->repnfunc++;
      ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
      state->xupdated = true, state->PQ = 3; goto Pause; Resume03: state->xupdated = false;
   }
   if (state->userterminationneeded) {
   // User requested termination
      ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
      state->repterminationtype = 8;
      goto Exit;
   }
// Prepare control variables
   state->nu = 1.0;
   state->lambdav = -maxrealnumber;
   state->modelage = state->maxmodelage + 1;
   state->deltaxready = false;
   state->deltafready = false;
   if (state->algomode != 2) {
   // Jacobian-based optimization mode
   //
   // Main cycle.
   //
   // We move through it until either:
   // * one of the stopping conditions is met
   // * we decide that stopping conditions are too stringent
   //   and break from cycle
      while (true) {
      // First, we have to prepare quadratic model for our function.
      // We use BFlag to ensure that model is prepared;
      // if it is false at the end of this block, something went wrong.
      //
      // We may either calculate brand new model or update old one.
      //
      // Before this block we have:
      // * State.XBase            - current position.
      // * State.DeltaX           - if DeltaXReady is True
      // * State.DeltaF           - if DeltaFReady is True
      //
      // After this block is over, we will have:
      // * State.XBase            - base point (unchanged)
      // * State.FBase            - F(XBase)
      // * State.GBase            - linear term
      // * State.QuadraticModel   - quadratic term
      // * State.LambdaV          - current estimate for lambda
      //
      // We also clear DeltaXReady/DeltaFReady flags
      // after initialization is done.
         ae_assert(state->algomode == 0 || state->algomode == 1, "MinLM: integrity check failed");
         if (state->modelage > state->maxmodelage || !(state->deltaxready && state->deltafready)) {
         // Refresh model (using either finite differences or analytic Jacobian)
            if (state->algomode == 0) {
            // Optimization using F values only.
            // Use finite differences to estimate Jacobian.
               ae_assert(state->hasfi, "MinLMIteration: internal error when estimating Jacobian (no f[])");
               for (k = 0; k < n; k++) {
               // We guard X[k] from leaving [BndL,BndU].
               // In case BndL == BndU, we assume that derivative in this direction is zero.
                  ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                  state->x.xR[k] -= state->s.xR[k] * state->diffstep;
                  if (state->havebndl.xB[k]) {
                     state->x.xR[k] = rmax2(state->x.xR[k], state->bndl.xR[k]);
                  }
                  if (state->havebndu.xB[k]) {
                     state->x.xR[k] = rmin2(state->x.xR[k], state->bndu.xR[k]);
                  }
                  state->xm1 = state->x.xR[k];
                  state->needfi = true, state->PQ = 4; goto Pause; Resume04: state->needfi = false;
                  state->repnfunc++;
                  ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, m);
                  ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                  state->x.xR[k] += state->s.xR[k] * state->diffstep;
                  if (state->havebndl.xB[k]) {
                     state->x.xR[k] = rmax2(state->x.xR[k], state->bndl.xR[k]);
                  }
                  if (state->havebndu.xB[k]) {
                     state->x.xR[k] = rmin2(state->x.xR[k], state->bndu.xR[k]);
                  }
                  state->xp1 = state->x.xR[k];
                  state->needfi = true, state->PQ = 5; goto Pause; Resume05: state->needfi = false;
                  state->repnfunc++;
                  ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, m);
                  v = state->xp1 - state->xm1;
                  if (v != 0.0) {
                     v = 1.0 / v;
                     ae_v_moved(&state->j.xyR[0][k], state->j.stride, state->fp1.xR, 1, m, v);
                     ae_v_subd(&state->j.xyR[0][k], state->j.stride, state->fm1.xR, 1, m, v);
                  } else {
                     for (i = 0; i < m; i++) {
                        state->j.xyR[i][k] = 0.0;
                     }
                  }
               }
            // Calculate F(XBase)
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->needfi = true, state->PQ = 6; goto Pause; Resume06: state->needfi = false;
               state->repnfunc++;
               state->repnjac++;
            } else {
            // Obtain f[] and Jacobian
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->needfij = true, state->PQ = 7; goto Pause; Resume07: state->needfij = false;
               state->repnfunc++;
               state->repnjac++;
            }
         // New model
            state->modelage = 0;
         } else {
         // State.J contains Jacobian or its current approximation;
         // refresh it using secant updates:
         //
         // f(x0+dx) = f(x0) + J*dx,
         // J_new = J_old + u*h'
         // h = x_new-x_old
         // u = (f_new - f_old - J_old*h)/(h'h)
         //
         // We can explicitly generate h and u, but it is
         // preferential to do in-place calculations. Only
         // I-th row of J_old is needed to calculate u[I],
         // so we can update J row by row in one pass.
         //
         // NOTE: we expect that State.XBase contains new point,
         // State.FBase contains old point, State.DeltaX and
         // State.DeltaY contain updates from last step.
            ae_assert(state->deltaxready && state->deltafready, "MinLMIteration: uninitialized DeltaX/DeltaF");
            t = ae_v_dotproduct(state->deltax.xR, 1, state->deltax.xR, 1, n);
            ae_assert(t != 0.0, "MinLM: internal error (T == 0)");
            for (i = 0; i < m; i++) {
               v = ae_v_dotproduct(state->j.xyR[i], 1, state->deltax.xR, 1, n);
               v = (state->deltaf.xR[i] - v) / t;
               ae_v_addd(state->j.xyR[i], 1, state->deltax.xR, 1, n, v);
            }
            ae_v_move(state->fi.xR, 1, state->fibase.xR, 1, m);
            ae_v_add(state->fi.xR, 1, state->deltaf.xR, 1, m);
         // Increase model age
            state->modelage++;
         }
         rmatrixgemm(n, n, m, 2.0, &state->j, 0, 0, 1, &state->j, 0, 0, 0, 0.0, &state->quadraticmodel, 0, 0);
         rmatrixmv(n, m, &state->j, 0, 0, 1, &state->fi, 0, &state->gbase, 0);
         ae_v_muld(state->gbase.xR, 1, n, 2.0);
         v = ae_v_dotproduct(state->fi.xR, 1, state->fi.xR, 1, m);
         state->fbase = v;
         ae_v_move(state->fibase.xR, 1, state->fi.xR, 1, m);
         state->deltaxready = false;
         state->deltafready = false;
      // Perform integrity check (presense of NAN/INF)
         v = state->fbase;
         for (i = 0; i < n; i++) {
            v = 0.1 * v + state->gbase.xR[i];
         }
         if (!isfinite(v)) {
         // Break!
            state->repterminationtype = -8;
            goto Exit;
         }
      // If Lambda is not initialized, initialize it using quadratic model
         if (state->lambdav < 0.0) {
            state->lambdav = 0.0;
            for (i = 0; i < n; i++) {
               state->lambdav = rmax2(state->lambdav, fabs(state->quadraticmodel.xyR[i][i]) * sqr(state->s.xR[i]));
            }
            state->lambdav *= 0.001;
            if (state->lambdav == 0.0) {
               state->lambdav = 1.0;
            }
         }
      // Find value of Levenberg-Marquardt damping parameter which:
      // * leads to positive definite damped model
      // * within bounds specified by StpMax
      // * generates step which decreases function value
      //
      // After this block IFlag is set to:
      // * -8:	if internal integrity control detected NAN/INF in function values
      // * -3:	if constraints are infeasible
      // * -2:	if model update is needed (either Lambda growth is too large
      //	or step is too short, but we can't rely on model and stop iterations)
      // * -1:	if model is fresh, Lambda have grown too large, termination is needed
      // *  0:	if everything is OK, continue iterations
      // * > 0:	successful termination, step is less than EpsX
      //
      // State.Nu can have any value on enter, but after exit it is set to 1.0
         iflag = -99;
         for (
            minlm_minlmstepfinderstart(&state->finderstate, &state->quadraticmodel, &state->gbase, state->fbase, &state->xbase, &state->fibase, state->modelage);
            minlm_minlmstepfinderiteration(&state->finderstate, &state->lambdav, &state->nu, &state->xnew, &state->deltax, &state->deltaxready, &state->deltaf, &state->deltafready, &iflag, &fnew, &state->repncholesky);
         ) {
            ae_assert(state->hasfi || state->hasf, "MinLM: internal error 2!");
            state->repnfunc++;
            if (state->finderstate.needfi) {
               ae_assert(state->hasfi, "MinLM: internal error 2!");
               ae_v_move(state->x.xR, 1, state->finderstate.x.xR, 1, n);
               state->needfi = true, state->PQ = 8; goto Pause; Resume08: state->needfi = false;
               ae_v_move(state->finderstate.fi.xR, 1, state->fi.xR, 1, m);
            } else if (state->finderstate.needf) {
               ae_assert(state->hasf, "MinLM: internal error 2!");
               ae_v_move(state->x.xR, 1, state->finderstate.x.xR, 1, n);
               state->needf = true, state->PQ = 9; goto Pause; Resume09: state->needf = false;
               state->finderstate.f = state->f;
            } else ae_assert(false, "MinLM: internal error 2!");
         }
         if (state->userterminationneeded) {
         // User requested termination
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            state->repterminationtype = 8;
            goto Exit;
         }
         state->nu = 1.0;
         ae_assert(iflag >= -3 && iflag <= 0 || iflag == -8 || iflag > 0, "MinLM: internal integrity check failed!");
         if (iflag == -3) {
            state->repterminationtype = -3;
            goto Exit;
         } else if (iflag == -2) {
            state->modelage = state->maxmodelage + 1;
            continue;
         } else if (iflag == -1) {
         // Stopping conditions are too stringent
            state->repterminationtype = 7;
            if (state->xrep) {
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->f = state->fbase;
               state->xupdated = true, state->PQ = 10; goto Pause; Resume10: state->xupdated = false;
            }
            goto Exit;
         } else if (iflag == -8 || iflag > 0) {
         // Either:
         // * Integrity check failed - infinities or NANs
         // * successful termination (step size is small enough)
            state->repterminationtype = iflag;
            if (state->xrep) {
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->f = state->fbase;
               state->xupdated = true, state->PQ = 11; goto Pause; Resume11: state->xupdated = false;
            }
            goto Exit;
         }
         state->f = fnew;
      // Levenberg-Marquardt step is ready.
      // Compare predicted vs. actual decrease and decide what to do with lambda.
      //
      // NOTE: we expect that State.DeltaX contains direction of step,
      // State.F contains function value at new point.
         ae_assert(state->deltaxready, "MinLM: deltaX is not ready");
         iflag = minlm_checkdecrease(&state->quadraticmodel, &state->gbase, state->fbase, n, &state->deltax, state->f, &state->lambdav, &state->nu);
         if (iflag != 0) {
            state->repterminationtype = iflag;
            if (state->xrep) {
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->f = state->fbase;
               state->xupdated = true, state->PQ = 12; goto Pause; Resume12: state->xupdated = false;
            }
            goto Exit;
         }
      // Accept step, report it and
      // test stopping conditions on iterations count and function decrease.
      //
      // NOTE: we expect that State.DeltaX contains direction of step,
      // State.F contains function value at new point.
      //
      // NOTE2: we should update XBase ONLY. In the beginning of the next
      // iteration we expect that State.FIBase is NOT updated and
      // contains old value of a function vector.
         ae_v_move(state->xbase.xR, 1, state->xnew.xR, 1, n);
         if (state->xrep) {
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            state->xupdated = true, state->PQ = 13; goto Pause; Resume13: state->xupdated = false;
         }
         state->repiterationscount++;
         if (state->repiterationscount >= state->maxits && state->maxits > 0) {
            state->repterminationtype = 5;
         }
         if (state->repterminationtype > 0) {
            if (state->xrep) {
            // Report: XBase contains new point, F contains function value at new point
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->xupdated = true, state->PQ = 14; goto Pause; Resume14: state->xupdated = false;
            }
            goto Exit;
         }
         state->modelage++;
      }
   // Lambda is too large, we have to break iterations.
      state->repterminationtype = 7;
      if (state->xrep) {
         ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
         state->f = state->fbase;
         state->xupdated = true, state->PQ = 15; goto Pause; Resume15: state->xupdated = false;
      }
   } else {
   // Legacy Hessian-based mode
   //
   // Main cycle.
   //
   // We move through it until either:
   // * one of the stopping conditions is met
   // * we decide that stopping conditions are too stringent
   //   and break from cycle
   //
      if (state->nec + state->nic > 0) {
      // FGH solver does not support general linear constraints
         state->repterminationtype = -5;
         goto Exit;
      }
      while (true) {
      // First, we have to prepare quadratic model for our function.
      // We use BFlag to ensure that model is prepared;
      // if it is false at the end of this block, something went wrong.
      //
      // We may either calculate brand new model or update old one.
      //
      // Before this block we have:
      // * State.XBase            - current position.
      // * State.DeltaX           - if DeltaXReady is True
      // * State.DeltaF           - if DeltaFReady is True
      //
      // After this block is over, we will have:
      // * State.XBase            - base point (unchanged)
      // * State.FBase            - F(XBase)
      // * State.GBase            - linear term
      // * State.QuadraticModel   - quadratic term
      // * State.LambdaV          - current estimate for lambda
      //
      // We also clear DeltaXReady/DeltaFReady flags
      // after initialization is done.
         bflag = false;
         if (state->algomode == 0 || state->algomode == 1) {
         // Calculate f[] and Jacobian
            if (state->modelage > state->maxmodelage || !(state->deltaxready && state->deltafready)) {
            // Refresh model (using either finite differences or analytic Jacobian)
               if (state->algomode == 0) {
               // Optimization using F values only.
               // Use finite differences to estimate Jacobian.
                  ae_assert(state->hasfi, "MinLMIteration: internal error when estimating Jacobian (no f[])");
                  for (k = 0; k < n; k++) {
                  // We guard X[k] from leaving [BndL,BndU].
                  // In case BndL == BndU, we assume that derivative in this direction is zero.
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] -= state->s.xR[k] * state->diffstep;
                     if (state->havebndl.xB[k]) {
                        state->x.xR[k] = rmax2(state->x.xR[k], state->bndl.xR[k]);
                     }
                     if (state->havebndu.xB[k]) {
                        state->x.xR[k] = rmin2(state->x.xR[k], state->bndu.xR[k]);
                     }
                     state->xm1 = state->x.xR[k];
                     state->needfi = true, state->PQ = 16; goto Pause; Resume16: state->needfi = false;
                     state->repnfunc++;
                     ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, m);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] += state->s.xR[k] * state->diffstep;
                     if (state->havebndl.xB[k]) {
                        state->x.xR[k] = rmax2(state->x.xR[k], state->bndl.xR[k]);
                     }
                     if (state->havebndu.xB[k]) {
                        state->x.xR[k] = rmin2(state->x.xR[k], state->bndu.xR[k]);
                     }
                     state->xp1 = state->x.xR[k];
                     state->needfi = true, state->PQ = 17; goto Pause; Resume17: state->needfi = false;
                     state->repnfunc++;
                     ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, m);
                     v = state->xp1 - state->xm1;
                     if (v != 0.0) {
                        v = 1.0 / v;
                        ae_v_moved(&state->j.xyR[0][k], state->j.stride, state->fp1.xR, 1, m, v);
                        ae_v_subd(&state->j.xyR[0][k], state->j.stride, state->fm1.xR, 1, m, v);
                     } else {
                        for (i = 0; i < m; i++) {
                           state->j.xyR[i][k] = 0.0;
                        }
                     }
                  }
               // Calculate F(XBase)
                  ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                  state->needfi = true, state->PQ = 18; goto Pause; Resume18: state->needfi = false;
                  state->repnfunc++;
                  state->repnjac++;
               } else {
               // Obtain f[] and Jacobian
                  ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                  state->needfij = true, state->PQ = 19; goto Pause; Resume19: state->needfij = false;
                  state->repnfunc++;
                  state->repnjac++;
               }
            // New model
               state->modelage = 0;
            } else {
            // State.J contains Jacobian or its current approximation;
            // refresh it using secant updates:
            //
            // f(x0+dx) = f(x0) + J*dx,
            // J_new = J_old + u*h'
            // h = x_new-x_old
            // u = (f_new - f_old - J_old*h)/(h'h)
            //
            // We can explicitly generate h and u, but it is
            // preferential to do in-place calculations. Only
            // I-th row of J_old is needed to calculate u[I],
            // so we can update J row by row in one pass.
            //
            // NOTE: we expect that State.XBase contains new point,
            // State.FBase contains old point, State.DeltaX and
            // State.DeltaY contain updates from last step.
               ae_assert(state->deltaxready && state->deltafready, "MinLMIteration: uninitialized DeltaX/DeltaF");
               t = ae_v_dotproduct(state->deltax.xR, 1, state->deltax.xR, 1, n);
               ae_assert(t != 0.0, "MinLM: internal error (T == 0)");
               for (i = 0; i < m; i++) {
                  v = ae_v_dotproduct(state->j.xyR[i], 1, state->deltax.xR, 1, n);
                  v = (state->deltaf.xR[i] - v) / t;
                  ae_v_addd(state->j.xyR[i], 1, state->deltax.xR, 1, n, v);
               }
               ae_v_move(state->fi.xR, 1, state->fibase.xR, 1, m);
               ae_v_add(state->fi.xR, 1, state->deltaf.xR, 1, m);
            // Increase model age
               state->modelage++;
            }
         // Generate quadratic model:
         //     f(xbase+dx) =
         //       = (f0 + J*dx)'(f0 + J*dx)
         //       = f0^2 + dx'J'f0 + f0*J*dx + dx'J'J*dx
         //       = f0^2 + 2*f0*J*dx + dx'J'J*dx
         //
         // Note that we calculate 2*(J'J) instead of J'J because
         // our quadratic model is based on Tailor decomposition,
         // i.e. it has 0.5 before quadratic term.
            rmatrixgemm(n, n, m, 2.0, &state->j, 0, 0, 1, &state->j, 0, 0, 0, 0.0, &state->quadraticmodel, 0, 0);
            rmatrixmv(n, m, &state->j, 0, 0, 1, &state->fi, 0, &state->gbase, 0);
            ae_v_muld(state->gbase.xR, 1, n, 2.0);
            v = ae_v_dotproduct(state->fi.xR, 1, state->fi.xR, 1, m);
            state->fbase = v;
            ae_v_move(state->fibase.xR, 1, state->fi.xR, 1, m);
         // set control variables
            bflag = true;
         }
         if (state->algomode == 2) {
            ae_assert(!state->hasfi, "MinLMIteration: internal error (HasFI is True in Hessian-based mode)");
         // Obtain F, G, H
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            state->needfgh = true, state->PQ = 20; goto Pause; Resume20: state->needfgh = false;
            state->repnfunc++;
            state->repngrad++;
            state->repnhess++;
            rmatrixcopy(n, n, &state->h, 0, 0, &state->quadraticmodel, 0, 0);
            ae_v_move(state->gbase.xR, 1, state->g.xR, 1, n);
            state->fbase = state->f;
         // set control variables
            bflag = true;
            state->modelage = 0;
         }
         ae_assert(bflag, "MinLM: internal integrity check failed!");
         state->deltaxready = false;
         state->deltafready = false;
      // Perform integrity check (presense of NAN/INF)
         v = state->fbase;
         for (i = 0; i < n; i++) {
            v = 0.1 * v + state->gbase.xR[i];
         }
         if (!isfinite(v)) {
         // Break!
            state->repterminationtype = -8;
            goto Exit;
         }
      // If Lambda is not initialized, initialize it using quadratic model
         if (state->lambdav < 0.0) {
            state->lambdav = 0.0;
            for (i = 0; i < n; i++) {
               state->lambdav = rmax2(state->lambdav, fabs(state->quadraticmodel.xyR[i][i]) * sqr(state->s.xR[i]));
            }
            state->lambdav *= 0.001;
            if (state->lambdav == 0.0) {
               state->lambdav = 1.0;
            }
         }
      // Find value of Levenberg-Marquardt damping parameter which:
      // * leads to positive definite damped model
      // * within bounds specified by StpMax
      // * generates step which decreases function value
      //
      // After this block IFlag is set to:
      // * -3, if constraints are infeasible
      // * -2, if model update is needed (either Lambda growth is too large
      //       or step is too short, but we can't rely on model and stop iterations)
      // * -1, if model is fresh, Lambda have grown too large, termination is needed
      // *  0, if everything is OK, continue iterations
      //
      // State.Nu can have any value on enter, but after exit it is set to 1.0
         iflag = -99;
         while (true) {
         // Do we need model update?
            if (state->modelage > 0 && state->nu >= minlm_suspiciousnu) {
               iflag = -2;
               break;
            }
         // Setup quadratic solver and solve quadratic programming problem.
         // After problem is solved we'll try to bound step by StpMax
         // (Lambda will be increased if step size is too large).
         //
         // We use BFlag variable to indicate that we have to increase Lambda.
         // If it is False, we will try to increase Lambda and move to new iteration.
            bflag = true;
            minqpsetstartingpointfast(&state->qpstate, &state->xbase);
            minqpsetoriginfast(&state->qpstate, &state->xbase);
            minqpsetlineartermfast(&state->qpstate, &state->gbase);
            minqpsetquadratictermfast(&state->qpstate, &state->quadraticmodel, true, 0.0);
            for (i = 0; i < n; i++) {
               state->tmp0.xR[i] = state->quadraticmodel.xyR[i][i] + state->lambdav / sqr(state->s.xR[i]);
            }
            minqprewritediagonal(&state->qpstate, &state->tmp0);
            minqpoptimize(&state->qpstate);
            minqpresultsbuf(&state->qpstate, &state->xdir, &state->qprep);
            if (state->qprep.terminationtype > 0) {
            // successful solution of QP problem
               ae_v_sub(state->xdir.xR, 1, state->xbase.xR, 1, n);
               v = ae_v_dotproduct(state->xdir.xR, 1, state->xdir.xR, 1, n);
               if (isfinite(v)) {
                  v = sqrt(v);
                  if (state->stpmax > 0.0 && v > state->stpmax) {
                     bflag = false;
                  }
               } else {
                  bflag = false;
               }
            } else {
            // Either problem is non-convex (increase LambdaV) or constraints are inconsistent
               ae_assert(state->qprep.terminationtype == -3 || state->qprep.terminationtype == -4 || state->qprep.terminationtype == -5, "MinLM: unexpected completion code from QP solver");
               if (state->qprep.terminationtype == -3) {
                  iflag = -3;
                  break;
               }
               bflag = false;
            }
            if (!bflag) {
            // Solution failed:
            // try to increase lambda to make matrix positive definite and continue.
               if (!minlm_increaselambda(&state->lambdav, &state->nu)) {
                  iflag = -1;
                  break;
               }
               continue;
            }
         // Step in State.XDir and it is bounded by StpMax.
         //
         // We should check stopping conditions on step size here.
         // DeltaX, which is used for secant updates, is initialized here.
         //
         // This code is a bit tricky because sometimes XDir != 0, but
         // it is so small that XDir + XBase == XBase (in finite precision
         // arithmetics). So we set DeltaX to XBase, then
         // add XDir, and then subtract XBase to get exact value of
         // DeltaX.
         //
         // Step length is estimated using DeltaX.
         //
         // NOTE: stopping conditions are tested
         // for fresh models only (ModelAge == 0)
            ae_v_move(state->deltax.xR, 1, state->xbase.xR, 1, n);
            ae_v_add(state->deltax.xR, 1, state->xdir.xR, 1, n);
            ae_v_sub(state->deltax.xR, 1, state->xbase.xR, 1, n);
            state->deltaxready = true;
            v = 0.0;
            for (i = 0; i < n; i++) {
               v += sqr(state->deltax.xR[i] / state->s.xR[i]);
            }
            v = sqrt(v);
            if (v <= state->epsx) {
               if (state->modelage == 0) {
               // Step is too short, model is fresh and we can rely on it.
               // Terminating.
                  state->repterminationtype = 2;
                  if (state->xrep) {
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->f = state->fbase;
                     state->xupdated = true, state->PQ = 21; goto Pause; Resume21: state->xupdated = false;
                  }
                  goto Exit;
               } else {
               // Step is suspiciously short, but model is not fresh
               // and we can't rely on it.
                  iflag = -2;
                  break;
               }
            }
         // Let's evaluate new step:
         // a) if we have Fi vector, we evaluate it using RComm, and
         //    then we manually calculate State.F as sum of squares of Fi[]
         // b) if we have F value, we just evaluate it through RComm interface
         //
         // We prefer (a) because we may need Fi vector for additional
         // iterations
            ae_assert(state->hasfi || state->hasf, "MinLM: internal error 2!");
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            ae_v_add(state->x.xR, 1, state->xdir.xR, 1, n);
            if (state->hasfi) {
               state->needfi = true, state->PQ = 22; goto Pause; Resume22: state->needfi = false;
               v = ae_v_dotproduct(state->fi.xR, 1, state->fi.xR, 1, m);
               state->f = v;
               ae_v_move(state->deltaf.xR, 1, state->fi.xR, 1, m);
               ae_v_sub(state->deltaf.xR, 1, state->fibase.xR, 1, m);
               state->deltafready = true;
            } else {
               state->needf = true, state->PQ = 23; goto Pause; Resume23: state->needf = false;
            }
            state->repnfunc++;
            if (!isfinite(state->f)) {
            // Integrity check failed, break!
               state->repterminationtype = -8;
               goto Exit;
            } else if (state->f >= state->fbase) {
            // Increase lambda and continue
               if (!minlm_increaselambda(&state->lambdav, &state->nu)) {
                  iflag = -1;
                  break;
               }
            } else {
            // We've found our step!
               iflag = 0;
               break;
            }
         }
         if (state->userterminationneeded) {
         // User requested termination
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            state->repterminationtype = 8;
            goto Exit;
         }
         state->nu = 1.0;
         ae_assert(iflag >= -3 && iflag <= 0, "MinLM: internal integrity check failed!");
         if (iflag == -3) {
            state->repterminationtype = -3;
            goto Exit;
         } else if (iflag == -2) {
            state->modelage = state->maxmodelage + 1;
            continue;
         } else if (iflag == -1) {
            break;
         }
      // Levenberg-Marquardt step is ready.
      // Compare predicted vs. actual decrease and decide what to do with lambda.
      //
      // NOTE: we expect that State.DeltaX contains direction of step,
      // State.F contains function value at new point.
         ae_assert(state->deltaxready, "MinLM: deltaX is not ready");
         t = 0.0;
         for (i = 0; i < n; i++) {
            v = ae_v_dotproduct(state->quadraticmodel.xyR[i], 1, state->deltax.xR, 1, n);
            t += state->deltax.xR[i] * state->gbase.xR[i] + 0.5 * state->deltax.xR[i] * v;
         }
         state->predicteddecrease = -t;
         state->actualdecrease = -(state->f - state->fbase);
         if (state->predicteddecrease <= 0.0) {
            break;
         }
         v = state->actualdecrease / state->predicteddecrease;
         if (v < 0.1) {
            if (!minlm_increaselambda(&state->lambdav, &state->nu)) {
            // Lambda is too large, we have to break iterations.
               state->repterminationtype = 7;
               if (state->xrep) {
                  ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                  state->f = state->fbase;
                  state->xupdated = true, state->PQ = 24; goto Pause; Resume24: state->xupdated = false;
               }
               goto Exit;
            }
         }
         if (v > 0.5) {
            minlm_decreaselambda(&state->lambdav, &state->nu);
         }
      // Accept step, report it and
      // test stopping conditions on iterations count and function decrease.
      //
      // NOTE: we expect that State.DeltaX contains direction of step,
      // State.F contains function value at new point.
      //
      // NOTE2: we should update XBase ONLY. In the beginning of the next
      // iteration we expect that State.FIBase is NOT updated and
      // contains old value of a function vector.
         ae_v_add(state->xbase.xR, 1, state->deltax.xR, 1, n);
         if (state->xrep) {
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            state->xupdated = true, state->PQ = 25; goto Pause; Resume25: state->xupdated = false;
         }
         state->repiterationscount++;
         if (state->repiterationscount >= state->maxits && state->maxits > 0) {
            state->repterminationtype = 5;
         }
         if (state->repterminationtype > 0) {
            if (state->xrep) {
            // Report: XBase contains new point, F contains function value at new point
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->xupdated = true, state->PQ = 26; goto Pause; Resume26: state->xupdated = false;
            }
            goto Exit;
         }
         state->modelage++;
      }
   // Lambda is too large, we have to break iterations.
      state->repterminationtype = 7;
      if (state->xrep) {
         ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
         state->f = state->fbase;
         state->xupdated = true, state->PQ = 27; goto Pause; Resume27: state->xupdated = false;
      }
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This  function  activates/deactivates verification  of  the  user-supplied
// analytic Jacobian.
//
// Upon  activation  of  this  option  OptGuard  integrity  checker  performs
// numerical differentiation of your target function vector  at  the  initial
// point (note: future versions may also perform check  at  the final  point)
// and compares numerical Jacobian with analytic one provided by you.
//
// If difference is too large, an error flag is set and optimization  session
// continues. After optimization session is over, you can retrieve the report
// which stores  both  Jacobians,  and  specific  components  highlighted  as
// suspicious by the OptGuard.
//
// The OptGuard report can be retrieved with minlmoptguardresults().
//
// IMPORTANT: gradient check is a high-overhead option which  will  cost  you
//            about 3*N additional function evaluations. In many cases it may
//            cost as much as the rest of the optimization session.
//
//            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
//            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
//
// NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
//       does NOT interrupt optimization even if it discovers bad gradient.
//
// Inputs:
//     State       -   structure used to store algorithm state
//     TestStep    -   verification step used for numerical differentiation:
//                     * TestStep == 0 turns verification off
//                     * TestStep > 0 activates verification
//                     You should carefully choose TestStep. Value  which  is
//                     too large (so large that  function  behavior  is  non-
//                     cubic at this scale) will lead  to  false  alarms. Too
//                     short step will result in rounding  errors  dominating
//                     numerical derivative.
//
//                     You may use different step for different parameters by
//                     means of setting scale with minlmsetscale().
//
// ==== EXPLANATION ====
//
// In order to verify gradient algorithm performs following steps:
//   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
//     where X[i] is i-th component of the initial point and S[i] is a  scale
//     of i-th parameter
//   * F(X) is evaluated at these trial points
//   * we perform one more evaluation in the middle point of the interval
//   * we  build  cubic  model using function values and derivatives at trial
//     points and we compare its prediction with actual value in  the  middle
//     point
// ALGLIB: Copyright 15.06.2014 by Sergey Bochkanov
// API: void minlmoptguardgradient(const minlmstate &state, const double teststep);
void minlmoptguardgradient(minlmstate *state, double teststep) {
   ae_assert(isfinite(teststep), "MinLMOptGuardGradient: TestStep contains NaN or INF");
   ae_assert(teststep >= 0.0, "MinLMOptGuardGradient: invalid argument TestStep(TestStep < 0)");
   state->teststep = teststep;
}

// Results of OptGuard integrity check, should be called  after  optimization
// session is over.
//
// OptGuard checks analytic Jacobian  against  reference  value  obtained  by
// numerical differentiation with user-specified step.
//
// NOTE: other optimizers perform additional OptGuard checks for things  like
//       C0/C1-continuity violations. However, LM optimizer  can  check  only
//       for incorrect Jacobian.
//
//       The reason is that unlike line search methods LM optimizer does  not
//       perform extensive evaluations along the line. Thus, we simply do not
//       have enough data to catch C0/C1-violations.
//
// This check is activated with  minlmoptguardgradient() function.
//
// Following flags are set when these errors are suspected:
// * rep.badgradsuspected, and additionally:
//   * rep.badgradfidx for specific function (Jacobian row) suspected
//   * rep.badgradvidx for specific variable (Jacobian column) suspected
//   * rep.badgradxbase, a point where gradient/Jacobian is tested
//   * rep.badgraduser, user-provided gradient/Jacobian
//   * rep.badgradnum, reference gradient/Jacobian obtained via numerical
//     differentiation
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     rep     -   OptGuard report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minlmoptguardresults(const minlmstate &state, optguardreport &rep);
void minlmoptguardresults(minlmstate *state, optguardreport *rep) {
   SetObj(optguardreport, rep);
   smoothnessmonitorexportreport(&state->smonitor, rep);
}

// Levenberg-Marquardt algorithm results
//
// Buffered implementation of MinLMResults(), which uses preallocated buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 10.03.2009 by Sergey Bochkanov
// API: void minlmresultsbuf(const minlmstate &state, real_1d_array &x, minlmreport &rep);
void minlmresultsbuf(minlmstate *state, RVector *x, minlmreport *rep) {
   vectorsetlengthatleast(x, state->n);
   ae_v_move(x->xR, 1, state->x.xR, 1, state->n);
   rep->iterationscount = state->repiterationscount;
   rep->terminationtype = state->repterminationtype;
   rep->nfunc = state->repnfunc;
   rep->njac = state->repnjac;
   rep->ngrad = state->repngrad;
   rep->nhess = state->repnhess;
   rep->ncholesky = state->repncholesky;
}

// Levenberg-Marquardt algorithm results
//
// NOTE: if you activated OptGuard integrity checking functionality and  want
//       to get OptGuard report,  it  can  be  retrieved  with  the  help  of
//       minlmoptguardresults() function.
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization  report;  includes  termination   codes   and
//                 additional information. Termination codes are listed below,
//                 see comments for this structure for more information.
//                 Termination code is stored in rep.terminationtype field:
//                 * -8    optimizer detected NAN/INF values either in the
//                         function itself, or in its Jacobian
//                 * -3    constraints are inconsistent
//                 *  2    relative step is no more than EpsX.
//                 *  5    MaxIts steps was taken
//                 *  7    stopping conditions are too stringent,
//                         further improvement is impossible
//                 *  8    terminated by user who called minlmrequesttermination().
//                         X contains point which was "current accepted" when
//                         termination request was submitted.
// ALGLIB: Copyright 10.03.2009 by Sergey Bochkanov
// API: void minlmresults(const minlmstate &state, real_1d_array &x, minlmreport &rep);
void minlmresults(minlmstate *state, RVector *x, minlmreport *rep) {
   SetVector(x);
   SetObj(minlmreport, rep);
   minlmresultsbuf(state, x, rep);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 08.10.2014 by Sergey Bochkanov
// API: void minlmrequesttermination(const minlmstate &state);
void minlmrequesttermination(minlmstate *state) {
   state->userterminationneeded = true;
}

void minlmstepfinder_init(void *_p, bool make_automatic) {
   minlmstepfinder *p = (minlmstepfinder *)_p;
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->modeldiag, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fibase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->havebndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->havebndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xdir, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->choleskybuf, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpct, 0, DT_INT, make_automatic);
   minqpstate_init(&p->qpstate, make_automatic);
   minqpreport_init(&p->qprep, make_automatic);
   sparsematrix_init(&p->tmpsp, make_automatic);
}

void minlmstepfinder_copy(void *_dst, const void *_src, bool make_automatic) {
   minlmstepfinder *dst = (minlmstepfinder *)_dst;
   const minlmstepfinder *src = (const minlmstepfinder *)_src;
   dst->n = src->n;
   dst->m = src->m;
   dst->stpmax = src->stpmax;
   dst->modelage = src->modelage;
   dst->maxmodelage = src->maxmodelage;
   dst->hasfi = src->hasfi;
   dst->epsx = src->epsx;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   dst->needf = src->needf;
   dst->needfi = src->needfi;
   dst->fbase = src->fbase;
   ae_vector_copy(&dst->modeldiag, &src->modeldiag, make_automatic);
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   ae_vector_copy(&dst->fibase, &src->fibase, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->havebndl, &src->havebndl, make_automatic);
   ae_vector_copy(&dst->havebndu, &src->havebndu, make_automatic);
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   dst->PQ = src->PQ;
   ae_vector_copy(&dst->xdir, &src->xdir, make_automatic);
   ae_vector_copy(&dst->choleskybuf, &src->choleskybuf, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmpct, &src->tmpct, make_automatic);
   dst->actualdecrease = src->actualdecrease;
   dst->predicteddecrease = src->predicteddecrease;
   minqpstate_copy(&dst->qpstate, &src->qpstate, make_automatic);
   minqpreport_copy(&dst->qprep, &src->qprep, make_automatic);
   sparsematrix_copy(&dst->tmpsp, &src->tmpsp, make_automatic);
}

void minlmstepfinder_free(void *_p, bool make_automatic) {
   minlmstepfinder *p = (minlmstepfinder *)_p;
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_vector_free(&p->modeldiag, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_vector_free(&p->fibase, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->havebndl, make_automatic);
   ae_vector_free(&p->havebndu, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->xdir, make_automatic);
   ae_vector_free(&p->choleskybuf, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmpct, make_automatic);
   minqpstate_free(&p->qpstate, make_automatic);
   minqpreport_free(&p->qprep, make_automatic);
   sparsematrix_free(&p->tmpsp, make_automatic);
}

void minlmstate_init(void *_p, bool make_automatic) {
   minlmstate *p = (minlmstate *)_p;
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->h, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fibase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gbase, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->quadraticmodel, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->havebndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->havebndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->cleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xnew, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xdir, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->deltax, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->deltaf, 0, DT_REAL, make_automatic);
   smoothnessmonitor_init(&p->smonitor, make_automatic);
   ae_vector_init(&p->lastscaleused, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->choleskybuf, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fm1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fc1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gm1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gc1, 0, DT_REAL, make_automatic);
   minlbfgsstate_init(&p->internalstate, make_automatic);
   minlbfgsreport_init(&p->internalrep, make_automatic);
   minqpstate_init(&p->qpstate, make_automatic);
   minqpreport_init(&p->qprep, make_automatic);
   minlmstepfinder_init(&p->finderstate, make_automatic);
}

void minlmstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minlmstate *dst = (minlmstate *)_dst;
   const minlmstate *src = (const minlmstate *)_src;
   dst->n = src->n;
   dst->m = src->m;
   dst->diffstep = src->diffstep;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->xrep = src->xrep;
   dst->stpmax = src->stpmax;
   dst->maxmodelage = src->maxmodelage;
   dst->makeadditers = src->makeadditers;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   ae_matrix_copy(&dst->j, &src->j, make_automatic);
   ae_matrix_copy(&dst->h, &src->h, make_automatic);
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->needf = src->needf;
   dst->needfg = src->needfg;
   dst->needfgh = src->needfgh;
   dst->needfij = src->needfij;
   dst->needfi = src->needfi;
   dst->xupdated = src->xupdated;
   dst->userterminationneeded = src->userterminationneeded;
   dst->algomode = src->algomode;
   dst->hasf = src->hasf;
   dst->hasfi = src->hasfi;
   dst->hasg = src->hasg;
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   dst->fbase = src->fbase;
   ae_vector_copy(&dst->fibase, &src->fibase, make_automatic);
   ae_vector_copy(&dst->gbase, &src->gbase, make_automatic);
   ae_matrix_copy(&dst->quadraticmodel, &src->quadraticmodel, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->havebndl, &src->havebndl, make_automatic);
   ae_vector_copy(&dst->havebndu, &src->havebndu, make_automatic);
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_matrix_copy(&dst->cleic, &src->cleic, make_automatic);
   dst->nec = src->nec;
   dst->nic = src->nic;
   dst->lambdav = src->lambdav;
   dst->nu = src->nu;
   dst->modelage = src->modelage;
   ae_vector_copy(&dst->xnew, &src->xnew, make_automatic);
   ae_vector_copy(&dst->xdir, &src->xdir, make_automatic);
   ae_vector_copy(&dst->deltax, &src->deltax, make_automatic);
   ae_vector_copy(&dst->deltaf, &src->deltaf, make_automatic);
   dst->deltaxready = src->deltaxready;
   dst->deltafready = src->deltafready;
   smoothnessmonitor_copy(&dst->smonitor, &src->smonitor, make_automatic);
   dst->teststep = src->teststep;
   ae_vector_copy(&dst->lastscaleused, &src->lastscaleused, make_automatic);
   dst->repiterationscount = src->repiterationscount;
   dst->repterminationtype = src->repterminationtype;
   dst->repnfunc = src->repnfunc;
   dst->repnjac = src->repnjac;
   dst->repngrad = src->repngrad;
   dst->repnhess = src->repnhess;
   dst->repncholesky = src->repncholesky;
   dst->PQ = src->PQ;
   ae_vector_copy(&dst->choleskybuf, &src->choleskybuf, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   dst->actualdecrease = src->actualdecrease;
   dst->predicteddecrease = src->predicteddecrease;
   dst->xm1 = src->xm1;
   dst->xp1 = src->xp1;
   ae_vector_copy(&dst->fm1, &src->fm1, make_automatic);
   ae_vector_copy(&dst->fp1, &src->fp1, make_automatic);
   ae_vector_copy(&dst->fc1, &src->fc1, make_automatic);
   ae_vector_copy(&dst->gm1, &src->gm1, make_automatic);
   ae_vector_copy(&dst->gp1, &src->gp1, make_automatic);
   ae_vector_copy(&dst->gc1, &src->gc1, make_automatic);
   minlbfgsstate_copy(&dst->internalstate, &src->internalstate, make_automatic);
   minlbfgsreport_copy(&dst->internalrep, &src->internalrep, make_automatic);
   minqpstate_copy(&dst->qpstate, &src->qpstate, make_automatic);
   minqpreport_copy(&dst->qprep, &src->qprep, make_automatic);
   minlmstepfinder_copy(&dst->finderstate, &src->finderstate, make_automatic);
}

void minlmstate_free(void *_p, bool make_automatic) {
   minlmstate *p = (minlmstate *)_p;
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_matrix_free(&p->j, make_automatic);
   ae_matrix_free(&p->h, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_vector_free(&p->fibase, make_automatic);
   ae_vector_free(&p->gbase, make_automatic);
   ae_matrix_free(&p->quadraticmodel, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->havebndl, make_automatic);
   ae_vector_free(&p->havebndu, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_matrix_free(&p->cleic, make_automatic);
   ae_vector_free(&p->xnew, make_automatic);
   ae_vector_free(&p->xdir, make_automatic);
   ae_vector_free(&p->deltax, make_automatic);
   ae_vector_free(&p->deltaf, make_automatic);
   smoothnessmonitor_free(&p->smonitor, make_automatic);
   ae_vector_free(&p->lastscaleused, make_automatic);
   ae_vector_free(&p->choleskybuf, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->fm1, make_automatic);
   ae_vector_free(&p->fp1, make_automatic);
   ae_vector_free(&p->fc1, make_automatic);
   ae_vector_free(&p->gm1, make_automatic);
   ae_vector_free(&p->gp1, make_automatic);
   ae_vector_free(&p->gc1, make_automatic);
   minlbfgsstate_free(&p->internalstate, make_automatic);
   minlbfgsreport_free(&p->internalrep, make_automatic);
   minqpstate_free(&p->qpstate, make_automatic);
   minqpreport_free(&p->qprep, make_automatic);
   minlmstepfinder_free(&p->finderstate, make_automatic);
}

void minlmreport_init(void *_p, bool make_automatic) {
}

void minlmreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minlmreport *dst = (minlmreport *)_dst;
   const minlmreport *src = (const minlmreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->terminationtype = src->terminationtype;
   dst->nfunc = src->nfunc;
   dst->njac = src->njac;
   dst->ngrad = src->ngrad;
   dst->nhess = src->nhess;
   dst->ncholesky = src->ncholesky;
}

void minlmreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
// Levenberg-Marquardt optimizer.
//
// This structure should be created using one of the MinLMCreate???()
// functions. You should not access its fields directly; use ALGLIB functions
// to work with it.
DefClass(minlmstate, DecVal(needf) DecVal(needfg) DecVal(needfgh) DecVal(needfi) DecVal(needfij) DecVal(xupdated) DecVal(f) DecVar(fi) DecVar(g) DecVar(h) DecVar(j) DecVar(x))

// Optimization report, filled by MinLMResults() function
//
// FIELDS:
// * TerminationType, completetion code:
//     * -8    optimizer detected NAN/INF values either in the function itself,
//             or in its Jacobian
//     * -5    inappropriate solver was used:
//             * solver created with minlmcreatefgh() used  on  problem  with
//               general linear constraints (set with minlmsetlc() call).
//     * -3    constraints are inconsistent
//     *  2    relative step is no more than EpsX.
//     *  5    MaxIts steps was taken
//     *  7    stopping conditions are too stringent,
//             further improvement is impossible
//     *  8    terminated   by  user  who  called  MinLMRequestTermination().
//             X contains point which was "current accepted" when termination
//             request was submitted.
// * IterationsCount, contains iterations count
// * NFunc, number of function calculations
// * NJac, number of Jacobi matrix calculations
// * NGrad, number of gradient calculations
// * NHess, number of Hessian calculations
// * NCholesky, number of Cholesky decomposition calculations
DefClass(minlmreport, DecVal(iterationscount) DecVal(terminationtype) DecVal(nfunc) DecVal(njac) DecVal(ngrad) DecVal(nhess) DecVal(ncholesky))

void minlmsetcond(const minlmstate &state, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetcond(ConstT(minlmstate, state), epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minlmsetxrep(const minlmstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetxrep(ConstT(minlmstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minlmsetstpmax(const minlmstate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetstpmax(ConstT(minlmstate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void minlmsetscale(const minlmstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetscale(ConstT(minlmstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minlmsetbc(const minlmstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetbc(ConstT(minlmstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minlmsetlc(const minlmstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetlc(ConstT(minlmstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmsetlc(const minlmstate &state, const real_2d_array &c, const integer_1d_array &ct) {
   ae_int_t k = c.rows();
   if (k != ct.length()) ThrowError("Error while calling 'minlmsetlc': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetlc(ConstT(minlmstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#endif

void minlmsetacctype(const minlmstate &state, const ae_int_t acctype) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmsetacctype(ConstT(minlmstate, state), acctype);
   alglib_impl::ae_state_clear();
}

void minlmrestartfrom(const minlmstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmrestartfrom(ConstT(minlmstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minlmcreatevj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatevj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmcreatevj(const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatevj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlmcreatev(const ae_int_t n, const ae_int_t m, const real_1d_array &x, const double diffstep, minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatev(n, m, ConstT(ae_vector, x), diffstep, ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmcreatev(const ae_int_t m, const real_1d_array &x, const double diffstep, minlmstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatev(n, m, ConstT(ae_vector, x), diffstep, ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlmcreatefgh(const ae_int_t n, const real_1d_array &x, minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatefgh(n, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmcreatefgh(const real_1d_array &x, minlmstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatefgh(n, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlmcreatevgj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatevgj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmcreatevgj(const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatevgj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlmcreatefj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatefj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmcreatefj(const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatefj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minlmcreatefgj(const ae_int_t n, const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatefgj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlmcreatefgj(const ae_int_t m, const real_1d_array &x, minlmstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmcreatefgj(n, m, ConstT(ae_vector, x), ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
#endif

bool minlmiteration(const minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minlmiteration(ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     func    -   callback which calculates function (or merit function)
//                 value func at given point x
//     grad    -   callback which calculates function (or merit function)
//                 value func and gradient grad at given point x
//     hess    -   callback which calculates function (or merit function)
//                 value func, gradient grad and Hessian hess at given point x
//     fvec    -   callback which calculates function vector fi[]
//                 at given point x
//     jac     -   callback which calculates function vector fi[]
//                 and Jacobian jac at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. Depending on function used to create state  structure,  this  algorithm
//    may accept Jacobian and/or Hessian and/or gradient.  According  to  the
//    said above, there ase several versions of this function,  which  accept
//    different sets of callbacks.
//
//    This flexibility opens way to subtle errors - you may create state with
//    MinLMCreateFGH() (optimization using Hessian), but call function  which
//    does not accept Hessian. So when algorithm will request Hessian,  there
//    will be no callback to call. In this case exception will be thrown.
//
//    Be careful to avoid such errors because there is no way to find them at
//    compile time - you can see them at runtime only.
// ALGLIB: Copyright 10.03.2009 by Sergey Bochkanov
void minlmoptimize(minlmstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(fvec != NULL, "minlmoptimize: fvec is NULL");
   while (alglib_impl::minlmiteration(state.c_ptr()))
   BegPoll
      if (state.needfi) fvec(state.x, state.fi, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlmoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minlmoptimize(minlmstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(fvec != NULL, "minlmoptimize: fvec is NULL");
   alglib_impl::ae_assert(jac != NULL, "minlmoptimize: jac is NULL");
   while (alglib_impl::minlmiteration(state.c_ptr()))
   BegPoll
      if (state.needfi) fvec(state.x, state.fi, ptr);
      else if (state.needfij) jac(state.x, state.fi, state.j, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlmoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minlmoptimize(minlmstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*hess)(const real_1d_array &x, double &func, real_1d_array &grad, real_2d_array &hess, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "minlmoptimize: func is NULL");
   alglib_impl::ae_assert(grad != NULL, "minlmoptimize: grad is NULL");
   alglib_impl::ae_assert(hess != NULL, "minlmoptimize: hess is NULL");
   while (alglib_impl::minlmiteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.needfgh) hess(state.x, state.f, state.g, state.h, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlmoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minlmoptimize(minlmstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "minlmoptimize: func is NULL");
   alglib_impl::ae_assert(jac != NULL, "minlmoptimize: jac is NULL");
   while (alglib_impl::minlmiteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.needfij) jac(state.x, state.fi, state.j, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlmoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minlmoptimize(minlmstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "minlmoptimize: func is NULL");
   alglib_impl::ae_assert(grad != NULL, "minlmoptimize: grad is NULL");
   alglib_impl::ae_assert(jac != NULL, "minlmoptimize: jac is NULL");
   while (alglib_impl::minlmiteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.needfij) jac(state.x, state.fi, state.j, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minlmoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minlmoptguardgradient(const minlmstate &state, const double teststep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmoptguardgradient(ConstT(minlmstate, state), teststep);
   alglib_impl::ae_state_clear();
}

void minlmoptguardresults(const minlmstate &state, optguardreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmoptguardresults(ConstT(minlmstate, state), ConstT(optguardreport, rep));
   alglib_impl::ae_state_clear();
}

void minlmresultsbuf(const minlmstate &state, real_1d_array &x, minlmreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmresultsbuf(ConstT(minlmstate, state), ConstT(ae_vector, x), ConstT(minlmreport, rep));
   alglib_impl::ae_state_clear();
}

void minlmresults(const minlmstate &state, real_1d_array &x, minlmreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmresults(ConstT(minlmstate, state), ConstT(ae_vector, x), ConstT(minlmreport, rep));
   alglib_impl::ae_state_clear();
}

void minlmrequesttermination(const minlmstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlmrequesttermination(ConstT(minlmstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === MINCG Package ===
// Depends on: (AlgLibInternal) LINMIN
// Depends on: OPTSERV
namespace alglib_impl {
// This function sets stopping conditions for CG optimization algorithm.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsG    -   >= 0
//                 The  subroutine  finishes  its  work   if   the  condition
//                 |v| < EpsG is satisfied, where:
//                 * |.| means Euclidian norm
//                 * v - scaled gradient vector, v[i] == g[i]*s[i]
//                 * g - gradient
//                 * s - scaling coefficients set by MinCGSetScale()
//     EpsF    -   >= 0
//                 The  subroutine  finishes  its work if on k+1-th iteration
//                 the  condition  |F(k+1)-F(k)| <= EpsF*max{|F(k)|,|F(k+1)|,1}
//                 is satisfied.
//     EpsX    -   >= 0
//                 The subroutine finishes its work if  on  k+1-th  iteration
//                 the condition |v| <= EpsX is fulfilled, where:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - ste pvector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinCGSetScale()
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited.
//
// Passing EpsG == 0, EpsF == 0, EpsX == 0 and MaxIts == 0 (simultaneously) will lead to
// automatic stopping criterion selection (small EpsX).
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void mincgsetcond(const mincgstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits);
void mincgsetcond(mincgstate *state, double epsg, double epsf, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsg), "MinCGSetCond: EpsG is not finite number!");
   ae_assert(epsg >= 0.0, "MinCGSetCond: negative EpsG!");
   ae_assert(isfinite(epsf), "MinCGSetCond: EpsF is not finite number!");
   ae_assert(epsf >= 0.0, "MinCGSetCond: negative EpsF!");
   ae_assert(isfinite(epsx), "MinCGSetCond: EpsX is not finite number!");
   ae_assert(epsx >= 0.0, "MinCGSetCond: negative EpsX!");
   ae_assert(maxits >= 0, "MinCGSetCond: negative MaxIts!");
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->epsg = epsg;
   state->epsf = epsf;
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function sets scaling coefficients for CG optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Scaling is also used by finite difference variant of CG optimizer  -  step
// along I-th axis is equal to DiffStep*S[I].
//
// In   most   optimizers  (and  in  the  CG  too)  scaling is NOT a form  of
// preconditioning. It just  affects  stopping  conditions.  You  should  set
// preconditioner by separate call to one of the MinCGSetPrec...() functions.
//
// There  is  special  preconditioning  mode, however,  which  uses   scaling
// coefficients to form diagonal preconditioning matrix. You  can  turn  this
// mode on, if you want.   But  you should understand that scaling is not the
// same thing as preconditioning - these are two different, although  related
// forms of tuning solver.
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void mincgsetscale(const mincgstate &state, const real_1d_array &s);
void mincgsetscale(mincgstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinCGSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinCGSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinCGSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to MinCGOptimize().
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void mincgsetxrep(const mincgstate &state, const bool needxrep);
void mincgsetxrep(mincgstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This function turns on/off line search reports.
// These reports are described in more details in developer-only  comments on
// MinCGState object.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedDRep-   whether line search reports are needed or not
//
// This function is intended for private use only. Turning it on artificially
// may cause program failure.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
void mincgsetdrep(mincgstate *state, bool needdrep) {
   state->drep = needdrep;
}

// This function sets CG algorithm.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     CGType  -   algorithm type:
//                 * -1    automatic selection of the best algorithm
//                 * 0     DY (Dai and Yuan) algorithm
//                 * 1     Hybrid DY-HS algorithm
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void mincgsetcgtype(const mincgstate &state, const ae_int_t cgtype);
void mincgsetcgtype(mincgstate *state, ae_int_t cgtype) {
   ae_assert(cgtype >= -1 && cgtype <= 1, "MinCGSetCGType: incorrect CGType!");
   if (cgtype == -1) {
      cgtype = 1;
   }
   state->cgtype = cgtype;
}

// This function sets maximum step length
//
// Inputs:
//     State   -   structure which stores algorithm state
//     StpMax  -   maximum step length, >= 0. Set StpMax to 0.0,  if you don't
//                 want to limit step length.
//
// Use this subroutine when you optimize target function which contains exp()
// or  other  fast  growing  functions,  and optimization algorithm makes too
// large  steps  which  leads  to overflow. This function allows us to reject
// steps  that  are  too  large  (and  therefore  expose  us  to the possible
// overflow) without actually calculating function value at the x+stp*d.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void mincgsetstpmax(const mincgstate &state, const double stpmax);
void mincgsetstpmax(mincgstate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinCGSetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinCGSetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// Modification of the preconditioner: preconditioning is turned off.
//
// Inputs:
//     State   -   structure which stores algorithm state
//
// NOTE:  you  can  change  preconditioner  "on  the  fly",  during algorithm
// iterations.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void mincgsetprecdefault(const mincgstate &state);
void mincgsetprecdefault(mincgstate *state) {
   state->prectype = 0;
   state->innerresetneeded = true;
}

// Faster version of MinCGSetPrecDiag(), for time-critical parts of code,
// without safety checks.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
void mincgsetprecdiagfast(mincgstate *state, RVector *d) {
   ae_int_t i;
   vectorsetlengthatleast(&state->diagh, state->n);
   vectorsetlengthatleast(&state->diaghl2, state->n);
   state->prectype = 2;
   state->vcnt = 0;
   state->innerresetneeded = true;
   for (i = 0; i < state->n; i++) {
      state->diagh.xR[i] = d->xR[i];
      state->diaghl2.xR[i] = 0.0;
   }
}

// Modification  of  the  preconditioner:  diagonal of approximate Hessian is
// used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     D       -   diagonal of the approximate Hessian, array[0..N-1],
//                 (if larger, only leading N elements are used).
//
// NOTE:  you  can  change  preconditioner  "on  the  fly",  during algorithm
// iterations.
//
// NOTE 2: D[i] should be positive. Exception will be thrown otherwise.
//
// NOTE 3: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void mincgsetprecdiag(const mincgstate &state, const real_1d_array &d);
void mincgsetprecdiag(mincgstate *state, RVector *d) {
   ae_int_t i;
   ae_assert(d->cnt >= state->n, "MinCGSetPrecDiag: D is too short");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(d->xR[i]), "MinCGSetPrecDiag: D contains infinite or NAN elements");
      ae_assert(d->xR[i] > 0.0, "MinCGSetPrecDiag: D contains non-positive elements");
   }
   mincgsetprecdiagfast(state, d);
}

// Modification of the preconditioner: scale-based diagonal preconditioning.
//
// This preconditioning mode can be useful when you  don't  have  approximate
// diagonal of Hessian, but you know that your  variables  are  badly  scaled
// (for  example,  one  variable is in [1,10], and another in [1000,100000]),
// and most part of the ill-conditioning comes from different scales of vars.
//
// In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
// can greatly improve convergence.
//
// IMPRTANT: you should set scale of your variables with MinCGSetScale() call
// (before or after MinCGSetPrecScale() call). Without knowledge of the scale
// of your variables scale-based preconditioner will be just unit matrix.
//
// Inputs:
//     State   -   structure which stores algorithm state
//
// NOTE:  you  can  change  preconditioner  "on  the  fly",  during algorithm
// iterations.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void mincgsetprecscale(const mincgstate &state);
void mincgsetprecscale(mincgstate *state) {
   state->prectype = 3;
   state->innerresetneeded = true;
}

// This function sets low-rank preconditioner for Hessian matrix  H == D+V'*C*V,
// where:
// * H is a Hessian matrix, which is approximated by D/V/C
// * D == D1+D2 is a diagonal matrix, which includes two positive definite terms:
//   * constant term D1 (is not updated or infrequently updated)
//   * variable term D2 (can be cheaply updated from iteration to iteration)
// * V is a low-rank correction
// * C is a diagonal factor of low-rank correction
//
// Preconditioner P is calculated using approximate Woodburry formula:
//     P  = D^(-1) - D^(-1)*V'*(C^(-1)+V*D1^(-1)*V')^(-1)*V*D^(-1)
//        = D^(-1) - D^(-1)*VC'*VC*D^(-1),
// where
//     VC = sqrt(B)*V
//     B  = (C^(-1)+V*D1^(-1)*V')^(-1)
//
// Note that B is calculated using constant term (D1) only,  which  allows us
// to update D2 without recalculation of B or   VC.  Such  preconditioner  is
// exact when D2 is zero. When D2 is non-zero, it is only approximation,  but
// very good and cheap one.
//
// This function accepts D1, V, C.
// D2 is set to zero by default.
//
// Cost of this update is O(N*VCnt*VCnt), but D2 can be updated in just O(N)
// by MinCGSetPrecVarPart.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
void mincgsetpreclowrankfast(mincgstate *state, RVector *d1, RVector *c, RMatrix *v, ae_int_t vcnt) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t n;
   double t;
   EnFrame();
   NewRMatrix(b, 0, 0);
   if (vcnt == 0) {
      mincgsetprecdiagfast(state, d1);
      DeFrame();
   }
   n = state->n;
   ae_matrix_set_length(&b, vcnt, vcnt);
   vectorsetlengthatleast(&state->diagh, n);
   vectorsetlengthatleast(&state->diaghl2, n);
   matrixsetlengthatleast(&state->vcorr, vcnt, n);
   state->prectype = 2;
   state->vcnt = vcnt;
   state->innerresetneeded = true;
   for (i = 0; i < n; i++) {
      state->diagh.xR[i] = d1->xR[i];
      state->diaghl2.xR[i] = 0.0;
   }
   for (i = 0; i < vcnt; i++) {
      for (j = i; j < vcnt; j++) {
         t = 0.0;
         for (k = 0; k < n; k++) {
            t += v->xyR[i][k] * v->xyR[j][k] / d1->xR[k];
         }
         b.xyR[i][j] = t;
      }
      b.xyR[i][i] += 1.0 / c->xR[i];
   }
   if (!spdmatrixcholeskyrec(&b, 0, vcnt, true, &state->work0)) {
      state->vcnt = 0;
      DeFrame();
   }
   for (i = 0; i < vcnt; i++) {
      ae_v_move(state->vcorr.xyR[i], 1, v->xyR[i], 1, n);
      for (j = 0; j < i; j++) {
         t = b.xyR[j][i];
         ae_v_subd(state->vcorr.xyR[i], 1, state->vcorr.xyR[j], 1, n, t);
      }
      t = 1.0 / b.xyR[i][i];
      ae_v_muld(state->vcorr.xyR[i], 1, n, t);
   }
   DeFrame();
}

// This function updates variable part (diagonal matrix D2)
// of low-rank preconditioner.
//
// This update is very cheap and takes just O(N) time.
//
// It has no effect with default preconditioner.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
void mincgsetprecvarpart(mincgstate *state, RVector *d2) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   for (i = 0; i < n; i++) {
      state->diaghl2.xR[i] = d2->xR[i];
   }
}

// This function allows to suggest initial step length to the CG algorithm.
//
// Suggested  step  length  is used as starting point for the line search. It
// can be useful when you have  badly  scaled  problem,  i.e.  when  ||grad||
// (which is used as initial estimate for the first step) is many  orders  of
// magnitude different from the desired step.
//
// Line search  may  fail  on  such problems without good estimate of initial
// step length. Imagine, for example, problem with ||grad|| == 10^50 and desired
// step equal to 0.1 Line  search function will use 10^50  as  initial  step,
// then  it  will  decrease step length by 2 (up to 20 attempts) and will get
// 10^44, which is still too large.
//
// This function allows us to tell than line search should  be  started  from
// some moderate step length, like 1.0, so algorithm will be able  to  detect
// desired step length in a several searches.
//
// Default behavior (when no step is suggested) is to use preconditioner,  if
// it is available, to generate initial estimate of step length.
//
// This function influences only first iteration of algorithm. It  should  be
// called between MinCGCreate/MinCGRestartFrom() call and MinCGOptimize call.
// Suggested step is ignored if you have preconditioner.
//
// Inputs:
//     State   -   structure used to store algorithm state.
//     Stp     -   initial estimate of the step length.
//                 Can be zero (no estimate).
// ALGLIB: Copyright 30.07.2010 by Sergey Bochkanov
// API: void mincgsuggeststep(const mincgstate &state, const double stp);
void mincgsuggeststep(mincgstate *state, double stp) {
   ae_assert(isfinite(stp), "MinCGSuggestStep: Stp is infinite or NAN");
   ae_assert(stp >= 0.0, "MinCGSuggestStep: Stp < 0");
   state->suggestedstep = stp;
}

// This developer-only function allows to retrieve  unscaled  (!)  length  of
// last good step (i.e. step which resulted in sufficient decrease of  target
// function).
//
// It can be used in for solution  of  sequential  optimization  subproblems,
// where MinCGSuggestStep()  is  called  with  length  of  previous  step  as
// parameter.
//
// Inputs:
//     State   -   structure used to store algorithm state.
//
// Result:
//     length of last good step being accepted
//
// NOTE:
//     result of this function is undefined if you called it before
// ALGLIB: Copyright 30.07.2010 by Sergey Bochkanov
double mincglastgoodstep(mincgstate *state) {
   double result;
   result = state->lastgoodstep;
   return result;
}

// This  subroutine  restarts  CG  algorithm from new point. All optimization
// parameters are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure used to store algorithm state.
//     X       -   new starting point.
// ALGLIB: Copyright 30.07.2010 by Sergey Bochkanov
// API: void mincgrestartfrom(const mincgstate &state, const real_1d_array &x);
void mincgrestartfrom(mincgstate *state, RVector *x) {
   ae_assert(x->cnt >= state->n, "MinCGRestartFrom: Length(X) < N!");
   ae_assert(isfinitevector(x, state->n), "MinCGCreate: X contains infinite or NaN values!");
   ae_v_move(state->xbase.xR, 1, x->xR, 1, state->n);
   mincgsuggeststep(state, 0.0);
   state->PQ = -1;
}

// Internal initialization subroutine
// ALGLIB: Copyright 16.05.2011 by Sergey Bochkanov
static void mincg_mincginitinternal(ae_int_t n, double diffstep, mincgstate *state) {
   ae_int_t i;
// Initialize
   state->teststep = 0.0;
   state->smoothnessguardlevel = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, 0, 0, false);
   state->n = n;
   state->diffstep = diffstep;
   state->lastgoodstep = 0.0;
   mincgsetcond(state, 0.0, 0.0, 0.0, 0);
   mincgsetxrep(state, false);
   mincgsetdrep(state, false);
   mincgsetstpmax(state, 0.0);
   mincgsetcgtype(state, -1);
   mincgsetprecdefault(state);
   ae_vector_set_length(&state->xk, n);
   ae_vector_set_length(&state->dk, n);
   ae_vector_set_length(&state->xn, n);
   ae_vector_set_length(&state->dn, n);
   ae_vector_set_length(&state->x, n);
   ae_vector_set_length(&state->d, n);
   ae_vector_set_length(&state->g, n);
   ae_vector_set_length(&state->work0, n);
   ae_vector_set_length(&state->work1, n);
   ae_vector_set_length(&state->yk, n);
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->invs, n);
   ae_vector_set_length(&state->lastscaleused, n);
   vectorsetlengthatleast(&state->xbase, n);
   for (i = 0; i < n; i++) {
      state->s.xR[i] = 1.0;
      state->invs.xR[i] = 1.0;
      state->lastscaleused.xR[i] = 1.0;
   }
}

// NONLINEAR CONJUGATE GRADIENT METHOD
// The subroutine minimizes function F(x) of N arguments by using one of  the
// nonlinear conjugate gradient methods.
//
// These CG methods are globally convergent (even on non-convex functions) as
// long as grad(f) is Lipschitz continuous in  a  some  neighborhood  of  the
// L = { x : f(x) <= f(x0) }.
//
// REQUIREMENTS:
// Algorithm will request following information during its operation:
// * function value F and its gradient G (simultaneously) at given point X
//
// USAGE:
// 1. User initializes algorithm state with MinCGCreate() call
// 2. User tunes solver parameters with MinCGSetCond(), MinCGSetStpMax() and
//    other functions
// 3. User calls MinCGOptimize() function which takes algorithm  state   and
//    pointer (delegate, etc.) to callback function which calculates F/G.
// 4. User calls MinCGResults() to get solution
// 5. Optionally, user may call MinCGRestartFrom() to solve another  problem
//    with same N but another starting point and/or another function.
//    MinCGRestartFrom() allows to reuse already initialized structure.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   starting point, array[0..N-1].
//
// Outputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 25.03.2010 by Sergey Bochkanov
// API: void mincgcreate(const ae_int_t n, const real_1d_array &x, mincgstate &state);
// API: void mincgcreate(const real_1d_array &x, mincgstate &state);
void mincgcreate(ae_int_t n, RVector *x, mincgstate *state) {
   SetObj(mincgstate, state);
   ae_assert(n >= 1, "MinCGCreate: N too small!");
   ae_assert(x->cnt >= n, "MinCGCreate: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinCGCreate: X contains infinite or NaN values!");
   mincg_mincginitinternal(n, 0.0, state);
   mincgrestartfrom(state, x);
}

// The subroutine is finite difference variant of MinCGCreate(). It uses
// finite differences in order to differentiate target function.
//
// Description below contains information which is specific to this function
// only. We recommend to read comments on MinCGCreate() in order to get more
// information about creation of CG optimizer.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   starting point, array[0..N-1].
//     DiffStep-   differentiation step, > 0
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. algorithm uses 4-point central formula for differentiation.
// 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
//    S[] is scaling vector which can be set by MinCGSetScale() call.
// 3. we recommend you to use moderate values of  differentiation  step.  Too
//    large step will result in too large truncation  errors, while too small
//    step will result in too large numerical  errors.  0.000001  can be good
//    value to start with.
// 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
//    calculation needs 4*N function evaluations. This function will work for
//    any N - either small (1...10), moderate (10...100) or  large  (100...).
//    However, performance penalty will be too severe for any N's except  for
//    small ones.
//    We should also say that code which relies on numerical  differentiation
//    is  less  robust  and  precise.  L-BFGS  needs  exact  gradient values.
//    Imprecise  gradient may slow down  convergence,  especially  on  highly
//    nonlinear problems.
//    Thus  we  recommend to use this function for fast prototyping on small-
//    dimensional problems only, and to implement analytical gradient as soon
//    as possible.
// ALGLIB: Copyright 16.05.2011 by Sergey Bochkanov
// API: void mincgcreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, mincgstate &state);
// API: void mincgcreatef(const real_1d_array &x, const double diffstep, mincgstate &state);
void mincgcreatef(ae_int_t n, RVector *x, double diffstep, mincgstate *state) {
   SetObj(mincgstate, state);
   ae_assert(n >= 1, "MinCGCreateF: N too small!");
   ae_assert(x->cnt >= n, "MinCGCreateF: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinCGCreateF: X contains infinite or NaN values!");
   ae_assert(isfinite(diffstep), "MinCGCreateF: DiffStep is infinite or NaN!");
   ae_assert(diffstep > 0.0, "MinCGCreateF: DiffStep is non-positive!");
   mincg_mincginitinternal(n, diffstep, state);
   mincgrestartfrom(state, x);
}

// This function calculates preconditioned product H^(-1)*x and stores result
// back into X. Work0[] and Work1[] are used as temporaries (size must be at
// least N; this function doesn't allocate arrays).
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
static void mincg_preconditionedmultiply(mincgstate *state, RVector *x, RVector *work0, RVector *work1) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t vcnt;
   double v;
   n = state->n;
   vcnt = state->vcnt;
   if (state->prectype == 0) {
      return;
   }
   if (state->prectype == 3) {
      for (i = 0; i < n; i++) {
         x->xR[i] *= state->s.xR[i] * state->s.xR[i];
      }
      return;
   }
   ae_assert(state->prectype == 2, "MinCG: internal error (unexpected PrecType)");
// handle part common for VCnt == 0 and VCnt != 0
   for (i = 0; i < n; i++) {
      x->xR[i] /= state->diagh.xR[i] + state->diaghl2.xR[i];
   }
// if VCnt > 0
   if (vcnt > 0) {
      for (i = 0; i < vcnt; i++) {
         v = ae_v_dotproduct(state->vcorr.xyR[i], 1, x->xR, 1, n);
         work0->xR[i] = v;
      }
      for (i = 0; i < n; i++) {
         work1->xR[i] = 0.0;
      }
      for (i = 0; i < vcnt; i++) {
         v = work0->xR[i];
         ae_v_addd(state->work1.xR, 1, state->vcorr.xyR[i], 1, n, v);
      }
      for (i = 0; i < n; i++) {
         x->xR[i] -= state->work1.xR[i] / (state->diagh.xR[i] + state->diaghl2.xR[i]);
      }
   }
}

// This function calculates preconditioned product x'*H^(-1)*y. Work0[] and
// Work1[] are used as temporaries (size must be at least N; this function
// doesn't allocate arrays).
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
static double mincg_preconditionedmultiply2(mincgstate *state, RVector *x, RVector *y, RVector *work0, RVector *work1) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t vcnt;
   double v0;
   double v1;
   double result;
   n = state->n;
   vcnt = state->vcnt;
// no preconditioning
   if (state->prectype == 0) {
      v0 = ae_v_dotproduct(x->xR, 1, y->xR, 1, n);
      result = v0;
      return result;
   }
   if (state->prectype == 3) {
      result = 0.0;
      for (i = 0; i < n; i++) {
         result += x->xR[i] * state->s.xR[i] * state->s.xR[i] * y->xR[i];
      }
      return result;
   }
   ae_assert(state->prectype == 2, "MinCG: internal error (unexpected PrecType)");
// low rank preconditioning
   result = 0.0;
   for (i = 0; i < n; i++) {
      result += x->xR[i] * y->xR[i] / (state->diagh.xR[i] + state->diaghl2.xR[i]);
   }
   if (vcnt > 0) {
      for (i = 0; i < n; i++) {
         work0->xR[i] = x->xR[i] / (state->diagh.xR[i] + state->diaghl2.xR[i]);
         work1->xR[i] = y->xR[i] / (state->diagh.xR[i] + state->diaghl2.xR[i]);
      }
      for (i = 0; i < vcnt; i++) {
         v0 = ae_v_dotproduct(work0->xR, 1, state->vcorr.xyR[i], 1, n);
         v1 = ae_v_dotproduct(work1->xR, 1, state->vcorr.xyR[i], 1, n);
         result -= v0 * v1;
      }
   }
   return result;
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions mincgoptimize() listed below.
// ALGLIB: Copyright 20.04.2009 by Sergey Bochkanov
// API: bool mincgiteration(const mincgstate &state);
// API: void mincgoptimize(mincgstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void mincgoptimize(mincgstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool mincgiteration(mincgstate *state) {
   const ae_int_t rscountdownlen = 10;
   const double gtol = 0.3;
   AutoS ae_int_t n;
   AutoS ae_int_t i;
   AutoS double betak;
   AutoS double v;
   AutoS double vv;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14;
      case 15: goto Resume15; case 16: goto Resume16; case 17: goto Resume17;
      default: goto Exit;
   }
Spawn:
// Prepare
   n = state->n;
   state->algpowerup = state->lsend = state->lsstart = state->xupdated = state->needfg = state->needf = false;
   state->terminationneeded = false;
   state->userterminationneeded = false;
   state->repterminationtype = 0;
   state->repiterationscount = 0;
   state->repnfev = 0;
   state->debugrestartscount = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, n, 1, state->smoothnessguardlevel > 0);
   vectorsetlengthatleast(&state->invs, n);
   for (i = 0; i < n; i++) {
      state->lastscaleused.xR[i] = state->s.xR[i];
      state->invs.xR[i] = 1.0 / state->s.xR[i];
   }
// Check, that transferred derivative value is right
   if (state->diffstep == 0.0 && state->teststep > 0.0) {
      while (smoothnessmonitorcheckgradientatx0(&state->smonitor, &state->xbase, &state->s, &state->s, &state->s, false, state->teststep)) {
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->smonitor.x.xR[i];
         }
         state->needfg = true, state->PQ = 0; goto Pause; Resume00: state->needfg = false;
         state->smonitor.fi.xR[0] = state->f;
         for (i = 0; i < n; i++) {
            state->smonitor.j.xyR[0][i] = state->g.xR[i];
         }
      }
   }
// Preparations continue:
// * set XK
// * calculate F/G
// * set DK to -G
// * powerup algo (it may change preconditioner)
// * apply preconditioner to DK
// * report update of X
// * check stopping conditions for G
   for (i = 0; i < n; i++) {
      state->x.xR[i] = state->xbase.xR[i];
   }
   ae_v_move(state->xk.xR, 1, state->x.xR, 1, n);
   if (state->diffstep == 0.0) {
      state->needfg = true, state->PQ = 1; goto Pause; Resume01: state->needfg = false;
   } else {
      state->needf = true;
      state->PQ = 2; goto Pause; Resume02:
      state->fbase = state->f;
      for (i = 0; i < n; i++) {
         v = state->x.xR[i];
         state->x.xR[i] = v - state->diffstep * state->s.xR[i];
         state->PQ = 3; goto Pause; Resume03:
         state->fm2 = state->f;
         state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
         state->PQ = 4; goto Pause; Resume04:
         state->fm1 = state->f;
         state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
         state->PQ = 5; goto Pause; Resume05:
         state->fp1 = state->f;
         state->x.xR[i] = v + state->diffstep * state->s.xR[i];
         state->PQ = 6; goto Pause; Resume06:
         state->fp2 = state->f;
         state->x.xR[i] = v;
         state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
      }
      state->needf = false;
      state->f = state->fbase;
   }
   if (state->drep) {
   // Report algorithm powerup (if needed)
      state->algpowerup = true, state->PQ = 7; goto Pause; Resume07: state->algpowerup = false;
   }
   trimprepare(state->f, &state->trimthreshold);
   ae_v_moveneg(state->dk.xR, 1, state->g.xR, 1, n);
   mincg_preconditionedmultiply(state, &state->dk, &state->work0, &state->work1);
   if (state->xrep) {
      state->xupdated = true, state->PQ = 8; goto Pause; Resume08: state->xupdated = false;
   }
   if (state->terminationneeded || state->userterminationneeded) {
   // Combined termination point for "internal" termination by TerminationNeeded flag
   // and for "user" termination by MinCGRequestTermination() (UserTerminationNeeded flag).
   // In this location rules for both of methods are same, thus only one exit point is needed.
      ae_v_move(state->xn.xR, 1, state->xk.xR, 1, n);
      state->repterminationtype = 8;
      goto Exit;
   }
   v = 0.0;
   for (i = 0; i < n; i++) {
      v += sqr(state->g.xR[i] * state->s.xR[i]);
   }
   if (sqrt(v) <= state->epsg) {
      ae_v_move(state->xn.xR, 1, state->xk.xR, 1, n);
      state->repterminationtype = 4;
      goto Exit;
   }
   state->repnfev = 1;
   state->k = 0;
   state->fold = state->f;
// Choose initial step.
// Apply preconditioner, if we have something other than default.
   if (state->prectype == 2 || state->prectype == 3) {
   // because we use preconditioner, step length must be equal
   // to the norm of DK
      v = ae_v_dotproduct(state->dk.xR, 1, state->dk.xR, 1, n);
      state->lastgoodstep = sqrt(v);
   } else {
   // No preconditioner is used, we try to use suggested step
      if (state->suggestedstep > 0.0) {
         state->lastgoodstep = state->suggestedstep;
      } else {
         state->lastgoodstep = 1.0;
      }
   }
// Main cycle
   state->rstimer = rscountdownlen;
   while (true) {
   // * clear reset flag
   // * clear termination flag
   // * store G[k] for later calculation of Y[k]
   // * prepare starting point and direction and step length for line search
      state->innerresetneeded = false;
      state->terminationneeded = false;
      ae_v_moveneg(state->yk.xR, 1, state->g.xR, 1, n);
      ae_v_move(state->d.xR, 1, state->dk.xR, 1, n);
      ae_v_move(state->x.xR, 1, state->xk.xR, 1, n);
      state->mcstage = 0;
      state->stp = 1.0;
      linminnormalized(&state->d, &state->stp, n);
      if (state->lastgoodstep != 0.0) {
         state->stp = state->lastgoodstep;
      }
      state->curstpmax = state->stpmax;
   // Report beginning of line search (if needed)
   // Terminate algorithm, if user request was detected
      if (state->drep) {
         state->lsstart = true, state->PQ = 9; goto Pause; Resume09: state->lsstart = false;
      }
      if (state->terminationneeded) {
         ae_v_move(state->xn.xR, 1, state->x.xR, 1, n);
         state->repterminationtype = 8;
         goto Exit;
      }
   // Minimization along D
      smoothnessmonitorstartlinesearch1u(&state->smonitor, &state->s, &state->invs, &state->x, state->f, &state->g, state->repiterationscount, -1);
      while (mcsrch(n, &state->x, state->f, &state->g, &state->d, &state->stp, state->curstpmax, gtol, &state->mcinfo, &state->nfev, &state->work0, &state->lstate, &state->mcstage)) {
      // Calculate function/gradient using either
      // analytical gradient supplied by user
      // or finite difference approximation.
      //
      // "Trim" function in order to handle near-singularity points.
         if (state->diffstep == 0.0) {
            state->needfg = true, state->PQ = 10; goto Pause; Resume10: state->needfg = false;
         } else {
            state->needf = true;
            state->PQ = 11; goto Pause; Resume11:
            state->fbase = state->f;
            for (i = 0; i < n; i++) {
               v = state->x.xR[i];
               state->x.xR[i] = v - state->diffstep * state->s.xR[i];
               state->PQ = 12; goto Pause; Resume12:
               state->fm2 = state->f;
               state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 13; goto Pause; Resume13:
               state->fm1 = state->f;
               state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 14; goto Pause; Resume14:
               state->fp1 = state->f;
               state->x.xR[i] = v + state->diffstep * state->s.xR[i];
               state->PQ = 15; goto Pause; Resume15:
               state->fp2 = state->f;
               state->x.xR[i] = v;
               state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
            }
            state->needf = false;
            state->f = state->fbase;
         }
         smoothnessmonitorenqueuepoint1u(&state->smonitor, &state->s, &state->invs, &state->d, state->stp, &state->x, state->f, &state->g);
         trimfunction(&state->f, &state->g, n, state->trimthreshold);
      // Call MCSRCH again
      }
      smoothnessmonitorfinalizelinesearch(&state->smonitor);
   // * terminate algorithm if "user" request for detected
   // * report end of line search
   // * store current point to XN
   // * report iteration
   // * terminate algorithm if "internal" request was detected
      if (state->userterminationneeded) {
         ae_v_move(state->xn.xR, 1, state->xk.xR, 1, n);
         state->repterminationtype = 8;
         goto Exit;
      }
      if (state->drep) {
      // Report end of line search (if needed)
         state->lsend = true, state->PQ = 16; goto Pause; Resume16: state->lsend = false;
      }
      ae_v_move(state->xn.xR, 1, state->x.xR, 1, n);
      if (state->xrep) {
         state->xupdated = true, state->PQ = 17; goto Pause; Resume17: state->xupdated = false;
      }
      if (state->terminationneeded) {
         ae_v_move(state->xn.xR, 1, state->x.xR, 1, n);
         state->repterminationtype = 8;
         goto Exit;
      }
   // Line search is finished.
   // * calculate BetaK
   // * calculate DN
   // * update timers
   // * calculate step length:
   //   * LastScaledStep is ALWAYS calculated because it is used in the stopping criteria
   //   * LastGoodStep is updated only when MCINFO is equal to 1 (Wolfe conditions hold).
   //     See below for more explanation.
      if (state->mcinfo == 1 && !state->innerresetneeded) {
      // Standard Wolfe conditions hold
      // Calculate Y[K] and D[K]'*Y[K]
         ae_v_add(state->yk.xR, 1, state->g.xR, 1, n);
         vv = ae_v_dotproduct(state->yk.xR, 1, state->dk.xR, 1, n);
      // Calculate BetaK according to DY formula
         v = mincg_preconditionedmultiply2(state, &state->g, &state->g, &state->work0, &state->work1);
         state->betady = v / vv;
      // Calculate BetaK according to HS formula
         v = mincg_preconditionedmultiply2(state, &state->g, &state->yk, &state->work0, &state->work1);
         state->betahs = v / vv;
      // Choose BetaK
         if (state->cgtype == 0) {
            betak = state->betady;
         }
         if (state->cgtype == 1) {
            betak = rmax2(0.0, rmin2(state->betady, state->betahs));
         }
      } else {
      // Something is wrong (may be function is too wild or too flat)
      // or we just have to restart algo.
      //
      // We'll set BetaK == 0, which will restart CG algorithm.
      // We can stop later (during normal checks) if stopping conditions are met.
         betak = 0.0;
         state->debugrestartscount++;
      }
      if (state->repiterationscount > 0 && state->repiterationscount % (3 + n) == 0) {
      // clear Beta every N iterations
         betak = 0.0;
      }
      if (state->mcinfo == 1 || state->mcinfo == 5) {
         state->rstimer = rscountdownlen;
      } else {
         state->rstimer--;
      }
      ae_v_moveneg(state->dn.xR, 1, state->g.xR, 1, n);
      mincg_preconditionedmultiply(state, &state->dn, &state->work0, &state->work1);
      ae_v_addd(state->dn.xR, 1, state->dk.xR, 1, n, betak);
      state->lastscaledstep = 0.0;
      for (i = 0; i < n; i++) {
         state->lastscaledstep += sqr(state->d.xR[i] / state->s.xR[i]);
      }
      state->lastscaledstep = state->stp * sqrt(state->lastscaledstep);
      if (state->mcinfo == 1) {
      // Step is good (Wolfe conditions hold), update LastGoodStep.
      //
      // This check for MCINFO == 1 is essential because sometimes in the
      // constrained optimization setting we may take very short steps
      // (like 1E-15) because we were very close to boundary of the
      // feasible area. Such short step does not mean that we've converged
      // to the solution - it was so short because we were close to the
      // boundary and there was a limit on step length.
      //
      // So having such short step is quite normal situation. However, we
      // should NOT start next iteration from step whose initial length is
      // estimated as 1E-15 because it may lead to the failure of the
      // linear minimizer (step is too short, function does not changes,
      // line search stagnates).
         state->lastgoodstep = 0.0;
         for (i = 0; i < n; i++) {
            state->lastgoodstep += sqr(state->d.xR[i]);
         }
         state->lastgoodstep = state->stp * sqrt(state->lastgoodstep);
      }
   // Update information.
   // Check stopping conditions.
      v = 0.0;
      for (i = 0; i < n; i++) {
         v += sqr(state->g.xR[i] * state->s.xR[i]);
      }
      if (!isfinite(v) || !isfinite(state->f)) {
      // Abnormal termination - infinities in function/gradient
         state->repterminationtype = -8;
         goto Exit;
      }
      state->repnfev += state->nfev;
      state->repiterationscount++;
      if (state->repiterationscount >= state->maxits && state->maxits > 0) {
      // Too many iterations
         state->repterminationtype = 5;
         goto Exit;
      }
      if (sqrt(v) <= state->epsg) {
      // Gradient is small enough
         state->repterminationtype = 4;
         goto Exit;
      }
      if (!state->innerresetneeded) {
      // These conditions are checked only when no inner reset was requested by user
         if (state->fold - state->f <= state->epsf * rmax2(fabs(state->fold), rmax2(fabs(state->f), 1.0))) {
         // F(k+1)-F(k) is small enough
            state->repterminationtype = 1;
            goto Exit;
         }
         if (state->lastscaledstep <= state->epsx) {
         // X(k+1)-X(k) is small enough
            state->repterminationtype = 2;
            goto Exit;
         }
      }
      if (state->rstimer <= 0) {
      // Too many subsequent restarts
         state->repterminationtype = 7;
         goto Exit;
      }
   // Shift Xk/Dk, update other information
      ae_v_move(state->xk.xR, 1, state->xn.xR, 1, n);
      ae_v_move(state->dk.xR, 1, state->dn.xR, 1, n);
      state->fold = state->f;
      state->k++;
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This  function  activates/deactivates verification  of  the  user-supplied
// analytic gradient.
//
// Upon  activation  of  this  option  OptGuard  integrity  checker  performs
// numerical differentiation of your target function  at  the  initial  point
// (note: future versions may also perform check  at  the  final  point)  and
// compares numerical gradient with analytic one provided by you.
//
// If difference is too large, an error flag is set and optimization  session
// continues. After optimization session is over, you can retrieve the report
// which  stores  both  gradients  and  specific  components  highlighted  as
// suspicious by the OptGuard.
//
// The primary OptGuard report can be retrieved with mincgoptguardresults().
//
// IMPORTANT: gradient check is a high-overhead option which  will  cost  you
//            about 3*N additional function evaluations. In many cases it may
//            cost as much as the rest of the optimization session.
//
//            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
//            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
//
// NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
//       does NOT interrupt optimization even if it discovers bad gradient.
//
// Inputs:
//     State       -   structure used to store algorithm state
//     TestStep    -   verification step used for numerical differentiation:
//                     * TestStep == 0 turns verification off
//                     * TestStep > 0 activates verification
//                     You should carefully choose TestStep. Value  which  is
//                     too large (so large that  function  behavior  is  non-
//                     cubic at this scale) will lead  to  false  alarms. Too
//                     short step will result in rounding  errors  dominating
//                     numerical derivative.
//
//                     You may use different step for different parameters by
//                     means of setting scale with mincgsetscale().
//
// ==== EXPLANATION ====
//
// In order to verify gradient algorithm performs following steps:
//   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
//     where X[i] is i-th component of the initial point and S[i] is a  scale
//     of i-th parameter
//   * F(X) is evaluated at these trial points
//   * we perform one more evaluation in the middle point of the interval
//   * we  build  cubic  model using function values and derivatives at trial
//     points and we compare its prediction with actual value in  the  middle
//     point
// ALGLIB: Copyright 15.06.2014 by Sergey Bochkanov
// API: void mincgoptguardgradient(const mincgstate &state, const double teststep);
void mincgoptguardgradient(mincgstate *state, double teststep) {
   ae_assert(isfinite(teststep), "MinCGOptGuardGradient: TestStep contains NaN or INF");
   ae_assert(teststep >= 0.0, "MinCGOptGuardGradient: invalid argument TestStep(TestStep < 0)");
   state->teststep = teststep;
}

// This  function  activates/deactivates nonsmoothness monitoring  option  of
// the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
// solution process and tries to detect ill-posed problems, i.e. ones with:
// a) discontinuous target function (non-C0)
// b) nonsmooth     target function (non-C1)
//
// Smoothness monitoring does NOT interrupt optimization  even if it suspects
// that your problem is nonsmooth. It just sets corresponding  flags  in  the
// OptGuard report which can be retrieved after optimization is over.
//
// Smoothness monitoring is a moderate overhead option which often adds  less
// than 1% to the optimizer running time. Thus, you can use it even for large
// scale problems.
//
// NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
//       continuity violations.
//
//       First, minor errors are hard to  catch - say, a 0.0001 difference in
//       the model values at two sides of the gap may be due to discontinuity
//       of the model - or simply because the model has changed.
//
//       Second, C1-violations  are  especially  difficult  to  detect  in  a
//       noninvasive way. The optimizer usually  performs  very  short  steps
//       near the nonsmoothness, and differentiation  usually   introduces  a
//       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
//       discontinuity in the slope is due to real nonsmoothness or just  due
//       to numerical noise alone.
//
//       Our top priority was to avoid false positives, so in some rare cases
//       minor errors may went unnoticed (however, in most cases they can  be
//       spotted with restart from different initial point).
//
// Inputs:
//     state   -   algorithm state
//     level   -   monitoring level:
//                 * 0 - monitoring is disabled
//                 * 1 - noninvasive low-overhead monitoring; function values
//                       and/or gradients are recorded, but OptGuard does not
//                       try to perform additional evaluations  in  order  to
//                       get more information about suspicious locations.
//
// ==== EXPLANATION ====
//
// One major source of headache during optimization  is  the  possibility  of
// the coding errors in the target function/constraints (or their gradients).
// Such  errors   most   often   manifest   themselves  as  discontinuity  or
// nonsmoothness of the target/constraints.
//
// Another frequent situation is when you try to optimize something involving
// lots of min() and max() operations, i.e. nonsmooth target. Although not  a
// coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
// stop right after encountering nonsmoothness, well before reaching solution.
//
// OptGuard integrity checker helps you to catch such situations: it monitors
// function values/gradients being passed  to  the  optimizer  and  tries  to
// errors. Upon discovering suspicious pair of points it  raises  appropriate
// flag (and allows you to continue optimization). When optimization is done,
// you can study OptGuard result.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void mincgoptguardsmoothness(const mincgstate &state, const ae_int_t level);
// API: void mincgoptguardsmoothness(const mincgstate &state);
void mincgoptguardsmoothness(mincgstate *state, ae_int_t level) {
   ae_assert(level == 0 || level == 1, "MinCGOptGuardSmoothness: unexpected value of level parameter");
   state->smoothnessguardlevel = level;
}

// Results of OptGuard integrity check, should be called  after  optimization
// session is over.
//
// ==== PRIMARY REPORT ====
//
// OptGuard performs several checks which are intended to catch common errors
// in the implementation of nonlinear function/gradient:
// * incorrect analytic gradient
// * discontinuous (non-C0) target functions (constraints)
// * nonsmooth     (non-C1) target functions (constraints)
//
// Each of these checks is activated with appropriate function:
// * mincgoptguardgradient() for gradient verification
// * mincgoptguardsmoothness() for C0/C1 checks
//
// Following flags are set when these errors are suspected:
// * rep.badgradsuspected, and additionally:
//   * rep.badgradvidx for specific variable (gradient element) suspected
//   * rep.badgradxbase, a point where gradient is tested
//   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
//     single row in order to make  report  structure  compatible  with  more
//     complex optimizers like MinNLC or MinLM)
//   * rep.badgradnum,   reference    gradient    obtained    via   numerical
//     differentiation (stored as  2D matrix with single row in order to make
//     report structure compatible with more complex optimizers  like  MinNLC
//     or MinLM)
// * rep.nonc0suspected
// * rep.nonc1suspected
//
// ==== ADDITIONAL REPORTS/LOGS ====
//
// Several different tests are performed to catch C0/C1 errors, you can  find
// out specific test signaled error by looking to:
// * rep.nonc0test0positive, for non-C0 test #0
// * rep.nonc1test0positive, for non-C1 test #0
// * rep.nonc1test1positive, for non-C1 test #1
//
// Additional information (including line search logs)  can  be  obtained  by
// means of:
// * mincgoptguardnonc1test0results()
// * mincgoptguardnonc1test1results()
// which return detailed error reports, specific points where discontinuities
// were found, and so on.
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     rep     -   generic OptGuard report;  more  detailed  reports  can  be
//                 retrieved with other functions.
//
// NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
//       ones) are possible although unlikely.
//
//       The reason  is  that  you  need  to  make several evaluations around
//       nonsmoothness  in  order  to  accumulate  enough  information  about
//       function curvature. Say, if you start right from the nonsmooth point,
//       optimizer simply won't get enough data to understand what  is  going
//       wrong before it terminates due to abrupt changes in the  derivative.
//       It is also  possible  that  "unlucky"  step  will  move  us  to  the
//       termination too quickly.
//
//       Our current approach is to have less than 0.1%  false  negatives  in
//       our test examples  (measured  with  multiple  restarts  from  random
//       points), and to have exactly 0% false positives.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void mincgoptguardresults(const mincgstate &state, optguardreport &rep);
void mincgoptguardresults(mincgstate *state, optguardreport *rep) {
   SetObj(optguardreport, rep);
   smoothnessmonitorexportreport(&state->smonitor, rep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #0
//
// Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
// obtained during line searches and monitors  behavior  of  the  directional
// derivative estimate.
//
// This test is less powerful than test #1, but it does  not  depend  on  the
// gradient values and thus it is more robust against artifacts introduced by
// numerical differentiation.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #0 "strong" report
//     lngrep  -   C1 test #0 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void mincgoptguardnonc1test0results(const mincgstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep);
void mincgoptguardnonc1test0results(mincgstate *state, optguardnonc1test0report *strrep, optguardnonc1test0report *lngrep) {
   SetObj(optguardnonc1test0report, strrep);
   SetObj(optguardnonc1test0report, lngrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0lngrep, &state->lastscaleused, lngrep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #1
//
// Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
// gradient computed during line search.
//
// When precise analytic gradient is provided this test is more powerful than
// test #0  which  works  with  function  values  and  ignores  user-provided
// gradient.  However,  test  #0  becomes  more   powerful   when   numerical
// differentiation is employed (in such cases test #1 detects  higher  levels
// of numerical noise and becomes too conservative).
//
// This test also tells specific components of the gradient which violate  C1
// continuity, which makes it more informative than #0, which just tells that
// continuity is violated.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * vidx - is an index of the variable in [0,N) with nonsmooth derivative
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], g[] - arrays of length CNT which store step lengths and  gradient
//   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
//   vidx-th component of the gradient.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #1 "strong" report
//     lngrep  -   C1 test #1 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void mincgoptguardnonc1test1results(const mincgstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep);
void mincgoptguardnonc1test1results(mincgstate *state, optguardnonc1test1report *strrep, optguardnonc1test1report *lngrep) {
   SetObj(optguardnonc1test1report, strrep);
   SetObj(optguardnonc1test1report, lngrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1lngrep, &state->lastscaleused, lngrep);
}

// Conjugate gradient results
//
// Buffered implementation of MinCGResults(), which uses preallocated buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 20.04.2009 by Sergey Bochkanov
// API: void mincgresultsbuf(const mincgstate &state, real_1d_array &x, mincgreport &rep);
void mincgresultsbuf(mincgstate *state, RVector *x, mincgreport *rep) {
   vectorsetlengthatleast(x, state->n);
   ae_v_move(x->xR, 1, state->xn.xR, 1, state->n);
   rep->iterationscount = state->repiterationscount;
   rep->nfev = state->repnfev;
   rep->terminationtype = state->repterminationtype;
}

// Conjugate gradient results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization report:
//                 * Rep.TerminationType completetion code:
//                     * -8    internal integrity control  detected  infinite
//                             or NAN values in  function/gradient.  Abnormal
//                             termination signalled.
//                     *  1    relative function improvement is no more than
//                             EpsF.
//                     *  2    relative step is no more than EpsX.
//                     *  4    gradient norm is no more than EpsG
//                     *  5    MaxIts steps was taken
//                     *  7    stopping conditions are too stringent,
//                             further improvement is impossible,
//                             we return best X found so far
//                     *  8    terminated by user
//                 * Rep.IterationsCount contains iterations count
//                 * NFEV countains number of function calculations
// ALGLIB: Copyright 20.04.2009 by Sergey Bochkanov
// API: void mincgresults(const mincgstate &state, real_1d_array &x, mincgreport &rep);
void mincgresults(mincgstate *state, RVector *x, mincgreport *rep) {
   SetVector(x);
   SetObj(mincgreport, rep);
   mincgresultsbuf(state, x, rep);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 08.10.2014 by Sergey Bochkanov
// API: void mincgrequesttermination(const mincgstate &state);
void mincgrequesttermination(mincgstate *state) {
   state->userterminationneeded = true;
}

void mincgstate_init(void *_p, bool make_automatic) {
   mincgstate *p = (mincgstate *)_p;
   ae_vector_init(&p->diagh, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diaghl2, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->vcorr, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->yk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   linminstate_init(&p->lstate, make_automatic);
   ae_vector_init(&p->work0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->work1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->invs, 0, DT_REAL, make_automatic);
   smoothnessmonitor_init(&p->smonitor, make_automatic);
   ae_vector_init(&p->lastscaleused, 0, DT_REAL, make_automatic);
}

void mincgstate_copy(void *_dst, const void *_src, bool make_automatic) {
   mincgstate *dst = (mincgstate *)_dst;
   const mincgstate *src = (const mincgstate *)_src;
   dst->n = src->n;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->stpmax = src->stpmax;
   dst->suggestedstep = src->suggestedstep;
   dst->xrep = src->xrep;
   dst->drep = src->drep;
   dst->cgtype = src->cgtype;
   dst->prectype = src->prectype;
   ae_vector_copy(&dst->diagh, &src->diagh, make_automatic);
   ae_vector_copy(&dst->diaghl2, &src->diaghl2, make_automatic);
   ae_matrix_copy(&dst->vcorr, &src->vcorr, make_automatic);
   dst->vcnt = src->vcnt;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   dst->diffstep = src->diffstep;
   dst->nfev = src->nfev;
   dst->mcstage = src->mcstage;
   dst->k = src->k;
   ae_vector_copy(&dst->xk, &src->xk, make_automatic);
   ae_vector_copy(&dst->dk, &src->dk, make_automatic);
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->dn, &src->dn, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->fold = src->fold;
   dst->stp = src->stp;
   dst->curstpmax = src->curstpmax;
   ae_vector_copy(&dst->yk, &src->yk, make_automatic);
   dst->lastgoodstep = src->lastgoodstep;
   dst->lastscaledstep = src->lastscaledstep;
   dst->mcinfo = src->mcinfo;
   dst->innerresetneeded = src->innerresetneeded;
   dst->terminationneeded = src->terminationneeded;
   dst->trimthreshold = src->trimthreshold;
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   dst->rstimer = src->rstimer;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->needf = src->needf;
   dst->needfg = src->needfg;
   dst->xupdated = src->xupdated;
   dst->algpowerup = src->algpowerup;
   dst->lsstart = src->lsstart;
   dst->lsend = src->lsend;
   dst->userterminationneeded = src->userterminationneeded;
   dst->PQ = src->PQ;
   dst->repiterationscount = src->repiterationscount;
   dst->repnfev = src->repnfev;
   dst->repterminationtype = src->repterminationtype;
   dst->debugrestartscount = src->debugrestartscount;
   linminstate_copy(&dst->lstate, &src->lstate, make_automatic);
   dst->fbase = src->fbase;
   dst->fm2 = src->fm2;
   dst->fm1 = src->fm1;
   dst->fp1 = src->fp1;
   dst->fp2 = src->fp2;
   dst->betahs = src->betahs;
   dst->betady = src->betady;
   ae_vector_copy(&dst->work0, &src->work0, make_automatic);
   ae_vector_copy(&dst->work1, &src->work1, make_automatic);
   ae_vector_copy(&dst->invs, &src->invs, make_automatic);
   dst->teststep = src->teststep;
   dst->smoothnessguardlevel = src->smoothnessguardlevel;
   smoothnessmonitor_copy(&dst->smonitor, &src->smonitor, make_automatic);
   ae_vector_copy(&dst->lastscaleused, &src->lastscaleused, make_automatic);
}

void mincgstate_free(void *_p, bool make_automatic) {
   mincgstate *p = (mincgstate *)_p;
   ae_vector_free(&p->diagh, make_automatic);
   ae_vector_free(&p->diaghl2, make_automatic);
   ae_matrix_free(&p->vcorr, make_automatic);
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->xk, make_automatic);
   ae_vector_free(&p->dk, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->dn, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->yk, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   linminstate_free(&p->lstate, make_automatic);
   ae_vector_free(&p->work0, make_automatic);
   ae_vector_free(&p->work1, make_automatic);
   ae_vector_free(&p->invs, make_automatic);
   smoothnessmonitor_free(&p->smonitor, make_automatic);
   ae_vector_free(&p->lastscaleused, make_automatic);
}

void mincgreport_init(void *_p, bool make_automatic) {
}

void mincgreport_copy(void *_dst, const void *_src, bool make_automatic) {
   mincgreport *dst = (mincgreport *)_dst;
   const mincgreport *src = (const mincgreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->terminationtype = src->terminationtype;
}

void mincgreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores state of the nonlinear CG optimizer.
//
// You should use ALGLIB functions to work with this object.
DefClass(mincgstate, DecVal(needf) DecVal(needfg) DecVal(xupdated) DecVal(f) DecVar(g) DecVar(x))

// This structure stores optimization report:
// * IterationsCount           total number of inner iterations
// * NFEV                      number of gradient evaluations
// * TerminationType           termination type (see below)
//
// TERMINATION CODES
//
// TerminationType field contains completion code, which can be:
//   -8    internal integrity control detected  infinite  or  NAN  values  in
//         function/gradient. Abnormal termination signalled.
//    1    relative function improvement is no more than EpsF.
//    2    relative step is no more than EpsX.
//    4    gradient norm is no more than EpsG
//    5    MaxIts steps was taken
//    7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//    8    terminated by user who called mincgrequesttermination(). X contains
//         point which was "current accepted" when  termination  request  was
//         submitted.
//
// Other fields of this structure are not documented and should not be used!
DefClass(mincgreport, DecVal(iterationscount) DecVal(nfev) DecVal(terminationtype))

void mincgsetcond(const mincgstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetcond(ConstT(mincgstate, state), epsg, epsf, epsx, maxits);
   alglib_impl::ae_state_clear();
}

void mincgsetscale(const mincgstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetscale(ConstT(mincgstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void mincgsetxrep(const mincgstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetxrep(ConstT(mincgstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void mincgsetcgtype(const mincgstate &state, const ae_int_t cgtype) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetcgtype(ConstT(mincgstate, state), cgtype);
   alglib_impl::ae_state_clear();
}

void mincgsetstpmax(const mincgstate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetstpmax(ConstT(mincgstate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void mincgsetprecdefault(const mincgstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetprecdefault(ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}

void mincgsetprecdiag(const mincgstate &state, const real_1d_array &d) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetprecdiag(ConstT(mincgstate, state), ConstT(ae_vector, d));
   alglib_impl::ae_state_clear();
}

void mincgsetprecscale(const mincgstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsetprecscale(ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}

void mincgsuggeststep(const mincgstate &state, const double stp) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgsuggeststep(ConstT(mincgstate, state), stp);
   alglib_impl::ae_state_clear();
}

void mincgrestartfrom(const mincgstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgrestartfrom(ConstT(mincgstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void mincgcreate(const ae_int_t n, const real_1d_array &x, mincgstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgcreate(n, ConstT(ae_vector, x), ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void mincgcreate(const real_1d_array &x, mincgstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgcreate(n, ConstT(ae_vector, x), ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void mincgcreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, mincgstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgcreatef(n, ConstT(ae_vector, x), diffstep, ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void mincgcreatef(const real_1d_array &x, const double diffstep, mincgstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgcreatef(n, ConstT(ae_vector, x), diffstep, ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}
#endif

bool mincgiteration(const mincgstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::mincgiteration(ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     func    -   callback which calculates function (or merit function)
//                 value func at given point x
//     grad    -   callback which calculates function (or merit function)
//                 value func and gradient grad at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. This function has two different implementations: one which  uses  exact
//    (analytical) user-supplied  gradient, and one which uses function value
//    only  and  numerically  differentiates  function  in  order  to  obtain
//    gradient.
//
//    Depending  on  the  specific  function  used to create optimizer object
//    (either MinCGCreate()  for analytical gradient  or  MinCGCreateF()  for
//    numerical differentiation) you should  choose  appropriate  variant  of
//    MinCGOptimize() - one which accepts function AND gradient or one  which
//    accepts function ONLY.
//
//    Be careful to choose variant of MinCGOptimize()  which  corresponds  to
//    your optimization scheme! Table below lists different  combinations  of
//    callback (function/gradient) passed  to  MinCGOptimize()  and  specific
//    function used to create optimizer.
//
//                   |         USER PASSED TO MinCGOptimize()
//    CREATED WITH   |  function only   |  function and gradient
//    ------------------------------------------------------------
//    MinCGCreateF() |     work                FAIL
//    MinCGCreate()  |     FAIL                work
//
//    Here "FAIL" denotes inappropriate combinations  of  optimizer  creation
//    function and MinCGOptimize() version. Attemps to use  such  combination
//    (for  example,  to create optimizer with  MinCGCreateF()  and  to  pass
//    gradient information to MinCGOptimize()) will lead to  exception  being
//    thrown. Either  you  did  not  pass  gradient when it WAS needed or you
//    passed gradient when it was NOT needed.
// ALGLIB: Copyright 20.04.2009 by Sergey Bochkanov
void mincgoptimize(mincgstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "mincgoptimize: func is NULL");
   while (alglib_impl::mincgiteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "mincgoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void mincgoptimize(mincgstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(grad != NULL, "mincgoptimize: grad is NULL");
   while (alglib_impl::mincgiteration(state.c_ptr()))
   BegPoll
      if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "mincgoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void mincgoptguardgradient(const mincgstate &state, const double teststep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgoptguardgradient(ConstT(mincgstate, state), teststep);
   alglib_impl::ae_state_clear();
}

void mincgoptguardsmoothness(const mincgstate &state, const ae_int_t level) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgoptguardsmoothness(ConstT(mincgstate, state), level);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void mincgoptguardsmoothness(const mincgstate &state) {
   ae_int_t level = 1;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgoptguardsmoothness(ConstT(mincgstate, state), level);
   alglib_impl::ae_state_clear();
}
#endif

void mincgoptguardresults(const mincgstate &state, optguardreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgoptguardresults(ConstT(mincgstate, state), ConstT(optguardreport, rep));
   alglib_impl::ae_state_clear();
}

void mincgoptguardnonc1test0results(const mincgstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgoptguardnonc1test0results(ConstT(mincgstate, state), ConstT(optguardnonc1test0report, strrep), ConstT(optguardnonc1test0report, lngrep));
   alglib_impl::ae_state_clear();
}

void mincgoptguardnonc1test1results(const mincgstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgoptguardnonc1test1results(ConstT(mincgstate, state), ConstT(optguardnonc1test1report, strrep), ConstT(optguardnonc1test1report, lngrep));
   alglib_impl::ae_state_clear();
}

void mincgresultsbuf(const mincgstate &state, real_1d_array &x, mincgreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgresultsbuf(ConstT(mincgstate, state), ConstT(ae_vector, x), ConstT(mincgreport, rep));
   alglib_impl::ae_state_clear();
}

void mincgresults(const mincgstate &state, real_1d_array &x, mincgreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgresults(ConstT(mincgstate, state), ConstT(ae_vector, x), ConstT(mincgreport, rep));
   alglib_impl::ae_state_clear();
}

void mincgrequesttermination(const mincgstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::mincgrequesttermination(ConstT(mincgstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === NLCSQP Package ===
// Depends on: VIPMSOLVER
namespace alglib_impl {
static const double nlcsqp_sqpdeltadecrease = 0.20;
static const double nlcsqp_sqpdeltaincrease = 0.80;
static const double nlcsqp_maxbigc = 100000.0;
static const double nlcsqp_augmentationfactor = 10.0;
static const ae_int_t nlcsqp_penaltymemlen = 5;

// This function initializes SQP subproblem.
// Should be called once in the beginning of the optimization.
//
// Inputs:
//     SState          -   solver state
//     Subsolver       -   SQP subproblem to initialize
//
// Return Value:
//     True on success
//     False on failure of the QP solver (unexpected... but possible due to numerical errors)
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static void nlcsqp_initqpsubsolver(minsqpstate *sstate, minsqpsubsolver *subsolver) {
   ae_int_t n;
   ae_int_t nslack;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t lccnt;
   ae_int_t nnz;
   ae_int_t offs;
   ae_int_t i;
   ae_int_t j;
   n = sstate->n;
   nec = sstate->nec;
   nic = sstate->nic;
   nlec = sstate->nlec;
   nlic = sstate->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   lccnt = nec + nic + nlec + nlic;
// Allocate temporaries
   vectorsetlengthatleast(&subsolver->cural, lccnt);
   vectorsetlengthatleast(&subsolver->curau, lccnt);
   vectorsetlengthatleast(&subsolver->curbndl, nslack);
   vectorsetlengthatleast(&subsolver->curbndu, nslack);
   vectorsetlengthatleast(&subsolver->curb, nslack);
// Initial state
   subsolver->algokind = 0;
// Linear constraints do not change across subiterations, that's
// why we allocate storage for them at the start of the program.
//
// A full set of "raw" constraints is stored; later we will filter
// out inequality ones which are inactive anywhere in the current
// trust region.
//
// NOTE: because sparserawlc object stores only linear constraint
//       (linearizations of nonlinear ones are not stored) we
//       allocate only minimum necessary space.
   nnz = 0;
   for (i = 0; i < nec + nic; i++) {
      for (j = 0; j < n; j++) {
         if (sstate->scaledcleic.xyR[i][j] != 0.0) {
            nnz++;
         }
      }
   }
   vectorsetlengthatleast(&subsolver->sparserawlc.ridx, nec + nic + 1);
   vectorsetlengthatleast(&subsolver->sparserawlc.vals, nnz);
   vectorsetlengthatleast(&subsolver->sparserawlc.idx, nnz);
   vectorsetlengthatleast(&subsolver->sparserawlc.didx, nec + nic);
   vectorsetlengthatleast(&subsolver->sparserawlc.uidx, nec + nic);
   offs = 0;
   subsolver->sparserawlc.ridx.xZ[0] = 0;
   for (i = 0; i < nec + nic; i++) {
      for (j = 0; j < n; j++) {
         if (sstate->scaledcleic.xyR[i][j] != 0.0) {
         // Primary part of the matrix
            subsolver->sparserawlc.vals.xR[offs] = sstate->scaledcleic.xyR[i][j];
            subsolver->sparserawlc.idx.xZ[offs] = j;
            offs++;
         }
      }
      subsolver->sparserawlc.ridx.xZ[i + 1] = offs;
   }
   subsolver->sparserawlc.matrixtype = 1;
   subsolver->sparserawlc.ninitialized = subsolver->sparserawlc.ridx.xZ[nec + nic];
   subsolver->sparserawlc.m = nec + nic;
   subsolver->sparserawlc.n = n;
   sparseinitduidx(&subsolver->sparserawlc);
}

// This function sets subsolver algorithm to interior point method (IPM)
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static void nlcsqp_qpsubsolversetalgoipm(minsqpsubsolver *subsolver) {
   subsolver->algokind = 0;
}

// This function solves QP subproblem given by initial point X, function vector Fi
// and Jacobian Jac, and returns estimates of Lagrangian multipliers and search direction D[].
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static void nlcsqp_fassolve(minsqpsubsolver *subsolver, RVector *d0, RMatrix *h, ae_int_t nq, RVector *b, ae_int_t n, RVector *bndl, RVector *bndu, sparsematrix *a, ae_int_t m, RVector *al, RVector *au, double trustrad, ae_int_t *terminationtype, RVector *d, RVector *lagmult) {
   ae_int_t i;
   *terminationtype = 1;
// Initial point, integrity check for constraints
   vectorsetlengthatleast(&subsolver->hasbndl, n);
   vectorsetlengthatleast(&subsolver->hasbndu, n);
   for (i = 0; i < n; i++) {
      subsolver->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      subsolver->hasbndu.xB[i] = isfinite(bndu->xR[i]);
      ae_assert(!subsolver->hasbndl.xB[i] || bndl->xR[i] <= d0->xR[i], "FASSolve: integrity check failed");
      ae_assert(!subsolver->hasbndu.xB[i] || bndu->xR[i] >= d0->xR[i], "FASSolve: integrity check failed");
      d->xR[i] = d0->xR[i];
   }
   vectorsetlengthatleast(&subsolver->hasal, m);
   vectorsetlengthatleast(&subsolver->hasau, m);
   for (i = 0; i < m; i++) {
      subsolver->hasal.xB[i] = isfinite(al->xR[i]);
      subsolver->hasau.xB[i] = isfinite(au->xR[i]);
      if (subsolver->hasal.xB[i] && subsolver->hasau.xB[i]) {
         ae_assert(al->xR[i] <= au->xR[i], "FASSolve: integrity check failed");
      }
   }
   matrixsetlengthatleast(&subsolver->activea, n, n);
   vectorsetlengthatleast(&subsolver->activerhs, n);
   vectorsetlengthatleast(&subsolver->activeidx, n);
   subsolver->activesetsize = 0;
// Activate equality constraints (at most N)
   for (i = 0; i < m; i++) {
      if (subsolver->hasal.xB[i] && subsolver->hasau.xB[i] && al->xR[i] == au->xR[i]) {
      // Stop if full set of constraints is activated
         if (subsolver->activesetsize >= n) {
            break;
         }
      }
   }
   vectorsetlengthatleast(&subsolver->tmp0, n);
   vectorsetlengthatleast(&subsolver->tmp1, n);
   for (i = 0; i < n; i++) {
      subsolver->tmp0.xR[i] = trustrad;
      subsolver->tmp1.xR[i] = 0.0;
   }
   vipminitdensewithslacks(&subsolver->ipmsolver, &subsolver->tmp0, &subsolver->tmp1, nq, n);
   vipmsetquadraticlinear(&subsolver->ipmsolver, h, &subsolver->sparsedummy, 0, true, b);
   vipmsetconstraints(&subsolver->ipmsolver, bndl, bndu, a, m, &subsolver->densedummy, 0, al, au);
   vipmoptimize(&subsolver->ipmsolver, false, &subsolver->tmp0, &subsolver->tmp1, &subsolver->tmp2, terminationtype);
   if (*terminationtype <= 0) {
      return;
   }
   for (i = 0; i < n; i++) {
      d->xR[i] = subsolver->tmp0.xR[i];
   }
   for (i = 0; i < m; i++) {
      lagmult->xR[i] = subsolver->tmp2.xR[i];
   }
}

// This function solves QP subproblem given by initial point X, function vector Fi
// and Jacobian Jac, and returns estimates of Lagrangian multipliers and search direction D[].
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static bool nlcsqp_qpsubproblemsolve(minsqpstate *state, minsqpsubsolver *subsolver, RVector *x, RVector *fi, RMatrix *jac, RVector *d, RVector *lagmult, ae_int_t *terminationtype) {
   ae_int_t n;
   ae_int_t nslack;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   double vv;
   double vright;
   double vmax;
   ae_int_t lccnt;
   ae_int_t offsslackec;
   ae_int_t offsslacknlec;
   ae_int_t offsslackic;
   ae_int_t offsslacknlic;
   ae_int_t offs;
   ae_int_t nnz;
   ae_int_t j0;
   ae_int_t j1;
   double rescaleby;
   bool result;
   *terminationtype = 0;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   lccnt = nec + nic + nlec + nlic;
// Locations of slack variables
   offsslackec = n;
   offsslacknlec = n + 2 * nec;
   offsslackic = n + 2 * nec + 2 * nlec;
   offsslacknlic = n + 2 * (nec + nlec) + nic;
// Prepare temporary structures
   rvectorgrowto(&subsolver->cural, lccnt);
   rvectorgrowto(&subsolver->curau, lccnt);
   vectorsetlengthatleast(&subsolver->d0, nslack);
// Prepare default solution: all zeros
   result = true;
   *terminationtype = 0;
   for (i = 0; i < nslack; i++) {
      d->xR[i] = 0.0;
      subsolver->d0.xR[i] = 0.0;
   }
   for (i = 0; i < lccnt; i++) {
      lagmult->xR[i] = 0.0;
   }
// Linear term B
//
// NOTE: elements [N,NSlack) are equal to bigC + perturbation to improve numeric properties of QP problem
   for (i = 0; i < n; i++) {
      subsolver->curb.xR[i] = jac->xyR[0][i];
   }
   v = 0.0;
   for (i = 0; i < n; i++) {
      v += sqr(jac->xyR[0][i]);
   }
   v = coalesce(sqrt(v), 1.0);
   for (i = n; i < nslack; i++) {
      subsolver->curb.xR[i] = (state->bigc + 1.0 / (1 + i)) * v;
   }
// Trust radius constraints for primary variables
   for (i = 0; i < n; i++) {
      subsolver->curbndl.xR[i] = -state->trustrad;
      subsolver->curbndu.xR[i] = state->trustrad;
      if (state->hasbndl.xB[i]) {
         subsolver->curbndl.xR[i] = rmax2(subsolver->curbndl.xR[i], state->scaledbndl.xR[i] - x->xR[i]);
      }
      if (state->hasbndu.xB[i]) {
         subsolver->curbndu.xR[i] = rmin2(subsolver->curbndu.xR[i], state->scaledbndu.xR[i] - x->xR[i]);
      }
   }
// Prepare storage for "effective" constraining matrix
   nnz = subsolver->sparserawlc.ridx.xZ[nec + nic];
   for (i = 0; i < nlec + nlic; i++) {
      for (j = 0; j < n; j++) {
         if (jac->xyR[1 + i][j] != 0.0) {
            nnz++;
         }
      }
   }
   nnz += 2 * nec + nic;
   nnz += 2 * nlec + nlic;
   ivectorgrowto(&subsolver->sparseefflc.ridx, lccnt + 1);
   rvectorgrowto(&subsolver->sparseefflc.vals, nnz);
   ivectorgrowto(&subsolver->sparseefflc.idx, nnz);
   vectorsetlengthatleast(&subsolver->sparseefflc.didx, lccnt);
   vectorsetlengthatleast(&subsolver->sparseefflc.uidx, lccnt);
   subsolver->sparseefflc.m = 0;
   subsolver->sparseefflc.n = nslack;
   subsolver->sparseefflc.matrixtype = 1;
// Append linear equality/inequality constraints
//
// Scan sparsified linear constraints stored in sparserawlc[], skip ones
// which are inactive anywhere in the trust region.
   vectorsetlengthatleast(&subsolver->tmp0, nslack);
   for (i = 0; i < n; i++) {
      subsolver->tmp0.xR[i] = x->xR[i];
   }
   for (i = n; i < nslack; i++) {
      subsolver->tmp0.xR[i] = 0.0;
   }
   for (i = 0; i < nec + nic; i++) {
   // Calculate:
   // * VRight - product of X[] (extended with zeros up to NSlack elements)
   //            and AR[i] - Ith row of sparserawlc matrix.
   // * VMax   - maximum value of X*ARi computed over trust region
      vright = 0.0;
      vmax = 0.0;
      j0 = subsolver->sparserawlc.ridx.xZ[i];
      j1 = subsolver->sparserawlc.ridx.xZ[i + 1] - 1;
      for (k = j0; k <= j1; k++) {
         j = subsolver->sparserawlc.idx.xZ[k];
         v = x->xR[j];
         vv = subsolver->sparserawlc.vals.xR[k];
         vright += vv * v;
         if (vv >= 0.0) {
            vmax += vv * (v + subsolver->curbndu.xR[j]);
         } else {
            vmax += vv * (v + subsolver->curbndl.xR[j]);
         }
      }
   // If constraint is an inequality one and guaranteed to be inactive
   // within trust region, it is skipped (row itself is retained but
   // filled by zeros).
      if (i >= nec && vmax <= state->scaledcleic.xyR[i][n]) {
         offs = subsolver->sparseefflc.ridx.xZ[i];
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslackic + (i - nec);
         subsolver->sparseefflc.ridx.xZ[i + 1] = offs + 1;
         subsolver->cural.xR[i] = 0.0;
         subsolver->curau.xR[i] = 0.0;
         subsolver->curbndl.xR[offsslackic + (i - nec)] = 0.0;
         subsolver->curbndu.xR[offsslackic + (i - nec)] = 0.0;
         continue;
      }
   // Start working on row I
      offs = subsolver->sparseefflc.ridx.xZ[i];
   // Copy constraint from sparserawlc[] to sparseefflc[]
      j0 = subsolver->sparserawlc.ridx.xZ[i];
      j1 = subsolver->sparserawlc.ridx.xZ[i + 1] - 1;
      for (k = j0; k <= j1; k++) {
         subsolver->sparseefflc.idx.xZ[offs] = subsolver->sparserawlc.idx.xZ[k];
         subsolver->sparseefflc.vals.xR[offs] = subsolver->sparserawlc.vals.xR[k];
         offs++;
      }
   // Set up slack variables
      if (i < nec) {
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.vals.xR[offs + 1] = 1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslackec + 2 * i;
         subsolver->sparseefflc.idx.xZ[offs + 1] = offsslackec + 2 * i + 1;
         offs += 2;
      } else {
      // Slack variables for inequality constraints
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslackic + (i - nec);
         offs++;
      }
   // Finalize row
      subsolver->sparseefflc.ridx.xZ[i + 1] = offs;
   // Set up bounds and slack part of D0.
   //
   // NOTE: bounds for equality and inequality constraints are
   //       handled differently
      v = vright - state->scaledcleic.xyR[i][n];
      if (i < nec) {
         subsolver->cural.xR[i] = -v;
         subsolver->curau.xR[i] = -v;
         subsolver->curbndl.xR[offsslackec + 2 * i] = 0.0;
         subsolver->curbndl.xR[offsslackec + 2 * i + 1] = 0.0;
         subsolver->curbndu.xR[offsslackec + 2 * i] = fabs(v);
         subsolver->curbndu.xR[offsslackec + 2 * i + 1] = fabs(v);
         if (v >= 0.0) {
            subsolver->d0.xR[offsslackec + 2 * i] = fabs(v);
            subsolver->d0.xR[offsslackec + 2 * i + 1] = 0.0;
         } else {
            subsolver->d0.xR[offsslackec + 2 * i] = 0.0;
            subsolver->d0.xR[offsslackec + 2 * i + 1] = fabs(v);
         }
      } else {
         subsolver->cural.xR[i] = -INFINITY;
         subsolver->curau.xR[i] = -v;
         subsolver->curbndl.xR[offsslackic + (i - nec)] = 0.0;
         subsolver->curbndu.xR[offsslackic + (i - nec)] = rmax2(v, 0.0);
         subsolver->d0.xR[offsslackic + (i - nec)] = rmax2(v, 0.0);
      }
   }
   subsolver->sparseefflc.m += nec + nic;
// Append nonlinear equality/inequality constraints
   for (i = 0; i < nlec + nlic; i++) {
   // Calculate:
   // * rescale coefficient used to normalize constraints
   // * VMax - maximum of constraint value over trust region
      vmax = fi->xR[1 + i];
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = jac->xyR[1 + i][j];
         vv += v * v;
         if (v >= 0.0) {
            vmax += v * subsolver->curbndu.xR[j];
         } else {
            vmax += v * subsolver->curbndl.xR[j];
         }
      }
      rescaleby = 1.0 / coalesce(sqrt(vv), 1.0);
   // If constraint is an inequality one and guaranteed to be inactive
   // within trust region, it is skipped (row itself is retained but
   // filled by zeros).
      if (i >= nlec && vmax <= 0.0) {
         offs = subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + i];
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslacknlic + (i - nlec);
         subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + i + 1] = offs + 1;
         v = rescaleby * fi->xR[1 + i];
         subsolver->cural.xR[subsolver->sparseefflc.m + i] = 0.0;
         subsolver->curau.xR[subsolver->sparseefflc.m + i] = 0.0;
         subsolver->curbndl.xR[offsslacknlic + (i - nlec)] = 0.0;
         subsolver->curbndu.xR[offsslacknlic + (i - nlec)] = 0.0;
         subsolver->d0.xR[offsslacknlic + (i - nlec)] = 0.0;
         continue;
      }
   // Copy scaled row
      offs = subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + i];
      for (j = 0; j < n; j++) {
         if (jac->xyR[1 + i][j] != 0.0) {
            subsolver->sparseefflc.vals.xR[offs] = rescaleby * jac->xyR[1 + i][j];
            subsolver->sparseefflc.idx.xZ[offs] = j;
            offs++;
         }
      }
      if (i < nlec) {
      // Add slack terms for equality constraints
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.vals.xR[offs + 1] = 1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslacknlec + 2 * i;
         subsolver->sparseefflc.idx.xZ[offs + 1] = offsslacknlec + 2 * i + 1;
         offs += 2;
      } else {
      // Add slack terms for inequality constraints
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslacknlic + (i - nlec);
         offs++;
      }
      subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + i + 1] = offs;
   // Set box constraints on slack variables and bounds on linear equality/inequality constraints
      v = rescaleby * fi->xR[1 + i];
      if (i < nlec) {
      // Equality constraint
         subsolver->cural.xR[subsolver->sparseefflc.m + i] = -v;
         subsolver->curau.xR[subsolver->sparseefflc.m + i] = -v;
         subsolver->curbndl.xR[offsslacknlec + 2 * i] = 0.0;
         subsolver->curbndl.xR[offsslacknlec + 2 * i + 1] = 0.0;
         subsolver->curbndu.xR[offsslacknlec + 2 * i] = fabs(v);
         subsolver->curbndu.xR[offsslacknlec + 2 * i + 1] = fabs(v);
         if (v >= 0.0) {
            subsolver->d0.xR[offsslacknlec + 2 * i] = fabs(v);
            subsolver->d0.xR[offsslacknlec + 2 * i + 1] = 0.0;
         } else {
            subsolver->d0.xR[offsslacknlec + 2 * i] = 0.0;
            subsolver->d0.xR[offsslacknlec + 2 * i + 1] = fabs(v);
         }
      } else {
      // Inequality constraint
         subsolver->cural.xR[subsolver->sparseefflc.m + i] = -INFINITY;
         subsolver->curau.xR[subsolver->sparseefflc.m + i] = -v;
         subsolver->curbndl.xR[offsslacknlic + (i - nlec)] = 0.0;
         subsolver->curbndu.xR[offsslacknlic + (i - nlec)] = rmax2(v, 0.0);
         subsolver->d0.xR[offsslacknlic + (i - nlec)] = rmax2(v, 0.0);
      }
   }
   subsolver->sparseefflc.m += nlec + nlic;
// Finalize sparse matrix structure
   ae_assert(subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m] <= subsolver->sparseefflc.idx.cnt, "QPSubproblemSolve: critical integrity check failed");
   ae_assert(subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m] <= subsolver->sparseefflc.vals.cnt, "QPSubproblemSolve: critical integrity check failed");
   subsolver->sparseefflc.ninitialized = subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m];
   sparseinitduidx(&subsolver->sparseefflc);
// Solve quadratic program
   if (subsolver->algokind == 0) {
   // Use dense IPM.
   //
   // We always treat its result as a valid solution, even for TerminationType <= 0.
   // In case anything is wrong with solution vector, we will detect it during line
   // search phase (merit function does not increase).
   //
   // NOTE: because we cleaned up constraints that are DEFINITELY inactive within
   //       trust region, we do not have to worry about StopOnExcessiveBounds option.
      rsetallocv(nslack, state->trustrad, &subsolver->tmp0);
      rsetallocv(nslack, 0.0, &subsolver->tmp1);
      hessiangetmatrix(&state->hess, true, &subsolver->denseh);
      vipminitdensewithslacks(&subsolver->ipmsolver, &subsolver->tmp0, &subsolver->tmp1, n, nslack);
      vipmsetquadraticlinear(&subsolver->ipmsolver, &subsolver->denseh, &subsolver->sparsedummy, 0, true, &subsolver->curb);
      vipmsetconstraints(&subsolver->ipmsolver, &subsolver->curbndl, &subsolver->curbndu, &subsolver->sparseefflc, subsolver->sparseefflc.m, &subsolver->densedummy, 0, &subsolver->cural, &subsolver->curau);
      vipmoptimize(&subsolver->ipmsolver, false, &subsolver->tmp0, &subsolver->tmp1, &subsolver->tmp2, terminationtype);
      for (i = 0; i < nslack; i++) {
         d->xR[i] = subsolver->tmp0.xR[i];
      }
      for (i = 0; i < lccnt; i++) {
         lagmult->xR[i] = subsolver->tmp2.xR[i];
      }
      return result;
   }
   if (subsolver->algokind == 1) {
   // Use fast active set
      nlcsqp_fassolve(subsolver, &subsolver->d0, &state->hess.hcurrent, n, &subsolver->curb, nslack, &subsolver->curbndl, &subsolver->curbndu, &subsolver->sparseefflc, subsolver->sparseefflc.m, &subsolver->cural, &subsolver->curau, state->trustrad, terminationtype, d, lagmult);
      if (*terminationtype <= 0) {
      // QP solver failed due to numerical errors; exit
         result = false;
         return result;
      }
      return result;
   }
// Unexpected
   ae_assert(false, "SQP: unexpected subsolver type");
   return result;
}

// This function initializes MeritPhase temporaries. It should be called before
// beginning of each new iteration. You may call it multiple  times  for  the
// same instance of MeritPhase temporaries.
//
// Inputs:
//     MeritState          -   instance to be initialized.
//     N                   -   problem dimensionality
//     NEC, NIC            -   linear equality/inequality constraint count
//     NLEC, NLIC          -   nonlinear equality/inequality constraint count
//     AbsLagMemory        -   array[MemLen,NEC+NIC+NLEC+NLIC], stores absolute
//                             values of Lagrange multipliers for the last MemLen
//                             iterations
//     MemLen              -   memory length
//
// Outputs:
//     MeritState          -   instance being initialized
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static void nlcsqp_meritphaseinit(minsqpmeritphasestate *meritstate, RVector *curx, RVector *curfi, RMatrix *curj, ae_int_t n, ae_int_t nec, ae_int_t nic, ae_int_t nlec, ae_int_t nlic, RMatrix *abslagmemory, ae_int_t memlen) {
   ae_int_t i;
   ae_int_t nslack;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   meritstate->n = n;
   meritstate->nec = nec;
   meritstate->nic = nic;
   meritstate->nlec = nlec;
   meritstate->nlic = nlic;
   vectorsetlengthatleast(&meritstate->d, nslack);
   vectorsetlengthatleast(&meritstate->d0, nslack);
   vectorsetlengthatleast(&meritstate->d1, nslack);
   vectorsetlengthatleast(&meritstate->stepkx, n);
   vectorsetlengthatleast(&meritstate->stepkxc, n);
   vectorsetlengthatleast(&meritstate->stepkxn, n);
   vectorsetlengthatleast(&meritstate->stepkfi, 1 + nlec + nlic);
   vectorsetlengthatleast(&meritstate->stepkfic, 1 + nlec + nlic);
   vectorsetlengthatleast(&meritstate->stepkfin, 1 + nlec + nlic);
   matrixsetlengthatleast(&meritstate->stepkj, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&meritstate->stepkjc, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&meritstate->stepkjn, 1 + nlec + nlic, n);
   vectorsetlengthatleast(&meritstate->stepklaggrad, n);
   vectorsetlengthatleast(&meritstate->stepknlaggrad, n);
   vectorsetlengthatleast(&meritstate->lagmult, nec + nic + nlec + nlic);
   vectorsetlengthatleast(&meritstate->dummylagmult, nec + nic + nlec + nlic);
   rsetallocv(nec + nic + nlec + nlic, 0.0, &meritstate->penalties);
   for (i = 0; i < memlen; i++) {
      rmergemaxrv(nec + nic + nlec + nlic, abslagmemory, i, &meritstate->penalties);
   }
   rcopyv(n, curx, &meritstate->stepkx);
   rcopyv(1 + nlec + nlic, curfi, &meritstate->stepkfi);
   for (i = 0; i <= nlec + nlic; i++) {
      rcopyrr(n, curj, i, &meritstate->stepkj, i);
   }
   meritstate->PQ = -1;
}

// Copies X to State.X
static void nlcsqp_sqpsendx(minsqpstate *state, RVector *xs) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i] && xs->xR[i] <= state->scaledbndl.xR[i]) {
         state->x.xR[i] = state->scaledbndl.xR[i];
         continue;
      }
      if (state->hasbndu.xB[i] && xs->xR[i] >= state->scaledbndu.xR[i]) {
         state->x.xR[i] = state->scaledbndu.xR[i];
         continue;
      }
      state->x.xR[i] = xs->xR[i];
   }
}

// Retrieves F-vector and scaled Jacobian, copies them to FiS and JS.
//
// Returns True on success, False on failure (when F or J are not finite numbers).
static bool nlcsqp_sqpretrievefij(minsqpstate *state, RVector *fis, RMatrix *js) {
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   bool result;
   n = state->n;
   nlec = state->nlec;
   nlic = state->nlic;
   v = 0.0;
   for (i = 0; i <= nlec + nlic; i++) {
      vv = 1.0 / state->fscales.xR[i];
      fis->xR[i] = vv * state->fi.xR[i];
      v += fis->xR[i];
      for (j = 0; j < n; j++) {
         js->xyR[i][j] = vv * state->j.xyR[i][j];
         v += js->xyR[i][j];
      }
   }
   result = isfinite(v);
   return result;
}

// Copies state (X point, Fi vector, J jacobian) to preallocated storage.
static void nlcsqp_sqpcopystate(minsqpstate *state, RVector *x0, RVector *fi0, RMatrix *j0, RVector *x1, RVector *fi1, RMatrix *j1) {
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   n = state->n;
   nlec = state->nlec;
   nlic = state->nlic;
   for (i = 0; i < n; i++) {
      x1->xR[i] = x0->xR[i];
   }
   for (i = 0; i <= nlec + nlic; i++) {
      fi1->xR[i] = fi0->xR[i];
      for (j = 0; j < n; j++) {
         j1->xyR[i][j] = j0->xyR[i][j];
      }
   }
}

// This function calculates Lagrangian of the problem (in scaled variables):
// its value and gradient.
//
// Additionally it also estimates violation of linear constraints at the point
// as well as index of the most violated constraint
static void nlcsqp_lagrangianfg(minsqpstate *state, RVector *x, double trustrad, RVector *fi, RMatrix *j, RVector *lagmult, minsqptmplagrangian *tmp, double *f, RVector *g) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   double v;
   double vlag;
   double vact;
   double vd;
   bool usesparsegemv;
   *f = 0.0;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
// Target function
   *f = fi->xR[0];
   for (i = 0; i < n; i++) {
      g->xR[i] = j->xyR[0][i];
   }
// Lagrangian terms for linear constraints, constraint violations
   if (nec + nic > 0) {
      usesparsegemv = state->subsolver.sparserawlc.ridx.xZ[nec + nic] < sparselevel2density() * n * (nec + nic);
      vectorsetlengthatleast(&tmp->sclagtmp0, imax2(nec + nic, n));
      vectorsetlengthatleast(&tmp->sclagtmp1, imax2(nec + nic, n));
      if (usesparsegemv) {
         sparsemv(&state->subsolver.sparserawlc, x, &tmp->sclagtmp0);
      } else {
         rmatrixgemv(nec + nic, n, 1.0, &state->scaledcleic, 0, 0, 0, x, 0, 0.0, &tmp->sclagtmp0, 0);
      }
      for (i = 0; i < nec + nic; i++) {
      // Prepare
         v = tmp->sclagtmp0.xR[i] - state->scaledcleic.xyR[i][n];
         vlag = lagmult->xR[i];
         tmp->sclagtmp1.xR[i] = 0.0;
      // Primary Lagrangian term
         vact = v;
         vd = 1.0;
         *f += vlag * vact;
         tmp->sclagtmp1.xR[i] += vlag * vd;
      // Quadratic augmentation term
         if (i < nec || v > 0.0) {
            vact = v;
         } else {
            vact = 0.0;
         }
         *f += 0.5 * nlcsqp_augmentationfactor * vact * vact;
         tmp->sclagtmp1.xR[i] += nlcsqp_augmentationfactor * vact;
      }
      if (usesparsegemv) {
         sparsemtv(&state->subsolver.sparserawlc, &tmp->sclagtmp1, &tmp->sclagtmp0);
         for (i = 0; i < n; i++) {
            g->xR[i] += tmp->sclagtmp0.xR[i];
         }
      } else {
         rmatrixgemv(n, nec + nic, 1.0, &state->scaledcleic, 0, 0, 1, &tmp->sclagtmp1, 0, 1.0, g, 0);
      }
   }
// Lagrangian terms for nonlinear constraints
   vectorsetlengthatleast(&tmp->sclagtmp1, nlec + nlic);
   for (i = 0; i < nlec + nlic; i++) {
      v = fi->xR[1 + i];
      vlag = lagmult->xR[nec + nic + i];
      tmp->sclagtmp1.xR[i] = 0.0;
   // Lagrangian term
      vact = v;
      vd = 1.0;
      *f += vlag * vact;
      tmp->sclagtmp1.xR[i] += vlag * vd;
   // Augmentation term
      if (i < nlec || v > 0.0) {
         vact = v;
      } else {
         vact = 0.0;
      }
      *f += 0.5 * nlcsqp_augmentationfactor * vact * vact;
      tmp->sclagtmp1.xR[i] += nlcsqp_augmentationfactor * vact;
   }
   rmatrixgemv(n, nlec + nlic, 1.0, j, 1, 0, 1, &tmp->sclagtmp1, 0, 1.0, g, 0);
}

// This function calculates L1-penalized merit function and raw  (smooth  and
// un-augmented) Lagrangian
static void nlcsqp_meritfunctionandrawlagrangian(minsqpstate *state, RVector *x, RVector *fi, RVector *lagmult, RVector *penalties, minsqptmpmerit *tmp, double *meritf, double *rawlag) {
   const double meritfunctionbase = 0.0, meritfunctiongain = 2.0;
   ae_int_t i;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   double v;
   *meritf = 0.0;
   *rawlag = 0.0;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
// Merit function and Lagrangian: primary term
   *meritf = fi->xR[0];
   *rawlag = fi->xR[0];
// Merit function: augmentation and penalty for linear constraints
   vectorsetlengthatleast(&tmp->mftmp0, nec + nic);
   rmatrixgemv(nec + nic, n, 1.0, &state->scaledcleic, 0, 0, 0, x, 0, 0.0, &tmp->mftmp0, 0);
   for (i = 0; i < nec + nic; i++) {
      v = tmp->mftmp0.xR[i] - state->scaledcleic.xyR[i][n];
      if (i < nec) {
      // Merit function: augmentation term + L1 penalty term
         *meritf += 0.5 * nlcsqp_augmentationfactor * v * v;
         *meritf += meritfunctionbase * fabs(v) + meritfunctiongain * fabs(1.0 + penalties->xR[i]) * fabs(v);
      // Raw Lagrangian
         *rawlag += lagmult->xR[i] * v;
      } else {
      // Merit function: augmentation term + L1 penalty term
         *meritf += 0.5 * nlcsqp_augmentationfactor * sqr(rmax2(v, 0.0));
         *meritf += meritfunctionbase * rmax2(v, 0.0) + meritfunctiongain * fabs(1.0 + penalties->xR[i]) * rmax2(v, 0.0);
      // Raw Lagrangian
         *rawlag += lagmult->xR[i] * v;
      }
   }
// Merit function: augmentation and penalty for nonlinear constraints
   for (i = 0; i < nlec + nlic; i++) {
      v = fi->xR[1 + i];
      if (i < nlec) {
      // Merit function: augmentation term + L1 penalty term
         *meritf += 0.5 * nlcsqp_augmentationfactor * v * v;
         *meritf += meritfunctionbase * fabs(v) + meritfunctiongain * fabs(1.0 + penalties->xR[nec + nic + i]) * fabs(v);
      // Raw Lagrangian
         *rawlag += lagmult->xR[nec + nic + i] * v;
      } else {
      // Merit function: augmentation term + L1 penalty term
         *meritf += 0.5 * nlcsqp_augmentationfactor * sqr(rmax2(v, 0.0));
         *meritf += meritfunctionbase * rmax2(v, 0.0) + meritfunctiongain * fabs(1.0 + penalties->xR[nec + nic + i]) * rmax2(v, 0.0);
      // Raw Lagrangian
         *rawlag += lagmult->xR[nec + nic + i] * v;
      }
   }
}

// This function calculates L1-penalized merit function
static double nlcsqp_meritfunction(minsqpstate *state, RVector *x, RVector *fi, RVector *lagmult, RVector *penalties, minsqptmpmerit *tmp) {
   double tmp0;
   double tmp1;
   double result;
   nlcsqp_meritfunctionandrawlagrangian(state, x, fi, lagmult, penalties, tmp, &tmp0, &tmp1);
   result = tmp0;
   return result;
}

#if 0 //(@) Not used.
// This function calculates raw (unaugmented and smooth) Lagrangian
static double nlcsqp_rawlagrangian(minsqpstate *state, RVector *x, RVector *fi, RVector *lagmult, RVector *penalties, minsqptmpmerit *tmp) {
   double tmp0;
   double tmp1;
   double result;
   nlcsqp_meritfunctionandrawlagrangian(state, x, fi, lagmult, penalties, tmp, &tmp0, &tmp1);
   result = tmp1;
   return result;
}
#endif

// This function tries to perform either phase #1 or phase #3 step.
//
// Former corresponds to linear model step (without conjugacy constraints) with
// correction for nonlinearity ("second order correction").  Such  correction
// helps to overcome  Maratos  effect  (a  tendency  of  L1  penalized  merit
// functions to reject nonzero steps).
//
// Latter is a step using linear model with no second order correction.
//
// Inputs:
//     State       -   SQP solver state
//     SMonitor    -   smoothness monitor
//     UserTerminationNeeded-True if user requested termination
//
// Outputs:
//     State       -   RepTerminationType is set to current termination code (if Status == 0).
//     Status      -   when reverse communication is done, Status is set to:
//                     * positive value,  if we can proceed to the next stage
//                       of the outer iteration
//                     * zero, if algorithm is terminated (RepTerminationType
//                       is set to appropriate value)
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static bool nlcsqp_meritphaseiteration(minsqpstate *state, minsqpmeritphasestate *meritstate, smoothnessmonitor *smonitor, bool userterminationneeded) {
   AutoS ae_int_t n;
   AutoS ae_int_t nslack;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t nlec;
   AutoS ae_int_t nlic;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS double v;
   AutoS double vv;
   AutoS double f0;
   AutoS double f1;
   AutoS double nu;
   AutoS double localstp;
   AutoS double tol;
   AutoS double stepklagval;
   AutoS double stepknlagval;
   AutoS double stp;
   AutoS double expandedrad;
   AutoS bool socperformed;
   AutoS ae_int_t didx;
   AutoS double sksk;
   AutoS double ykyk;
   AutoS double skyk;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (meritstate->PQ >= 0) switch (meritstate->PQ) {
      case 0: goto Resume0; case 1: goto Resume1;/* case 2: goto Resume2;*/ case 3: goto Resume3;
      default: goto Exit;
   }
Spawn:
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   ae_assert(meritstate->lagmult.cnt >= nec + nic + nlec + nlic, "MeritPhaseIteration: integrity check failed");
   rsetv(nslack, 0.0, &meritstate->d0);
   rsetv(nslack, 0.0, &meritstate->d1);
// Default decision is to continue algorithm
   meritstate->status = 1;
   meritstate->increasebigc = false;
   stp = 0.0;
// Determine step direction using initial quadratic model.
// Update penalties vector with current Lagrange multipliers.
   socperformed = false;
   if (!nlcsqp_qpsubproblemsolve(state, &state->subsolver, &meritstate->stepkx, &meritstate->stepkfi, &meritstate->stepkj, &meritstate->d0, &meritstate->lagmult, &j)) {
      goto Exit;
   }
   for (i = 0; i < nec + nic + nlec + nlic; i++) {
      meritstate->penalties.xR[i] = rmax2(meritstate->penalties.xR[i], fabs(meritstate->lagmult.xR[i]));
   }
   rcopyv(nslack, &meritstate->d0, &meritstate->d);
// Perform merit function line search.
//
// First, we try unit step. If it does not decrease merit function,
// a second-order correction is tried (helps to combat Maratos effect).
   localstp = 1.0;
   f0 = nlcsqp_meritfunction(state, &meritstate->stepkx, &meritstate->stepkfi, &meritstate->lagmult, &meritstate->penalties, &meritstate->tmpmerit);
   for (i = 0; i < n; i++) {
      meritstate->stepkxn.xR[i] = meritstate->stepkx.xR[i] + localstp * meritstate->d.xR[i];
   }
   nlcsqp_sqpsendx(state, &meritstate->stepkxn);
   state->needfij = true, meritstate->PQ = 0; goto Pause; Resume0: state->needfij = false;
   if (!nlcsqp_sqpretrievefij(state, &meritstate->stepkfin, &meritstate->stepkjn)) {
   // Failed to retrieve func/Jac, infinities detected
      state->repterminationtype = -8;
      meritstate->status = 0;
      goto Exit;
   }
   f1 = nlcsqp_meritfunction(state, &meritstate->stepkxn, &meritstate->stepkfin, &meritstate->lagmult, &meritstate->penalties, &meritstate->tmpmerit);
   if (f1 >= f0) { //(@) if (!(f1 < f0)) might be necessary to use, instead.
   // Full step increases merit function. Let's compute second order
   // correction to the constraint model and recompute trial step D:
   // * use original model of the target
   // * extrapolate model of nonlinear constraints at StepKX+D back to origin
   //
      socperformed = true;
      meritstate->stepkfic.xR[0] = meritstate->stepkfi.xR[0];
      for (j = 0; j < n; j++) {
         meritstate->stepkjc.xyR[0][j] = meritstate->stepkj.xyR[0][j];
      }
      for (i = 1; i <= nlec + nlic; i++) {
         v = 0.0;
         for (j = 0; j < n; j++) {
            v += meritstate->d0.xR[j] * meritstate->stepkj.xyR[i][j];
            meritstate->stepkjc.xyR[i][j] = meritstate->stepkj.xyR[i][j];
         }
         meritstate->stepkfic.xR[i] = meritstate->stepkfin.xR[i] - v;
      }
      if (!nlcsqp_qpsubproblemsolve(state, &state->subsolver, &meritstate->stepkx, &meritstate->stepkfic, &meritstate->stepkjc, &meritstate->d1, &meritstate->dummylagmult, &j)) {
         goto Exit;
      }
      rcopyv(n, &meritstate->d1, &meritstate->d);
   // Perform line search, we again try full step (maybe it will work after SOC)
      localstp = 1.0;
      nu = 0.5;
      f1 = f0;
      smoothnessmonitorstartlinesearch(smonitor, &meritstate->stepkx, &meritstate->stepkfi, &meritstate->stepkj, state->repiterationscount, -1);
      while (true) {
         for (i = 0; i < n; i++) {
            meritstate->stepkxn.xR[i] = meritstate->stepkx.xR[i] + localstp * meritstate->d.xR[i];
         }
         nlcsqp_sqpsendx(state, &meritstate->stepkxn);
         state->needfij = true, meritstate->PQ = 1; goto Pause; Resume1: state->needfij = false;
         if (!nlcsqp_sqpretrievefij(state, &meritstate->stepkfin, &meritstate->stepkjn)) {
         // Failed to retrieve func/Jac, infinities detected
            state->repterminationtype = -8;
            meritstate->status = 0;
            goto Exit;
         }
         smoothnessmonitorenqueuepoint(smonitor, &meritstate->d, localstp, &meritstate->stepkxn, &meritstate->stepkfin, &meritstate->stepkjn);
         f1 = nlcsqp_meritfunction(state, &meritstate->stepkxn, &meritstate->stepkfin, &meritstate->lagmult, &meritstate->penalties, &meritstate->tmpmerit);
         if (f1 < f0) {
         // Step is found!
            break;
         }
         if (localstp < 0.001) {
         // Step is shorter than 0.001 times current search direction,
         // it means that no good step can be found.
            localstp = 0.0;
            nlcsqp_sqpcopystate(state, &meritstate->stepkx, &meritstate->stepkfi, &meritstate->stepkj, &meritstate->stepkxn, &meritstate->stepkfin, &meritstate->stepkjn);
            break;
         }
         localstp *= nu;
         nu = rmax2(0.1, 0.5 * nu);
      }
      smoothnessmonitorfinalizelinesearch(smonitor);
   }
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i]) {
         meritstate->stepkxn.xR[i] = rmax2(meritstate->stepkxn.xR[i], state->scaledbndl.xR[i]);
      }
      if (state->hasbndu.xB[i]) {
         meritstate->stepkxn.xR[i] = rmin2(meritstate->stepkxn.xR[i], state->scaledbndu.xR[i]);
      }
   }
   if (userterminationneeded) {
   // User requested termination, break before we move to new point
      state->repterminationtype = 8;
      meritstate->status = 0;
      goto Exit;
   }
   nlcsqp_lagrangianfg(state, &meritstate->stepkx, state->trustrad, &meritstate->stepkfi, &meritstate->stepkj, &meritstate->lagmult, &meritstate->tmplagrangianfg, &stepklagval, &meritstate->stepklaggrad);
   nlcsqp_lagrangianfg(state, &meritstate->stepkxn, state->trustrad, &meritstate->stepkfin, &meritstate->stepkjn, &meritstate->lagmult, &meritstate->tmplagrangianfg, &stepknlagval, &meritstate->stepknlaggrad);
// Decide whether we want to request increase BigC (a constraint enforcing multiplier for L1 penalized
// QP subproblem) or not.
//
// An increase is NOT needed if at least one of the following holds:
// * present value of BigC is already nearly maximum
// * a long step was performed
// * any single constraint can be made feasible within box with radius slightly larger max|D|
//
// Thus, BigC is requested to be increased if a short step was made, but there are some
// constraints that are infeasible within max|D|-sized box
   if (rmaxabsv(n, &meritstate->d) < 0.9 * state->trustrad && state->bigc < 0.9 * nlcsqp_maxbigc) {
      expandedrad = 1.1 * rmaxabsv(n, &meritstate->d);
      tol = rmax2(sqrt(machineepsilon) * state->trustrad, 1000.0 * machineepsilon);
      for (i = 0; i < nec + nic; i++) {
         v = 0.0;
         vv = 0.0;
         for (j = 0; j < n; j++) {
            v += state->scaledcleic.xyR[i][j] * state->stepkx.xR[j];
            vv += fabs(state->scaledcleic.xyR[i][j] * expandedrad);
         }
         v -= state->scaledcleic.xyR[i][n];
         if (i >= nec) {
            v = rmax2(v, 0.0);
         }
         meritstate->increasebigc = meritstate->increasebigc || !SmallAtR(v, vv + tol);
      }
      for (i = 1; i <= nlec + nlic; i++) {
         v = state->stepkfi.xR[i];
         vv = 0.0;
         for (j = 0; j < n; j++) {
            vv += fabs(state->stepkj.xyR[i][j] * expandedrad);
         }
         if (i > nlec) {
            v = rmax2(v, 0.0);
         }
         meritstate->increasebigc = meritstate->increasebigc || !SmallAtR(v, vv + tol);
      }
   }
#if 0 //(@) Not used.
// Update debug curvature information. Let
//
//     Sk = X(k+1)-X(k), Yk = G(k+1)-G(k)
//
// for a function Fi and store maximum over curvatures
//
//     gamma = (Yk,Yk)/|(Sk,Yk)|
//
// to TraceGamma[] array. Set MaxNewGamma to maximum of new values, set GammaIncreased
// flag if at least one of TraceGamma[] entries was increased.
   sksk = 0.0;
   for (j = 0; j < n; j++) {
      v = meritstate->stepkxn.xR[j] - meritstate->stepkx.xR[j];
      sksk += v * v;
   }
   if (sksk > 0.0) {
      for (i = 0; i <= nlec + nlic; i++) {
         ykyk = 0.0;
         skyk = 0.0;
         for (j = 0; j < n; j++) {
            v = meritstate->stepkxn.xR[j] - meritstate->stepkx.xR[j];
            vv = meritstate->stepkjn.xyR[i][j] - meritstate->stepkj.xyR[i][j];
            skyk += v * vv;
            ykyk += vv * vv;
         }
         v = ykyk / (fabs(skyk) + machineepsilon * ykyk + machineepsilon * sksk);
      }
   }
// Perform aggressive probing of the search direction - additional function evaluations
// which help us to determine possible discontinuity and nonsmoothness of the problem
#   if 0 //(@) Not used.
   for (didx = 0; didx < 2; didx++) {
      if (didx == 1 && !socperformed) {
         break;
      }
      if (didx == 0) {
         smoothnessmonitorstartlagrangianprobing(smonitor, &meritstate->stepkx, &meritstate->d0, 1.0, state->repiterationscount, -1);
      } else {
         smoothnessmonitorstartlagrangianprobing(smonitor, &meritstate->stepkx, &meritstate->d1, 1.0, state->repiterationscount, -1);
      }
      while (smoothnessmonitorprobelagrangian(smonitor)) {
         for (j = 0; j < n; j++) {
            meritstate->stepkxc.xR[j] = smonitor->lagprobx.xR[j];
            if (state->hasbndl.xB[j]) {
               meritstate->stepkxc.xR[j] = rmax2(meritstate->stepkxc.xR[j], state->scaledbndl.xR[j]);
            }
            if (state->hasbndu.xB[j]) {
               meritstate->stepkxc.xR[j] = rmin2(meritstate->stepkxc.xR[j], state->scaledbndu.xR[j]);
            }
         }
         nlcsqp_sqpsendx(state, &meritstate->stepkxc);
         state->needfij = true, meritstate->PQ = 2; goto Pause; Resume2: state->needfij = false;
         if (!nlcsqp_sqpretrievefij(state, &smonitor->lagprobfi, &smonitor->lagprobj)) {
            break;
         }
         smonitor->lagprobrawlag = nlcsqp_rawlagrangian(state, &meritstate->stepkxc, &smonitor->lagprobfi, &meritstate->lagmult, &meritstate->penalties, &meritstate->tmpmerit);
      }
   }
#   endif
// Output other information
   hessiangetdiagonal(&state->hess, &meritstate->tmphdiag);
   v = meritstate->tmphdiag.xR[0];
   for (i = 0; i < n; i++) {
      v = rmin2(v, meritstate->tmphdiag.xR[i]);
   }
   v = meritstate->tmphdiag.xR[0];
   for (i = 0; i < n; i++) {
      v = rmax2(v, meritstate->tmphdiag.xR[i]);
   }
#endif
// Perform Hessian update
   if (localstp > 0.0) {
      hessianupdate(&state->hess, &meritstate->stepkx, &meritstate->stepklaggrad, &meritstate->stepkxn, &meritstate->stepknlaggrad);
   }
// Move to new point
   stp = localstp;
   nlcsqp_sqpcopystate(state, &meritstate->stepkxn, &meritstate->stepkfin, &meritstate->stepkjn, &meritstate->stepkx, &meritstate->stepkfi, &meritstate->stepkj);
   if (localstp > 0.0) {
   // Report one more inner iteration
      nlcsqp_sqpsendx(state, &meritstate->stepkx);
      state->f = meritstate->stepkfi.xR[0] * state->fscales.xR[0];
      state->xupdated = true, meritstate->PQ = 3; goto Pause; Resume3: state->xupdated = false;
   // Update constraint violations
      checklcviolation(&state->scaledcleic, &state->lcsrcidx, nec, nic, &meritstate->stepkx, n, &state->replcerr, &state->replcidx);
      unscaleandchecknlcviolation(&meritstate->stepkfi, &state->fscales, nlec, nlic, &state->repnlcerr, &state->repnlcidx);
   }
Exit:
   meritstate->PQ = -1;
   return false;
Pause:
   return true;
}

// This function initializes MeritPhase temporaries. It should be called before
// beginning of each new iteration. You may call it multiple  times  for  the
// same instance of MeritPhase temporaries.
//
// Inputs:
//     MeritState          -   instance to be initialized.
//     N                   -   problem dimensionality
//     NEC, NIC            -   linear equality/inequality constraint count
//     NLEC, NLIC          -   nonlinear equality/inequality constraint count
//
// Outputs:
//     IncreaseBigC        -   whether increasing BigC is suggested (we detected
//                             infeasible constraints that are NOT improved)
//                             or not.
//     MeritState          -   instance being initialized
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static void nlcsqp_meritphaseresults(minsqpmeritphasestate *meritstate, RVector *curx, RVector *curfi, RMatrix *curj, RVector *lagmult, bool *increasebigc, ae_int_t *status) {
   ae_int_t i;
   ae_int_t j;
   *increasebigc = meritstate->increasebigc;
   *status = meritstate->status;
   for (i = 0; i < meritstate->n; i++) {
      curx->xR[i] = meritstate->stepkx.xR[i];
   }
   for (i = 0; i <= meritstate->nlec + meritstate->nlic; i++) {
      curfi->xR[i] = meritstate->stepkfi.xR[i];
      for (j = 0; j < meritstate->n; j++) {
         curj->xyR[i][j] = meritstate->stepkj.xyR[i][j];
      }
   }
   ae_assert(lagmult->cnt >= meritstate->nec + meritstate->nic + meritstate->nlec + meritstate->nlic, "MeritPhaseResults: LagMult too short");
   for (i = 0; i < meritstate->nec + meritstate->nic + meritstate->nlec + meritstate->nlic; i++) {
      lagmult->xR[i] = meritstate->lagmult.xR[i];
   }
}

void minsqpinitbuf(RVector *bndl, RVector *bndu, RVector *s, RVector *x0, ae_int_t n, RMatrix *cleic, ZVector *lcsrcidx, ae_int_t nec, ae_int_t nic, ae_int_t nlec, ae_int_t nlic, double epsx, ae_int_t maxits, minsqpstate *state) {
   const ae_int_t defaultbfgsresetfreq = 999999;
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   state->n = n;
   state->nec = nec;
   state->nic = nic;
   state->nlec = nlec;
   state->nlic = nlic;
// Prepare RCOMM state
   state->PQ = -1;
   ae_vector_set_length(&state->x, n);
   ae_vector_set_length(&state->fi, 1 + nlec + nlic);
   ae_matrix_set_length(&state->j, 1 + nlec + nlic, n);
// Allocate memory.
   vectorsetlengthatleast(&state->s, n);
   vectorsetlengthatleast(&state->step0x, n);
   vectorsetlengthatleast(&state->stepkx, n);
   vectorsetlengthatleast(&state->backupx, n);
   vectorsetlengthatleast(&state->step0fi, 1 + nlec + nlic);
   vectorsetlengthatleast(&state->stepkfi, 1 + nlec + nlic);
   vectorsetlengthatleast(&state->backupfi, 1 + nlec + nlic);
   matrixsetlengthatleast(&state->step0j, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&state->stepkj, 1 + nlec + nlic, n);
   vectorsetlengthatleast(&state->fscales, 1 + nlec + nlic);
   vectorsetlengthatleast(&state->dummylagmult, nec + nic + nlec + nlic);
   vectorsetlengthatleast(&state->hasbndl, n);
   vectorsetlengthatleast(&state->hasbndu, n);
   vectorsetlengthatleast(&state->scaledbndl, n);
   vectorsetlengthatleast(&state->scaledbndu, n);
   matrixsetlengthatleast(&state->scaledcleic, nec + nic, n + 1);
   vectorsetlengthatleast(&state->lcsrcidx, nec + nic);
   allocv(nec + nic + nlec + nlic, &state->meritlagmult);
   rsetallocm(nlcsqp_penaltymemlen, nec + nic + nlec + nlic, 0.0, &state->abslagmemory);
// Prepare scaled problem
   for (i = 0; i < n; i++) {
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
      if (state->hasbndl.xB[i]) {
         state->scaledbndl.xR[i] = bndl->xR[i] / s->xR[i];
      }
      if (state->hasbndu.xB[i]) {
         state->scaledbndu.xR[i] = bndu->xR[i] / s->xR[i];
      }
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i]) {
         ae_assert(bndl->xR[i] <= bndu->xR[i], "SQP: integrity check failed, box constraints are inconsistent");
      }
      state->step0x.xR[i] = x0->xR[i] / s->xR[i];
      state->s.xR[i] = s->xR[i];
   }
   for (i = 0; i < nec + nic; i++) {
   // Permutation
      state->lcsrcidx.xZ[i] = lcsrcidx->xZ[i];
   // Scale and normalize linear constraints
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = cleic->xyR[i][j] * s->xR[j];
         state->scaledcleic.xyR[i][j] = v;
         vv += v * v;
      }
      vv = sqrt(vv);
      state->scaledcleic.xyR[i][n] = cleic->xyR[i][n];
      if (vv > 0.0) {
         for (j = 0; j <= n; j++) {
            state->scaledcleic.xyR[i][j] /= vv;
         }
      }
   }
// Initial enforcement of box constraints
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i]) {
         state->step0x.xR[i] = rmax2(state->step0x.xR[i], state->scaledbndl.xR[i]);
      }
      if (state->hasbndu.xB[i]) {
         state->step0x.xR[i] = rmin2(state->step0x.xR[i], state->scaledbndu.xR[i]);
      }
   }
// Stopping criteria and settings
   state->epsx = epsx;
   state->maxits = maxits;
   state->bfgsresetfreq = defaultbfgsresetfreq;
// Report fields
   state->repsimplexiterations = 0;
   state->repsimplexiterations1 = 0;
   state->repsimplexiterations2 = 0;
   state->repsimplexiterations3 = 0;
   state->repterminationtype = 0;
   state->repbcerr = 0.0;
   state->repbcidx = -1;
   state->replcerr = 0.0;
   state->replcidx = -1;
   state->repnlcerr = 0.0;
   state->repnlcidx = -1;
   state->repiterationscount = 0;
// Integrity checks
   ae_assert(nlcsqp_sqpdeltadecrease < nlcsqp_sqpdeltaincrease, "MinSQP: integrity check failed");
}

// This function performs actual processing for  SQP  algorithm.  It  expects
// that caller redirects its reverse communication  requests NeedFiJ/XUpdated
// to external user who will provide analytic derivative (or  handle  reports
// about progress).
//
// In case external user does not have analytic derivative, it is responsibility
// of caller to intercept NeedFiJ request and  replace  it  with  appropriate
// numerical differentiation scheme.
//
// Results are stored:
// * point - in State.StepKX
//
// IMPORTANT: this function works with scaled problem formulation; it is
//            responsibility of the caller to unscale request and scale
//            Jacobian.
//
// NOTE: SMonitor is expected to be correctly initialized smoothness monitor.
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
bool minsqpiteration(minsqpstate *state, smoothnessmonitor *smonitor, bool userterminationneeded) {
   const double maxtrustraddecay = 0.1, maxtrustradgrowth = 1.333;
   const double inittrustrad = 0.1, stagnationepsf = 1.0E-12;
   const ae_int_t fstagnationlimit = 20, trustradstagnationlimit = 10;
   const double sqpbigscale = 5.0, sqpsmallscale = 0.2;
   AutoS ae_int_t n;
   AutoS ae_int_t nslack;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t nlec;
   AutoS ae_int_t nlic;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS double v;
   AutoS double vv;
   AutoS double mx;
   AutoS ae_int_t status;
   AutoS double deltamax;
   AutoS double multiplyby;
   AutoS double setscaleto;
   AutoS double prevtrustrad;
   AutoS ae_int_t subiterationidx;
   AutoS bool trustradstagnated;
   AutoS bool increasebigc;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume0; case 1: goto Resume1; case 2: goto Resume2;
      default: goto Exit;
   }
Spawn:
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
// Prepare RComm interface
   state->xupdated = state->needfij = false;
// Initialize algorithm data:
// * Lagrangian and "Big C" estimates
// * trust region
// * initial function scales (vector of 1's)
// * current approximation of the Hessian matrix H (unit matrix)
// * initial linearized constraints
// * initial violation of linear/nonlinear constraints
   state->fstagnationcnt = 0;
   state->trustradstagnationcnt = 0;
   state->trustrad = inittrustrad;
   for (i = 0; i <= nlec + nlic; i++) {
      state->fscales.xR[i] = 1.0;
   }
   state->haslagmult = false;
// Avoid spurious warnings about possibly uninitialized vars
   status = 0;
// Evaluate function vector and Jacobian at Step0X, send first location report.
// Compute initial violation of constraints.
   nlcsqp_sqpsendx(state, &state->step0x);
   state->needfij = true, state->PQ = 0; goto Pause; Resume0: state->needfij = false;
   if (!nlcsqp_sqpretrievefij(state, &state->step0fi, &state->step0j)) {
   // Failed to retrieve function/Jaconian, infinities detected!
      for (i = 0; i < n; i++) {
         state->stepkx.xR[i] = state->step0x.xR[i];
      }
      state->repterminationtype = -8;
      goto Exit;
   }
   nlcsqp_sqpcopystate(state, &state->step0x, &state->step0fi, &state->step0j, &state->stepkx, &state->stepkfi, &state->stepkj);
   nlcsqp_sqpsendx(state, &state->stepkx);
   state->f = state->stepkfi.xR[0] * state->fscales.xR[0];
   state->xupdated = true, state->PQ = 1; goto Pause; Resume1: state->xupdated = false;
   checklcviolation(&state->scaledcleic, &state->lcsrcidx, nec, nic, &state->stepkx, n, &state->replcerr, &state->replcidx);
   unscaleandchecknlcviolation(&state->stepkfi, &state->fscales, nlec, nlic, &state->repnlcerr, &state->repnlcidx);
// Perform outer (NLC) iterations
   state->bigc = 500.0;
   hessianinitbfgs(&state->hess, n, state->bfgsresetfreq, coalesce(state->epsx, sqrt(machineepsilon)));
   nlcsqp_initqpsubsolver(state, &state->subsolver);
   while (true) {
   // Before beginning new outer iteration:
   // * renormalize target function and/or constraints, if some of them have too large magnitudes
   // * save initial point for the outer iteration
      for (i = 0; i <= nlec + nlic; i++) {
      // Determine (a) multiplicative coefficient applied to function value
      // and Jacobian row, and (b) new value of the function scale.
         mx = 0.0;
         for (j = 0; j < n; j++) {
            mx = rmax2(mx, fabs(state->stepkj.xyR[i][j]));
         }
         multiplyby = 1.0;
         setscaleto = state->fscales.xR[i];
         if (mx >= sqpbigscale) {
            multiplyby = 1.0 / mx;
            setscaleto = state->fscales.xR[i] * mx;
         }
         if (mx <= sqpsmallscale && state->fscales.xR[i] > 1.0) {
            if (state->fscales.xR[i] * mx > 1.0) {
               multiplyby = 1.0 / mx;
               setscaleto = state->fscales.xR[i] * mx;
            } else {
               multiplyby = state->fscales.xR[i];
               setscaleto = 1.0;
            }
         }
         if (multiplyby != 1.0) {
         // Function #I needs renormalization:
         // * update function vector element and Jacobian matrix row
         // * update FScales[] array
            state->stepkfi.xR[i] *= multiplyby;
            for (j = 0; j < n; j++) {
               state->stepkj.xyR[i][j] *= multiplyby;
            }
            state->fscales.xR[i] = setscaleto;
         }
      }
   // PHASE 2
   //
   // This phase is a primary part of the algorithm which is responsible for its
   // convergence properties.
   //
   // It solves QP subproblem with possible activation and deactivation of constraints
   // and then starts backtracking (step length is bounded by 1.0) merit function search
   // (with second-order correction to deal with Maratos effect) on the direction produced
   // by QP subproblem.
   //
   // This phase is everything we need to in order to have convergence; however,
   // it has one performance-related issue: using "general" interior point QP solver
   // results in slow solution times. Fast equality-constrained phase is essential for
   // the quick convergence.
      nlcsqp_qpsubsolversetalgoipm(&state->subsolver);
      nlcsqp_sqpcopystate(state, &state->stepkx, &state->stepkfi, &state->stepkj, &state->step0x, &state->step0fi, &state->step0j);
      for (
         nlcsqp_meritphaseinit(&state->meritstate, &state->stepkx, &state->stepkfi, &state->stepkj, n, nec, nic, nlec, nlic, &state->abslagmemory, nlcsqp_penaltymemlen);
         nlcsqp_meritphaseiteration(state, &state->meritstate, smonitor, userterminationneeded);
      ) {
         state->PQ = 2; goto Pause; Resume2: ;
      }
      nlcsqp_meritphaseresults(&state->meritstate, &state->stepkx, &state->stepkfi, &state->stepkj, &state->meritlagmult, &increasebigc, &status);
      if (status == 0) {
         break;
      }
      ae_assert(status > 0, "MinSQPIteration: integrity check failed");
      state->haslagmult = true;
      for (i = nlcsqp_penaltymemlen - 1; i >= 1; i--) {
         rcopyrr(nec + nic + nlec + nlic, &state->abslagmemory, i - 1, &state->abslagmemory, i);
      }
      for (i = 0; i < nec + nic + nlec + nlic; i++) {
         state->abslagmemory.xyR[0][i] = fabs(state->meritlagmult.xR[i]);
      }
   // Caller requested to update BigC - L1 penalty coefficient for linearized constraint violation
      if (increasebigc) {
         state->bigc = rmin2(10.0 * state->bigc, nlcsqp_maxbigc);
      }
   // Update trust region.
   //
   // NOTE: when trust region radius remains fixed for a long time it may mean that we
   //       stagnated in eternal loop. In such cases we decrease it slightly in order
   //       to break possible loop. If such decrease was unnecessary, it may be easily
   //       fixed within few iterations.
      deltamax = 0.0;
      for (i = 0; i < n; i++) {
         deltamax = rmax2(deltamax, fabs(state->step0x.xR[i] - state->stepkx.xR[i]) / state->trustrad);
      }
      trustradstagnated = false;
      state->trustradstagnationcnt++;
      prevtrustrad = state->trustrad;
      if (deltamax <= nlcsqp_sqpdeltadecrease) {
         state->trustrad *= rmax2(deltamax / nlcsqp_sqpdeltadecrease, maxtrustraddecay);
      }
      if (deltamax >= nlcsqp_sqpdeltaincrease) {
         state->trustrad *= rmin2(deltamax / nlcsqp_sqpdeltaincrease, maxtrustradgrowth);
      }
      if (state->trustrad < 0.99 * prevtrustrad || state->trustrad > 1.01 * prevtrustrad) {
         state->trustradstagnationcnt = 0;
      }
      if (state->trustradstagnationcnt >= trustradstagnationlimit) {
         state->trustrad *= 0.5;
         state->trustradstagnationcnt = 0;
         trustradstagnated = true;
      }
   // Advance outer iteration counter, test stopping criteria
      state->repiterationscount++;
      if (NearAtR(state->stepkfi.xR[0], state->step0fi.xR[0], stagnationepsf * fabs(state->step0fi.xR[0]))) {
         state->fstagnationcnt++;
      } else {
         state->fstagnationcnt = 0;
      }
      if (state->trustrad <= state->epsx) {
         state->repterminationtype = 2;
         break;
      } else if (state->maxits > 0 && state->repiterationscount >= state->maxits) {
         state->repterminationtype = 5;
         break;
      } else if (state->fstagnationcnt >= fstagnationlimit) {
         state->repterminationtype = 7;
         break;
      }
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

void minsqpsubsolver_init(void *_p, bool make_automatic) {
   minsqpsubsolver *p = (minsqpsubsolver *)_p;
   vipmstate_init(&p->ipmsolver, make_automatic);
   ae_vector_init(&p->curb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cural, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curau, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparserawlc, make_automatic);
   sparsematrix_init(&p->sparseefflc, make_automatic);
   ae_vector_init(&p->d0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->denseh, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dummy1, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->densedummy, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsedummy, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasal, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasau, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->activea, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->activerhs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->activeidx, 0, DT_INT, make_automatic);
}

void minsqpsubsolver_copy(void *_dst, const void *_src, bool make_automatic) {
   minsqpsubsolver *dst = (minsqpsubsolver *)_dst;
   const minsqpsubsolver *src = (const minsqpsubsolver *)_src;
   dst->algokind = src->algokind;
   vipmstate_copy(&dst->ipmsolver, &src->ipmsolver, make_automatic);
   ae_vector_copy(&dst->curb, &src->curb, make_automatic);
   ae_vector_copy(&dst->curbndl, &src->curbndl, make_automatic);
   ae_vector_copy(&dst->curbndu, &src->curbndu, make_automatic);
   ae_vector_copy(&dst->cural, &src->cural, make_automatic);
   ae_vector_copy(&dst->curau, &src->curau, make_automatic);
   sparsematrix_copy(&dst->sparserawlc, &src->sparserawlc, make_automatic);
   sparsematrix_copy(&dst->sparseefflc, &src->sparseefflc, make_automatic);
   ae_vector_copy(&dst->d0, &src->d0, make_automatic);
   ae_matrix_copy(&dst->denseh, &src->denseh, make_automatic);
   ae_vector_copy(&dst->dummy1, &src->dummy1, make_automatic);
   ae_matrix_copy(&dst->densedummy, &src->densedummy, make_automatic);
   sparsematrix_copy(&dst->sparsedummy, &src->sparsedummy, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->tmp2, &src->tmp2, make_automatic);
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_vector_copy(&dst->hasal, &src->hasal, make_automatic);
   ae_vector_copy(&dst->hasau, &src->hasau, make_automatic);
   ae_matrix_copy(&dst->activea, &src->activea, make_automatic);
   ae_vector_copy(&dst->activerhs, &src->activerhs, make_automatic);
   ae_vector_copy(&dst->activeidx, &src->activeidx, make_automatic);
   dst->activesetsize = src->activesetsize;
}

void minsqpsubsolver_free(void *_p, bool make_automatic) {
   minsqpsubsolver *p = (minsqpsubsolver *)_p;
   vipmstate_free(&p->ipmsolver, make_automatic);
   ae_vector_free(&p->curb, make_automatic);
   ae_vector_free(&p->curbndl, make_automatic);
   ae_vector_free(&p->curbndu, make_automatic);
   ae_vector_free(&p->cural, make_automatic);
   ae_vector_free(&p->curau, make_automatic);
   sparsematrix_free(&p->sparserawlc, make_automatic);
   sparsematrix_free(&p->sparseefflc, make_automatic);
   ae_vector_free(&p->d0, make_automatic);
   ae_matrix_free(&p->denseh, make_automatic);
   ae_vector_free(&p->dummy1, make_automatic);
   ae_matrix_free(&p->densedummy, make_automatic);
   sparsematrix_free(&p->sparsedummy, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->tmp2, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_vector_free(&p->hasal, make_automatic);
   ae_vector_free(&p->hasau, make_automatic);
   ae_matrix_free(&p->activea, make_automatic);
   ae_vector_free(&p->activerhs, make_automatic);
   ae_vector_free(&p->activeidx, make_automatic);
}

void minsqptmplagrangian_init(void *_p, bool make_automatic) {
   minsqptmplagrangian *p = (minsqptmplagrangian *)_p;
   ae_vector_init(&p->sclagtmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sclagtmp1, 0, DT_REAL, make_automatic);
}

void minsqptmplagrangian_copy(void *_dst, const void *_src, bool make_automatic) {
   minsqptmplagrangian *dst = (minsqptmplagrangian *)_dst;
   const minsqptmplagrangian *src = (const minsqptmplagrangian *)_src;
   ae_vector_copy(&dst->sclagtmp0, &src->sclagtmp0, make_automatic);
   ae_vector_copy(&dst->sclagtmp1, &src->sclagtmp1, make_automatic);
}

void minsqptmplagrangian_free(void *_p, bool make_automatic) {
   minsqptmplagrangian *p = (minsqptmplagrangian *)_p;
   ae_vector_free(&p->sclagtmp0, make_automatic);
   ae_vector_free(&p->sclagtmp1, make_automatic);
}

void minsqptmpmerit_init(void *_p, bool make_automatic) {
   minsqptmpmerit *p = (minsqptmpmerit *)_p;
   ae_vector_init(&p->mftmp0, 0, DT_REAL, make_automatic);
}

void minsqptmpmerit_copy(void *_dst, const void *_src, bool make_automatic) {
   minsqptmpmerit *dst = (minsqptmpmerit *)_dst;
   const minsqptmpmerit *src = (const minsqptmpmerit *)_src;
   ae_vector_copy(&dst->mftmp0, &src->mftmp0, make_automatic);
}

void minsqptmpmerit_free(void *_p, bool make_automatic) {
   minsqptmpmerit *p = (minsqptmpmerit *)_p;
   ae_vector_free(&p->mftmp0, make_automatic);
}

void minsqpmeritphasestate_init(void *_p, bool make_automatic) {
   minsqpmeritphasestate *p = (minsqpmeritphasestate *)_p;
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkxc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkxn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfic, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfin, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkj, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkjc, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkjn, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagmult, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dummylagmult, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->penalties, 0, DT_REAL, make_automatic);
   minsqptmpmerit_init(&p->tmpmerit, make_automatic);
   minsqptmplagrangian_init(&p->tmplagrangianfg, make_automatic);
   ae_vector_init(&p->stepklaggrad, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepknlaggrad, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmphdiag, 0, DT_REAL, make_automatic);
}

void minsqpmeritphasestate_copy(void *_dst, const void *_src, bool make_automatic) {
   minsqpmeritphasestate *dst = (minsqpmeritphasestate *)_dst;
   const minsqpmeritphasestate *src = (const minsqpmeritphasestate *)_src;
   dst->n = src->n;
   dst->nec = src->nec;
   dst->nic = src->nic;
   dst->nlec = src->nlec;
   dst->nlic = src->nlic;
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_vector_copy(&dst->d0, &src->d0, make_automatic);
   ae_vector_copy(&dst->d1, &src->d1, make_automatic);
   ae_vector_copy(&dst->stepkx, &src->stepkx, make_automatic);
   ae_vector_copy(&dst->stepkxc, &src->stepkxc, make_automatic);
   ae_vector_copy(&dst->stepkxn, &src->stepkxn, make_automatic);
   ae_vector_copy(&dst->stepkfi, &src->stepkfi, make_automatic);
   ae_vector_copy(&dst->stepkfic, &src->stepkfic, make_automatic);
   ae_vector_copy(&dst->stepkfin, &src->stepkfin, make_automatic);
   ae_matrix_copy(&dst->stepkj, &src->stepkj, make_automatic);
   ae_matrix_copy(&dst->stepkjc, &src->stepkjc, make_automatic);
   ae_matrix_copy(&dst->stepkjn, &src->stepkjn, make_automatic);
   ae_vector_copy(&dst->lagmult, &src->lagmult, make_automatic);
   ae_vector_copy(&dst->dummylagmult, &src->dummylagmult, make_automatic);
   ae_vector_copy(&dst->penalties, &src->penalties, make_automatic);
   minsqptmpmerit_copy(&dst->tmpmerit, &src->tmpmerit, make_automatic);
   minsqptmplagrangian_copy(&dst->tmplagrangianfg, &src->tmplagrangianfg, make_automatic);
   ae_vector_copy(&dst->stepklaggrad, &src->stepklaggrad, make_automatic);
   ae_vector_copy(&dst->stepknlaggrad, &src->stepknlaggrad, make_automatic);
   dst->status = src->status;
   dst->increasebigc = src->increasebigc;
   ae_vector_copy(&dst->tmphdiag, &src->tmphdiag, make_automatic);
   dst->PQ = src->PQ;
}

void minsqpmeritphasestate_free(void *_p, bool make_automatic) {
   minsqpmeritphasestate *p = (minsqpmeritphasestate *)_p;
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->d0, make_automatic);
   ae_vector_free(&p->d1, make_automatic);
   ae_vector_free(&p->stepkx, make_automatic);
   ae_vector_free(&p->stepkxc, make_automatic);
   ae_vector_free(&p->stepkxn, make_automatic);
   ae_vector_free(&p->stepkfi, make_automatic);
   ae_vector_free(&p->stepkfic, make_automatic);
   ae_vector_free(&p->stepkfin, make_automatic);
   ae_matrix_free(&p->stepkj, make_automatic);
   ae_matrix_free(&p->stepkjc, make_automatic);
   ae_matrix_free(&p->stepkjn, make_automatic);
   ae_vector_free(&p->lagmult, make_automatic);
   ae_vector_free(&p->dummylagmult, make_automatic);
   ae_vector_free(&p->penalties, make_automatic);
   minsqptmpmerit_free(&p->tmpmerit, make_automatic);
   minsqptmplagrangian_free(&p->tmplagrangianfg, make_automatic);
   ae_vector_free(&p->stepklaggrad, make_automatic);
   ae_vector_free(&p->stepknlaggrad, make_automatic);
   ae_vector_free(&p->tmphdiag, make_automatic);
}

void minsqpstate_init(void *_p, bool make_automatic) {
   minsqpstate *p = (minsqpstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->scaledcleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lcsrcidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->scaledbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->scaledbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j, 0, 0, DT_REAL, make_automatic);
   minsqpmeritphasestate_init(&p->meritstate, make_automatic);
   ae_vector_init(&p->step0x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->backupx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->step0fi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->backupfi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->step0j, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkj, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->meritlagmult, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dummylagmult, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->abslagmemory, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fscales, 0, DT_REAL, make_automatic);
   minsqpsubsolver_init(&p->subsolver, make_automatic);
   xbfgshessian_init(&p->hess, make_automatic);
   minsqptmpmerit_init(&p->tmpmerit, make_automatic);
}

void minsqpstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minsqpstate *dst = (minsqpstate *)_dst;
   const minsqpstate *src = (const minsqpstate *)_src;
   dst->n = src->n;
   dst->nec = src->nec;
   dst->nic = src->nic;
   dst->nlec = src->nlec;
   dst->nlic = src->nlic;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_matrix_copy(&dst->scaledcleic, &src->scaledcleic, make_automatic);
   ae_vector_copy(&dst->lcsrcidx, &src->lcsrcidx, make_automatic);
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_vector_copy(&dst->scaledbndl, &src->scaledbndl, make_automatic);
   ae_vector_copy(&dst->scaledbndu, &src->scaledbndu, make_automatic);
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->bfgsresetfreq = src->bfgsresetfreq;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   ae_matrix_copy(&dst->j, &src->j, make_automatic);
   dst->f = src->f;
   dst->needfij = src->needfij;
   dst->xupdated = src->xupdated;
   minsqpmeritphasestate_copy(&dst->meritstate, &src->meritstate, make_automatic);
   dst->bigc = src->bigc;
   dst->trustrad = src->trustrad;
   dst->trustradstagnationcnt = src->trustradstagnationcnt;
   dst->fstagnationcnt = src->fstagnationcnt;
   ae_vector_copy(&dst->step0x, &src->step0x, make_automatic);
   ae_vector_copy(&dst->stepkx, &src->stepkx, make_automatic);
   ae_vector_copy(&dst->backupx, &src->backupx, make_automatic);
   ae_vector_copy(&dst->step0fi, &src->step0fi, make_automatic);
   ae_vector_copy(&dst->stepkfi, &src->stepkfi, make_automatic);
   ae_vector_copy(&dst->backupfi, &src->backupfi, make_automatic);
   ae_matrix_copy(&dst->step0j, &src->step0j, make_automatic);
   ae_matrix_copy(&dst->stepkj, &src->stepkj, make_automatic);
   dst->haslagmult = src->haslagmult;
   ae_vector_copy(&dst->meritlagmult, &src->meritlagmult, make_automatic);
   ae_vector_copy(&dst->dummylagmult, &src->dummylagmult, make_automatic);
   ae_matrix_copy(&dst->abslagmemory, &src->abslagmemory, make_automatic);
   ae_vector_copy(&dst->fscales, &src->fscales, make_automatic);
   minsqpsubsolver_copy(&dst->subsolver, &src->subsolver, make_automatic);
   xbfgshessian_copy(&dst->hess, &src->hess, make_automatic);
   minsqptmpmerit_copy(&dst->tmpmerit, &src->tmpmerit, make_automatic);
   dst->repsimplexiterations = src->repsimplexiterations;
   dst->repsimplexiterations1 = src->repsimplexiterations1;
   dst->repsimplexiterations2 = src->repsimplexiterations2;
   dst->repsimplexiterations3 = src->repsimplexiterations3;
   dst->repiterationscount = src->repiterationscount;
   dst->repterminationtype = src->repterminationtype;
   dst->repbcerr = src->repbcerr;
   dst->repbcidx = src->repbcidx;
   dst->replcerr = src->replcerr;
   dst->replcidx = src->replcidx;
   dst->repnlcerr = src->repnlcerr;
   dst->repnlcidx = src->repnlcidx;
   dst->PQ = src->PQ;
}

void minsqpstate_free(void *_p, bool make_automatic) {
   minsqpstate *p = (minsqpstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_matrix_free(&p->scaledcleic, make_automatic);
   ae_vector_free(&p->lcsrcidx, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_vector_free(&p->scaledbndl, make_automatic);
   ae_vector_free(&p->scaledbndu, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_matrix_free(&p->j, make_automatic);
   minsqpmeritphasestate_free(&p->meritstate, make_automatic);
   ae_vector_free(&p->step0x, make_automatic);
   ae_vector_free(&p->stepkx, make_automatic);
   ae_vector_free(&p->backupx, make_automatic);
   ae_vector_free(&p->step0fi, make_automatic);
   ae_vector_free(&p->stepkfi, make_automatic);
   ae_vector_free(&p->backupfi, make_automatic);
   ae_matrix_free(&p->step0j, make_automatic);
   ae_matrix_free(&p->stepkj, make_automatic);
   ae_vector_free(&p->meritlagmult, make_automatic);
   ae_vector_free(&p->dummylagmult, make_automatic);
   ae_matrix_free(&p->abslagmemory, make_automatic);
   ae_vector_free(&p->fscales, make_automatic);
   minsqpsubsolver_free(&p->subsolver, make_automatic);
   xbfgshessian_free(&p->hess, make_automatic);
   minsqptmpmerit_free(&p->tmpmerit, make_automatic);
}
} // end of namespace alglib_impl

// === LPQPPRESOLVE Package ===
// Depends on: (AlgLibInternal) APSTRUCT
// Depends on: (LinAlg) SPARSE
namespace alglib_impl {
// Initialize dynamic CRS matrix using SparseMatrix structure
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_dyncrsinitfromsparsecrs(sparsematrix *s, dynamiccrs *r) {
   ae_int_t m;
   ae_int_t n;
   m = s->m;
   n = s->n;
   ae_assert(s->matrixtype == 1, "DynCRSInitFromSparseCRS: S is not CRS matrix");
   r->m = m;
   r->n = n;
   icopyallocv(s->ridx.xZ[m], &s->idx, &r->idx);
   rcopyallocv(s->ridx.xZ[m], &s->vals, &r->vals);
   allocv(m, &r->rowbegin);
   allocv(m, &r->rowend);
   icopyvx(m, &s->ridx, 0, &r->rowbegin, 0);
   icopyvx(m, &s->ridx, 1, &r->rowend, 0);
}

// Drops numerical zeros from the matrix
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_dyncrsdropzeros(dynamiccrs *a) {
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   ae_int_t jj;
   ae_int_t offs;
   double v;
   m = a->m;
   for (i = 0; i < m; i++) {
      offs = a->rowbegin.xZ[i];
      for (jj = a->rowbegin.xZ[i]; jj < a->rowend.xZ[i]; jj++) {
         j = a->idx.xZ[jj];
         v = a->vals.xR[jj];
         if (v == 0.0) {
            continue;
         }
         a->idx.xZ[offs] = j;
         a->vals.xR[offs] = v;
         offs++;
      }
      a->rowend.xZ[i] = offs;
   }
}

// Removes rows
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_dyncrsremoverow(dynamiccrs *a, ae_int_t rowidx) {
   a->rowend.xZ[rowidx] = a->rowbegin.xZ[rowidx];
}

// Removes element from the row
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_dyncrsremovefromrow(dynamiccrs *a, ae_int_t rowidx, ae_int_t j) {
   ae_int_t ii;
   ae_int_t offs;
   offs = a->rowbegin.xZ[rowidx];
   for (ii = a->rowbegin.xZ[rowidx]; ii < a->rowend.xZ[rowidx]; ii++) {
      if (a->idx.xZ[ii] != j) {
         a->idx.xZ[offs] = a->idx.xZ[ii];
         a->vals.xR[offs] = a->vals.xR[ii];
         offs++;
      }
   }
   a->rowend.xZ[rowidx] = offs;
}

// Removes elements with indexes in the set from the row
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_dyncrsremovesetfromrow(dynamiccrs *a, ae_int_t rowidx, niset *s) {
   ae_int_t ii;
   ae_int_t offs;
   offs = a->rowbegin.xZ[rowidx];
   for (ii = a->rowbegin.xZ[rowidx]; ii < a->rowend.xZ[rowidx]; ii++) {
      if (s->locationof.xZ[a->idx.xZ[ii]] < 0) {
         a->idx.xZ[offs] = a->idx.xZ[ii];
         a->vals.xR[offs] = a->vals.xR[ii];
         offs++;
      }
   }
   a->rowend.xZ[rowidx] = offs;
}

// Initialize presolver stack
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverstackinit(ae_int_t n, ae_int_t m, presolverstack *s) {
   s->n = n;
   s->m = m;
   s->ntrf = 0;
   isetallocv(1, 0, &s->idataridx);
   isetallocv(1, 0, &s->rdataridx);
}

// Streams boolean value to the presolver stack data storage (the data
// are appended to the last transform on top of the stack).
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverstreamb(presolverstack *s, bool b) {
   ae_int_t ilast;
   ilast = s->idataridx.xZ[s->ntrf];
   igrowv(ilast + 1, &s->idata);
   s->idata.xZ[ilast] = b ? 1 : 0;
   s->idataridx.xZ[s->ntrf] = ilast + 1;
}

// Streams integer value to the presolver stack data storage (the data
// are appended to the last transform on top of the stack).
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverstreami(presolverstack *s, ae_int_t i) {
   ae_int_t ilast;
   ilast = s->idataridx.xZ[s->ntrf];
   igrowv(ilast + 1, &s->idata);
   s->idata.xZ[ilast] = i;
   s->idataridx.xZ[s->ntrf] = ilast + 1;
}

// Streams real value to the presolver stack data storage (the data
// are appended to the last transform on top of the stack).
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverstreamr(presolverstack *s, double v) {
   ae_int_t rlast;
   rlast = s->rdataridx.xZ[s->ntrf];
   rgrowv(rlast + 1, &s->rdata);
   s->rdata.xR[rlast] = v;
   s->rdataridx.xZ[s->ntrf] = rlast + 1;
}

// Streams a integer/real pair to the presolver stack data storage (the data
// are appended to the last transform on top of the stack).
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverstreamir(presolverstack *s, ae_int_t i, double v) {
   ae_int_t ilast;
   ae_int_t rlast;
   ilast = s->idataridx.xZ[s->ntrf];
   rlast = s->rdataridx.xZ[s->ntrf];
   igrowv(ilast + 1, &s->idata);
   rgrowv(rlast + 1, &s->rdata);
   s->idata.xZ[ilast] = i;
   s->rdata.xR[rlast] = v;
   s->idataridx.xZ[s->ntrf] = ilast + 1;
   s->rdataridx.xZ[s->ntrf] = rlast + 1;
}

// Streams DynamicCRS row.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverstreamcrsrow(presolverstack *s, dynamiccrs *a, ae_int_t i) {
   ae_int_t k;
   lpqppresolve_presolverstreami(s, a->rowend.xZ[i] - a->rowbegin.xZ[i]);
   for (k = a->rowbegin.xZ[i]; k < a->rowend.xZ[i]; k++) {
      lpqppresolve_presolverstreamir(s, a->idx.xZ[k], a->vals.xR[k]);
   }
}

// Select transformation TIdx as the source for stream reads
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverselectstreamsource(presolverstack *s, ae_int_t tidx) {
   s->sourceidx = tidx;
   s->isrc = s->idataridx.xZ[tidx];
   s->rsrc = s->rdataridx.xZ[tidx];
}

// Reads from presolver stack boolean value, advances stream pointer
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverunstreamb(presolverstack *s, bool *v) {
   *v = false;
   *v = s->idata.xZ[s->isrc] != 0;
   s->isrc++;
}

// Reads from presolver stack integer value, advances stream pointer
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverunstreami(presolverstack *s, ae_int_t *v) {
   *v = 0;
   *v = s->idata.xZ[s->isrc];
   s->isrc++;
}

// Reads from presolver stack real value, advances stream pointer
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverunstreamr(presolverstack *s, double *v) {
   *v = 0.0;
   *v = s->rdata.xR[s->rsrc];
   s->rsrc++;
}

// Reads from presolver stack int/real pair, advances stream pointers
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverunstreamir(presolverstack *s, ae_int_t *vi, double *vr) {
   *vi = 0;
   *vr = 0.0;
   *vi = s->idata.xZ[s->isrc];
   s->isrc++;
   *vr = s->rdata.xR[s->rsrc];
   s->rsrc++;
}

// Reads from presolver stack compressed sparse vector, advances stream pointers
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverunstreamsparsevec(presolverstack *s, ae_int_t *cnt, ZVector *idx, RVector *vals) {
   ae_int_t i;
   ae_int_t j;
   double v;
   lpqppresolve_presolverunstreami(s, cnt);
   allocv(*cnt, idx);
   allocv(*cnt, vals);
   for (i = 0; i < *cnt; i++) {
      lpqppresolve_presolverunstreamir(s, &j, &v);
      idx->xZ[i] = j;
      vals->xR[i] = v;
   }
}

// Checks that we are at the end of the stream corresponding to transfrom #TIdx
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverasserteos(presolverstack *s) {
   ae_assert(s->isrc == s->idataridx.xZ[s->sourceidx + 1], "PresolverAssertEOS: unread integers in the stream");
   ae_assert(s->rsrc == s->rdataridx.xZ[s->sourceidx + 1], "PresolverAssertEOS: unread reals in the stream");
}

// Appends transform placeholder
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendtrf(presolverstack *s, ae_int_t tt) {
   igrowv(s->ntrf + 1, &s->trftype);
   igrowv(s->ntrf + 2, &s->idataridx);
   igrowv(s->ntrf + 2, &s->rdataridx);
   s->trftype.xZ[s->ntrf] = tt;
   s->idataridx.xZ[s->ntrf + 1] = s->idataridx.xZ[s->ntrf];
   s->rdataridx.xZ[s->ntrf + 1] = s->rdataridx.xZ[s->ntrf];
   s->ntrf++;
}

// Appends cost scaling to the presolver stack.
//
// The cost vector is MULTIPLIED by the scale coefficient.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendcostscaling(presolverstack *s, double vmul) {
   lpqppresolve_presolverappendtrf(s, 0);
   lpqppresolve_presolverstreamr(s, vmul);
}

// Appends column scaling to the presolver stack.
//
// The variable is MULTIPLIED by the scale coefficient.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendcolscaling(presolverstack *s, ae_int_t colidx, double vmul) {
   lpqppresolve_presolverappendtrf(s, 1);
   lpqppresolve_presolverstreamir(s, colidx, vmul);
}

// Appends row scaling to the presolver stack.
//
// The row is MULTIPLIED by the scale coefficient.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendrowscaling(presolverstack *s, ae_int_t rowidx, double vmul) {
   lpqppresolve_presolverappendtrf(s, 2);
   lpqppresolve_presolverstreamir(s, rowidx, vmul);
}

// Appends command to drop empty col and set variable and Lagrange multiplier
// to prescribed values
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappenddropemptycol(presolverstack *s, ae_int_t colidx, double varval, double lagval, ae_int_t statval) {
   lpqppresolve_presolverappendtrf(s, 3);
   lpqppresolve_presolverstreami(s, colidx);
   lpqppresolve_presolverstreamr(s, varval);
   lpqppresolve_presolverstreamr(s, lagval);
   lpqppresolve_presolverstreami(s, statval);
}

// Appends command to drop empty row
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappenddropemptyrow(presolverstack *s, ae_int_t rowidx) {
   lpqppresolve_presolverappendtrf(s, 4);
   lpqppresolve_presolverstreami(s, rowidx);
}

// Appends command to convert singleton row to box constraint
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendsingletonrow(presolverstack *s, ae_int_t i, ae_int_t j, double v, double swapsign, double bndl, bool bndlisbc, double bndu, bool bnduisbc) {
   lpqppresolve_presolverappendtrf(s, 5);
   lpqppresolve_presolverstreami(s, i);
   lpqppresolve_presolverstreami(s, j);
   lpqppresolve_presolverstreamr(s, v);
   lpqppresolve_presolverstreamr(s, swapsign);
   lpqppresolve_presolverstreamr(s, bndl);
   lpqppresolve_presolverstreamb(s, bndlisbc);
   lpqppresolve_presolverstreamr(s, bndu);
   lpqppresolve_presolverstreamb(s, bnduisbc);
}

// Appends command to fix variable
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendfixedvar(presolverstack *s, ae_int_t colidx, double fixval, double ci, dynamiccrs *at) {
   lpqppresolve_presolverappendtrf(s, 6);
   lpqppresolve_presolverstreami(s, colidx);
   lpqppresolve_presolverstreamr(s, fixval);
   lpqppresolve_presolverstreamr(s, ci);
   lpqppresolve_presolverstreamcrsrow(s, at, colidx);
}

// Appends explicit slack transformation
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendexplicitslack(presolverstack *s, ae_int_t i, ae_int_t j, double aij, double slackbndl, double slackbndu, double al, double au, dynamiccrs *a) {
   lpqppresolve_presolverappendtrf(s, 7);
   lpqppresolve_presolverstreami(s, i);
   lpqppresolve_presolverstreami(s, j);
   lpqppresolve_presolverstreamr(s, aij);
   lpqppresolve_presolverstreamr(s, slackbndl);
   lpqppresolve_presolverstreamr(s, slackbndu);
   lpqppresolve_presolverstreamr(s, al);
   lpqppresolve_presolverstreamr(s, au);
   lpqppresolve_presolverstreamcrsrow(s, a, i);
}

// Appends implicit slack transformation
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverappendimplicitslack(presolverstack *s, ae_int_t i, ae_int_t j, double aij, double cj, double equalitybnd, dynamiccrs *a) {
   lpqppresolve_presolverappendtrf(s, 8);
   lpqppresolve_presolverstreami(s, i);
   lpqppresolve_presolverstreami(s, j);
   lpqppresolve_presolverstreamr(s, aij);
   lpqppresolve_presolverstreamr(s, cj);
   lpqppresolve_presolverstreamr(s, equalitybnd);
   lpqppresolve_presolverstreamcrsrow(s, a, i);
}

// This function restores original solution, given the solution of the
// transformed problem.
//
// Below N and M denote column/row count for both the original problem and
// transformed one PRIOR to removal of dropped columns and rows.
//
// Inputs:
//     S   -           a sequence of presolve transformations
//     X   -           array[N], transformed solution after permutation
//                     that restores original variable order (moves all
//                     fixed variables to their positions)
//     LagBC-          array[N], Lagrange coeffs for box constraints
//     LagLC-          array[M], Lagrange coeffs for linear constraints
//                     after permutation that restores original row order
//                     (moves all dropped rows to their positions)
//     Stats-          array[N+M], constraint stats
//
// Outputs:
//     X, LagBC, LagLC, Stats-restored solution
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolverrestoresolution(presolverstack *s, RVector *x, RVector *lagbc, RVector *laglc, ZVector *stats) {
   ae_int_t tidx;
   ae_int_t tt;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t cnt;
   ae_int_t vstat;
   double aij;
   double v;
   double vvar;
   double vlag;
   double vswap;
   double fixval;
   double ci;
   double cj;
   double equalitybnd;
   double bndl;
   double bndu;
   double al;
   double au;
   bool bndlisbc;
   bool bnduisbc;
   bool transferlagtobc;
   double ratingl;
   double ratingu;
   for (tidx = s->ntrf - 1; tidx >= 0; tidx--) {
      tt = s->trftype.xZ[tidx];
      if (tt == 0) {
      // Reverse cost scaling
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreamr(s, &v);
         lpqppresolve_presolverasserteos(s);
         rmulv(s->n, 1.0 / v, lagbc);
         rmulv(s->m, 1.0 / v, laglc);
         continue;
      }
      if (tt == 1) {
      // Reverse column scaling
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreamir(s, &k, &v);
         lpqppresolve_presolverasserteos(s);
         x->xR[k] /= v;
         lagbc->xR[k] *= v;
         continue;
      }
      if (tt == 2) {
      // Reverse row scaling
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreamir(s, &k, &v);
         lpqppresolve_presolverasserteos(s);
         laglc->xR[k] *= v;
         continue;
      }
      if (tt == 3) {
      // Reverse dropping empty col
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreami(s, &k);
         lpqppresolve_presolverunstreamr(s, &vvar);
         lpqppresolve_presolverunstreamr(s, &vlag);
         lpqppresolve_presolverunstreami(s, &vstat);
         lpqppresolve_presolverasserteos(s);
         x->xR[k] = vvar;
         lagbc->xR[k] = vlag;
         stats->xZ[k] = vstat;
         continue;
      }
      if (tt == 4) {
      // Reverse dropping empty row
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreami(s, &k);
         lpqppresolve_presolverasserteos(s);
         laglc->xR[k] = 0.0;
         stats->xZ[k] = 0;
         continue;
      }
      if (tt == 5) {
      // Handle singleton row.
      // Read data from stream.
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreami(s, &i);
         lpqppresolve_presolverunstreami(s, &j);
         lpqppresolve_presolverunstreamr(s, &v);
         lpqppresolve_presolverunstreamr(s, &vswap);
         lpqppresolve_presolverunstreamr(s, &bndl);
         lpqppresolve_presolverunstreamb(s, &bndlisbc);
         lpqppresolve_presolverunstreamr(s, &bndu);
         lpqppresolve_presolverunstreamb(s, &bnduisbc);
         lpqppresolve_presolverasserteos(s);
      // Determine bound that is "most active" using rating that combines Lagrangian magnitude
         ae_assert(isfinite(bndl) || isfinite(bndu), "PRESOLVE: singleton row with both bounds absent");
         ae_assert(fabs(vswap) == 1.0, "PRESOLVE: unexpected VSwap");
         ratingl = x->xR[j] - bndl + rmax2(lagbc->xR[j], 0.0);
         ratingu = bndu - x->xR[j] + rmax2(-lagbc->xR[j], 0.0);
         if (ratingl < ratingu) {
         // Lower bound is more likely
            transferlagtobc = bndlisbc;
         } else {
         // Upper bound is more likely
            transferlagtobc = bnduisbc;
         }
      // Transfer constraint activity from the transformed problem to the original one
         if (transferlagtobc) {
         // Box constraint of the original problem is active, linear singleton constraint is inactive
            laglc->xR[i] = 0.0;
            stats->xZ[s->n + i] = 0;
         } else {
         // Linear constraint of the original problem is active, box constraint is inactive.
            laglc->xR[i] = lagbc->xR[j] / v * vswap;
            stats->xZ[s->n + i] = iround(stats->xZ[j] * vswap);
            lagbc->xR[j] = 0.0;
            stats->xZ[j] = 0;
         }
         continue;
      }
      if (tt == 6) {
      // Fixed variable
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreami(s, &j);
         lpqppresolve_presolverunstreamr(s, &fixval);
         lpqppresolve_presolverunstreamr(s, &ci);
         lpqppresolve_presolverunstreamsparsevec(s, &cnt, &s->sparseidx0, &s->sparseval0);
         lpqppresolve_presolverasserteos(s);
         x->xR[j] = fixval;
         v = ci;
         for (i = 0; i < cnt; i++) {
            v += s->sparseval0.xR[i] * laglc->xR[s->sparseidx0.xZ[i]];
         }
         lagbc->xR[j] = -v;
         stats->xZ[j] = sign(lagbc->xR[j]);
         continue;
      }
      if (tt == 7) {
      // Explicit slack variable:
      // * deduce its bounds from row activity
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreami(s, &i);
         lpqppresolve_presolverunstreami(s, &j);
         lpqppresolve_presolverunstreamr(s, &aij);
         lpqppresolve_presolverunstreamr(s, &bndl);
         lpqppresolve_presolverunstreamr(s, &bndu);
         lpqppresolve_presolverunstreamr(s, &al);
         lpqppresolve_presolverunstreamr(s, &au);
         lpqppresolve_presolverunstreamsparsevec(s, &cnt, &s->sparseidx0, &s->sparseval0);
         lpqppresolve_presolverasserteos(s);
         x->xR[j] = 0.0;
         v = 0.0;
         for (k = 0; k < cnt; k++) {
            v += s->sparseval0.xR[k] * x->xR[s->sparseidx0.xZ[k]];
         }
         if (isfinite(al)) {
            al = (al - v) / aij;
         }
         if (isfinite(au)) {
            au = (au - v) / aij;
         }
         if (aij < 0.0) {
            swapr(&al, &au);
            if (!isfinite(al)) {
               al = -INFINITY;
            }
            if (!isfinite(au)) {
               au = +INFINITY;
            }
         }
         if (isfinite(al) && al > bndl) {
            bndl = al;
         }
         if (isfinite(au) && au < bndu) {
            bndu = au;
         }
         if (isfinite(bndl)) {
            x->xR[j] = bndl;
         } else {
            if (isfinite(bndu)) {
               x->xR[j] = bndu;
            } else {
               x->xR[j] = 0.0;
            }
         }
         lagbc->xR[j] = -aij * laglc->xR[i];
         stats->xZ[j] = -sign(aij) * stats->xZ[s->n + i];
         continue;
      }
      if (tt == 8) {
      // Implicit slack variable:
      // * deduce its bounds from row activity
         lpqppresolve_presolverselectstreamsource(s, tidx);
         lpqppresolve_presolverunstreami(s, &i);
         lpqppresolve_presolverunstreami(s, &j);
         lpqppresolve_presolverunstreamr(s, &aij);
         lpqppresolve_presolverunstreamr(s, &cj);
         lpqppresolve_presolverunstreamr(s, &equalitybnd);
         lpqppresolve_presolverunstreamsparsevec(s, &cnt, &s->sparseidx0, &s->sparseval0);
         lpqppresolve_presolverasserteos(s);
         x->xR[j] = 0.0;
         v = 0.0;
         for (k = 0; k < cnt; k++) {
            v += s->sparseval0.xR[k] * x->xR[s->sparseidx0.xZ[k]];
         }
         x->xR[j] = (equalitybnd - v) / aij;
         lagbc->xR[j] = -aij * laglc->xR[i];
         laglc->xR[i] -= cj / aij;
         stats->xZ[j] = -sign(aij) * stats->xZ[s->n + i];
         continue;
      }
      ae_assert(false, "PresolverRestoreSolution: unexpected transform type");
   }
}

// Prepare temporaries
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_presolvebuffersinit(presolvebuffers *buf, ae_int_t n, ae_int_t m) {
   if (n > 0) {
      nisinitemptyslow(n, &buf->setn);
   }
   if (m > 0) {
      nisinitemptyslow(m, &buf->setm);
   }
}

// This function drops empty columns from the matrix. It may detect unbounded
// problems (when unboundedness is caused by unconstrained column).
//
// Inputs:
//     C, BndL, BndU  -   array[N], current cost and box constraints.
//     IsDroppedCol-   array[N], column statuses; only non-dropped ones are examined.
//     LagrangeFromResidual- array[N], whether we want to compute Lagrange coeffs
//                     for box constraints using residual costs
//     N           -   variables count (including both fixed and non-fixed)
//     A, AT       -   current A and AT, dynamic CRS matrices
//     AL, AU      -   array[M], lower/upper bounds for linear constraints
//     M           -   linear constraints count
//     Eps         -   unboundedness is checked subject to small dual feasibility
//                     error tolerance
//     DoTrace     -   whether tracing is needed or not
//     SomethingChanged-flag variable
//     CntFixed    -   debug counter, updated by the function
//     trfStack    -   sequence of already applied transformations
//
// Outputs:
//     IsDroppedCol-   array[N], dropped columns are marked
//     LagrangeFromResidual-
//                     array[N], dropped cols are marked
//     ProblemStatus-  on failure (unboundedness detected) is set to -2,
//                     unchanged otherwise
//     SomethingChanged-is set to True if at least one col was dropped
//                     It is not changed otherwise.
//     CntDropped  -   debug counter, updated by the function
//     trfStack -      updated with new transforms
//
// Result:
//     if unboundedness was detected, False is returned.
//     True is returned otherwise.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static bool lpqppresolve_dropemptycol(RVector *c, RVector *bndl, RVector *bndu, BVector *isdroppedcol, BVector *lagrangefromresidual, ae_int_t n, dynamiccrs *a, dynamiccrs *at, RVector *al, RVector *au, ae_int_t m, double eps, presolvebuffers *buf, presolverstack *trfstack, ae_int_t *problemstatus, bool *somethingchanged, ae_int_t *cntdropped) {
   ae_int_t i;
   double v;
   ae_int_t statsval;
   bool result;
   ae_assert(eps >= 0.0, "LPPRESOLVE: Eps < 0");
   result = true;
// Scan columns, search for an empty one
   for (i = 0; i < n; i++) {
      if (!isdroppedcol->xB[i] && at->rowbegin.xZ[i] == at->rowend.xZ[i]) {
      // Try to detect unboundedness
         if (c->xR[i] < -eps && isposinf(bndu->xR[i]) || c->xR[i] > eps && isneginf(bndl->xR[i])) {
            *problemstatus = -2;
            *somethingchanged = true;
            ++*cntdropped;
            result = false;
            return result;
         }
      // Mark variable as fixed and issue transformation
         isdroppedcol->xB[i] = true;
         *somethingchanged = true;
         ++*cntdropped;
         v = 0.0;
         statsval = 0;
         if (c->xR[i] > 0.0 && isfinite(bndl->xR[i])) {
         // Variable has to be fixed at the lower bound
            v = bndl->xR[i];
            statsval = -1;
         }
         if (c->xR[i] < 0.0 && isfinite(bndu->xR[i])) {
         // Variable has to be fixed at the upper bound
            v = bndu->xR[i];
            statsval = 1;
         }
         if (statsval == 0) {
         // Variable value can be chosen arbitrarily, choose as close to zero as possible
            if (isfinite(bndl->xR[i])) {
               v = rmax2(v, bndl->xR[i]);
            }
            if (isfinite(bndu->xR[i])) {
               v = rmin2(v, bndu->xR[i]);
            }
         }
         lpqppresolve_presolverappenddropemptycol(trfstack, i, v, -c->xR[i], statsval);
      }
   }
   return result;
}

// This function drops clearly nonbinding rows from the matrix: empty and ones
// with infinite bounds.
//
// It may detect infeasible problems (when infeasibility is caused by
// constraint ranges  that  do  not include zero - the only value possible for
// an empty row).
//
// Inputs:
//     N           -   vars count
//     IsDroppedRow-   array[M], column statuses; only non-dropped ones are examined.
//     A, AT       -   current A and AT, dynamic CRS matrices
//     AL, AU      -   array[M], lower/upper bounds for linear constraints
//     M           -   linear constraints count
//     Eps         -   small primal feasibility error is allowed
//     DoTrace     -   whether tracing is needed or not
//     SomethingChanged-flag variable
//     TrfYLag, TrfYTgt, TrfStat, TrfStatTgt -
//                     sequence of already applied transformations
//
// Outputs:
//     IsDroppedRow-   array[M], dropped rows are marked
//     ProblemStatus-  on failure (infeasibility detected) is set to -3,
//                     unchanged otherwise
//     SomethingChanged-is set to True if at least one row was dropped
//                     It is not changed otherwise.
//     CntEmpty    -   debug counter, updated by the function
//     CntNoBounds -   debug counter, updated by the function
//     TrfYLag, TrfYTgt, TrfStat, TrfStatTgt -
//                     sequence of already applied transformations
//
// Result:
//     if infeasibility was detected, False is returned.
//     True is returned otherwise.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static bool lpqppresolve_dropclearlynonbindingrows(ae_int_t n, BVector *isdroppedrow, dynamiccrs *a, dynamiccrs *at, RVector *al, RVector *au, ae_int_t m, double eps, presolvebuffers *buf, presolverstack *trfstack, ae_int_t *problemstatus, bool *somethingchanged, ae_int_t *cntempty, ae_int_t *cntnobounds) {
   ae_int_t i;
   ae_int_t ii;
   ae_int_t jj;
   bool result;
   result = true;
// Scan rows
   nisclear(&buf->setn);
   nisclear(&buf->setm);
   for (i = 0; i < m; i++) {
      if (!isdroppedrow->xB[i]) {
      // Empty row
         if (a->rowbegin.xZ[i] == a->rowend.xZ[i]) {
         // Try to detect infeasibility
            if (isfinite(al->xR[i]) && al->xR[i] > eps || isfinite(au->xR[i]) && au->xR[i] < -eps) {
               *problemstatus = -3;
               *somethingchanged = true;
               result = false;
               return result;
            }
         // Mark row as dropped and issue transformation
            isdroppedrow->xB[i] = true;
            *somethingchanged = true;
            ++*cntempty;
            lpqppresolve_presolverappenddropemptyrow(trfstack, i);
            continue;
         }
      // No bounds
         if (isneginf(al->xR[i]) && isposinf(au->xR[i])) {
         // Add row and column containing its elements to the cleanup list
            nisaddelement(&buf->setm, i);
            for (jj = a->rowbegin.xZ[i]; jj < a->rowend.xZ[i]; jj++) {
               nisaddelement(&buf->setn, a->idx.xZ[jj]);
            }
         // Mark row as dropped and issue transformation
            isdroppedrow->xB[i] = true;
            *somethingchanged = true;
            ++*cntnobounds;
            lpqppresolve_presolverappenddropemptyrow(trfstack, i);
            continue;
         }
      }
   }
// Clean up the matrix
   for (ii = 0; ii < buf->setm.nstored; ii++) {
      a->rowend.xZ[buf->setm.items.xZ[ii]] = a->rowbegin.xZ[buf->setm.items.xZ[ii]];
   }
   for (jj = 0; jj < buf->setn.nstored; jj++) {
      lpqppresolve_dyncrsremovesetfromrow(at, buf->setn.items.xZ[jj], &buf->setm);
   }
   return result;
}

// This function scans rows and converts singleton rows to box constraints.
//
// Inputs:
//     BndL, BndU  -   array[N], box constraints.
//     IsDroppedCol-   array[N], column statuses, used for integrity checks
//     N           -   variables count (including both fixed and non-fixed)
//     A, AT       -   current A and AT, dynamic CRS matrices
//     AL, AU      -   array[M], lower/upper bounds for linear constraints
//     M           -   linear constraints count
//     Eps         -   tolerance used to resolve infeasibilities
//     DoTrace     -   whether tracing is needed or not
//     SomethingChanged-flag variable
//     CntFixed    -   debug counter, updated by the function
//     trfStack    -   sequence of already applied transformations
//
// Outputs:
//     IsDroppedCol-   array[N], dropped columns are marked
//     LagrangeFromResidual-
//                     array[N], dropped cols are marked
//     ProblemStatus-  on failure (unboundedness detected) is set to -2,
//                     unchanged otherwise
//     SomethingChanged-is set to True if at least one col was dropped
//                     It is not changed otherwise.
//     CntDropped  -   debug counter, updated by the function
//     trfStack -      updated with new transforms
//
// Result:
//     if unboundedness was detected, False is returned.
//     True is returned otherwise.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static bool lpqppresolve_singletonrowtobc(RVector *bndl, RVector *bndu, BVector *isdroppedcol, ae_int_t n, dynamiccrs *a, dynamiccrs *at, RVector *al, RVector *au, BVector *isdroppedrow, ae_int_t m, double eps, presolvebuffers *buf, presolverstack *trfstack, ae_int_t *problemstatus, bool *somethingchanged, ae_int_t *cntsingleton) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t ii;
   ae_int_t offs;
   double v;
   double prevbndl;
   double prevbndu;
   double wrkal;
   double wrkau;
   double swapsign;
   double midpoint;
   bool lowerboundisbc;
   bool upperboundisbc;
   bool result;
   result = true;
   for (i = 0; i < m; i++) {
      if (a->rowbegin.xZ[i] + 1 == a->rowend.xZ[i] && (isfinite(al->xR[i]) || isfinite(au->xR[i]))) {
      // Read singleton row, perform integrity checks and normalization
         j = a->idx.xZ[a->rowbegin.xZ[i]];
         v = a->vals.xR[a->rowbegin.xZ[i]];
         ae_assert(!isdroppedrow->xB[i], "SingletonRowToBC: integrity check 6363 failed");
         ae_assert(!isdroppedcol->xB[j], "SingletonRowToBC: integrity check 6364 failed");
         ae_assert(v != 0.0, "SingletonRowToBC: integrity check 6366 failed");
         wrkal = al->xR[i];
         wrkau = au->xR[i];
         swapsign = 1.0;
         if (v < 0.0) {
            swapr(&wrkal, &wrkau);
            wrkal = -wrkal;
            wrkau = -wrkau;
            v = -v;
            swapsign = -1.0;
         }
         wrkal /= v;
         wrkau /= v;
         prevbndl = bndl->xR[j];
         prevbndu = bndu->xR[j];
      // Check feasibility
         if (prevbndl > prevbndu + eps) {
            *problemstatus = -3;
            *somethingchanged = true;
            result = false;
            return result;
         }
         if (wrkal > prevbndu + eps || wrkau < prevbndl - eps) {
            *problemstatus = -3;
            *somethingchanged = true;
            result = false;
            return result;
         }
      // Modify problem, perform constraint harmonization for slightly infeasible box constraints
         lowerboundisbc = true;
         upperboundisbc = true;
         if (isfinite(wrkal) && wrkal > prevbndl) {
            bndl->xR[j] = wrkal;
            lowerboundisbc = false;
         }
         if (isfinite(wrkau) && wrkau < prevbndu) {
            bndu->xR[j] = wrkau;
            upperboundisbc = false;
         }
         if (bndu->xR[j] < bndl->xR[j]) {
            midpoint = 0.5 * (bndu->xR[j] + bndl->xR[j]);
            bndl->xR[j] = midpoint;
            bndu->xR[j] = midpoint;
         }
         a->rowend.xZ[i] = a->rowbegin.xZ[i];
         offs = at->rowbegin.xZ[j];
         for (ii = at->rowbegin.xZ[j]; ii < at->rowend.xZ[j]; ii++) {
            if (at->idx.xZ[ii] != i) {
               at->idx.xZ[offs] = at->idx.xZ[ii];
               at->vals.xR[offs] = at->vals.xR[ii];
               offs++;
            }
         }
         at->rowend.xZ[j] = offs;
         isdroppedrow->xB[i] = true;
         *somethingchanged = true;
         ++*cntsingleton;
         lpqppresolve_presolverappendsingletonrow(trfstack, i, j, v, swapsign, bndl->xR[j], lowerboundisbc, bndu->xR[j], upperboundisbc);
      }
   }
   return result;
}

// This function tries to process singleton cols using various heuristics:
// * detect explicit slacks
//
// Inputs:
//     C. BndL, BndU-  array[N], cost and box constraints.
//     IsDroppedCol-   array[N], column statuses, used for integrity checks
//     N           -   variables count (including both fixed and non-fixed)
//     A, AT       -   current A and AT, dynamic CRS matrices
//     AL, AU      -   array[M], lower/upper bounds for linear constraints
//     M           -   linear constraints count
//     Eps         -   tolerance used to resolve infeasibilities
//     DoTrace     -   whether tracing is needed or not
//     SomethingChanged-flag variable
//     CntFixed    -   debug counter, updated by the function
//     trfStack    -   sequence of already applied transformations
//
// Outputs:
//     C, BndL, BndU-  may be modified
//     IsDroppedCol-   array[N], dropped columns are marked
//     LagrangeFromResidual-
//                     array[N], dropped cols are marked
//     ProblemStatus-  on failure (unboundedness detected) is set to -2,
//                     unchanged otherwise
//     SomethingChanged-is set to True if at least one col was dropped
//                     It is not changed otherwise.
//     CntSlackVars-   debug counter, updated by the function
//     trfStack -      updated with new transforms
//
// Result:
//     if infeasibility or unboundedness was detected, False is returned.
//     True is returned otherwise.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static bool lpqppresolve_singletoncols(RVector *c, RVector *bndl, RVector *bndu, BVector *isdroppedcol, ae_int_t n, dynamiccrs *a, dynamiccrs *at, RVector *al, RVector *au, BVector *isdroppedrow, ae_int_t m, double eps, presolvebuffers *buf, presolverstack *trfstack, ae_int_t *problemstatus, bool *somethingchanged, ae_int_t *cntslackvars, ae_int_t *cntimplicitslacks, ae_int_t *cntfreecolumnsingletons) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t ii;
   double preval;
   double prevau;
   double prevabnd;
   double aij;
   double aslk;
   double vslk;
   double v;
   double cj;
   bool result;
   result = true;
   for (j = 0; j < n; j++) {
      if (!isdroppedcol->xB[j] && at->rowbegin.xZ[j] + 1 == at->rowend.xZ[j]) {
         i = at->idx.xZ[at->rowbegin.xZ[j]];
         aij = at->vals.xR[at->rowbegin.xZ[j]];
      // Skip rows with no bounds, at least one bound is expected for the transformations below
         if (!(isfinite(al->xR[i]) || isfinite(au->xR[i]))) {
            continue;
         }
      // Is it an explicit slack?
         if (SmallAtR(c->xR[j], eps)) {
         // Clear Cj
         // Update constraint bounds
         // Issue "explicit slack" transformation
            c->xR[j] = 0.0;
            preval = al->xR[i];
            prevau = au->xR[i];
            if (aij > 0.0) {
               if (isfinite(bndl->xR[j])) {
                  au->xR[i] -= aij * bndl->xR[j];
               } else {
                  au->xR[i] = +INFINITY;
               }
               if (isfinite(bndu->xR[j])) {
                  al->xR[i] -= aij * bndu->xR[j];
               } else {
                  al->xR[i] = -INFINITY;
               }
            } else {
               if (isfinite(bndu->xR[j])) {
                  au->xR[i] -= aij * bndu->xR[j];
               } else {
                  au->xR[i] = +INFINITY;
               }
               if (isfinite(bndl->xR[j])) {
                  al->xR[i] -= aij * bndl->xR[j];
               } else {
                  al->xR[i] = -INFINITY;
               }
            }
            lpqppresolve_presolverappendexplicitslack(trfstack, i, j, aij, bndl->xR[j], bndu->xR[j], preval, prevau, a);
         // Remove variable from A and AT
            lpqppresolve_dyncrsremoverow(at, j);
            lpqppresolve_dyncrsremovefromrow(a, i, j);
            isdroppedcol->xB[j] = true;
         // Done
            *somethingchanged = true;
            ++*cntslackvars;
            continue;
         }
      // Is it equality row? The variable can be treated as an implicit slack
         if (isfinite(al->xR[i]) && isfinite(au->xR[i]) && NearAtR(al->xR[i], au->xR[i], eps)) {
         // Enforce AL == AU, set Cj to zero
            prevabnd = 0.5 * (al->xR[i] + au->xR[i]);
            al->xR[i] = prevabnd;
            au->xR[i] = prevabnd;
            cj = c->xR[j];
            v = c->xR[j] / aij;
            for (ii = a->rowbegin.xZ[i]; ii < a->rowend.xZ[i]; ii++) {
               c->xR[a->idx.xZ[ii]] -= v * a->vals.xR[ii];
            }
            c->xR[j] = 0.0;
         // Update constraint bounds
         // Issue "implicit slack" transformation
            if (aij > 0.0) {
               if (isfinite(bndl->xR[j])) {
                  au->xR[i] -= aij * bndl->xR[j];
               } else {
                  au->xR[i] = +INFINITY;
               }
               if (isfinite(bndu->xR[j])) {
                  al->xR[i] -= aij * bndu->xR[j];
               } else {
                  al->xR[i] = -INFINITY;
               }
            } else {
               if (isfinite(bndu->xR[j])) {
                  au->xR[i] -= aij * bndu->xR[j];
               } else {
                  au->xR[i] = +INFINITY;
               }
               if (isfinite(bndl->xR[j])) {
                  al->xR[i] -= aij * bndl->xR[j];
               } else {
                  al->xR[i] = -INFINITY;
               }
            }
            lpqppresolve_presolverappendimplicitslack(trfstack, i, j, aij, cj, prevabnd, a);
         // Remove variable from A and AT, set Cj to zero
            lpqppresolve_dyncrsremoverow(at, j);
            lpqppresolve_dyncrsremovefromrow(a, i, j);
            isdroppedcol->xB[j] = true;
         // Done
            *somethingchanged = true;
            ++*cntimplicitslacks;
            continue;
         }
      // Is it a free column singleton?
         if (!isfinite(bndl->xR[j]) && !isfinite(bndu->xR[j])) {
         // Handle single-sided linear constraints or two-sided one.
         //
         // A general inequality/range constraint is converted to an equality one by
         // adding temporary slack variable SLK. This variable is not actually added
         // to the problem - we analytically remove it right after the addition.
         //
         // See 3.2.2 from "A modular presolve procedure for large scale linear programming"
         // by Swietanowski for more information
            if (!isfinite(al->xR[i]) || !isfinite(au->xR[i])) {
            // Single-sided constraint
            //
            // Determine multiplier for the artificial temporary slack variable S.
            // Check for unboundedness. If bounded, the slack S is zero, right-hand
            // side of the equality constraint is not modified.
               aslk = isfinite(au->xR[i]) ? +1.0 : -1.0;
               if (aslk * c->xR[j] / aij > eps) {
                  *problemstatus = -2;
                  *somethingchanged = true;
                  result = false;
                  return result;
               }
               vslk = 0.0;
               if (!isfinite(au->xR[i])) {
                  au->xR[i] = al->xR[i];
               }
            } else {
            // Two-sided constraint
            //
            // Determine value of the temporary slack variable, modify right-hand side
            // of the constraint.
               vslk = c->xR[j] / aij > 0.0 ? au->xR[i] - al->xR[i] : 0.0;
            }
            cj = c->xR[j];
            v = cj / aij;
            for (ii = a->rowbegin.xZ[i]; ii < a->rowend.xZ[i]; ii++) {
               c->xR[a->idx.xZ[ii]] -= v * a->vals.xR[ii];
            }
            c->xR[j] = 0.0;
            lpqppresolve_presolverappendimplicitslack(trfstack, i, j, aij, cj, au->xR[i] - vslk, a);
            al->xR[i] = -INFINITY;
            au->xR[i] = +INFINITY;
            lpqppresolve_dyncrsremoverow(at, j);
            lpqppresolve_dyncrsremovefromrow(a, i, j);
            isdroppedcol->xB[j] = true;
            ++*cntfreecolumnsingletons;
            continue;
         }
      }
   }
   return result;
}

// This function scans box constraints list and tries  to  fix  variables  by
// removing them from the A and AT matrices and by  recording  transformation
// in trfStack.
//
// If infeasibility is detected, returns False.
//
// Inputs:
//     BndL, BndU  -   array[N], current set of box constraints. Only entries
//                     with IsDroppedCol[] == False are examined
//     IsDroppedCol-   array[N], column statuses; only non-dropped ones are examined.
//     N           -   variables count (including both fixed and non-fixed)
//     A, AT       -   current A and AT, dynamic CRS matrices
//     AL, AU      -   array[M], lower/upper bounds for linear constraints
//     M           -   linear constraints count
//     Eps         -   tolerance to resolve slightly infeasible constraints
//     DoTrace     -   whether tracing is needed or not
//     SomethingChanged-flag variable
//     CntFixed    -   debug counter, updated by the function
//
// Outputs:
//     IsDroppedCol-   array[N], fixed vars are marked
//     LagrangeFromResidual-
//                     array[N], fixed vars are marked
//     A           -   columns corresponding to fixed vars are removed from A.
//                     The matrix size does not change.
//     AT          -   rows corresponding to fixed vars are removed from A.
//                     The matrix size does not change.
//     AL, AU      -   updated with fixed values
//     SomethingChanged-is set to True if at least one variable was fixed.
//                     It is not changed otherwise.
//     CntFixed    -   debug counter, updated by the function
//
// Result:
//     if infeasibility is detected, returns False.
//     True otherwise.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static bool lpqppresolve_fixvariables(RVector *c, RVector *bndl, RVector *bndu, BVector *isdroppedcol, ae_int_t n, dynamiccrs *a, dynamiccrs *at, RVector *al, RVector *au, ae_int_t m, double eps, presolvebuffers *buf, presolverstack *trfstack, ae_int_t *problemstatus, bool *somethingchanged, ae_int_t *cntfixed) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t ii;
   ae_int_t jj;
   ae_int_t offs;
   double v;
   bool result;
   result = true;
// Scan variables, determine rows to update
   nisclear(&buf->setn);
   nisclear(&buf->setm);
   for (i = 0; i < n; i++) {
      if (!isdroppedcol->xB[i] && isfinite(bndl->xR[i]) && isfinite(bndu->xR[i]) && bndl->xR[i] >= bndu->xR[i] - eps) {
      // Detect infeasibility
         if (bndl->xR[i] > bndu->xR[i] + eps) {
            *somethingchanged = true;
            *problemstatus = -3;
            result = false;
            return result;
         }
      // Fix variable and issue transformation
         isdroppedcol->xB[i] = true;
         *somethingchanged = true;
         ++*cntfixed;
         lpqppresolve_presolverappendfixedvar(trfstack, i, rboundval(0.5 * (bndl->xR[i] + bndu->xR[i]), bndl->xR[i], bndu->xR[i]), c->xR[i], at);
      // Save dependent row indexes to SetM
         nisaddelement(&buf->setn, i);
         for (jj = at->rowbegin.xZ[i]; jj < at->rowend.xZ[i]; jj++) {
            nisaddelement(&buf->setm, at->idx.xZ[jj]);
         }
      }
   }
   if (!*somethingchanged) {
      return result;
   }
// Clear columns of AT corresponding to fixed variables
   for (jj = 0; jj < buf->setn.nstored; jj++) {
      i = buf->setn.items.xZ[jj];
      at->rowend.xZ[i] = at->rowend.xZ[i];
   }
// Scan marked rows of A and remove fixed variables
   for (ii = 0; ii < buf->setm.nstored; ii++) {
      i = buf->setm.items.xZ[ii];
      offs = a->rowbegin.xZ[i];
      v = 0.0;
      for (jj = a->rowbegin.xZ[i]; jj < a->rowend.xZ[i]; jj++) {
         j = a->idx.xZ[jj];
         if (buf->setn.locationof.xZ[j] >= 0) {
         // Update constraint bounds with fixed variables, remove from linear constraint
            v += bndl->xR[j] * a->vals.xR[jj];
         } else {
         // Non-fixed variable, retain it
            a->idx.xZ[offs] = j;
            a->vals.xR[offs] = a->vals.xR[jj];
            offs++;
         }
      }
      a->rowend.xZ[i] = offs;
      if (isfinite(al->xR[i])) {
         al->xR[i] -= v;
      }
      if (isfinite(au->xR[i])) {
         au->xR[i] -= v;
      }
   }
   return result;
}

// Scale cost vector and constraints, normalize cost.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
static void lpqppresolve_scalecostandconstraints(RVector *s, ae_int_t n, RVector *c, RVector *bndl, RVector *bndu, sparsematrix *sparsea, RVector *al, RVector *au, ae_int_t m, presolverstack *trfstack) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   double costscale;
   double avgln;
   double v;
   double rowscale;
// Apply scaling to cost, determine additional scaling due to normalization
   avgln = 0.0;
   for (i = 0; i < n; i++) {
      c->xR[i] *= s->xR[i];
      avgln += log(1.0 + fabs(c->xR[i]));
   }
   costscale = exp(avgln / n);
   rmulv(n, 1.0 / costscale, c);
   lpqppresolve_presolverappendcostscaling(trfstack, 1.0 / costscale);
// Apply column scaling to BndL/BndU, output backward transformation
   for (i = 0; i < n; i++) {
   // Transform problem
      lpqppresolve_presolverappendcolscaling(trfstack, i, 1.0 / s->xR[i]);
      bndl->xR[i] /= s->xR[i];
      bndu->xR[i] /= s->xR[i];
   }
   for (i = 0; i < m; i++) {
      rowscale = 0.0;
      j0 = sparsea->ridx.xZ[i];
      j1 = sparsea->ridx.xZ[i + 1] - 1;
      for (j = j0; j <= j1; j++) {
         v = s->xR[sparsea->idx.xZ[j]] * sparsea->vals.xR[j];
         sparsea->vals.xR[j] = v;
         rowscale = rmax2(rowscale, fabs(v));
      }
      rowscale = rmax2(rowscale, 1.0);
   // Apply transformation to A/AL/AU
      v = 1.0 / rowscale;
      for (j = j0; j <= j1; j++) {
         sparsea->vals.xR[j] *= v;
      }
      al->xR[i] *= v;
      au->xR[i] *= v;
      lpqppresolve_presolverappendrowscaling(trfstack, i, 1.0 / rowscale);
   }
}

// No presolve, just user-supplied scaling + constraint and cost vector
// normalization.
//
// Inputs:
//     S           -   array[N], user-supplied scale vector, S[I] > 0
//     C           -   array[N], costs
//     BndL        -   array[N], lower bounds (may contain -INF)
//     BndU        -   array[N], upper bounds (may contain +INF)
//     N           -   variable count, N > 0
//     SparseA     -   matrix[K,N], sparse constraints
//     AL          -   array[K], lower constraint bounds (may contain -INF)
//     AU          -   array[K], upper constraint bounds (may contain +INF)
//     K           -   constraint count, K >= 0
//     Info        -   presolve info structure; temporaries allocated during
//                     previous calls may be reused by this function.
//
// Outputs:
//     Info        -   contains transformed C, BndL, bndU,  SparseA,  AL,  AU
//                     and   information   necessary   to   perform  backward
//                     transformation.
//                     Following fields can be accessed:
//                     * ProblemStatus    which is:
//                                        *  0 for successful transformation
//                                        * -3 for infeasible problem
//                                        * -4 for unbounded problem
//
//                     If Info.ProblemStatus == 0, then the following fields can
//                     be accessed:
//                     * Info.NewN > 0  for transformed problem size
//                     * Info.NewM >= 0 for transformed constraint count
//                     * always:          Info.C, Info.BndL, Info.BndU - array[NewN]
//                     * for Info.NewM > 0: Info.SparseA, Info.AL, Info.AU
//
// NOTE: this routine does not reallocate arrays if NNew <= NOld and/or KNew <= KOld.
// ALGLIB: Copyright 01.07.2020 by Sergey Bochkanov
void presolvenonescaleuser(RVector *s, RVector *c, RVector *bndl, RVector *bndu, ae_int_t n, sparsematrix *sparsea, RVector *al, RVector *au, ae_int_t k, presolveinfo *info) {
   ae_int_t i;
// Integrity checks
   ae_assert(bndl->cnt >= n, "PresolveNoneScaleUser: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "PresolveNoneScaleUser: Length(BndU) < N");
   ae_assert(s->cnt >= n, "PresolveNoneScaleUser: Length(S) < N");
   ae_assert(isfinitevector(s, n), "PresolveNoneScaleUser: S contains infinite or NaN elements");
   ae_assert(c->cnt >= n, "PresolveNoneScaleUser: Length(C) < N");
   ae_assert(isfinitevector(c, n), "PresolveNoneScaleUser: C contains infinite or NaN elements");
   ae_assert(k >= 0, "PresolveNoneScaleUser: K < 0");
   ae_assert(k == 0 || sparseiscrs(sparsea), "PresolveNoneScaleUser: A is not CRS");
   ae_assert(k == 0 || sparsea->m == k, "PresolveNoneScaleUser: rows(A) != K");
   ae_assert(k == 0 || sparsea->n == n, "PresolveNoneScaleUser: cols(A) != N");
// Initial check for constraint feasibility
   for (i = 0; i < n; i++) {
      if (isfinite(bndl->xR[i]) && isfinite(bndu->xR[i]) && bndl->xR[i] > bndu->xR[i]) {
         info->problemstatus = -3;
         return;
      }
   }
   for (i = 0; i < k; i++) {
      if (isfinite(al->xR[i]) && isfinite(au->xR[i]) && al->xR[i] > au->xR[i]) {
         info->problemstatus = -3;
         return;
      }
   }
// Reallocate storage
   rvectorgrowto(&info->rawc, n);
   rvectorgrowto(&info->rawbndl, n);
   rvectorgrowto(&info->rawbndu, n);
// Save original problem formulation
   lpqppresolve_presolverstackinit(n, k, &info->trfstack);
   info->problemstatus = 0;
   info->newn = n;
   info->oldn = n;
   info->newm = k;
   info->oldm = k;
   bsetallocv(n, false, &info->lagrangefromresidual);
   allocv(n, &info->packxperm);
   allocv(n, &info->unpackxperm);
   for (i = 0; i < n; i++) {
      ae_assert(s->xR[i] > 0.0, "PresolveNoneScaleUser: S <= 0");
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "PresolveNoneScaleUser: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "PresolveNoneScaleUser: BndU contains NAN or -INF");
      info->rawc.xR[i] = c->xR[i];
      info->rawbndl.xR[i] = bndl->xR[i];
      info->rawbndu.xR[i] = bndu->xR[i];
      info->packxperm.xZ[i] = i;
      info->unpackxperm.xZ[i] = i;
   }
   allocv(k, &info->packyperm);
   allocv(k, &info->unpackyperm);
   for (i = 0; i < k; i++) {
      info->packyperm.xZ[i] = i;
      info->unpackyperm.xZ[i] = i;
   }
   allocv(n + k, &info->packstatperm);
   allocv(n + k, &info->unpackstatperm);
   for (i = 0; i < n + k; i++) {
      info->packstatperm.xZ[i] = i;
      info->unpackstatperm.xZ[i] = i;
   }
   sparsecopytocrsbuf(sparsea, &info->rawa);
// Scale cost and box constraints
   rcopyallocv(n, c, &info->c);
   rcopyallocv(n, bndl, &info->bndl);
   rcopyallocv(n, bndu, &info->bndu);
   if (k > 0) {
      rcopyallocv(k, al, &info->al);
      rcopyallocv(k, au, &info->au);
      sparsecopybuf(sparsea, &info->sparsea);
   }
   lpqppresolve_scalecostandconstraints(s, n, &info->c, &info->bndl, &info->bndu, &info->sparsea, &info->al, &info->au, k, &info->trfstack);
}

// Extensive presolving for an LP problem, all techniques are used
//
// Inputs:
//     S           -   array[N], user-supplied scale vector, S[I] > 0
//     C           -   array[N], costs
//     BndL        -   array[N], lower bounds (may contain -INF)
//     BndU        -   array[N], upper bounds (may contain +INF)
//     N           -   variable count, N > 0
//     SparseA     -   matrix[K,N], sparse constraints
//     AL          -   array[K], lower constraint bounds (may contain -INF)
//     AU          -   array[K], upper constraint bounds (may contain +INF)
//     K           -   constraint count, K >= 0
//     Info        -   presolve info structure; temporaries allocated during
//                     previous calls may be reused by this function.
//
// Outputs:
//     Info        -   contains transformed C, BndL, bndU,  SparseA,  AL,  AU
//                     and   information   necessary   to   perform  backward
//                     transformation.
//                     Following fields can be acessed:
//                     * Info.NewN > 0  for transformed problem size
//                     * Info.NewM >= 0 for transformed constraint count
//                     * always:          Info.C, Info.BndL, Info.BndU - array[NewN]
//                     * for Info.NewM > 0: Info.SparseA, Info.AL, Info.AU
//
// NOTE: this routine does not reallocate arrays if NNew <= NOld and/or KNew <= KOld.
// ALGLIB: Copyright 01.07.2022 by Sergey Bochkanov
void presolvelp(RVector *raws, RVector *rawc, RVector *rawbndl, RVector *rawbndu, ae_int_t n, sparsematrix *rawsparsea, RVector *rawal, RVector *rawau, ae_int_t m, presolveinfo *presolved) {
   bool somethingchanged;
   ae_int_t i;
   ae_int_t j;
   ae_int_t jj;
   ae_int_t j0;
   ae_int_t j1;
   ae_int_t offs;
   ae_int_t dbgemptycol;
   ae_int_t dbgemptyrow;
   ae_int_t dbgnonbindingrows;
   ae_int_t dbgfixed;
   ae_int_t dbgsingletonrow;
   ae_int_t dbgslackvars;
   ae_int_t dbgimplicitslacks;
   ae_int_t dbgfreecolumnsingletons;
   double eps;
   ae_int_t presolverounds;
   EnFrame();
   NewBVector(isdroppedcol, 0);
   NewBVector(isdroppedrow, 0);
   NewObj(sparsematrix, normsparsea);
   NewObj(sparsematrix, normsparseat);
   NewObj(dynamiccrs, a);
   NewObj(dynamiccrs, at);
   NewRVector(c, 0);
   NewRVector(bndl, 0);
   NewRVector(bndu, 0);
   NewRVector(al, 0);
   NewRVector(au, 0);
   ae_assert(m == 0 || sparseiscrs(rawsparsea), "PRESOLVER: A is non-CRS sparse matrix");
// Quick exit for M == 0
   if (m == 0) {
      presolvenonescaleuser(raws, rawc, rawbndl, rawbndu, n, rawsparsea, rawal, rawau, m, presolved);
      DeFrame();
   }
// Initial check for constraint feasibility
   for (i = 0; i < n; i++) {
      if (isfinite(rawbndl->xR[i]) && isfinite(rawbndu->xR[i]) && rawbndl->xR[i] > rawbndu->xR[i]) {
         presolved->problemstatus = -3;
         DeFrame();
      }
   }
   for (i = 0; i < m; i++) {
      if (isfinite(rawal->xR[i]) && isfinite(rawau->xR[i]) && rawal->xR[i] > rawau->xR[i]) {
         presolved->problemstatus = -3;
         DeFrame();
      }
   }
// Trace counters
   dbgemptycol = 0;
   dbgemptyrow = 0;
   dbgnonbindingrows = 0;
   dbgfixed = 0;
   dbgsingletonrow = 0;
   dbgslackvars = 0;
   dbgimplicitslacks = 0;
   dbgfreecolumnsingletons = 0;
// Initial state of the presolver
   eps = (1000 + n + m) * machineepsilon;
   lpqppresolve_presolverstackinit(n, m, &presolved->trfstack);
   presolved->problemstatus = 0;
   rcopyallocv(n, rawc, &c);
   rcopyallocv(n, rawbndl, &bndl);
   rcopyallocv(n, rawbndu, &bndu);
   sparsecopybuf(rawsparsea, &normsparsea);
   rcopyallocv(m, rawal, &al);
   rcopyallocv(m, rawau, &au);
   lpqppresolve_scalecostandconstraints(raws, n, &c, &bndl, &bndu, &normsparsea, &al, &au, m, &presolved->trfstack);
   sparsecopytransposecrsbuf(&normsparsea, &normsparseat);
   lpqppresolve_dyncrsinitfromsparsecrs(&normsparsea, &a);
   lpqppresolve_dyncrsinitfromsparsecrs(&normsparseat, &at);
   lpqppresolve_dyncrsdropzeros(&a);
   lpqppresolve_dyncrsdropzeros(&at);
   bsetallocv(n, false, &presolved->lagrangefromresidual);
   bsetallocv(n, false, &isdroppedcol);
   bsetallocv(m, false, &isdroppedrow);
   lpqppresolve_presolvebuffersinit(&presolved->buf, n, m);
// While something changes, keep iterating
   presolverounds = 0;
   somethingchanged = true;
   while (somethingchanged) {
      somethingchanged = false;
   // Try the very basic reductions:
   // * empty column
   // * empty row
   // * fixed variables removal
   // * singleton rows to box constraints
      if (!lpqppresolve_dropemptycol(&c, &bndl, &bndu, &isdroppedcol, &presolved->lagrangefromresidual, n, &a, &at, &al, &au, m, eps, &presolved->buf, &presolved->trfstack, &presolved->problemstatus, &somethingchanged, &dbgemptycol)) {
         DeFrame();
      }
      if (!lpqppresolve_dropclearlynonbindingrows(n, &isdroppedrow, &a, &at, &al, &au, m, eps, &presolved->buf, &presolved->trfstack, &presolved->problemstatus, &somethingchanged, &dbgemptyrow, &dbgnonbindingrows)) {
         DeFrame();
      }
      if (!lpqppresolve_singletonrowtobc(&bndl, &bndu, &isdroppedcol, n, &a, &at, &al, &au, &isdroppedrow, m, eps, &presolved->buf, &presolved->trfstack, &presolved->problemstatus, &somethingchanged, &dbgsingletonrow)) {
         DeFrame();
      }
      if (!lpqppresolve_fixvariables(&c, &bndl, &bndu, &isdroppedcol, n, &a, &at, &al, &au, m, eps, &presolved->buf, &presolved->trfstack, &presolved->problemstatus, &somethingchanged, &dbgfixed)) {
         DeFrame();
      }
      if (!lpqppresolve_singletoncols(&c, &bndl, &bndu, &isdroppedcol, n, &a, &at, &al, &au, &isdroppedrow, m, eps, &presolved->buf, &presolved->trfstack, &presolved->problemstatus, &somethingchanged, &dbgslackvars, &dbgimplicitslacks, &dbgfreecolumnsingletons)) {
         DeFrame();
      }
      presolverounds++;
   }
// Starting output
   rcopyallocv(n, rawc, &presolved->rawc);
   rcopyallocv(n, rawbndl, &presolved->rawbndl);
   rcopyallocv(n, rawbndu, &presolved->rawbndu);
   sparsecopytocrsbuf(rawsparsea, &presolved->rawa);
// Output data that are permuted by XPerm[]
   presolved->oldn = n;
   presolved->newn = 0;
   isetallocv(n, -1, &presolved->packxperm);
   isetallocv(n, -1, &presolved->unpackxperm);
   for (i = 0; i < n; i++) {
      if (!isdroppedcol.xB[i]) {
         presolved->unpackxperm.xZ[presolved->newn] = i;
         presolved->packxperm.xZ[i] = presolved->newn;
         presolved->newn++;
      }
   }
   allocv(presolved->newn, &presolved->bndl);
   allocv(presolved->newn, &presolved->bndu);
   allocv(presolved->newn, &presolved->c);
   for (i = 0; i < presolved->newn; i++) {
      presolved->c.xR[i] = c.xR[presolved->unpackxperm.xZ[i]];
      presolved->bndl.xR[i] = bndl.xR[presolved->unpackxperm.xZ[i]];
      presolved->bndu.xR[i] = bndu.xR[presolved->unpackxperm.xZ[i]];
   }
// Output data that are permuted by YPerm[]
   presolved->oldm = m;
   presolved->newm = 0;
   isetallocv(m, -1, &presolved->packyperm);
   isetallocv(m, -1, &presolved->unpackyperm);
   for (i = 0; i < m; i++) {
      if (!isdroppedrow.xB[i]) {
         presolved->unpackyperm.xZ[presolved->newm] = i;
         presolved->packyperm.xZ[i] = presolved->newm;
         presolved->newm++;
      }
   }
   allocv(presolved->newm, &presolved->al);
   allocv(presolved->newm, &presolved->au);
   for (i = 0; i < presolved->newm; i++) {
      presolved->al.xR[i] = al.xR[presolved->unpackyperm.xZ[i]];
      presolved->au.xR[i] = au.xR[presolved->unpackyperm.xZ[i]];
   }
// Output A which is permuted by both XPerm[] and YPerm[]
   presolved->sparsea.m = 0;
   presolved->sparsea.n = presolved->newn;
   allocv(presolved->newm + 1, &presolved->sparsea.ridx);
   presolved->sparsea.ridx.xZ[0] = 0;
   for (i = 0; i < m; i++) {
      if (!isdroppedrow.xB[i]) {
         offs = presolved->sparsea.ridx.xZ[presolved->sparsea.m];
         igrowv(offs + n, &presolved->sparsea.idx);
         rgrowv(offs + n, &presolved->sparsea.vals);
         j0 = a.rowbegin.xZ[i];
         j1 = a.rowend.xZ[i] - 1;
         for (jj = j0; jj <= j1; jj++) {
            j = presolved->packxperm.xZ[a.idx.xZ[jj]];
            ae_assert(j >= 0, "PRESOLVE: integrity check 54fc failed");
            presolved->sparsea.idx.xZ[offs] = j;
            presolved->sparsea.vals.xR[offs] = a.vals.xR[jj];
            offs++;
         }
         presolved->sparsea.m++;
         presolved->sparsea.ridx.xZ[presolved->sparsea.m] = offs;
      }
   }
   ae_assert(presolved->sparsea.m == presolved->newm, "PRESOLVE: integrity check ee3a failed");
   sparsecreatecrsinplace(&presolved->sparsea);
// Prepare permutation for constraint Stats[]
   isetallocv(n + m, -1, &presolved->packstatperm);
   isetallocv(n + m, -1, &presolved->unpackstatperm);
   offs = 0;
   for (i = 0; i < n; i++) {
      if (!isdroppedcol.xB[i]) {
         presolved->packstatperm.xZ[i] = offs;
         offs++;
      }
   }
   for (i = 0; i < m; i++) {
      if (!isdroppedrow.xB[i]) {
         presolved->packstatperm.xZ[n + i] = offs;
         offs++;
      }
   }
   ae_assert(offs == presolved->newn + presolved->newm, "PRESOLVE: integrity check 3632 failed");
   for (i = 0; i < n + m; i++) {
      if (presolved->packstatperm.xZ[i] >= 0) {
         presolved->unpackstatperm.xZ[presolved->packstatperm.xZ[i]] = i;
      }
   }
   DeFrame();
}

// Backward transformation which extracts original solution from that of  the
// converted problem.
//
// Below NNew/KNew correspond to transformed problem size (as returned by the
// presolve routine) and NOld/KOld correspond to original  problem  size  (as
// specified by caller). We expect that caller knows  these  sizes,  so  this
// routine does not report them.
//
// Inputs:
//     Info        -   presolve info structure
//     X           -   array[NNew], transformed solution (primal variables)
//     Stats       -   array[NNew+MNew], transformed constraint status (negative -
//                     at lower bound, positive -  at  upper  bound,  zero  -
//                     inactive).
//     LagBC       -   array[NNew], transformed Lagrange multipliers
//     LagLC       -   array[KNew], transformed Lagrange multipliers
//
// Outputs:
//     X           -   array[NOld], original solution (primal variables)
//     Stats       -   array[NOld+MOld], original constraint status
//     LagBC       -   array[NOld], Lagrange multipliers
//     LagLC       -   array[KOld], Lagrange multipliers
//
// NOTE: this routine does not reallocate arrays if NOld <= NNew and/or KOld <= KNew.
// ALGLIB: Copyright 01.07.2020 by Sergey Bochkanov
void presolvebwd(presolveinfo *info, RVector *x, ZVector *stats, RVector *lagbc, RVector *laglc) {
   ae_int_t i;
// Read state of the transformed problem into storage allocated for the original problem
   isetallocv(info->oldn + info->oldm, 0, &info->s1);
   for (i = 0; i < info->newn + info->newm; i++) {
      info->s1.xZ[info->unpackstatperm.xZ[i]] = stats->xZ[i];
   }
   rsetallocv(info->oldn, 0.0, &info->x1);
   for (i = 0; i < info->newn; i++) {
      info->x1.xR[info->unpackxperm.xZ[i]] = x->xR[i];
   }
   rsetallocv(info->oldn, 0.0, &info->bc1);
   for (i = 0; i < info->newn; i++) {
      info->bc1.xR[info->unpackxperm.xZ[i]] = lagbc->xR[i];
   }
   rsetallocv(info->oldm, 0.0, &info->y1);
   for (i = 0; i < info->newm; i++) {
      info->y1.xR[info->unpackyperm.xZ[i]] = laglc->xR[i];
   }
// Apply reverse transformation
   lpqppresolve_presolverrestoresolution(&info->trfstack, &info->x1, &info->bc1, &info->y1, &info->s1);
// Polish X according to box constraints and info from newly recovered Stats[]
// Recompute coefficients corresponding to variables fixed during presolve using residual costs.
   for (i = 0; i < info->oldn; i++) {
      if (isfinite(info->rawbndl.xR[i])) {
         info->x1.xR[i] = rmax2(info->x1.xR[i], info->rawbndl.xR[i]);
      }
      if (isfinite(info->rawbndu.xR[i])) {
         info->x1.xR[i] = rmin2(info->x1.xR[i], info->rawbndu.xR[i]);
      }
      if (info->s1.xZ[i] < 0) {
         info->x1.xR[i] = info->rawbndl.xR[i];
      }
      if (info->s1.xZ[i] > 0) {
         info->x1.xR[i] = info->rawbndu.xR[i];
      }
   }
   rcopyallocv(info->oldn, &info->rawc, &info->d);
   if (info->oldm > 0) {
      sparsegemv(&info->rawa, 1.0, 1, &info->y1, 0, 1.0, &info->d, 0);
   }
   for (i = 0; i < info->oldn; i++) {
      if (info->lagrangefromresidual.xB[i]) {
         info->bc1.xR[i] = -info->d.xR[i];
      }
   }
// Output
   rcopyallocv(info->oldn, &info->x1, x);
   rcopyallocv(info->oldm, &info->y1, laglc);
   icopyallocv(info->oldn + info->oldm, &info->s1, stats);
   rcopyallocv(info->oldn, &info->bc1, lagbc);
}

void dynamiccrs_init(void *_p, bool make_automatic) {
   dynamiccrs *p = (dynamiccrs *)_p;
   ae_vector_init(&p->rowbegin, 0, DT_INT, make_automatic);
   ae_vector_init(&p->rowend, 0, DT_INT, make_automatic);
   ae_vector_init(&p->idx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->vals, 0, DT_REAL, make_automatic);
}

void dynamiccrs_copy(void *_dst, const void *_src, bool make_automatic) {
   dynamiccrs *dst = (dynamiccrs *)_dst;
   const dynamiccrs *src = (const dynamiccrs *)_src;
   dst->m = src->m;
   dst->n = src->n;
   ae_vector_copy(&dst->rowbegin, &src->rowbegin, make_automatic);
   ae_vector_copy(&dst->rowend, &src->rowend, make_automatic);
   ae_vector_copy(&dst->idx, &src->idx, make_automatic);
   ae_vector_copy(&dst->vals, &src->vals, make_automatic);
}

void dynamiccrs_free(void *_p, bool make_automatic) {
   dynamiccrs *p = (dynamiccrs *)_p;
   ae_vector_free(&p->rowbegin, make_automatic);
   ae_vector_free(&p->rowend, make_automatic);
   ae_vector_free(&p->idx, make_automatic);
   ae_vector_free(&p->vals, make_automatic);
}

void presolvebuffers_init(void *_p, bool make_automatic) {
   presolvebuffers *p = (presolvebuffers *)_p;
   niset_init(&p->setn, make_automatic);
   niset_init(&p->setm, make_automatic);
}

void presolvebuffers_copy(void *_dst, const void *_src, bool make_automatic) {
   presolvebuffers *dst = (presolvebuffers *)_dst;
   const presolvebuffers *src = (const presolvebuffers *)_src;
   niset_copy(&dst->setn, &src->setn, make_automatic);
   niset_copy(&dst->setm, &src->setm, make_automatic);
}

void presolvebuffers_free(void *_p, bool make_automatic) {
   presolvebuffers *p = (presolvebuffers *)_p;
   niset_free(&p->setn, make_automatic);
   niset_free(&p->setm, make_automatic);
}

void presolverstack_init(void *_p, bool make_automatic) {
   presolverstack *p = (presolverstack *)_p;
   ae_vector_init(&p->trftype, 0, DT_INT, make_automatic);
   ae_vector_init(&p->idata, 0, DT_INT, make_automatic);
   ae_vector_init(&p->rdata, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->idataridx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->rdataridx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->sparseidx0, 0, DT_INT, make_automatic);
   ae_vector_init(&p->sparseval0, 0, DT_REAL, make_automatic);
}

void presolverstack_copy(void *_dst, const void *_src, bool make_automatic) {
   presolverstack *dst = (presolverstack *)_dst;
   const presolverstack *src = (const presolverstack *)_src;
   dst->n = src->n;
   dst->m = src->m;
   dst->ntrf = src->ntrf;
   ae_vector_copy(&dst->trftype, &src->trftype, make_automatic);
   ae_vector_copy(&dst->idata, &src->idata, make_automatic);
   ae_vector_copy(&dst->rdata, &src->rdata, make_automatic);
   ae_vector_copy(&dst->idataridx, &src->idataridx, make_automatic);
   ae_vector_copy(&dst->rdataridx, &src->rdataridx, make_automatic);
   dst->sourceidx = src->sourceidx;
   dst->isrc = src->isrc;
   dst->rsrc = src->rsrc;
   ae_vector_copy(&dst->sparseidx0, &src->sparseidx0, make_automatic);
   ae_vector_copy(&dst->sparseval0, &src->sparseval0, make_automatic);
}

void presolverstack_free(void *_p, bool make_automatic) {
   presolverstack *p = (presolverstack *)_p;
   ae_vector_free(&p->trftype, make_automatic);
   ae_vector_free(&p->idata, make_automatic);
   ae_vector_free(&p->rdata, make_automatic);
   ae_vector_free(&p->idataridx, make_automatic);
   ae_vector_free(&p->rdataridx, make_automatic);
   ae_vector_free(&p->sparseidx0, make_automatic);
   ae_vector_free(&p->sparseval0, make_automatic);
}

void presolveinfo_init(void *_p, bool make_automatic) {
   presolveinfo *p = (presolveinfo *)_p;
   ae_vector_init(&p->rawc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawbndu, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->rawa, make_automatic);
   ae_vector_init(&p->lagrangefromresidual, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->c, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsea, make_automatic);
   ae_vector_init(&p->al, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->au, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->packxperm, 0, DT_INT, make_automatic);
   ae_vector_init(&p->packyperm, 0, DT_INT, make_automatic);
   ae_vector_init(&p->packstatperm, 0, DT_INT, make_automatic);
   ae_vector_init(&p->unpackxperm, 0, DT_INT, make_automatic);
   ae_vector_init(&p->unpackyperm, 0, DT_INT, make_automatic);
   ae_vector_init(&p->unpackstatperm, 0, DT_INT, make_automatic);
   presolverstack_init(&p->trfstack, make_automatic);
   ae_vector_init(&p->s1, 0, DT_INT, make_automatic);
   ae_vector_init(&p->bc1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->y1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   presolvebuffers_init(&p->buf, make_automatic);
}

void presolveinfo_copy(void *_dst, const void *_src, bool make_automatic) {
   presolveinfo *dst = (presolveinfo *)_dst;
   const presolveinfo *src = (const presolveinfo *)_src;
   dst->newn = src->newn;
   dst->oldn = src->oldn;
   dst->newm = src->newm;
   dst->oldm = src->oldm;
   ae_vector_copy(&dst->rawc, &src->rawc, make_automatic);
   ae_vector_copy(&dst->rawbndl, &src->rawbndl, make_automatic);
   ae_vector_copy(&dst->rawbndu, &src->rawbndu, make_automatic);
   sparsematrix_copy(&dst->rawa, &src->rawa, make_automatic);
   dst->problemstatus = src->problemstatus;
   ae_vector_copy(&dst->lagrangefromresidual, &src->lagrangefromresidual, make_automatic);
   ae_vector_copy(&dst->c, &src->c, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   sparsematrix_copy(&dst->sparsea, &src->sparsea, make_automatic);
   ae_vector_copy(&dst->al, &src->al, make_automatic);
   ae_vector_copy(&dst->au, &src->au, make_automatic);
   ae_vector_copy(&dst->packxperm, &src->packxperm, make_automatic);
   ae_vector_copy(&dst->packyperm, &src->packyperm, make_automatic);
   ae_vector_copy(&dst->packstatperm, &src->packstatperm, make_automatic);
   ae_vector_copy(&dst->unpackxperm, &src->unpackxperm, make_automatic);
   ae_vector_copy(&dst->unpackyperm, &src->unpackyperm, make_automatic);
   ae_vector_copy(&dst->unpackstatperm, &src->unpackstatperm, make_automatic);
   presolverstack_copy(&dst->trfstack, &src->trfstack, make_automatic);
   ae_vector_copy(&dst->s1, &src->s1, make_automatic);
   ae_vector_copy(&dst->bc1, &src->bc1, make_automatic);
   ae_vector_copy(&dst->x1, &src->x1, make_automatic);
   ae_vector_copy(&dst->y1, &src->y1, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   presolvebuffers_copy(&dst->buf, &src->buf, make_automatic);
}

void presolveinfo_free(void *_p, bool make_automatic) {
   presolveinfo *p = (presolveinfo *)_p;
   ae_vector_free(&p->rawc, make_automatic);
   ae_vector_free(&p->rawbndl, make_automatic);
   ae_vector_free(&p->rawbndu, make_automatic);
   sparsematrix_free(&p->rawa, make_automatic);
   ae_vector_free(&p->lagrangefromresidual, make_automatic);
   ae_vector_free(&p->c, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   sparsematrix_free(&p->sparsea, make_automatic);
   ae_vector_free(&p->al, make_automatic);
   ae_vector_free(&p->au, make_automatic);
   ae_vector_free(&p->packxperm, make_automatic);
   ae_vector_free(&p->packyperm, make_automatic);
   ae_vector_free(&p->packstatperm, make_automatic);
   ae_vector_free(&p->unpackxperm, make_automatic);
   ae_vector_free(&p->unpackyperm, make_automatic);
   ae_vector_free(&p->unpackstatperm, make_automatic);
   presolverstack_free(&p->trfstack, make_automatic);
   ae_vector_free(&p->s1, make_automatic);
   ae_vector_free(&p->bc1, make_automatic);
   ae_vector_free(&p->x1, make_automatic);
   ae_vector_free(&p->y1, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   presolvebuffers_free(&p->buf, make_automatic);
}
} // end of namespace alglib_impl

// === REVISEDDUALSIMPLEX Package ===
// Depends on: (LinAlg) TRFAC
// Depends on: LPQPPRESOLVE
namespace alglib_impl {
static const double reviseddualsimplex_maxudecay = 0.001;
static const double reviseddualsimplex_shiftlen = 1.0E-12;
static const ae_int_t reviseddualsimplex_ssinvalid = 0;
static const ae_int_t reviseddualsimplex_ssvalidxn = 1;
static const ae_int_t reviseddualsimplex_ssvalid = 2;
static const ae_int_t reviseddualsimplex_ccfixed = 0;
static const ae_int_t reviseddualsimplex_cclower = 1;
static const ae_int_t reviseddualsimplex_ccupper = 2;
static const ae_int_t reviseddualsimplex_ccrange = 3;
static const ae_int_t reviseddualsimplex_ccfree = 4;
static const ae_int_t reviseddualsimplex_ccinfeasible = 5;

// This function initializes subproblem structure. Previously allocated memory
// is reused as much as possible.
//
// Default state of the problem is zero cost vector, all variables are  fixed
// at zero, linear constraint matrix is zero.
// ALGLIB: Copyright 01.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_subprobleminit(ae_int_t n, dualsimplexsubproblem *s) {
   ae_int_t i;
   ae_assert(n > 0, "SubproblemInit: N <= 0");
   s->ns = n;
   s->m = 0;
   s->state = reviseddualsimplex_ssinvalid;
   vectorsetlengthatleast(&s->xa, n);
   vectorsetlengthatleast(&s->xb, 0);
   vectorsetlengthatleast(&s->d, n);
   vectorsetlengthatleast(&s->rawc, n);
   vectorsetlengthatleast(&s->effc, n);
   vectorsetlengthatleast(&s->bndl, n);
   vectorsetlengthatleast(&s->bndu, n);
   vectorsetlengthatleast(&s->bndt, n);
   for (i = 0; i < n; i++) {
      s->rawc.xR[i] = 0.0;
      s->effc.xR[i] = 0.0;
      s->bndl.xR[i] = 0.0;
      s->bndu.xR[i] = 0.0;
      s->bndt.xZ[i] = reviseddualsimplex_ccfixed;
      s->xa.xR[i] = 0.0;
      s->d.xR[i] = 0.0;
   }
}

// This function initializes phase #1 subproblem which minimizes sum of  dual
// infeasibilities.  It is required that total count of  non-boxed  non-fixed
// variables is at least M.
//
// It splits out basic components of XA[] to XB[]
// ALGLIB: Copyright 01.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_subprobleminitphase1(dualsimplexsubproblem *s0, dualsimplexbasis *basis, dualsimplexsubproblem *s1) {
   ae_int_t i;
   s1->ns = s0->ns;
   s1->m = s0->m;
   copyrealarray(&s0->rawc, &s1->rawc);
   copyrealarray(&s0->effc, &s1->effc);
   copyrealarray(&s0->bndl, &s1->bndl);
   copyrealarray(&s0->bndu, &s1->bndu);
   copyintegerarray(&s0->bndt, &s1->bndt);
   copyrealarray(&s0->xa, &s1->xa);
   copyrealarray(&s0->xb, &s1->xb);
   copyrealarray(&s0->bndlb, &s1->bndlb);
   copyrealarray(&s0->bndub, &s1->bndub);
   copyintegerarray(&s0->bndtb, &s1->bndtb);
   copyrealarray(&s0->bndtollb, &s1->bndtollb);
   copyrealarray(&s0->bndtolub, &s1->bndtolub);
   copyrealarray(&s0->d, &s1->d);
   for (i = 0; i < s1->ns + s1->m; i++) {
      if (s1->bndt.xZ[i] == reviseddualsimplex_cclower) {
         s1->bndt.xZ[i] = reviseddualsimplex_ccrange;
         s1->bndl.xR[i] = 0.0;
         s1->bndu.xR[i] = 1.0;
         s1->xa.xR[i] = 0.0;
         continue;
      }
      if (s1->bndt.xZ[i] == reviseddualsimplex_ccupper) {
         s1->bndt.xZ[i] = reviseddualsimplex_ccrange;
         s1->bndl.xR[i] = -1.0;
         s1->bndu.xR[i] = 0.0;
         s1->xa.xR[i] = 0.0;
         continue;
      }
      if (s1->bndt.xZ[i] == reviseddualsimplex_ccfree) {
         s1->bndt.xZ[i] = reviseddualsimplex_ccrange;
         s1->bndl.xR[i] = -1.0;
         s1->bndu.xR[i] = 1.0;
         if (s1->effc.xR[i] >= 0.0) {
            s1->xa.xR[i] = -1.0;
         } else {
            s1->xa.xR[i] = 1.0;
         }
         continue;
      }
      s1->bndt.xZ[i] = reviseddualsimplex_ccfixed;
      s1->bndl.xR[i] = 0.0;
      s1->bndu.xR[i] = 0.0;
      s1->xa.xR[i] = 0.0;
   }
   s1->state = reviseddualsimplex_ssvalidxn;
}

// This function initializes phase #3 subproblem which applies primal simplex
// method to the result of the phase #2.
//
// It also performs modification of the subproblem in order to ensure that
// initial point is primal feasible.
//
// NOTE: this function expects that all components (basic and nonbasic ones)
//       are stored in XA[]
// ALGLIB: Copyright 01.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_subprobleminitphase3(dualsimplexsubproblem *s0, dualsimplexsubproblem *s1) {
   s1->ns = s0->ns;
   s1->m = s0->m;
   copyrealarray(&s0->rawc, &s1->rawc);
   copyrealarray(&s0->effc, &s1->effc);
   copyrealarray(&s0->bndl, &s1->bndl);
   copyrealarray(&s0->bndu, &s1->bndu);
   copyintegerarray(&s0->bndt, &s1->bndt);
   copyrealarray(&s0->xa, &s1->xa);
   copyrealarray(&s0->xb, &s1->xb);
   copyrealarray(&s0->bndlb, &s1->bndlb);
   copyrealarray(&s0->bndub, &s1->bndub);
   copyintegerarray(&s0->bndtb, &s1->bndtb);
   copyrealarray(&s0->bndtollb, &s1->bndtollb);
   copyrealarray(&s0->bndtolub, &s1->bndtolub);
   copyrealarray(&s0->d, &s1->d);
   s1->state = reviseddualsimplex_ssvalidxn;
}

// This function infers nonbasic variables of X using sign of effective C[].
//
// Only non-basic components of XN are changed; everything else is NOT updated.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_subprobleminferinitialxn(dualsimplexstate *state, dualsimplexsubproblem *s) {
   ae_int_t i;
   ae_int_t ii;
   ae_int_t bndt;
   for (ii = 0; ii < s->ns; ii++) {
      i = state->basis.nidx.xZ[ii];
      bndt = s->bndt.xZ[i];
      if (bndt == reviseddualsimplex_ccfixed || bndt == reviseddualsimplex_ccrange) {
         if (s->effc.xR[i] >= 0.0) {
            s->xa.xR[i] = s->bndl.xR[i];
         } else {
            s->xa.xR[i] = s->bndu.xR[i];
         }
         continue;
      }
      if (bndt == reviseddualsimplex_cclower) {
         s->xa.xR[i] = s->bndl.xR[i];
         continue;
      }
      if (bndt == reviseddualsimplex_ccupper) {
         s->xa.xR[i] = s->bndu.xR[i];
         continue;
      }
      if (bndt == reviseddualsimplex_ccfree) {
         s->xa.xR[i] = 0.0;
         continue;
      }
      ae_assert(false, "SubproblemInferInitialXN: integrity check failed (infeasible constraint)");
   }
   s->state = reviseddualsimplex_ssvalidxn;
}

// This function computes solution to B*x == r. It  also   additionally  outputs
// intermediate  result  of multiplication by inv(DS)*inv(U)*inv(colPerm),  a
// value essential for Forest-Tomlin update.
//
// Output arrays are reallocated if needed. Temporary  array  TX[]   can   be
// used/reallocated.
//
// If NeedIntermediate is False or Forest-Tomlin updates are not used,
// then Xim[] is not referenced at all.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basissolvex(dualsimplexbasis *s, RVector *r, RVector *x, RVector *xim, bool needintermediate, RVector *tx) {
   ae_int_t m;
   ae_int_t i;
   ae_int_t d;
   ae_int_t k;
   double v;
   double vd;
   double vv;
   bool processed;
   ae_assert(s->isvalidtrf, "BasisSolve: integrity check failed");
   m = s->m;
   processed = false;
   vectorsetlengthatleast(tx, m);
// Dense/sparse factorizations with dense PFI
//
// NOTE: although we solve B*x == r, internally we store factorization of B^T
   if (s->trftype == 0 || s->trftype == 1 || s->trftype == 2) {
      ae_assert(s->trfage == 0 || s->trftype != 0, "BasisSolve: integrity check failed TrfAge vs TrfType");
      vectorsetlengthatleast(x, m);
      for (i = 0; i < m; i++) {
         x->xR[i] = r->xR[s->colpermbwd.xZ[i]];
      }
      if (s->trftype == 0 || s->trftype == 1) {
      // Dense TRF
         rmatrixtrsv(m, &s->denselu, 0, 0, true, false, 1, x, 0);
         rmatrixtrsv(m, &s->denselu, 0, 0, false, true, 1, x, 0);
      } else {
      // Sparse TRF
         sparsetrsv(&s->sparseu, true, false, 1, x);
         sparsetrsv(&s->sparsel, false, false, 1, x);
      }
      for (i = 0; i < m; i++) {
         tx->xR[s->rowpermbwd.xZ[i]] = x->xR[i];
      }
      for (i = 0; i < m; i++) {
         x->xR[i] = tx->xR[i];
      }
      for (k = 0; k < s->trfage; k++) {
         v = x->xR[s->rk.xZ[k]];
         for (i = 0; i < m; i++) {
            x->xR[i] += s->densepfieta.xR[k * m + i] * v;
         }
         x->xR[s->rk.xZ[k]] -= v;
      }
      processed = true;
   }
// Sparse factorization with Forest-Tomlin update
//
// NOTE: although we solve B*x == r, internally we store factorization of B^T
   if (s->trftype == 3) {
      vectorsetlengthatleast(x, m);
      for (i = 0; i < m; i++) {
         x->xR[i] = r->xR[s->colpermbwd.xZ[i]];
      }
      sparsetrsv(&s->sparseu, true, false, 1, x);
      for (k = 0; k < s->trfage; k++) {
      // The code below is an amalgamation of two parts:
      //
      // cyclic permutation
      // V = X[D];
      // for I = D to M-2 do
      //     X[I] = X[I+1];
      // X[M-1] = V;
      //
      // and triangular factor
      // V = 0;
      // for I = D to M-1 do
      //     V = V+X[I]*S.DenseMu[K*M+I];
      // X[M-1] = V;
         d = s->dk.xZ[k];
         vv = 0.0;
         vd = x->xR[d];
         for (i = d; i < m - 1; i++) {
            v = x->xR[i + 1];
            x->xR[i] = v;
            vv += v * s->densemu.xR[k * m + i];
         }
         x->xR[m - 1] = vv + vd * s->densemu.xR[k * m + m - 1];
      }
      if (needintermediate) {
         vectorsetlengthatleast(xim, m);
         for (i = 0; i < m; i++) {
            xim->xR[i] = x->xR[i];
         }
      }
      sparsetrsv(&s->sparsel, false, false, 1, x);
      for (i = 0; i < m; i++) {
         tx->xR[s->rowpermbwd.xZ[i]] = x->xR[i];
      }
      for (i = 0; i < m; i++) {
         x->xR[i] = tx->xR[i];
      }
      processed = true;
   }
// Integrity check
   ae_assert(processed, "BasisSolve: unsupported TRF type");
   v = 0.0;
   for (i = 0; i < m; i++) {
      v += x->xR[i];
   }
   ae_assert(isfinite(v), "BasisSolve: integrity check failed (degeneracy in B?)");
}

// This function computes solution to B*x == r.
//
// Output array is reallocated if needed. Temporary array TmpX[] is used  and
// reallocated if necessary.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basissolve(dualsimplexbasis *s, RVector *r, RVector *x, RVector *tmpx) {
   reviseddualsimplex_basissolvex(s, r, x, x, false, tmpx);
}

// This function computes solution to (B^T)*x == r.
//
// Output array is reallocated if needed. TX[] temporary is reallocated if
// needed
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basissolvet(dualsimplexbasis *s, RVector *r, RVector *x, RVector *tx) {
   ae_int_t m;
   ae_int_t i;
   ae_int_t d;
   ae_int_t k;
   double v;
   double vm;
   bool processed;
   ae_assert(s->isvalidtrf, "BasisSolveT: integrity check failed");
   m = s->m;
   processed = false;
   vectorsetlengthatleast(tx, m);
// Dense factorizations
   if (s->trftype == 0 || s->trftype == 1 || s->trftype == 2) {
      ae_assert(s->trfage == 0 || s->trftype != 0, "BasisSolveT: integrity check failed TrfAge vs TrfType");
      vectorsetlengthatleast(x, m);
      for (i = 0; i < m; i++) {
         x->xR[i] = r->xR[i];
      }
      for (k = s->trfage - 1; k >= 0; k--) {
         v = 0.0;
         for (i = 0; i < m; i++) {
            v += s->densepfieta.xR[k * m + i] * x->xR[i];
         }
         x->xR[s->rk.xZ[k]] = v;
      }
      for (i = 0; i < m; i++) {
         tx->xR[i] = x->xR[s->rowpermbwd.xZ[i]];
      }
      for (i = 0; i < m; i++) {
         x->xR[i] = tx->xR[i];
      }
      if (s->trftype == 0 || s->trftype == 1) {
      // Dense TRF
         rmatrixtrsv(m, &s->denselu, 0, 0, false, true, 0, x, 0);
         rmatrixtrsv(m, &s->denselu, 0, 0, true, false, 0, x, 0);
      } else {
      // Sparse TRF
         sparsetrsv(&s->sparsel, false, false, 0, x);
         sparsetrsv(&s->sparseu, true, false, 0, x);
      }
      for (i = 0; i < m; i++) {
         tx->xR[s->colpermbwd.xZ[i]] = x->xR[i];
      }
      for (i = 0; i < m; i++) {
         x->xR[i] = tx->xR[i];
      }
      processed = true;
   }
// Sparse factorization with Forest-Tomlin update
   if (s->trftype == 3) {
      vectorsetlengthatleast(x, m);
      for (i = 0; i < m; i++) {
         x->xR[i] = r->xR[i];
      }
      for (i = 0; i < m; i++) {
         tx->xR[i] = x->xR[s->rowpermbwd.xZ[i]];
      }
      for (i = 0; i < m; i++) {
         x->xR[i] = tx->xR[i];
      }
      sparsetrsv(&s->sparsel, false, false, 0, x);
      for (k = s->trfage - 1; k >= 0; k--) {
      // The code below is an amalgamation of two parts:
      //
      // triangular factor
      // V = X[M-1];
      // for I = D to M-2 do
      //     X[I] = X[I]+S.DenseMu[K*M+I]*V;
      // X[M-1] = S.DenseMu[K*M+(M-1)]*V;
      //
      // inverse of cyclic permutation
      // V = X[M-1];
      // for I = M-1 downto D+1 do
      //     X[I] = X[I-1];
      // X[D] = V;
         d = s->dk.xZ[k];
         vm = x->xR[m - 1];
         v = s->densemu.xR[k * m + (m - 1)] * vm;
         if (vm != 0.0) {
         // X[M-1] is non-zero, apply update
            for (i = m - 2; i >= d; i--) {
               x->xR[i + 1] = x->xR[i] + s->densemu.xR[k * m + i] * vm;
            }
         } else {
         // X[M-1] is zero, just cyclic permutation
            for (i = m - 2; i >= d; i--) {
               x->xR[i + 1] = x->xR[i];
            }
         }
         x->xR[d] = v;
      }
      sparsetrsv(&s->sparseut, false, false, 1, x);
      for (i = 0; i < m; i++) {
         tx->xR[s->colpermbwd.xZ[i]] = x->xR[i];
      }
      for (i = 0; i < m; i++) {
         x->xR[i] = tx->xR[i];
      }
      processed = true;
   }
// Integrity check
   ae_assert(processed, "BasisSolveT: unsupported TRF type");
   v = 0.0;
   for (i = 0; i < m; i++) {
      v += x->xR[i];
   }
   ae_assert(isfinite(v), "BasisSolveT: integrity check failed (degeneracy in B?)");
}

// This function computes product AN*XN, where AN is a  non-basic  subset  of
// columns of A, and XN is a non-basic subset of columns of X.
//
// Output array is reallocated if its size is too small.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_computeanxn(dualsimplexstate *state, dualsimplexsubproblem *subproblem, RVector *x, RVector *y) {
   ae_int_t nn;
   ae_int_t nx;
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t j0;
   ae_int_t j1;
   double v;
   nx = subproblem->ns + subproblem->m;
   m = subproblem->m;
   nn = nx - m;
// Integrity check
   ae_assert(subproblem->state >= reviseddualsimplex_ssvalidxn, "ComputeANXN: XN is invalid");
// Compute
   vectorsetlengthatleast(y, m);
   for (i = 0; i < m; i++) {
      y->xR[i] = 0.0;
   }
   for (i = 0; i < nn; i++) {
      j0 = state->at.ridx.xZ[state->basis.nidx.xZ[i]];
      j1 = state->at.ridx.xZ[state->basis.nidx.xZ[i] + 1] - 1;
      v = x->xR[state->basis.nidx.xZ[i]];
      for (j = j0; j <= j1; j++) {
         k = state->at.idx.xZ[j];
         y->xR[k] += v * state->at.vals.xR[j];
      }
   }
}

// This function computes product (AN^T)*y, where AN is a non-basic subset of
// columns of A, and y is some vector.
//
// Output array is set to full NX-sized length, with basic components of  the
// output being set to zeros.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_computeantv(dualsimplexstate *state, RVector *y, RVector *r) {
   ae_int_t nn;
   ae_int_t nx;
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   double v;
   nx = state->ns + state->m;
   m = state->m;
   nn = nx - m;
// Allocate output, set to zero
   vectorsetlengthatleast(r, nx);
   for (i = 0; i < nx; i++) {
      r->xR[i] = 0.0;
   }
   for (i = 0; i < nn; i++) {
      j0 = state->at.ridx.xZ[state->basis.nidx.xZ[i]];
      j1 = state->at.ridx.xZ[state->basis.nidx.xZ[i] + 1] - 1;
      v = 0.0;
      for (j = j0; j <= j1; j++) {
         v += state->at.vals.xR[j] * y->xR[state->at.idx.xZ[j]];
      }
      r->xR[state->basis.nidx.xZ[i]] = v;
   }
}

// This function infers basic variables of X using values of non-basic vars
// and updates reduced cost vector D and target function Z. Sets state age
// to zero.
//
// D[] is allocated during computations.
//
// Temporary vectors Tmp0 and Tmp1 are used (reallocated as needed).
//
// NOTE: this function expects that both nonbasic and basic components are
//       stored in XA[]. XB[] array is not referenced.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_subproblemhandlexnupdate(dualsimplexstate *state, dualsimplexsubproblem *s) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t m;
   ae_int_t nn;
   ae_assert(s->state >= reviseddualsimplex_ssvalidxn, "SubproblemHandleXNUpdate: integrity check failed (XN is not valid)");
   nn = s->ns;
   m = s->m;
// Compute nonbasic components
   reviseddualsimplex_computeanxn(state, s, &s->xa, &state->tmp0);
   reviseddualsimplex_basissolve(&state->basis, &state->tmp0, &state->tmp1, &state->tmp2);
   for (i = 0; i < m; i++) {
      s->xa.xR[state->basis.idx.xZ[i]] = -state->tmp1.xR[i];
   }
// Compute D
   for (i = 0; i < m; i++) {
      state->tmp0.xR[i] = s->effc.xR[state->basis.idx.xZ[i]];
   }
   reviseddualsimplex_basissolvet(&state->basis, &state->tmp0, &state->tmp1, &state->tmp2);
   reviseddualsimplex_computeantv(state, &state->tmp1, &s->d);
   for (i = 0; i < nn; i++) {
      j = state->basis.nidx.xZ[i];
      s->d.xR[j] = s->effc.xR[j] - s->d.xR[j];
   }
// Update state validity/age
   s->state = reviseddualsimplex_ssvalid;
}

// This function returns minimum diagonal element of S. Result == 1 is  returned
// for M == 0.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static double reviseddualsimplex_basisminimumdiagonalelement(dualsimplexbasis *s) {
   double v;
   double vv;
   ae_int_t i;
   ae_int_t m;
   double result;
   m = s->m;
   if (m == 0) {
      result = 1.0;
      return result;
   }
   ae_assert(s->trftype == 0 || s->trftype == 1 || s->trftype == 2 || s->trftype == 3, "BasisMinimumDiagonalElement: unexpected TRF type");
   ae_assert(s->isvalidtrf, "BasisMinimumDiagonalElement: TRF is invalid");
   v = maxrealnumber;
   for (i = 0; i < m; i++) {
      vv = 0.0;
      if (s->trftype == 0 || s->trftype == 1) {
         vv = s->denselu.xyR[i][i];
      }
      if (s->trftype == 2 || s->trftype == 3) {
         vv = sparsegetdiagonal(&s->sparseu, i);
      }
      if (vv < 0.0) {
         vv = -vv;
      }
      if (vv < v) {
         v = vv;
      }
   }
   result = v;
   return result;
}

// Transforms sequence of pivot permutations P0*P1*...*Pm to forward/backward
// permutation representation.
// ALGLIB: Copyright 12.09.2018 by Sergey Bochkanov
static void reviseddualsimplex_pivottobwd(ZVector *p, ae_int_t m, ZVector *bwd) {
   ae_int_t i;
   ae_int_t k;
   vectorsetlengthatleast(bwd, m);
   for (i = 0; i < m; i++) {
      bwd->xZ[i] = i;
   }
   for (i = 0; i < m; i++) {
      k = p->xZ[i];
      if (k != i) {
         swapi(&bwd->xZ[i], &bwd->xZ[k]);
      }
   }
}

// This function computes fresh triangular factorization.
//
// If TRF of age 0 (fresh) is already present, no new factorization is calculated.
//
// It returns min[abs(u[i,i])] which can be used to determine whether factorization
// is degenerate or not (it will factorize anything, the question is whether
// it is possible to use factorization)
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static double reviseddualsimplex_basisfreshtrfunsafe(dualsimplexbasis *s, sparsematrix *at, dualsimplexsettings *settings) {
   ae_int_t m;
   ae_int_t ns;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t j0;
   ae_int_t j1;
   ae_int_t k1;
   ae_int_t nzl;
   ae_int_t nzu;
   ae_int_t nlogical;
   ae_int_t nstructural;
   ae_int_t offs;
   ae_int_t offs1;
   ae_int_t offs2;
   double result;
   m = s->m;
   ns = s->ns;
   result = 0.0;
// Compare TRF type with one required by settings, invalidation and refresh otherwise
   if (s->trftype != settings->trftype) {
      s->trftype = settings->trftype;
      s->isvalidtrf = false;
      result = reviseddualsimplex_basisfreshtrfunsafe(s, at, settings);
      return result;
   }
// Is it valid and fresh?
   if (s->isvalidtrf && s->trfage == 0) {
      result = reviseddualsimplex_basisminimumdiagonalelement(s);
      return result;
   }
// Dense TRF
   if (s->trftype == 0 || s->trftype == 1) {
      vectorsetlengthatleast(&s->colpermbwd, m);
      for (i = 0; i < m; i++) {
         s->colpermbwd.xZ[i] = i;
      }
      matrixsetlengthatleast(&s->denselu, m, m);
      for (i = 0; i < m; i++) {
         for (j = 0; j < m; j++) {
            s->denselu.xyR[i][j] = 0.0;
         }
      }
      for (i = 0; i < m; i++) {
         j0 = at->ridx.xZ[s->idx.xZ[i]];
         j1 = at->ridx.xZ[s->idx.xZ[i] + 1] - 1;
         for (j = j0; j <= j1; j++) {
            s->denselu.xyR[i][at->idx.xZ[j]] = at->vals.xR[j];
         }
      }
      rmatrixlu(&s->denselu, m, m, &s->tmpi);
      reviseddualsimplex_pivottobwd(&s->tmpi, m, &s->rowpermbwd);
      s->isvalidtrf = true;
      s->trfage = 0;
      s->statfact++;
      s->statoffdiag += sqr(m - 1.0);
      result = reviseddualsimplex_basisminimumdiagonalelement(s);
      return result;
   }
// Sparse TRF (with either PFI or Forest-Tomlin)
   if (s->trftype == 2 || s->trftype == 3) {
   // Determine permutation which moves logical variables
   // to the beginning.
   //
   // NOTE: this reordering results in stable factorization
   //       because we prenormalized constraints with 2-norm,
   //       all elements in the logical columns are less than
   //       1.0 in magnitude.
   //
   // After this block is done we have following arrays:
   // * tCInvIdx[j], which is an inverse of ColPermBwf[]
      vectorsetlengthatleast(&s->tcinvidx, m);
      vectorsetlengthatleast(&s->rowpermbwd, m);
      vectorsetlengthatleast(&s->colpermbwd, m);
      for (i = 0; i < m; i++) {
         s->tcinvidx.xZ[i] = i;
         s->rowpermbwd.xZ[i] = i;
         s->colpermbwd.xZ[i] = i;
      }
      nlogical = 0;
      for (i = 0; i < m; i++) {
         if (s->idx.xZ[i] >= ns) {
            swapi(&s->rowpermbwd.xZ[nlogical], &s->rowpermbwd.xZ[i]);
            j1 = s->tcinvidx.xZ[s->idx.xZ[i] - ns];
            swapi(&s->colpermbwd.xZ[j1], &s->colpermbwd.xZ[nlogical]);
            s->tcinvidx.xZ[s->colpermbwd.xZ[nlogical]] = nlogical;
            s->tcinvidx.xZ[s->colpermbwd.xZ[j1]] = j1;
            nlogical++;
         }
      }
      tagsortmiddlei(&s->colpermbwd, m - nlogical, nlogical);
      for (i = 0; i < m; i++) {
         s->tcinvidx.xZ[s->colpermbwd.xZ[i]] = i;
      }
      nstructural = m - nlogical;
   // Prepare SparseLU1 to receive factored out logical part of the matrix
   // and SparseLU2 to receive structural part of the matrix.
      vectorsetlengthatleast(&s->sparselu1.ridx, nstructural + 1);
      vectorsetlengthatleast(&s->sparselu1.didx, nstructural);
      vectorsetlengthatleast(&s->sparselu1.uidx, nstructural);
      s->sparselu1.matrixtype = 1;
      s->sparselu1.m = nstructural;
      s->sparselu1.n = nlogical;
      s->sparselu1.ridx.xZ[0] = 0;
      vectorsetlengthatleast(&s->sparselu2.ridx, nstructural + 1);
      vectorsetlengthatleast(&s->sparselu2.didx, nstructural);
      vectorsetlengthatleast(&s->sparselu2.uidx, nstructural);
      s->sparselu2.matrixtype = 1;
      s->sparselu2.m = nstructural;
      s->sparselu2.n = nstructural;
      s->sparselu2.ridx.xZ[0] = 0;
   // Reorder array, perform LU factorization
      for (k = 0; k < nstructural; k++) {
      // Make sure SparseLU1 and SparseLU2 have enough place.
         offs1 = s->sparselu1.ridx.xZ[k];
         offs2 = s->sparselu2.ridx.xZ[k];
         ivectorgrowto(&s->sparselu1.idx, offs1 + m);
         rvectorgrowto(&s->sparselu1.vals, offs1 + m);
         ivectorgrowto(&s->sparselu2.idx, offs2 + m);
         rvectorgrowto(&s->sparselu2.vals, offs2 + m);
      // Extract K-th row of the SparseLU1/2 (I-th row of the original matrix)
         i = s->rowpermbwd.xZ[k + nlogical];
         j0 = at->ridx.xZ[s->idx.xZ[i]];
         j1 = at->ridx.xZ[s->idx.xZ[i] + 1] - 1;
         for (j = j0; j <= j1; j++) {
            k1 = s->tcinvidx.xZ[at->idx.xZ[j]];
            if (k1 < nlogical) {
            // Append element to SparseLU1
               s->sparselu1.idx.xZ[offs1] = k1;
               s->sparselu1.vals.xR[offs1] = at->vals.xR[j];
               offs1++;
            } else {
            // Append element to SparseLU2
               s->sparselu2.idx.xZ[offs2] = k1 - nlogical;
               s->sparselu2.vals.xR[offs2] = at->vals.xR[j];
               offs2++;
            }
         }
      // Elements added to the last row of LU1 can be unordered,
      // so it needs resorting.
      //
      // LU2 does NOT need resorting because trailing NStructural
      // elements of permutation were post-sorted to produce
      // already sorted results.
         tagsortmiddleir(&s->sparselu1.idx, &s->sparselu1.vals, offs1 - s->sparselu1.ridx.xZ[k], s->sparselu1.ridx.xZ[k]);
         s->sparselu1.ridx.xZ[k + 1] = offs1;
         s->sparselu2.ridx.xZ[k + 1] = offs2;
      }
      s->sparselu1.ninitialized = s->sparselu1.ridx.xZ[nstructural];
      s->sparselu2.ninitialized = s->sparselu2.ridx.xZ[nstructural];
      sparseinitduidx(&s->sparselu1);
      sparseinitduidx(&s->sparselu2);
      if (nstructural > 0) {
         sptrflu(&s->sparselu2, 2, &s->densep2, &s->densep2c, &s->lubuf2);
         for (i = 0; i < nstructural; i++) {
            swapi(&s->rowpermbwd.xZ[i + nlogical], &s->rowpermbwd.xZ[s->densep2.xZ[i] + nlogical]);
            swapi(&s->colpermbwd.xZ[i + nlogical], &s->colpermbwd.xZ[s->densep2c.xZ[i] + nlogical]);
         }
      // Process L factor:
      //
      // 1. count number of non-zeros in the L factor,
      // 2. fill NLogical*NLogical leading block
      // 3. NStructural*M bottom block
         nzl = nlogical;
         for (i = 0; i < nstructural; i++) {
            k = s->lubuf2.rowpermrawidx.xZ[i];
            nzl += s->sparselu1.ridx.xZ[k + 1] - s->sparselu1.ridx.xZ[k];
            nzl += 1 + s->sparselu2.didx.xZ[i] - s->sparselu2.ridx.xZ[i];
         }
         vectorsetlengthatleast(&s->sparsel.vals, nzl);
         vectorsetlengthatleast(&s->sparsel.idx, nzl);
         vectorsetlengthatleast(&s->sparsel.ridx, m + 1);
         vectorsetlengthatleast(&s->sparsel.didx, m);
         vectorsetlengthatleast(&s->sparsel.uidx, m);
         s->sparsel.matrixtype = 1;
         s->sparsel.m = m;
         s->sparsel.n = m;
         s->sparsel.ninitialized = nzl;
         s->sparsel.ridx.xZ[0] = 0;
         for (i = 0; i < nlogical; i++) {
            s->sparsel.idx.xZ[i] = i;
            s->sparsel.vals.xR[i] = 1.0;
            s->sparsel.ridx.xZ[i + 1] = i + 1;
         }
         for (i = 0; i < nstructural; i++) {
            offs = s->sparsel.ridx.xZ[nlogical + i];
            k = s->lubuf2.rowpermrawidx.xZ[i];
            j0 = s->sparselu1.ridx.xZ[k];
            j1 = s->sparselu1.ridx.xZ[k + 1] - 1;
            for (j = j0; j <= j1; j++) {
               s->sparsel.idx.xZ[offs] = s->sparselu1.idx.xZ[j];
               s->sparsel.vals.xR[offs] = -s->sparselu1.vals.xR[j];
               offs++;
            }
            j0 = s->sparselu2.ridx.xZ[i];
            j1 = s->sparselu2.didx.xZ[i] - 1;
            for (j = j0; j <= j1; j++) {
               s->sparsel.idx.xZ[offs] = nlogical + s->sparselu2.idx.xZ[j];
               s->sparsel.vals.xR[offs] = s->sparselu2.vals.xR[j];
               offs++;
            }
            s->sparsel.idx.xZ[offs] = nlogical + i;
            s->sparsel.vals.xR[offs] = 1.0;
            offs++;
            s->sparsel.ridx.xZ[nlogical + i + 1] = offs;
         }
         ae_assert(s->sparsel.ninitialized == s->sparsel.ridx.xZ[m], "BasisFreshTrf: integrity check failed");
         sparseinitduidx(&s->sparsel);
      // Process U factor:
      //
      // 1. count number of non-zeros in the U factor,
      // 2. fill NLogical*NLogical leading block
      // 3. NStructural*NStructural bottom block
         nzu = nlogical;
         for (i = 0; i < nstructural; i++) {
            nzu += 1 + s->sparselu2.ridx.xZ[i + 1] - s->sparselu2.uidx.xZ[i];
         }
         vectorsetlengthatleast(&s->sparseu.vals, nzu);
         vectorsetlengthatleast(&s->sparseu.idx, nzu);
         vectorsetlengthatleast(&s->sparseu.ridx, m + 1);
         vectorsetlengthatleast(&s->sparseu.didx, m);
         vectorsetlengthatleast(&s->sparseu.uidx, m);
         s->sparseu.matrixtype = 1;
         s->sparseu.m = m;
         s->sparseu.n = m;
         s->sparseu.ninitialized = nzu;
         s->sparseu.ridx.xZ[0] = 0;
         for (i = 0; i < nlogical; i++) {
            s->sparseu.idx.xZ[i] = i;
            s->sparseu.vals.xR[i] = -1.0;
            s->sparseu.ridx.xZ[i + 1] = i + 1;
         }
         for (i = 0; i < nstructural; i++) {
            offs = s->sparseu.ridx.xZ[nlogical + i];
            s->sparseu.idx.xZ[offs] = nlogical + i;
            j = s->sparselu2.didx.xZ[i];
            if (j < s->sparselu2.uidx.xZ[i]) {
               ae_assert(s->sparselu2.idx.xZ[j] == i, "BasisFreshTrf: integrity check failed");
               s->sparseu.vals.xR[offs] = s->sparselu2.vals.xR[j];
            } else {
               s->sparseu.vals.xR[offs] = 0.0;
            }
            offs++;
            j0 = s->sparselu2.uidx.xZ[i];
            j1 = s->sparselu2.ridx.xZ[i + 1] - 1;
            for (j = j0; j <= j1; j++) {
               s->sparseu.idx.xZ[offs] = nlogical + s->sparselu2.idx.xZ[j];
               s->sparseu.vals.xR[offs] = s->sparselu2.vals.xR[j];
               offs++;
            }
            s->sparseu.ridx.xZ[nlogical + i + 1] = offs;
         }
         ae_assert(s->sparseu.ninitialized == s->sparseu.ridx.xZ[m], "BasisFreshTrf: integrity check failed");
         sparseinitduidx(&s->sparseu);
      } else {
         vectorsetlengthatleast(&s->nrs, m);
         for (i = 0; i < m; i++) {
            s->nrs.xZ[i] = 1;
         }
         sparsecreatecrsbuf(m, m, &s->nrs, &s->sparsel);
         for (i = 0; i < nlogical; i++) {
            sparseset(&s->sparsel, i, i, 1.0);
         }
         sparsecreatecrsbuf(m, m, &s->nrs, &s->sparseu);
         for (i = 0; i < nlogical; i++) {
            sparseset(&s->sparseu, i, i, -1.0);
         }
      }
      sparsecopytransposecrsbuf(&s->sparseu, &s->sparseut);
      s->isvalidtrf = true;
      s->trfage = 0;
      s->statfact++;
      s->statoffdiag += (s->sparsel.ridx.xZ[m] - m) + (s->sparseu.ridx.xZ[m] - m);
      result = reviseddualsimplex_basisminimumdiagonalelement(s);
      return result;
   }
//
   ae_assert(false, "BasisFreshTrf: unexpected TRF type");
   return result;
}

// This function computes fresh triangular factorization.
//
// If TRF of age 0 (fresh) is already present, no new factorization is calculated.
// If factorization has exactly zero element along diagonal, this function
// generates exception.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basisfreshtrf(dualsimplexbasis *s, sparsematrix *at, dualsimplexsettings *settings) {
   double v;
   v = reviseddualsimplex_basisfreshtrfunsafe(s, at, settings);
   ae_assert(v > 0.0, "BasisFreshTrf: degeneracy of B is detected");
}

// This function performs initial dual feasibility correction on the subproblem.
// It assumes that problem state is at least ssValidXN. After call to this
// function the problem state is set to ssValid.
//
// This function returns dual feasibility error after dual feasibility correction.
//
// NOTE: this function expects that both nonbasic and basic components are
//       stored in XA[]. XB[] array is not referenced.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static double reviseddualsimplex_initialdualfeasibilitycorrection(dualsimplexstate *state, dualsimplexsubproblem *s, dualsimplexsettings *settings) {
   ae_int_t nn;
   ae_int_t m;
   ae_int_t ii;
   ae_int_t i;
   ae_int_t j;
   bool flipped;
   double v;
   double dj;
   double xj;
   ae_int_t bndt;
   double result;
   EnFrame();
   NewRVector(dummy, 0);
   nn = s->ns;
   m = s->m;
   ae_assert(s->state >= reviseddualsimplex_ssvalidxn, "InitialDualFeasibilityCorrection: XN is invalid");
// Prepare
   vectorsetlengthatleast(&state->dfctmp0, m);
   vectorsetlengthatleast(&state->dfctmp1, m);
// Recompute D[] using fresh factorization
   reviseddualsimplex_basisfreshtrf(&state->basis, &state->at, settings);
   for (i = 0; i < m; i++) {
      state->dfctmp0.xR[i] = s->effc.xR[state->basis.idx.xZ[i]];
   }
   reviseddualsimplex_basissolvet(&state->basis, &state->dfctmp0, &state->dfctmp1, &state->dfctmp2);
   reviseddualsimplex_computeantv(state, &state->dfctmp1, &s->d);
   for (i = 0; i < nn; i++) {
      j = state->basis.nidx.xZ[i];
      s->d.xR[j] = s->effc.xR[j] - s->d.xR[j];
   }
// Perform flips for dual-infeasible boxed variables
   result = 0.0;
   flipped = false;
   for (ii = 0; ii < nn; ii++) {
      j = state->basis.nidx.xZ[ii];
      bndt = s->bndt.xZ[j];
   // Boxed variables, perform DFC
      if (bndt == reviseddualsimplex_ccrange) {
         dj = s->d.xR[j];
         xj = s->xa.xR[j];
         if (xj == s->bndl.xR[j] && dj < 0.0) {
            s->xa.xR[j] = s->bndu.xR[j];
            flipped = true;
            continue;
         }
         if (xj == s->bndu.xR[j] && dj > 0.0) {
            s->xa.xR[j] = s->bndl.xR[j];
            flipped = true;
            continue;
         }
         continue;
      }
   // Non-boxed variables, compute dual feasibility error
      if (bndt == reviseddualsimplex_ccfixed) {
         continue;
      }
      if (bndt == reviseddualsimplex_cclower) {
         v = -s->d.xR[j];
         if (v > result) {
            result = v;
         }
         continue;
      }
      if (bndt == reviseddualsimplex_ccupper) {
         v = s->d.xR[j];
         if (v > result) {
            result = v;
         }
         continue;
      }
      if (bndt == reviseddualsimplex_ccfree) {
         result = rmax2(result, fabs(s->d.xR[j]));
         continue;
      }
   }
// Recompute basic components of X[]
   if (flipped || s->state < reviseddualsimplex_ssvalid) {
      reviseddualsimplex_computeanxn(state, s, &s->xa, &state->dfctmp0);
      reviseddualsimplex_basissolve(&state->basis, &state->dfctmp0, &state->dfctmp1, &state->dfctmp2);
      for (i = 0; i < m; i++) {
         s->xa.xR[state->basis.idx.xZ[i]] = -state->dfctmp1.xR[i];
      }
   }
// Update state validity/age
   s->state = reviseddualsimplex_ssvalid;
   DeFrame(result);
}

// This function performs shifting using current algorithm  as  specified  by
// settings.shifting.
//
// It accepts following parameters:
// * AlphaR - pivot row
// * Delta - delta from pricing step
// * Q - variable selected by ratio test
// * AlphaRPiv - pivot element, Q-th element of  AlphaR  (because  alphaR  is
//   stored in compressed format, we can't extract it easily)
// * ThetaD - dual step length
//
// If no shifts are necessary, it silently returns. If shifts are  necessary,
// it modifies ThetaD, S.D, S.EffC according to shifting algorithm.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_shifting(dualsimplexstate *state, dualsimplexsubproblem *s, dssvector *alphar, double delta, ae_int_t q, double alpharpiv, double *thetad, dualsimplexsettings *settings) {
   ae_int_t dir;
   double sft;
   ae_int_t ii;
   ae_int_t j;
   ae_int_t bndt;
// No shifts
   if (settings->shifting == 0) {
      return;
   }
   if (q < 0) {
      return;
   }
// EXPAND with ThetaD == 0
   if (settings->shifting == 1) {
      dir = sign(delta);
      if (*thetad * dir >= 0.0) {
         return;
      }
      s->effc.xR[q] -= s->d.xR[q];
      s->d.xR[q] = 0.0;
      *thetad = 0.0;
      return;
   }
// EXPAND with ThetaD == ShiftLen
   if (settings->shifting == 2) {
      dir = sign(delta);
      if (*thetad * dir > 0.0) {
         return;
      }
   // Ensure that non-zero step is performed
      *thetad = dir * reviseddualsimplex_shiftlen;
   // Shift Q-th coefficient
      sft = *thetad * (dir * alpharpiv) - s->d.xR[q];
      s->effc.xR[q] += sft;
      s->d.xR[q] += sft;
   // Shift other coefficients
      for (ii = 0; ii < alphar->k; ii++) {
         j = alphar->idx.xZ[ii];
         bndt = s->bndt.xZ[j];
         if (j == q || bndt == reviseddualsimplex_ccfixed || bndt == reviseddualsimplex_ccfree) {
            continue;
         }
         sft = *thetad * (dir * alphar->vals.xR[ii]) - s->d.xR[j];
      // Handle variables at lower bound
         if (bndt == reviseddualsimplex_cclower || bndt == reviseddualsimplex_ccrange && s->xa.xR[j] == s->bndl.xR[j]) {
            sft -= settings->dtolabs;
            if (sft > 0.0) {
               s->effc.xR[j] += sft;
               s->d.xR[j] += sft;
            }
            continue;
         }
         if (bndt == reviseddualsimplex_ccupper || bndt == reviseddualsimplex_ccrange && s->xa.xR[j] == s->bndu.xR[j]) {
            sft += settings->dtolabs;
            if (sft < 0.0) {
               s->effc.xR[j] += sft;
               s->d.xR[j] += sft;
            }
            continue;
         }
      }
   // Done
      return;
   }
   ae_assert(false, "Shifting: unexpected shifting type");
}

// This function fills S.DSEWeights by actual weights according to current
// settings and sets validity flag.
//
// Basis object MUST store valid triangular factorization, otherwise this
// function throws an exception.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basisrequestweights(dualsimplexbasis *s, dualsimplexsettings *settings) {
   ae_int_t m;
   ae_int_t ns;
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   m = s->m;
   ns = s->ns;
   ae_assert(settings->pricing == -1 || settings->pricing == 0 || settings->pricing == 1, "BasisRequestWeights: unknown pricing type");
   ae_assert(s->isvalidtrf, "BasisRequestWeights: factorization is not computed prior to calling this function");
// If weights are valid, return immediately
   if (s->dsevalid) {
      return;
   }
// Compute weights from scratch
   if (settings->pricing == -1 || settings->pricing == 1) {
      for (i = 0; i < m; i++) {
         if (s->idx.xZ[i] < ns) {
         // Structural variable, DSE weight is computed by definition
            vectorsetlengthatleast(&s->wtmp0, m);
            vectorsetlengthatleast(&s->wtmp1, m);
            for (j = 0; j < m; j++) {
               s->wtmp0.xR[j] = 0.0;
            }
            s->wtmp0.xR[i] = 1.0;
            reviseddualsimplex_basissolvet(s, &s->wtmp0, &s->wtmp1, &s->wtmp2);
            v = 0.0;
            for (j = 0; j < m; j++) {
               vv = s->wtmp1.xR[j];
               v += vv * vv;
            }
            s->dseweights.xR[i] = v;
         } else {
         // Logical variable, weight can be set to 1.0
            s->dseweights.xR[i] = 1.0;
         }
      }
      s->dsevalid = true;
      return;
   }
// Compute weights from scratch
   if (settings->pricing == 0) {
      for (i = 0; i < m; i++) {
         s->dseweights.xR[i] = 1.0;
      }
      s->dsevalid = true;
      return;
   }
   ae_assert(false, "BasisRequestWeights: unexpected pricing type");
}

// This function performs pricing step
//
// Additional parameters:
// * Phase1Pricing - if True, then special Phase #1 restriction is applied to
//   leaving variables: only those are eligible which will move to zero bound
//   after basis change.
//
//   This trick allows to accelerate and stabilize phase #1. See Robert Fourer,
//   'Notes on the dual simplex method', draft report, 1994, for more information.
//
// Returns:
// * leaving variable index P
// * its index R in the basis, in [0,M) range
// * Delta - difference between variable value and corresponding bound
//
// NOTE: this function expects that basic components are stored in XB[];
//       corresponding entries of XA[] are ignored.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_pricingstep(dualsimplexstate *state, dualsimplexsubproblem *s, bool phase1pricing, ae_int_t *p, ae_int_t *r, double *delta, dualsimplexsettings *settings) {
   ae_int_t m;
   ae_int_t i;
   ae_int_t bi;
   double v;
   double vtarget;
   double xbi;
   double bndl;
   double bndu;
   double vdiff;
   double vtest;
   double invw;
   ae_int_t bndt;
   bool hasboth;
   bool hasl;
   bool hasu;
   *p = 0;
   *r = 0;
   *delta = 0.0;
   m = s->m;
// Integrity checks
   ae_assert(s->state == reviseddualsimplex_ssvalid, "PricingStep: invalid X");
   ae_assert(m > 0, "PricingStep: M <= 0");
// Pricing
   if (settings->pricing == 0) {
   // "Most infeasible" pricing
      *p = -1;
      *r = -1;
      *delta = 0.0;
      vtarget = 0.0;
      for (i = 0; i < m; i++) {
         bndt = s->bndtb.xZ[i];
         hasboth = bndt == 3 || bndt == 0;
         hasl = hasboth || bndt == 1;
         hasu = hasboth || bndt == 2;
         xbi = s->xb.xR[i];
         if (hasl) {
            bndl = s->bndlb.xR[i];
            vdiff = xbi - bndl;
            v = -vdiff;
            if (v > s->bndtollb.xR[i] && v > vtarget) {
            // Special phase 1 pricing: do not choose variables which move to non-zero bound
               if (phase1pricing && !(bndl == 0.0)) {
                  continue;
               }
            // Proceed as usual
               *p = state->basis.idx.xZ[i];
               *r = i;
               *delta = vdiff;
               vtarget = v;
               continue;
            }
         }
         if (hasu) {
            bndu = s->bndub.xR[i];
            vdiff = xbi - bndu;
            v = vdiff;
            if (v > s->bndtolub.xR[i] && v > vtarget) {
            // Special phase 1 pricing: do not choose variables which move to non-zero bound
               if (phase1pricing && !(bndu == 0.0)) {
                  continue;
               }
            // Proceed as usual
               *p = state->basis.idx.xZ[i];
               *r = i;
               *delta = vdiff;
               vtarget = v;
               continue;
            }
         }
      }
   // Done
      return;
   }
   if (settings->pricing == -1 || settings->pricing == 1) {
   // Dual steepest edge pricing
      reviseddualsimplex_basisrequestweights(&state->basis, settings);
      *p = -1;
      *r = -1;
      *delta = 0.0;
      vtarget = 0.0;
      for (i = 0; i < m; i++) {
         bi = state->basis.idx.xZ[i];
         bndt = s->bndtb.xZ[i];
         hasboth = bndt == 3 || bndt == 0;
         hasl = hasboth || bndt == 1;
         hasu = hasboth || bndt == 2;
         xbi = s->xb.xR[i];
         invw = 1.0 / state->basis.dseweights.xR[i];
         if (hasl) {
            bndl = s->bndlb.xR[i];
            vdiff = xbi - bndl;
            vtest = vdiff * vdiff * invw;
            if (vdiff < -s->bndtollb.xR[i] && (*p < 0 || vtest > vtarget)) {
            // Special phase 1 pricing: do not choose variables which move to non-zero bound
               if (phase1pricing && !(bndl == 0.0)) {
                  continue;
               }
            // Proceed as usual
               *p = bi;
               *r = i;
               *delta = vdiff;
               vtarget = vtest;
               continue;
            }
         }
         if (hasu) {
            bndu = s->bndub.xR[i];
            vdiff = xbi - bndu;
            vtest = vdiff * vdiff * invw;
            if (vdiff > s->bndtolub.xR[i] && (*p < 0 || vtest > vtarget)) {
            // Special phase 1 pricing: do not choose variables which move to non-zero bound
               if (phase1pricing && !(bndu == 0.0)) {
                  continue;
               }
            // Proceed as usual
               *p = bi;
               *r = i;
               *delta = vdiff;
               vtarget = vtest;
               continue;
            }
         }
      }
   // Done
      return;
   }
   ae_assert(false, "PricingStep: unknown pricing type");
}

// Initializes vector, sets all internal arrays to length N (so that  we  may
// store any vector without reallocation).  Previously  allocated  memory  is
// reused as much as possible.
//
// No zero-filling is performed, X.K is undefined. Only X.N is set.
//
// Inputs:
//     X           -   temporary buffers
//
// Outputs:
//     X           -   preallocated vector, X.N == N, contents undefined
// ALGLIB: Copyright 24.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_dvalloc(dssvector *x, ae_int_t n) {
   vectorsetlengthatleast(&x->idx, n);
   vectorsetlengthatleast(&x->vals, n);
   vectorsetlengthatleast(&x->dense, n);
   x->n = n;
}

// Copies dense part to sparse one.
//
// Inputs:
//     X           -   allocated vector; dense part must be valid
//
// Outputs:
//     X           -   both dense and sparse parts are valid.
// ALGLIB: Copyright 24.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_dvdensetosparse(dssvector *x) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t k;
   double v;
   n = x->n;
   vectorsetlengthatleast(&x->idx, n);
   vectorsetlengthatleast(&x->vals, n);
   k = 0;
   for (i = 0; i < n; i++) {
      v = x->dense.xR[i];
      if (v != 0.0) {
         x->idx.xZ[k] = i;
         x->vals.xR[k] = v;
         k++;
      }
   }
   x->k = k;
}

// This function performs BTran step
//
// Accepts:
// * R, index of the leaving variable in the basis, in [0,M) range
//
// Returns:
// * RhoR, array[M], BTran result
// ALGLIB: Copyright 19.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_btranstep(dualsimplexstate *state, dualsimplexsubproblem *s, ae_int_t r, dssvector *rhor, dualsimplexsettings *settings) {
   ae_int_t m;
   ae_int_t i;
   m = s->m;
// Integrity checks
   ae_assert(m > 0, "BTranStep: M <= 0");
// BTran
   vectorsetlengthatleast(&state->btrantmp0, m);
   vectorsetlengthatleast(&state->btrantmp1, m);
   vectorsetlengthatleast(&state->btrantmp2, m);
   for (i = 0; i < m; i++) {
      state->btrantmp0.xR[i] = 0.0;
   }
   state->btrantmp0.xR[r] = 1.0;
   reviseddualsimplex_dvalloc(rhor, m);
   reviseddualsimplex_basissolvet(&state->basis, &state->btrantmp0, &rhor->dense, &state->btrantmp1);
   reviseddualsimplex_dvdensetosparse(rhor);
}

// Initializes vector, sets all internal arrays to length  N  and  zero-fills
// them. Previously allocated memory is reused as much as possible.
//
// Inputs:
//     X           -   temporary buffers
//
// Outputs:
//     X           -   preallocated vector:
//                     * X.N == N
//                     * X.K == 0
//                     * X.Dense is zero-filled.
// ALGLIB: Copyright 24.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_dvinit(dssvector *x, ae_int_t n) {
   vectorsetlengthatleast(&x->idx, n);
   vectorsetlengthatleast(&x->vals, n);
   vectorsetlengthatleast(&x->dense, n);
   rsetv(n, 0.0, &x->dense);
   x->n = n;
   x->k = 0;
}

// Copies sparse part to dense one.
//
// Inputs:
//     X           -   allocated vector; sparse part must be valid
//
// Outputs:
//     X           -   both dense and sparse parts are valid.
// ALGLIB: Copyright 24.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_dvsparsetodense(dssvector *x) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t k;
   n = x->n;
   k = x->k;
   rsetv(n, 0.0, &x->dense);
   for (i = 0; i < k; i++) {
      x->dense.xR[x->idx.xZ[i]] = x->vals.xR[i];
   }
}

#if 0 //(@) Not used.
static void reviseddualsimplex_updateavgcounter(double v, double *acc, ae_int_t *cnt) {
   *acc += v;
   ++*cnt;
}
#endif

// This function performs PivotRow step
//
// Accepts:
// * RhoR, BTRan result
//
// Returns:
// * AlphaR, array[N+M], pivot row
// ALGLIB: Copyright 19.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_pivotrowstep(dualsimplexstate *state, dualsimplexsubproblem *s, dssvector *rhor, dssvector *alphar, dualsimplexsettings *settings) {
   ae_int_t m;
   ae_int_t ns;
   ae_int_t nx;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t jj;
   ae_int_t j0;
   ae_int_t j1;
   ae_int_t alphark;
   double v;
   double avgcolwise;
   double avgrowwise;
   m = s->m;
   ns = s->ns;
   nx = s->ns + s->m;
// Integrity checks
   ae_assert(m > 0, "BTranStep: M <= 0");
// Determine operation counts for columnwise and rowwise approaches
   avgrowwise = rhor->k * ((double)state->at.ridx.xZ[nx] / m);
   avgcolwise = ns * ((double)state->at.ridx.xZ[nx] / nx);
// Pivot row
   if (avgrowwise < avgcolwise) {
   // Use rowwise algorithm
      reviseddualsimplex_dvinit(alphar, nx);
      for (i = 0; i < rhor->k; i++) {
         k = rhor->idx.xZ[i];
         v = rhor->vals.xR[i];
         j0 = state->a.ridx.xZ[k];
         j1 = state->a.ridx.xZ[k + 1] - 1;
         for (j = j0; j <= j1; j++) {
            jj = state->a.idx.xZ[j];
            alphar->dense.xR[jj] += v * state->a.vals.xR[j];
         }
      }
      alphark = 0;
      for (i = 0; i < nx; i++) {
         if (!state->basis.isbasic.xB[i]) {
         // Fetch nonbasic nonzeros to sparse part
            v = alphar->dense.xR[i];
            if (v != 0.0) {
               alphar->idx.xZ[alphark] = i;
               alphar->vals.xR[alphark] = v;
               alphark++;
            }
         } else {
         // Enforce condition that basic elements of AlphaR are exactly zero
            alphar->dense.xR[i] = 0.0;
         }
      }
      alphar->k = alphark;
   } else {
   // Use colwise algorithm
      reviseddualsimplex_dvalloc(alphar, nx);
      alphark = 0;
      for (i = 0; i < ns; i++) {
         k = state->basis.nidx.xZ[i];
         j0 = state->at.ridx.xZ[k];
         j1 = state->at.ridx.xZ[k + 1] - 1;
         v = 0.0;
         for (j = j0; j <= j1; j++) {
            v += state->at.vals.xR[j] * rhor->dense.xR[state->at.idx.xZ[j]];
         }
         if (v != 0.0) {
            alphar->idx.xZ[alphark] = k;
            alphar->vals.xR[alphark] = v;
            alphark++;
         }
      }
      alphar->k = alphark;
      reviseddualsimplex_dvsparsetodense(alphar);
   }
}

// This function performs FTran step
//
// Accepts:
// * RhoR, array[M]
// * Q, index of the entering variable, in [0,NX) range
//
// Returns:
// * AlphaQ,   array[M], FTran result
// * AlphaQim, array[M], intermediate FTran result used by Forest-Tomlin update
// * Tau,      array[M], used to compute DSE temporaries
// ALGLIB: Copyright 19.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_ftranstep(dualsimplexstate *state, dualsimplexsubproblem *s, dssvector *rhor, ae_int_t q, RVector *alphaq, RVector *alphaqim, RVector *tau, dualsimplexsettings *settings) {
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   ae_int_t j0;
   ae_int_t j1;
   m = s->m;
// Integrity checks
   ae_assert(m > 0, "BTranStep: M <= 0");
// FTran
   vectorsetlengthatleast(&state->ftrantmp0, m);
   for (i = 0; i < m; i++) {
      state->ftrantmp0.xR[i] = 0.0;
   }
   j0 = state->at.ridx.xZ[q];
   j1 = state->at.ridx.xZ[q + 1] - 1;
   for (j = j0; j <= j1; j++) {
      state->ftrantmp0.xR[state->at.idx.xZ[j]] = state->at.vals.xR[j];
   }
   reviseddualsimplex_basissolvex(&state->basis, &state->ftrantmp0, alphaq, alphaqim, true, &state->ftrantmp1);
   ae_assert(settings->pricing == -1 || settings->pricing == 0 || settings->pricing == 1, "FTran: unexpected Settings.Pricing");
   if (settings->pricing == 1) {
      reviseddualsimplex_basissolve(&state->basis, &rhor->dense, tau, &state->ftrantmp1);
   }
}

// This function performs ratio test, either simple one or BFRT.
//
// It accepts following parameters:
// * AlphaR - pivot row
// * Delta - delta from pricing step
// * P - index of leaving variable from pricing step
//
// It returns following results:
// * Q - non-negative value for success, negative for primal infeasible problem
// * AlphaRPiv - AlphaR[Q] (due to AlphaR being stored in sparse format this
//   value is difficult to extract by index Q).
// * ThetaD - dual step length
// * PossibleFlips[PossibleFlipsCnt] - for possible flip indexes (for BFRT
//   this set coincides with actual flips, but stabilizing BFRT is a bit more
//   complex - some variables in PossibleFlips[] may need flipping and some not)
//
// Internally it uses following fields of State for temporaries:
// * EligibleAlphaR
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_ratiotest(dualsimplexstate *state, dualsimplexsubproblem *s, dssvector *alphar, double delta, ae_int_t p, ae_int_t *q, double *alpharpiv, double *thetad, ZVector *possibleflips, ae_int_t *possibleflipscnt, dualsimplexsettings *settings) {
   ae_int_t nx;
   ae_int_t j;
   ae_int_t nj;
   ae_int_t dir;
   double vx;
   double vp;
   ae_int_t ej;
   double alpharej;
   double vtarget;
   double vtest;
   ae_int_t eligiblecnt;
   ae_int_t originaleligiblecnt;
   ae_int_t bndt;
   double alphawaver;
   double adelta;
   ae_int_t idx;
   double vtheta;
   *q = 0;
   *alpharpiv = 0.0;
   *thetad = 0.0;
   nx = s->ns + s->m;
   ae_assert(delta != 0.0, "RatioTest: zero delta");
   ae_assert(s->state == reviseddualsimplex_ssvalid, "RatioTest: invalid X");
// Clear output
   *q = -1;
   *alpharpiv = 0.0;
   *thetad = 0.0;
   *possibleflipscnt = 0;
// Prepare temporaries
//
// Scaled tolerances are used to test AlphaWaveR for positivity/negativity,
// scale of I-th tolerance is calculated as ratio of ColScale[I] and ColScale[P].
   dir = sign(delta);
   vectorsetlengthatleast(possibleflips, nx);
// Prepare set of eligible variables
//
// NOTE: free variables are immediately chosen at this stage
   vectorsetlengthatleast(&state->eligiblealphar, alphar->k);
   eligiblecnt = 0;
   for (j = 0; j < alphar->k; j++) {
      nj = alphar->idx.xZ[j];
      bndt = s->bndt.xZ[nj];
   // Handle fixed and free variables: fixed ones are not eligible,
   // free non-basic variables are always and immediately eligible
      if (bndt == reviseddualsimplex_ccfixed) {
         continue;
      }
      if (bndt == reviseddualsimplex_ccfree) {
         *q = nj;
         *thetad = 0.0;
         *alpharpiv = alphar->vals.xR[j];
         return;
      }
   // Handle lower/upper/range constraints
      vx = s->xa.xR[nj];
      vp = settings->pivottol;
      alphawaver = dir * alphar->vals.xR[j];
      if (bndt == reviseddualsimplex_cclower || bndt == reviseddualsimplex_ccrange && vx == s->bndl.xR[nj]) {
         if (alphawaver > vp) {
            state->eligiblealphar.xZ[eligiblecnt] = j;
            eligiblecnt++;
            continue;
         }
      }
      if (bndt == reviseddualsimplex_ccupper || bndt == reviseddualsimplex_ccrange && vx == s->bndu.xR[nj]) {
         if (alphawaver < -vp) {
            state->eligiblealphar.xZ[eligiblecnt] = j;
            eligiblecnt++;
            continue;
         }
      }
   }
   originaleligiblecnt = eligiblecnt;
// Simple ratio test.
   if (settings->ratiotest == 0) {
   // Ratio test
      vtarget = 0.0;
      for (j = 0; j < eligiblecnt; j++) {
         ej = state->eligiblealphar.xZ[j];
         nj = alphar->idx.xZ[ej];
         alpharej = alphar->vals.xR[ej];
      // More general case
         alphawaver = dir * alpharej;
         vtest = s->d.xR[nj] / alphawaver;
         if (*q < 0 || vtest < vtarget) {
            *q = nj;
            *alpharpiv = alpharej;
            vtarget = vtest;
            *thetad = s->d.xR[nj] / alpharej;
         }
      }
      reviseddualsimplex_shifting(state, s, alphar, delta, *q, *alpharpiv, thetad, settings);
   // Done
      return;
   }
// Bounds flipping ratio test
   if (settings->ratiotest == 1) {
      adelta = fabs(delta);
   // Quick exit
      if (eligiblecnt == 0) {
         return;
      }
   // BFRT
      while (eligiblecnt > 0) {
      // Find Q satisfying BFRT criteria
         idx = -1;
         *q = -1;
         *alpharpiv = 0.0;
         vtarget = 0.0;
         for (j = 0; j < eligiblecnt; j++) {
            ej = state->eligiblealphar.xZ[j];
            nj = alphar->idx.xZ[ej];
            alpharej = alphar->vals.xR[ej];
            vtheta = s->d.xR[nj] / alpharej;
            vtest = dir * vtheta;
            if (*q < 0 || vtest < vtarget) {
               *q = nj;
               *alpharpiv = alpharej;
               vtarget = vtest;
               *thetad = vtheta;
               idx = j;
            }
         }
         ae_assert(*q >= 0, "RatioTest: integrity check failed (BFRT)");
      // BFRT mini-iterations will be terminated upon discovery
      // of non-boxed variable or upon exhausting of eligible set.
         if (s->bndt.xZ[*q] != reviseddualsimplex_ccrange) {
            break;
         }
         if (eligiblecnt == 1) {
            break;
         }
      // Update and test ADelta. Break BFRT mini-iterations once
      // we get negative slope.
         adelta -= (s->bndu.xR[*q] - s->bndl.xR[*q]) * fabs(*alpharpiv);
         if (adelta <= 0.0) {
            break;
         }
      // Update eligible set, record flip
         possibleflips->xZ[*possibleflipscnt] = state->eligiblealphar.xZ[idx];
         ++*possibleflipscnt;
         state->eligiblealphar.xZ[idx] = state->eligiblealphar.xZ[eligiblecnt - 1];
         eligiblecnt--;
      }
      ae_assert(*q >= 0, "RatioTest: unexpected failure");
      *thetad = s->d.xR[*q] / *alpharpiv;
      reviseddualsimplex_shifting(state, s, alphar, delta, *q, *alpharpiv, thetad, settings);
   // Done
      return;
   }
// Unknown test type
   ae_assert(false, "RatioTest: integrity check failed, unknown test type");
}

// Applies inverse cyclic permutation of [D,M-1) (element D is moved to the end, the
// rest of elements is shifted one position backward) to the already existing
// permutation.
// ALGLIB: Copyright 12.09.2018 by Sergey Bochkanov
static void reviseddualsimplex_inversecyclicpermutation(ZVector *bwd, ae_int_t m, ae_int_t d, ZVector *tmpi) {
   ae_int_t i;
   ae_int_t k;
// update Bwd[]
   k = bwd->xZ[d];
   for (i = d; i < m - 1; i++) {
      bwd->xZ[i] = bwd->xZ[i + 1];
   }
   bwd->xZ[m - 1] = k;
}

// This function updates triangular factorization by adding Q  to  basis  and
// removing P from basis. It also updates index tables IsBasic[], BasicIdx[],
// Basis.NIdx[].
//
// AlphaQim contains intermediate result from Ftran for AlphaQ, it is used
// by Forest-Tomlin update scheme. If other update is used, it is not referenced
// at all.
//
// X[], D[], Z are NOT recomputed.
//
// Tau is used if Settings.Pricing == 1, ignored otherwise.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basisupdatetrf(dualsimplexbasis *s, sparsematrix *at, ae_int_t p, ae_int_t q, RVector *alphaq, RVector *alphaqim, ae_int_t r, RVector *tau, dualsimplexsettings *settings) {
   const double minbeta = 0.0001;
   ae_int_t m;
   ae_int_t nn;
   ae_int_t i;
   ae_int_t j;
   bool processed;
   double invaq;
   ae_int_t dstoffs;
   ae_int_t srcoffs;
   ae_int_t srcidx;
   double srcval;
   double vcorner;
   ae_int_t idxd;
   double v;
   m = s->m;
   nn = s->ns;
// Update index tables
//
// TODO: better code!!!!!!!!!!!!!!!!!!!!!!!
   s->isbasic.xB[p] = false;
   s->isbasic.xB[q] = true;
   for (i = 0; i < m; i++) {
      if (s->idx.xZ[i] == p) {
         s->idx.xZ[i] = q;
         break;
      }
   }
   for (i = 0; i < nn; i++) {
      if (s->nidx.xZ[i] == q) {
         s->nidx.xZ[i] = p;
         break;
      }
   }
// Update dense factorization
   if (s->trftype != settings->trftype || s->trftype == 0 || !s->isvalidtrf || s->trfage >= settings->maxtrfage) {
   // Complete refresh is needed for factorization
      s->isvalidtrf = false;
      reviseddualsimplex_basisfreshtrf(s, at, settings);
   } else {
      processed = false;
      if (s->trftype == 0 || s->trftype == 1 || s->trftype == 2) {
      // Dense/sparse factorizations with dense PFI
         ae_assert(alphaq->xR[r] != 0.0, "BasisUpdateTrf: integrity check failed, AlphaQ[R] == 0");
         rvectorgrowto(&s->densepfieta, (s->trfage + 1) * m);
         ivectorgrowto(&s->rk, s->trfage + 1);
         s->rk.xZ[s->trfage] = r;
         invaq = 1.0 / alphaq->xR[r];
         for (i = 0; i < m; i++) {
            if (i != r) {
               s->densepfieta.xR[s->trfage * m + i] = -alphaq->xR[i] * invaq;
            } else {
               s->densepfieta.xR[s->trfage * m + i] = invaq;
            }
         }
         s->trfage++;
         s->statupdt++;
         s->statoffdiag += sqr(m - 1.0);
         processed = true;
      }
      if (s->trftype == 3) {
      // Sparse factorization with Forest-Tomlin update
         ae_assert(alphaq->xR[r] != 0.0, "BasisUpdateTrf: integrity check failed, AlphaQ[R] == 0");
         rvectorgrowto(&s->densemu, (s->trfage + 1) * m);
         ivectorgrowto(&s->rk, s->trfage + 1);
         ivectorgrowto(&s->dk, s->trfage + 1);
         vectorsetlengthatleast(&s->utmp0, m);
      // Determine D - index of row being overwritten by Forest-Tomlin update
         idxd = -1;
         for (i = 0; i < m; i++) {
            if (s->rowpermbwd.xZ[i] == r) {
               idxd = i;
               break;
            }
         }
         ae_assert(idxd >= 0, "BasisUpdateTrf: unexpected integrity check failure");
         s->rk.xZ[s->trfage] = r;
         s->dk.xZ[s->trfage] = idxd;
      // Modify L with permutation which moves D-th row/column to the end:
      // * rows 0...D-1 are left intact
      // * rows D+1...M-1 are moved one position up, with columns 0..D-1
      //   retained as is, and columns D+1...M-1 being moved one position left.
      // * last row is filled by permutation/modification of AlphaQim
      // Determine FT update coefficients in the process.
         ivectorgrowto(&s->sparsel.idx, s->sparsel.ridx.xZ[m] + m);
         rvectorgrowto(&s->sparsel.vals, s->sparsel.ridx.xZ[m] + m);
         for (i = 0; i < m; i++) {
            s->utmp0.xR[i] = 0.0;
         }
         for (i = idxd + 1; i < m; i++) {
            j = s->sparsel.ridx.xZ[i + 1] - 1;
            if (s->sparsel.idx.xZ[j] != i || s->sparsel.vals.xR[j] != 1.0) {
               ae_assert(false, "UpdateTrf: integrity check failed for sparse L");
            }
            dstoffs = s->sparsel.ridx.xZ[i - 1];
            srcoffs = s->sparsel.ridx.xZ[i];
         // Read first element in the row (it has at least one - unit diagonal)
            srcidx = s->sparsel.idx.xZ[srcoffs];
            srcval = s->sparsel.vals.xR[srcoffs];
         // Read/write columns 0...D-1
            while (srcidx < idxd) {
               s->sparsel.idx.xZ[dstoffs] = srcidx;
               s->sparsel.vals.xR[dstoffs] = srcval;
               dstoffs++;
               srcoffs++;
               srcidx = s->sparsel.idx.xZ[srcoffs];
               srcval = s->sparsel.vals.xR[srcoffs];
            }
         // If we have non-zero element in column D, use it as
         // right-hand side of intermediate linear system which
         // is used to determine coefficients of update matrix.
            if (srcidx == idxd) {
               s->utmp0.xR[i - 1] = srcval;
               srcoffs++;
               srcidx = s->sparsel.idx.xZ[srcoffs];
               srcval = s->sparsel.vals.xR[srcoffs];
            }
         // Process columns D+1...I-1
            v = s->utmp0.xR[i - 1];
            while (srcidx < i) {
               s->sparsel.idx.xZ[dstoffs] = srcidx - 1;
               s->sparsel.vals.xR[dstoffs] = srcval;
               v -= srcval * s->utmp0.xR[srcidx - 1];
               dstoffs++;
               srcoffs++;
               srcidx = s->sparsel.idx.xZ[srcoffs];
               srcval = s->sparsel.vals.xR[srcoffs];
            }
            s->utmp0.xR[i - 1] = v;
         // Write out unit diagonal, finalize row
            s->sparsel.idx.xZ[dstoffs] = i - 1;
            s->sparsel.vals.xR[dstoffs] = 1.0;
            dstoffs++;
            s->sparsel.ridx.xZ[i] = dstoffs;
         }
         s->utmp0.xR[m - 1] = 1.0;
         dstoffs = s->sparsel.ridx.xZ[m - 1];
         for (j = 0; j < idxd; j++) {
            v = alphaqim->xR[j];
            if (v != 0.0) {
               s->sparsel.idx.xZ[dstoffs] = j;
               s->sparsel.vals.xR[dstoffs] = v;
               dstoffs++;
            }
         }
         vcorner = alphaqim->xR[idxd];
         for (j = idxd + 1; j < m; j++) {
            v = alphaqim->xR[j];
            if (v != 0.0) {
               s->sparsel.idx.xZ[dstoffs] = j - 1;
               s->sparsel.vals.xR[dstoffs] = v;
               dstoffs++;
               vcorner -= v * s->utmp0.xR[j - 1];
            }
         }
         s->sparsel.idx.xZ[dstoffs] = m - 1;
         s->sparsel.vals.xR[dstoffs] = 1.0;
         dstoffs++;
         s->sparsel.ridx.xZ[m] = dstoffs;
         s->sparsel.ninitialized = s->sparsel.ridx.xZ[m];
         for (i = 0; i < m; i++) {
            j = s->sparsel.ridx.xZ[i + 1];
            s->sparsel.didx.xZ[i] = j - 1;
            s->sparsel.uidx.xZ[i] = j;
         }
         ae_assert(vcorner != 0.0, "UpdateTrf: corner element is zero, degeneracy detected");
         v = 1.0 / vcorner;
         for (i = 0; i < m - 1; i++) {
            s->densemu.xR[s->trfage * m + i] = -s->utmp0.xR[i] * v;
         }
         s->densemu.xR[s->trfage * m + m - 1] = v;
      // Multiply row permutation matrix by cyclic permutation applied to L
         reviseddualsimplex_inversecyclicpermutation(&s->rowpermbwd, m, idxd, &s->utmpi);
      // Done
         s->trfage++;
         s->statupdt++;
         s->statoffdiag += (s->sparsel.ridx.xZ[m] - m) + (s->sparseu.ridx.xZ[m] - m);
         processed = true;
      }
      ae_assert(processed, "BasisUpdateTrf: unexpected TRF type");
   }
// Update pricing weights
   ae_assert(settings->pricing == -1 || settings->pricing == 0 || settings->pricing == 1, "BasisUpdateTrf: unexpected Settings.Pricing");
   processed = false;
   if (settings->pricing == -1) {
   // Weights are recomputed from scratch at every step.
   // VERY, VERY time consuming, used only for debug purposes.
      s->dsevalid = false;
      reviseddualsimplex_basisrequestweights(s, settings);
      processed = true;
   }
   if (settings->pricing == 0) {
   // Weights are filled by 1.0
      if (!s->dsevalid) {
         for (i = 0; i < m; i++) {
            s->dseweights.xR[i] = 1.0;
         }
         s->dsevalid = true;
      }
      processed = true;
   }
   if (settings->pricing == 1) {
   // Weights are computed using DSE update formula.
      if (s->dsevalid) {
      // Compute using update formula
         for (i = 0; i < m; i++) {
            if (i != r) {
               s->dseweights.xR[i] -= 2.0 * (alphaq->xR[i] / alphaq->xR[r]) * tau->xR[i] - s->dseweights.xR[r] * sqr(alphaq->xR[i] / alphaq->xR[r]);
               s->dseweights.xR[i] = rmax2(s->dseweights.xR[i], minbeta);
            }
         }
         s->dseweights.xR[r] /= alphaq->xR[r] * alphaq->xR[r];
      } else {
      // No prior values, compute from scratch (usually it is done only once)
         reviseddualsimplex_basisrequestweights(s, settings);
      }
      processed = true;
   }
   ae_assert(processed, "BasisUpdateTrf: unexpected pricing type");
}

// This function caches information for I-th column of the  basis,  which  is
// assumed to store variable K:
// * lower bound in S.BndLB[I] == S.BndL[K]
// * upper bound in S.BndUB[I] == S.BndU[K]
// * bound type in  S.BndTB[I] == S.BndT[K]
// * lower bound primal error tolerance in S.BndTolLB[I] (nonnegative)
// * upper bound primal error tolerance in S.BndTolLB[I] (nonnegative).
// ALGLIB: Copyright 18.07.2020 by Sergey Bochkanov
static void reviseddualsimplex_cacheboundinfo(dualsimplexsubproblem *s, ae_int_t i, ae_int_t k, dualsimplexsettings *settings) {
   s->bndlb.xR[i] = s->bndl.xR[k];
   s->bndub.xR[i] = s->bndu.xR[k];
   s->bndtb.xZ[i] = s->bndt.xZ[k];
   s->bndtollb.xR[i] = settings->xtolabs + settings->xtolrelabs * settings->xtolabs * fabs(s->bndlb.xR[i]);
   s->bndtolub.xR[i] = settings->xtolabs + settings->xtolrelabs * settings->xtolabs * fabs(s->bndub.xR[i]);
}

#if 0 //(@) Not used.
static double reviseddualsimplex_sparsityof(RVector *x, ae_int_t n) {
   ae_int_t i;
   ae_int_t k;
   double mx;
   double result;
   if (n <= 1) {
      result = 0.0;
      return result;
   }
   mx = 1.0;
   for (i = 0; i < n; i++) {
      mx = rmax2(mx, fabs(x->xR[i]));
   }
   mx *= 100000.0 * machineepsilon;
   k = 0;
   for (i = 0; i < n; i++) {
      if (!SmallAtR(x->xR[i], mx)) {
         k++;
      }
   }
   result = (double)k / n;
   return result;
}
#endif

// This function performs update of XB, XN, D and Z during final step of revised
// dual simplex method.
//
// It also updates basis cache of the subproblem (s.bcache field).
//
// Depending on Settings.RatioTest, following operations are performed:
// * Settings.RatioTest == 0 -> simple update is performed
// * Settings.RatioTest == 1 -> bounds flipping ratio test update is performed
// * Settings.RatioTest == 2 -> stabilizing bounds flipping ratio test update is performed
//
// It accepts following parameters:
// * P - index of leaving variable from pricing step
// * Q - index of entering variable.
// * R - index of leaving variable in AlphaQ
// * Delta    - delta from pricing step
// * AlphaPiv - pivot element (in absence of numerical rounding it is AlphaR[Q] == AlphaQ[R])
// * ThetaP   - primal step length
// * ThetaD   - dual step length
// * AlphaQ   - pivot column
// * AlphaQim - intermediate result from Ftran for AlphaQ, used for
//              Forest-Tomlin update, not referenced when other update scheme is set
// * AlphaR   - pivot row
// * Tau - tau-vector for DSE pricing (ignored if simple pricing is used)
// * PossibleAlphaRFlips, PossibleAlphaRFlipsCnt - outputs of the RatioTest()
//   information about possible variable flips - indexes of AlphaR positions
//   which are considered for flipping due to BFRT (however, we have to check
//   residual costs before actually flipping variables - it is possible that some variables
//   in this set actually do not need flipping)
//
// It performs following operations:
// * basis update
// * update of XB/BndTB/BndLB/BndUB[] and XA[] (basic and nonbasic components), D
// * update of pricing weights
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_updatestep(dualsimplexstate *state, dualsimplexsubproblem *s, ae_int_t p, ae_int_t q, ae_int_t r, double delta, double alphapiv, double thetap, double thetad, RVector *alphaq, RVector *alphaqim, dssvector *alphar, RVector *tau, ZVector *possiblealpharflips, ae_int_t possiblealpharflipscnt, dualsimplexsettings *settings) {
   ae_int_t nx;
   ae_int_t m;
   ae_int_t ii;
   ae_int_t j;
   ae_int_t k;
   ae_int_t aj;
   ae_int_t k0;
   ae_int_t k1;
   double bndl;
   double bndu;
   bool flipped;
   double flip;
   double dj;
   ae_int_t dir;
   ae_int_t idx;
   ae_int_t actualflipscnt;
   ae_int_t alpharlen;
   nx = s->ns + s->m;
   m = s->m;
// Integrity checks
   ae_assert(settings->ratiotest == 0 || settings->ratiotest == 1 || settings->ratiotest == 2, "UpdateStep: invalid X");
   ae_assert(s->state == reviseddualsimplex_ssvalid, "UpdateStep: invalid X");
   ae_assert(p >= 0 && q >= 0, "UpdateStep: invalid P/Q");
   ae_assert(delta != 0.0, "UpdateStep: Delta == 0");
   ae_assert(alphapiv != 0.0, "UpdateStep: AlphaPiv == 0");
// Prepare
   dir = sign(delta);
   alpharlen = alphar->k;
   flip = 0.0;
   vectorsetlengthatleast(&state->tmp0, m);
   for (k = 0; k < m; k++) {
      state->tmp0.xR[k] = 0.0;
   }
   vectorsetlengthatleast(&state->ustmpi, nx);
   actualflipscnt = 0;
// Evaluate and update non-basic elements of D
   for (ii = 0; ii < alpharlen; ii++) {
      j = alphar->idx.xZ[ii];
      s->d.xR[j] -= thetad * alphar->vals.xR[ii];
   }
   for (ii = 0; ii < possiblealpharflipscnt; ii++) {
      aj = possiblealpharflips->xZ[ii];
      j = alphar->idx.xZ[aj];
      dj = s->d.xR[j];
      bndl = s->bndl.xR[j];
      bndu = s->bndu.xR[j];
      flipped = false;
      if (s->xa.xR[j] == bndl && dj < 0.0) {
         flip = bndu - bndl;
         flipped = true;
      } else {
         if (s->xa.xR[j] == bndu && dj > 0.0) {
            flip = bndl - bndu;
            flipped = true;
         }
      }
      if (flipped) {
         delta -= dir * (bndu - bndl) * fabs(alphar->vals.xR[aj]);
         state->ustmpi.xZ[actualflipscnt] = j;
         actualflipscnt++;
         k0 = state->at.ridx.xZ[j];
         k1 = state->at.ridx.xZ[j + 1] - 1;
         for (k = k0; k <= k1; k++) {
            idx = state->at.idx.xZ[k];
            state->tmp0.xR[idx] += flip * state->at.vals.xR[k];
         }
      }
   }
   s->d.xR[p] = -thetad;
   s->d.xR[q] = 0.0;
// Apply BFRT update (aka long dual step) or simple ratio update
   if (actualflipscnt > 0) {
      thetap = delta / alphapiv;
      k0 = state->at.ridx.xZ[q];
      k1 = state->at.ridx.xZ[q + 1] - 1;
      for (k = k0; k <= k1; k++) {
         idx = state->at.idx.xZ[k];
         state->tmp0.xR[idx] += thetap * state->at.vals.xR[k];
      }
      reviseddualsimplex_basissolve(&state->basis, &state->tmp0, &state->tmp1, &state->tmp2);
      for (j = 0; j < m; j++) {
         s->xb.xR[j] -= state->tmp1.xR[j];
      }
      for (ii = 0; ii < actualflipscnt; ii++) {
         j = state->ustmpi.xZ[ii];
         if (s->xa.xR[j] == s->bndl.xR[j]) {
            s->xa.xR[j] = s->bndu.xR[j];
         } else {
            s->xa.xR[j] = s->bndl.xR[j];
         }
      }
      s->xb.xR[r] = s->xa.xR[q] + thetap;
      if (dir < 0) {
         s->xa.xR[p] = s->bndl.xR[p];
      } else {
         s->xa.xR[p] = s->bndu.xR[p];
      }
   } else {
      for (j = 0; j < m; j++) {
         s->xb.xR[j] -= thetap * alphaq->xR[j];
      }
      s->xb.xR[r] = s->xa.xR[q] + thetap;
      if (dir < 0) {
         s->xa.xR[p] = s->bndl.xR[p];
      } else {
         s->xa.xR[p] = s->bndu.xR[p];
      }
   }
// Update basis
   reviseddualsimplex_basisupdatetrf(&state->basis, &state->at, p, q, alphaq, alphaqim, r, tau, settings);
// Update cached variables
   reviseddualsimplex_cacheboundinfo(s, r, q, settings);
}

// This function performs several checks for accumulation of errors during
// factorization update. It returns True if refactorization is advised.
// ALGLIB: Copyright 24.01.2019 by Sergey Bochkanov
static bool reviseddualsimplex_refactorizationrequired(dualsimplexstate *state, dualsimplexsubproblem *s, ae_int_t q, double alpharpiv, ae_int_t r, double alphaqpiv) {
   const ae_int_t safetrfage = 5;
   const double alphatrigger = 100000000.0 * machineepsilon, alphatrigger2 = 0.001;
   ae_int_t m;
   ae_int_t i;
   double mx;
   double v;
   bool result;
   m = s->m;
   result = false;
// Quick exit
   if (state->basis.trfage <= safetrfage) {
      return result;
   }
// Compare Q-th entry of the pivot row AlphaR with R-th entry of the AlphaQ;
// ideally, both should match exactly. The difference is a rough estimate
// of the magnitude of the numerical errors.
   mx = 0.0;
   for (i = 0; i < m; i++) {
      v = state->alphaq.xR[i];
      v *= v;
      if (v > mx) {
         mx = v;
      }
   }
   mx = sqrt(mx);
   result = result || !NearAtR(alphaqpiv, alpharpiv, alphatrigger * (1.0 + mx));
   result = result || !NearAtR(alphaqpiv, alpharpiv, alphatrigger2 * fabs(alpharpiv));
   return result;
}

// Returns maximum dual infeasibility (only non-basic variables are  checked,
// we assume that basic variables are good enough).
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static double reviseddualsimplex_dualfeasibilityerror(dualsimplexstate *state, dualsimplexsubproblem *s) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t nn;
   ae_int_t bndt;
   double result;
   nn = s->ns;
   ae_assert(s->state == reviseddualsimplex_ssvalid, "DualFeasibilityError: invalid X");
   result = 0.0;
   for (i = 0; i < nn; i++) {
      j = state->basis.nidx.xZ[i];
      bndt = s->bndt.xZ[j];
      if (bndt == reviseddualsimplex_ccfixed) {
         continue;
      }
      if (bndt == reviseddualsimplex_ccrange) {
         if (s->xa.xR[j] == s->bndl.xR[j]) {
            result = rmax2(result, -s->d.xR[j]);
            continue;
         }
         if (s->xa.xR[j] == s->bndu.xR[j]) {
            result = rmax2(result, s->d.xR[j]);
            continue;
         }
         ae_assert(false, "DualFeasibilityError: integrity check failed");
      }
      if (bndt == reviseddualsimplex_cclower) {
         ae_assert(s->xa.xR[j] == s->bndl.xR[j], "DualFeasibilityError: integrity check failed");
         result = rmax2(result, -s->d.xR[j]);
         continue;
      }
      if (bndt == reviseddualsimplex_ccupper) {
         ae_assert(s->xa.xR[j] == s->bndu.xR[j], "DualFeasibilityError: integrity check failed");
         result = rmax2(result, s->d.xR[j]);
         continue;
      }
      if (bndt == reviseddualsimplex_ccfree) {
         result = rmax2(result, fabs(s->d.xR[j]));
         continue;
      }
      ae_assert(false, "DSSOptimize: integrity check failed (infeasible constraint)");
   }
   return result;
}

// Returns True for dual feasible basis (some minor dual feasibility error is
// allowed), False otherwise
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static bool reviseddualsimplex_isdualfeasible(dualsimplexstate *state, dualsimplexsubproblem *s, dualsimplexsettings *settings) {
   bool result;
   result = reviseddualsimplex_dualfeasibilityerror(state, s) <= settings->dtolabs;
   return result;
}

// Offloads basic components of X[], BndT[], BndL[], BndU[] to XB/BndTB/BndLB/BndUB.
// ALGLIB: Copyright 24.01.2019 by Sergey Bochkanov
static void reviseddualsimplex_offloadbasiccomponents(dualsimplexsubproblem *s, dualsimplexbasis *basis, dualsimplexsettings *settings) {
   ae_int_t i;
   ae_int_t m;
   m = basis->m;
   for (i = 0; i < m; i++) {
      s->xb.xR[i] = s->xa.xR[basis->idx.xZ[i]];
      reviseddualsimplex_cacheboundinfo(s, i, basis->idx.xZ[i], settings);
   }
}

// Recombines basic and non-basic components in X[]
// ALGLIB: Copyright 24.01.2019 by Sergey Bochkanov
static void reviseddualsimplex_recombinebasicnonbasicx(dualsimplexsubproblem *s, dualsimplexbasis *basis) {
   ae_int_t m;
   ae_int_t i;
   m = basis->m;
   for (i = 0; i < m; i++) {
      s->xa.xR[basis->idx.xZ[i]] = s->xb.xR[i];
   }
}

// This function performs actual solution of dual simplex subproblem  (either
// primary one or phase 1 one).
//
// A problem with following properties is expected:
// * M > 0
// * feasible box constraints
// * dual feasible initial basis
// * actual initial point XC and target value Z
// * actual reduced cost vector D
// * pricing weights being set to 1.0 or copied from previous problem
//
// Returns:
//     * Info = +1 for success, -3 for infeasible
//     * IterationsCount is increased by amount of iterations performed
//
// NOTE: this function internally uses separate storage of basic and nonbasic
//       components; however, all inputs and outputs use single array S.XA[]
//       to store both basic and nonbasic variables. It transparently splits
//       variables on input and recombines them on output.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_solvesubproblemdual(dualsimplexstate *state, dualsimplexsubproblem *s, bool isphase1, dualsimplexsettings *settings, ae_int_t *info) {
   const ae_int_t maxforcedrestarts = 1;
   ae_int_t nx;
   ae_int_t m;
   ae_int_t i;
   ae_int_t p;
   ae_int_t r;
   ae_int_t q;
   double alpharpiv;
   double alphaqpiv;
   double thetad;
   double thetap;
   double delta;
   ae_int_t forcedrestarts;
   *info = 0;
   nx = s->ns + s->m;
   m = s->m;
   forcedrestarts = 0;
// Integrity checks
   ae_assert(s->state == reviseddualsimplex_ssvalid, "SolveSubproblemDual: X is not valid");
   ae_assert(m > 0, "SolveSubproblemDual: M <= 0");
   for (i = 0; i < nx; i++) {
      ae_assert(s->bndt.xZ[i] != reviseddualsimplex_ccinfeasible, "SolveSubproblemDual: infeasible box constraints");
   }
   ae_assert(reviseddualsimplex_isdualfeasible(state, s, settings), "SolveSubproblemDual: dual infeasible initial basis");
// Actual processing
   reviseddualsimplex_offloadbasiccomponents(s, &state->basis, settings);
   *info = 0;
   vectorsetlengthatleast(&state->tmp0, m);
   while (true) {
   // Pricing
      reviseddualsimplex_pricingstep(state, s, isphase1, &p, &r, &delta, settings);
      if (delta == 0.0) {
      // Solved! Feasible and bounded!
         reviseddualsimplex_recombinebasicnonbasicx(s, &state->basis);
         *info = 1;
         return;
      }
   // BTran
      reviseddualsimplex_btranstep(state, s, r, &state->rhor, settings);
   // Pivot row
      reviseddualsimplex_pivotrowstep(state, s, &state->rhor, &state->alphar, settings);
   // Ratio test
      reviseddualsimplex_ratiotest(state, s, &state->alphar, delta, p, &q, &alpharpiv, &thetad, &state->possibleflips, &state->possibleflipscnt, settings);
      if (q < 0) {
      // Do we have fresh factorization and state? If not,
      // refresh them prior to declaring that we have no solution.
         if (state->basis.trfage > 0 && forcedrestarts < maxforcedrestarts) {
            reviseddualsimplex_basisfreshtrf(&state->basis, &state->at, settings);
            reviseddualsimplex_subproblemhandlexnupdate(state, s);
            reviseddualsimplex_offloadbasiccomponents(s, &state->basis, settings);
            forcedrestarts++;
            continue;
         }
      // Dual unbounded, primal infeasible
         reviseddualsimplex_recombinebasicnonbasicx(s, &state->basis);
         *info = -3;
         return;
      }
      thetap = delta / alpharpiv;
   // FTran, including additional FTran for DSE weights (if needed)
   //
   // NOTE: AlphaQim is filled by intermediate FTran result which is useful
   //       for Forest-Tomlin update scheme. If not Forest-Tomlin update is
   //       used, then it is not set.
      reviseddualsimplex_ftranstep(state, s, &state->rhor, q, &state->alphaq, &state->alphaqim, &state->tau, settings);
      alphaqpiv = state->alphaq.xR[r];
   // Check numerical accuracy, trigger refactorization if needed
      if (reviseddualsimplex_refactorizationrequired(state, s, q, alpharpiv, r, alphaqpiv)) {
         reviseddualsimplex_basisfreshtrf(&state->basis, &state->at, settings);
         reviseddualsimplex_subproblemhandlexnupdate(state, s);
         reviseddualsimplex_offloadbasiccomponents(s, &state->basis, settings);
         continue;
      }
   // Basis change and update
      reviseddualsimplex_updatestep(state, s, p, q, r, delta, alpharpiv, thetap, thetad, &state->alphaq, &state->alphaqim, &state->alphar, &state->tau, &state->possibleflips, state->possibleflipscnt, settings);
      state->repiterationscount++;
      if (isphase1) {
         state->repiterationscount1++;
      } else {
         state->repiterationscount2++;
      }
   }
}

// Returns True if I-th lower bound is present
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static bool reviseddualsimplex_hasbndl(dualsimplexsubproblem *subproblem, ae_int_t i) {
   ae_int_t k;
   bool result;
   k = subproblem->bndt.xZ[i];
   result = false;
   if (k == 0 || k == 1 || k == 3) {
      result = true;
      return result;
   }
   if (k == 2 || k == 4) {
      result = false;
      return result;
   }
   ae_assert(false, "HasBndL: integrity check failed");
   return result;
}

// Returns True if I-th upper bound is present
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static bool reviseddualsimplex_hasbndu(dualsimplexsubproblem *subproblem, ae_int_t i) {
   ae_int_t k;
   bool result;
   k = subproblem->bndt.xZ[i];
   result = false;
   if (k == 0 || k == 2 || k == 3) {
      result = true;
      return result;
   }
   if (k == 1 || k == 4) {
      result = false;
      return result;
   }
   ae_assert(false, "HasBndL: integrity check failed");
   return result;
}

// This function solves simplex subproblem using primal simplex method.
//
// A problem with following properties is expected:
// * M > 0
// * feasible box constraints
// * primal feasible initial basis
// * actual initial point XC and target value Z
// * actual reduced cost vector D
// * pricing weights being set to 1.0 or copied from previous problem
//
// Returns:
//     * Info = +1 for success, -3 for infeasible
//     * IterationsCount is increased by amount of iterations performed
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_solvesubproblemprimal(dualsimplexstate *state, dualsimplexsubproblem *s, dualsimplexsettings *settings, ae_int_t *info) {
   ae_int_t nn;
   ae_int_t nx;
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   double v;
   double vmax;
   ae_int_t bi;
   double dj;
   ae_int_t bndt;
   ae_int_t q;
   ae_int_t p;
   ae_int_t r;
   ae_int_t dir;
   double lim;
   bool haslim;
   double thetap;
   double xbnd;
   double flip;
   ae_int_t canddir;
   double candlim;
   double candflip;
   ae_int_t j0;
   ae_int_t j1;
   double alphawave;
   double vp;
   double vb;
   double vx;
   double vtest;
   double vv;
   *info = 0;
   nn = s->ns;
   nx = s->ns + s->m;
   m = s->m;
// Integrity checks
   ae_assert(s->state == reviseddualsimplex_ssvalid, "SolveSubproblemPrimal: X is not valid");
   ae_assert(m > 0, "SolveSubproblemPrimal: M <= 0");
   for (i = 0; i < nx; i++) {
      ae_assert(s->bndt.xZ[i] != reviseddualsimplex_ccinfeasible, "SolveSubproblemPrimal: infeasible box constraints");
   }
// Actual processing
   *info = 1;
   vectorsetlengthatleast(&state->tmp0, m);
   while (true) {
   // Primal simplex pricing step: we implement the very basic version
   // of the pricing step because it is expected that primal simplex method
   // is used just to apply quick correction after removal of the perturbation.
      q = -1;
      vmax = 0.0;
      dir = 0;
      lim = maxrealnumber;
      haslim = false;
      flip = 0.0;
      canddir = 0;
      for (i = 0; i < nn; i++) {
         j = state->basis.nidx.xZ[i];
         dj = s->d.xR[j];
         bndt = s->bndt.xZ[j];
         if (bndt == reviseddualsimplex_ccfixed) {
            continue;
         }
         if (bndt == reviseddualsimplex_ccrange) {
            v = 0.0;
            candlim = s->bndu.xR[j] - s->bndl.xR[j];
            candflip = 0.0;
            if (s->xa.xR[j] == s->bndl.xR[j]) {
               v = -dj;
               canddir = 1;
               candflip = s->bndu.xR[j];
            }
            if (s->xa.xR[j] == s->bndu.xR[j]) {
               v = dj;
               canddir = -1;
               candflip = s->bndl.xR[j];
            }
            if (v > vmax) {
               vmax = v;
               dir = canddir;
               lim = candlim;
               haslim = true;
               flip = candflip;
               q = j;
            }
            continue;
         }
         v = 0.0;
         canddir = 0;
         if (bndt == reviseddualsimplex_cclower) {
            v = -dj;
            canddir = 1;
         }
         if (bndt == reviseddualsimplex_ccupper) {
            v = dj;
            canddir = -1;
         }
         if (bndt == reviseddualsimplex_ccfree) {
            v = fabs(dj);
            canddir = -sign(dj);
         }
         if (v > vmax) {
            vmax = v;
            dir = canddir;
            lim = maxrealnumber;
            haslim = false;
            q = j;
         }
         continue;
      }
      if (vmax <= settings->dtolabs) {
      // Solved: primal and dual feasible!
         return;
      }
      ae_assert(q >= 0, "SolveSubproblemPrimal: integrity check failed");
   // FTran and textbook ratio test (again, we expect primal phase to terminate quickly)
   //
   // NOTE: AlphaQim is filled by intermediate FTran result which is useful
   //       for Forest-Tomlin update scheme. If not Forest-Tomlin update is
   //       used, then it is not set.
      for (i = 0; i < m; i++) {
         state->tmp0.xR[i] = 0.0;
      }
      j0 = state->at.ridx.xZ[q];
      j1 = state->at.ridx.xZ[q + 1] - 1;
      for (j = j0; j <= j1; j++) {
         state->tmp0.xR[state->at.idx.xZ[j]] = state->at.vals.xR[j];
      }
      reviseddualsimplex_basissolvex(&state->basis, &state->tmp0, &state->alphaq, &state->alphaqim, true, &state->tmp2);
      vp = settings->pivottol;
      p = -1;
      r = -1;
      thetap = 0.0;
      xbnd = 0.0;
      for (i = 0; i < m; i++) {
         bi = state->basis.idx.xZ[i];
         alphawave = -dir * state->alphaq.xR[i];
         vx = s->xa.xR[bi];
         if (alphawave < -vp && reviseddualsimplex_hasbndl(s, bi)) {
            vb = s->bndl.xR[bi];
            if (vx <= vb) {
            // X[Bi] is already out of bounds due to rounding errors, perform shifting
               vb = vx - reviseddualsimplex_shiftlen;
               s->bndl.xR[bi] = vx;
            }
            vtest = (vb - vx) / alphawave;
            if (p < 0 || vtest < thetap) {
               p = bi;
               r = i;
               thetap = vtest;
               xbnd = vb;
            }
         }
         if (alphawave > vp && reviseddualsimplex_hasbndu(s, bi)) {
            vb = s->bndu.xR[bi];
            if (vx >= vb) {
            // X[Bi] is already out of bounds due to rounding errors, perform shifting
               vb = vx + reviseddualsimplex_shiftlen;
               s->bndu.xR[bi] = vb;
            }
            vtest = (vb - vx) / alphawave;
            if (p < 0 || vtest < thetap) {
               p = bi;
               r = i;
               thetap = vtest;
               xbnd = vb;
            }
         }
      }
      if (p < 0 && !haslim) {
      // Primal unbounded
         *info = -4;
         return;
      }
   // Update step
      if (p >= 0 && (!haslim || thetap < lim)) {
      // One of the basic variables hit the boundary and become non-basic.
      //
      // Perform update:
      // * update basic elements of X[] (X[p] is explicitly set to the
      //   boundary value) and X[q]
      // * update target value Z
      // * update factorization
      // * update D[]
         vectorsetlengthatleast(&state->tmp0, m);
         for (i = 0; i < m; i++) {
            bi = state->basis.idx.xZ[i];
            vv = thetap * (dir * state->alphaq.xR[i]);
            s->xa.xR[bi] -= vv;
         }
         s->xa.xR[p] = xbnd;
         s->xa.xR[q] += dir * thetap;
         for (i = 0; i < m; i++) {
            state->tmp0.xR[i] = 0.0;
         }
         reviseddualsimplex_basisupdatetrf(&state->basis, &state->at, p, q, &state->alphaq, &state->alphaqim, r, &state->tmp0, settings);
         for (i = 0; i < m; i++) {
            state->tmp0.xR[i] = s->effc.xR[state->basis.idx.xZ[i]];
         }
         reviseddualsimplex_basissolvet(&state->basis, &state->tmp0, &state->tmp1, &state->tmp2);
         reviseddualsimplex_computeantv(state, &state->tmp1, &s->d);
         for (i = 0; i < nn; i++) {
            j = state->basis.nidx.xZ[i];
            s->d.xR[j] = s->effc.xR[j] - s->d.xR[j];
         }
      } else {
      // Basis does not change because Qth variable flips from one bound
      // to another one long before we encounter the boundary
         s->xa.xR[q] = flip;
         for (i = 0; i < m; i++) {
            bi = state->basis.idx.xZ[i];
            vv = lim * (dir * state->alphaq.xR[i]);
            s->xa.xR[bi] -= vv;
         }
      }
      state->repiterationscount++;
      state->repiterationscount3++;
   }
}

// This function estimates feasibility properties of the  current  basis  and
// invokes phase 1 if necessary.
//
// A problem with following properties is expected:
// * M > 0
// * feasible box constraints
// * some initial basis (can be dual infeasible) with actual factorization
// * actual initial point XC and target value Z
// * actual reduced cost vector D
//
// It returns:
// * +1 if dual feasible basis was found
// * -4 if problem is dual infeasible
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_invokephase1(dualsimplexstate *state, dualsimplexsettings *settings) {
   ae_int_t m;
   double dualerr;
   m = state->primary.m;
   state->repterminationtype = 0;
// Integrity checks
   ae_assert(state->primary.state == reviseddualsimplex_ssvalid, "InvokePhase1: invalid primary X");
   ae_assert(m > 0, "InvokePhase1: M <= 0");
// Is it dual feasible from the very beginning (or maybe after initial DFC)?
   dualerr = reviseddualsimplex_initialdualfeasibilitycorrection(state, &state->primary, settings);
   if (dualerr <= settings->dtolabs) {
      state->repterminationtype = 1;
      return;
   }
// Solve phase #1 subproblem
   reviseddualsimplex_subprobleminitphase1(&state->primary, &state->basis, &state->phase1);
   dualerr = reviseddualsimplex_initialdualfeasibilitycorrection(state, &state->phase1, settings);
   reviseddualsimplex_solvesubproblemdual(state, &state->phase1, true, settings, &state->repterminationtype);
   ae_assert(state->repterminationtype > 0, "DualSimplexSolver: unexpected failure of phase #1");
   state->repterminationtype = 1;
// Setup initial basis for phase #2 using solution of phase #1
   reviseddualsimplex_subprobleminferinitialxn(state, &state->primary);
   dualerr = reviseddualsimplex_initialdualfeasibilitycorrection(state, &state->primary, settings);
   if (dualerr > settings->dtolabs) {
      state->repterminationtype = -4;
      return;
   }
   state->repterminationtype = 1;
}

// Box-constrained solver; sets State.RepX, State.RepStats and State.RepTerminationType,
// does not change other fields.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_solveboxonly(dualsimplexstate *state) {
   ae_int_t i;
   ae_int_t ns;
   ns = state->primary.ns;
   ae_assert(state->primary.m == 0, "SolveBoxOnly: integrity check failed");
   rsetv(ns, 0.0, &state->replagbc);
   for (i = 0; i < ns; i++) {
   // Handle infeasible variable
      if (state->primary.bndt.xZ[i] == reviseddualsimplex_ccinfeasible) {
         state->repterminationtype = -3;
         state->repx.xR[i] = 0.5 * (state->primary.bndl.xR[i] + state->primary.bndu.xR[i]);
         state->repstats.xZ[i] = 0;
         continue;
      }
   // Handle fixed variable
      if (state->primary.bndt.xZ[i] == reviseddualsimplex_ccfixed) {
         state->repx.xR[i] = state->primary.bndl.xR[i];
         state->repstats.xZ[i] = -1;
         state->replagbc.xR[i] = -state->primary.rawc.xR[i];
         continue;
      }
   // Handle non-zero cost component
      if (state->primary.rawc.xR[i] > 0.0) {
         if (state->primary.bndt.xZ[i] != reviseddualsimplex_ccrange && state->primary.bndt.xZ[i] != reviseddualsimplex_cclower) {
            if (state->repterminationtype > 0) {
               state->repterminationtype = -4;
            }
            if (state->primary.bndt.xZ[i] == reviseddualsimplex_ccupper) {
               state->repx.xR[i] = state->primary.bndu.xR[i];
               state->repstats.xZ[i] = 1;
            } else {
               state->repx.xR[i] = 0.0;
               state->repstats.xZ[i] = 0;
            }
            state->replagbc.xR[i] = 0.0;
         } else {
            state->repx.xR[i] = state->primary.bndl.xR[i];
            state->repstats.xZ[i] = -1;
            state->replagbc.xR[i] = -state->primary.rawc.xR[i];
         }
         continue;
      }
      if (state->primary.rawc.xR[i] < 0.0) {
         if (state->primary.bndt.xZ[i] != reviseddualsimplex_ccrange && state->primary.bndt.xZ[i] != reviseddualsimplex_ccupper) {
            if (state->repterminationtype > 0) {
               state->repterminationtype = -4;
            }
            if (state->primary.bndt.xZ[i] == reviseddualsimplex_cclower) {
               state->repx.xR[i] = state->primary.bndl.xR[i];
               state->repstats.xZ[i] = -1;
            } else {
               state->repx.xR[i] = 0.0;
               state->repstats.xZ[i] = 0;
            }
            state->replagbc.xR[i] = 0.0;
         } else {
            state->repx.xR[i] = state->primary.bndu.xR[i];
            state->repstats.xZ[i] = 1;
            state->replagbc.xR[i] = -state->primary.rawc.xR[i];
         }
         continue;
      }
   // Handle non-free variable with zero cost component
      if (state->primary.bndt.xZ[i] == reviseddualsimplex_ccupper || state->primary.bndt.xZ[i] == reviseddualsimplex_ccrange) {
         state->repx.xR[i] = state->primary.bndu.xR[i];
         state->repstats.xZ[i] = 1;
         state->replagbc.xR[i] = 0.0;
         continue;
      }
      if (state->primary.bndt.xZ[i] == reviseddualsimplex_cclower) {
         state->repx.xR[i] = state->primary.bndl.xR[i];
         state->repstats.xZ[i] = -1;
         state->replagbc.xR[i] = 0.0;
         continue;
      }
   // Free variable, zero cost component
      ae_assert(state->primary.bndt.xZ[i] == reviseddualsimplex_ccfree, "DSSOptimize: integrity check failed");
      state->repx.xR[i] = 0.0;
      state->repstats.xZ[i] = 0;
      state->replagbc.xR[i] = 0.0;
   }
}

// Zero-fill RepX, RepLagBC, RepLagLC, RepStats.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_setzeroxystats(dualsimplexstate *state) {
   ae_int_t i;
   for (i = 0; i < state->primary.ns; i++) {
      state->repx.xR[i] = 0.0;
      state->replagbc.xR[i] = 0.0;
   }
   for (i = 0; i < state->primary.m; i++) {
      state->replaglc.xR[i] = 0.0;
   }
   for (i = 0; i < state->primary.ns + state->primary.m; i++) {
      state->repstats.xZ[i] = 0;
   }
}

// Returns True if I-th variable if free
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static bool reviseddualsimplex_isfree(dualsimplexsubproblem *subproblem, ae_int_t i) {
   ae_int_t k;
   bool result;
   k = subproblem->bndt.xZ[i];
   result = false;
   if (k == 0 || k == 1 || k == 2 || k == 3) {
      result = false;
      return result;
   }
   if (k == 4) {
      result = true;
      return result;
   }
   ae_assert(false, "IsFree: integrity check failed");
   return result;
}

// Computes Stats array
//
// Inputs:
//     S           -   problem, contains current solution at S.XA
//     Basis       -   basis
//     X           -   possibly preallocated output buffer
//     LagBC       -   possibly preallocated output buffer
//     LagLC       -   possibly preallocated output buffer
//     Stats       -   possibly preallocated output buffer
//     Buffers     -   temporary buffers
//
// Outputs:
//     X           -   array[NS], solution
//     LagBC       -   array[NS], Lagrange multipliers for box constraints
//     LagLC       -   array[M], Lagrange multipliers for linear constraints
//     Stats       -   array[NS+M], primary/slack variable stats:
//                     * -1 = variable at lower bound
//                     * +1 = variable at upper bound
//                     *  0 = basic or free (possibly nonbasic) variable
//                     fixed variables may be set to +1 or -1
// ALGLIB: Copyright 24.01.2019 by Sergey Bochkanov
static void reviseddualsimplex_setxydstats(dualsimplexstate *state, dualsimplexsubproblem *s, dualsimplexbasis *basis, apbuffers *buffers, RVector *x, RVector *lagbc, RVector *laglc, ZVector *stats) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t m;
   ae_int_t ns;
   ae_int_t nx;
// Prepare
   m = s->m;
   ns = s->ns;
   nx = s->ns + s->m;
   vectorsetlengthatleast(x, ns);
   vectorsetlengthatleast(laglc, m);
   vectorsetlengthatleast(stats, nx);
   rsetallocv(ns, 0.0, lagbc);
// Compute Y (in Buffers.RA1) and D (in Buffers.RA3)
   vectorsetlengthatleast(&buffers->ra0, m);
   vectorsetlengthatleast(&buffers->ra1, m);
   vectorsetlengthatleast(&buffers->ra3, nx);
   for (i = 0; i < m; i++) {
      buffers->ra0.xR[i] = s->rawc.xR[basis->idx.xZ[i]];
   }
   reviseddualsimplex_basissolvet(basis, &buffers->ra0, &buffers->ra1, &buffers->ra2);
   reviseddualsimplex_computeantv(state, &buffers->ra1, &buffers->ra3);
   for (i = 0; i < ns; i++) {
      j = state->basis.nidx.xZ[i];
      buffers->ra3.xR[j] = state->primary.rawc.xR[j] - buffers->ra3.xR[j];
      if (j < ns) {
         lagbc->xR[j] = -buffers->ra3.xR[j];
      }
   }
   for (i = 0; i < m; i++) {
      buffers->ra3.xR[state->basis.idx.xZ[i]] = 0.0;
   }
// Compute X, Y, Stats
   for (i = 0; i < ns; i++) {
      x->xR[i] = s->xa.xR[i];
      if (isfinite(state->rawbndl.xR[i])) {
         x->xR[i] = rmax2(x->xR[i], state->rawbndl.xR[i]);
      }
      if (isfinite(state->rawbndu.xR[i])) {
         x->xR[i] = rmin2(x->xR[i], state->rawbndu.xR[i]);
      }
   }
   for (i = 0; i < ns; i++) {
      if (basis->isbasic.xB[i]) {
         lagbc->xR[i] = 0.0;
         continue;
      }
      if (s->bndt.xZ[i] == reviseddualsimplex_ccfixed) {
         continue;
      }
      if (reviseddualsimplex_hasbndl(s, i) && s->xa.xR[i] == s->bndl.xR[i]) {
         lagbc->xR[i] = rmin2(lagbc->xR[i], 0.0);
         continue;
      }
      if (reviseddualsimplex_hasbndu(s, i) && s->xa.xR[i] == s->bndu.xR[i]) {
         lagbc->xR[i] = rmax2(lagbc->xR[i], 0.0);
         continue;
      }
      ae_assert(!reviseddualsimplex_hasbndl(s, i) && !reviseddualsimplex_hasbndu(s, i), "SetStats: integrity check failed (zetta5)");
      lagbc->xR[i] = 0.0;
   }
   for (i = 0; i < m; i++) {
      laglc->xR[i] = -buffers->ra1.xR[i] / state->rowscales.xR[i];
   }
   for (i = 0; i < nx; i++) {
      if (basis->isbasic.xB[i]) {
         stats->xZ[i] = 0;
         continue;
      }
      if (reviseddualsimplex_hasbndl(s, i) && s->xa.xR[i] == s->bndl.xR[i]) {
         stats->xZ[i] = -1;
         continue;
      }
      if (reviseddualsimplex_hasbndu(s, i) && s->xa.xR[i] == s->bndu.xR[i]) {
         stats->xZ[i] = 1;
         continue;
      }
      ae_assert(!reviseddualsimplex_hasbndl(s, i) && !reviseddualsimplex_hasbndu(s, i), "SetStats: integrity check failed (zetta5)");
      stats->xZ[i] = 0;
   }
}

// This function performs actual solution.
//
// Inputs:
//     State   -   state
//
// Solution results can be found in fields  of  State  which  are  explicitly
// declared as accessible by external code.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_dssoptimizewrk(dualsimplexstate *state, dualsimplexsettings *settings) {
   ae_int_t nx;
   ae_int_t m;
   ae_int_t i;
   ae_int_t j;
   double v;
   EnFrame();
   NewObj(hqrndstate, rs);
   nx = state->primary.ns + state->primary.m;
   m = state->primary.m;
// Handle case when M == 0; after this block we assume that M > 0.
   if (m == 0) {
   // Solve
      reviseddualsimplex_solveboxonly(state);
      DeFrame();
   }
// Most basic check for correctness of box and/or linear constraints
   for (j = 0; j < nx; j++) {
      if (state->primary.bndt.xZ[j] == reviseddualsimplex_ccinfeasible) {
      // Set error flag and generate some point to return
         state->repterminationtype = -3;
         reviseddualsimplex_setzeroxystats(state);
         DeFrame();
      }
   }
// Initialization:
// * initial perturbed C[]
   hqrndseed(7456, 2355, &rs);
   for (i = 0; i < nx; i++) {
      if (!reviseddualsimplex_isfree(&state->primary, i)) {
      // apply perturbation
         v = settings->perturbmag * (1.0 + fabs(state->primary.rawc.xR[i])) * (1.0 + hqrnduniformr(&rs));
         if (!reviseddualsimplex_hasbndl(&state->primary, i)) {
            v = -v;
         }
         state->primary.effc.xR[i] = state->primary.rawc.xR[i] + v;
      }
   }
// Solve phase 1 subproblem, then perturbed subproblem
   reviseddualsimplex_basisfreshtrf(&state->basis, &state->at, settings);
   if (state->primary.state == reviseddualsimplex_ssinvalid) {
      reviseddualsimplex_subprobleminferinitialxn(state, &state->primary);
   }
   if (state->primary.state == reviseddualsimplex_ssvalidxn) {
      reviseddualsimplex_subproblemhandlexnupdate(state, &state->primary);
   }
   ae_assert(state->primary.state == reviseddualsimplex_ssvalid, "DSS: integrity check failed (init)");
   reviseddualsimplex_invokephase1(state, settings);
   if (state->repterminationtype <= 0) {
   // Primal unbounded, dual infeasible
      ae_assert(state->repterminationtype == -4, "DSS: integrity check for InvokePhase1() result failed");
      reviseddualsimplex_setxydstats(state, &state->primary, &state->basis, &state->xydsbuf, &state->repx, &state->replagbc, &state->replaglc, &state->repstats);
      DeFrame();
   }
   reviseddualsimplex_solvesubproblemdual(state, &state->primary, false, settings, &state->repterminationtype);
   if (state->repterminationtype <= 0) {
   // Primal infeasible
      ae_assert(state->repterminationtype == -3, "DSS: integrity check for SolveSubproblemDual() result failed");
      reviseddualsimplex_setxydstats(state, &state->primary, &state->basis, &state->xydsbuf, &state->repx, &state->replagbc, &state->replaglc, &state->repstats);
      DeFrame();
   }
// Remove perturbation from the cost vector,
// then use primal simplex to enforce dual feasibility
// after removal of the perturbation (if necessary).
   reviseddualsimplex_subprobleminitphase3(&state->primary, &state->phase3);
   for (i = 0; i < nx; i++) {
      state->phase3.effc.xR[i] = state->primary.rawc.xR[i];
   }
   ae_assert(state->phase3.state >= reviseddualsimplex_ssvalidxn, "DSS: integrity check failed (remove perturbation)");
   reviseddualsimplex_subproblemhandlexnupdate(state, &state->phase3);
   reviseddualsimplex_solvesubproblemprimal(state, &state->phase3, settings, &state->repterminationtype);
   if (state->repterminationtype <= 0) {
   // Dual infeasible, primal unbounded
      ae_assert(state->repterminationtype == -4, "DSS: integrity check for SolveSubproblemPrimal() result failed");
      reviseddualsimplex_setxydstats(state, &state->phase3, &state->basis, &state->xydsbuf, &state->repx, &state->replagbc, &state->replaglc, &state->repstats);
      DeFrame();
   }
   for (i = 0; i < nx; i++) {
      state->primary.xa.xR[i] = state->phase3.xa.xR[i];
      if (reviseddualsimplex_hasbndl(&state->primary, i)) {
         state->primary.xa.xR[i] = rmax2(state->primary.xa.xR[i], state->primary.bndl.xR[i]);
      }
      if (reviseddualsimplex_hasbndu(&state->primary, i)) {
         state->primary.xa.xR[i] = rmin2(state->primary.xa.xR[i], state->primary.bndu.xR[i]);
      }
   }
// Primal and dual feasible, problem solved
   state->repterminationtype = 1;
   reviseddualsimplex_setxydstats(state, &state->primary, &state->basis, &state->xydsbuf, &state->repx, &state->replagbc, &state->replaglc, &state->repstats);
   DeFrame();
}

// This function clears internal performance counters of the basis
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basisclearstats(dualsimplexbasis *s) {
   s->statfact = 0;
   s->statupdt = 0;
   s->statoffdiag = 0.0;
}

// This function initializes basis structure; no triangular factorization is
// prepared yet. Previously allocated memory is reused.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basisinit(ae_int_t ns, ae_int_t m, dualsimplexbasis *s) {
   ae_int_t i;
   s->ns = ns;
   s->m = m;
   ivectorgrowto(&s->idx, m);
   ivectorgrowto(&s->nidx, ns);
   bvectorgrowto(&s->isbasic, ns + m);
   for (i = 0; i < ns; i++) {
      s->nidx.xZ[i] = i;
      s->isbasic.xB[i] = false;
   }
   for (i = 0; i < m; i++) {
      s->idx.xZ[i] = ns + i;
      s->isbasic.xB[ns + i] = true;
   }
   s->trftype = 3;
   s->trfage = 0;
   s->isvalidtrf = false;
   vectorsetlengthatleast(&s->dseweights, m);
   for (i = 0; i < m; i++) {
      s->dseweights.xR[i] = 1.0;
   }
   s->dsevalid = false;
   reviseddualsimplex_basisclearstats(s);
}

// This function resizes basis. It is assumed that constraint matrix is
// completely overwritten by new one, but both matrices are similar enough
// so we can reuse previous basis.
//
// Dual steepest edge weights are invalidated by this function.
//
// This function:
// * tries to resize basis
// * if possible, returns True and valid basis with valid factorization
// * if resize is impossible (or abandoned due to stability reasons), it
//   returns False and basis object is left in the invalid state (you have
//   to reinitialize it by all-logicals basis)
//
// Following types of resize are supported:
// * new basis size is larger than previous one => logical elements are
//   added to the new basis
// * basis sizes match => no operation is performed
// * new basis size is zero => basis is set to zero
//
// This function:
// * requires valid triangular factorization at S on entry
// * replaces it by another, valid factorization
// * checks that new factorization deviates from the previous one not too much
//   by comparing magnitudes of min[abs(u_ii)] in both factorization (sharp
//   decrease results in attempt to resize being abandoned
//
// IMPORTANT: if smooth resize is not possible, this function throws an
//            exception! It is responsibility of the caller to check that
//            smooth resize is possible
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static bool reviseddualsimplex_basistryresize(dualsimplexbasis *s, ae_int_t newm, sparsematrix *at, dualsimplexsettings *settings) {
   ae_int_t ns;
   ae_int_t oldm;
   ae_int_t i;
   double oldminu;
   double newminu;
   bool result;
   ns = s->ns;
   oldm = s->m;
   result = false;
// Quick exit strategies
   if (newm == 0) {
      reviseddualsimplex_basisinit(ns, 0, s);
      result = true;
      return result;
   }
// Same size or larger
   if (newm >= oldm) {
      ae_assert(s->isvalidtrf || oldm == 0, "BasisTryResize: needs valid TRF in S");
   // Save information about matrix conditioning
      oldminu = reviseddualsimplex_basisminimumdiagonalelement(s);
   // Growth if needed
      s->m = newm;
      ivectorgrowto(&s->idx, newm);
      bvectorgrowto(&s->isbasic, ns + newm);
      for (i = oldm; i < newm; i++) {
         s->idx.xZ[i] = ns + i;
         s->isbasic.xB[ns + i] = true;
      }
   // DSE weights are invalid and filled by 1.0
      rvectorgrowto(&s->dseweights, newm);
      for (i = 0; i < newm; i++) {
         s->dseweights.xR[i] = 1.0;
      }
      s->dsevalid = false;
   // Invalidate TRF.
   // Try to refactorize.
      s->isvalidtrf = false;
      newminu = reviseddualsimplex_basisfreshtrfunsafe(s, at, settings);
      result = newminu >= reviseddualsimplex_maxudecay * oldminu;
      return result;
   }
   ae_assert(false, "BasisTryResize: unexpected branch");
   return result;
}

// This function exports division of variables into basic/nonbasic ones; only
// basic/nonbasic sets are exported - triangular factorization is NOT exported;
// however, valid triangular factorization IS required in order to perform
// exporting.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_basisexportto(dualsimplexbasis *s0, dualsimplexbasis *s1) {
   s1->ns = s0->ns;
   s1->m = s0->m;
   copyintegerarray(&s0->idx, &s1->idx);
   copyintegerarray(&s0->nidx, &s1->nidx);
   copybooleanarray(&s0->isbasic, &s1->isbasic);
   s1->isvalidtrf = false;
   s1->trftype = -1;
   s1->dsevalid = false;
   if (s0->m > 0) {
      ae_assert(s0->isvalidtrf, "BasisExport: valid factorization is required for source basis");
      s1->eminu = reviseddualsimplex_basisminimumdiagonalelement(s0);
   } else {
      s1->eminu = 1.0;
   }
}

// This function imports from S1 to S0 a division of variables into
// basic/nonbasic ones; only basic/nonbasic sets are imported.
//
// Triangular factorization is not imported; however,  this  function  checks
// that new factorization deviates from the previous  one  not  too  much  by
// comparing magnitudes of min[abs(u_ii)] in both factorization (basis being
// imported stores statistics about U). Sharp decrease of diagonal elements
// means that we have too unstable situation which results in import being
// abandoned. In this case False is returned, and the basis S0 is left in the
// indeterminate invalid state (you have to reinitialize it by all-logicals).
//
// IMPORTANT: if metrics of S0 and S1 do not match, an exception will be generated.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static bool reviseddualsimplex_basistryimportfrom(dualsimplexbasis *s0, dualsimplexbasis *s1, sparsematrix *at, dualsimplexsettings *settings) {
   ae_int_t i;
   double newminu;
   bool result;
   ae_assert(s0->ns == s1->ns, "BasisImportFrom: structural variable counts do not match");
   reviseddualsimplex_basisclearstats(s0);
   s0->m = s1->m;
   for (i = 0; i < s0->m; i++) {
      s0->idx.xZ[i] = s1->idx.xZ[i];
   }
   for (i = 0; i < s0->ns; i++) {
      s0->nidx.xZ[i] = s1->nidx.xZ[i];
   }
   for (i = 0; i < s0->m + s0->ns; i++) {
      s0->isbasic.xB[i] = s1->isbasic.xB[i];
   }
   s0->isvalidtrf = false;
   vectorsetlengthatleast(&s0->dseweights, s1->m);
   for (i = 0; i < s1->m; i++) {
      s0->dseweights.xR[i] = 1.0;
   }
   s0->dsevalid = false;
   newminu = reviseddualsimplex_basisfreshtrfunsafe(s0, at, settings);
   result = newminu >= reviseddualsimplex_maxudecay * s1->eminu;
   if (!result) {
      s0->isvalidtrf = false;
      s0->trftype = -1;
   }
   return result;
}

// Downgrades problem state to the specified one (if status is lower than one
// specified by user, nothing is changed)
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void reviseddualsimplex_downgradestate(dualsimplexsubproblem *subproblem, ae_int_t s) {
   subproblem->state = imin2(subproblem->state, s);
}

void dsssettingsinit(dualsimplexsettings *settings) {
   const ae_int_t defaultmaxtrfage = 100;
   settings->xtolabs = 0.000001;
   settings->dtolabs = 0.000001;
   settings->xtolrelabs = 0.01;
   settings->pivottol = 10.0 * sqrt(machineepsilon);
   settings->perturbmag = 10.0 * settings->pivottol;
   settings->maxtrfage = defaultmaxtrfage;
   settings->trftype = 3;
   settings->ratiotest = 1;
   settings->pricing = 1;
   settings->shifting = 2;
}

// This function initializes DSS structure. Previously  allocated  memory  is
// reused as much as possible.
//
// Default state of the problem is zero cost vector, all variables are  fixed
// at zero.
// ALGLIB: Copyright 01.07.2018 by Sergey Bochkanov
void dssinit(ae_int_t n, dualsimplexstate *s) {
   ae_int_t i;
   ae_assert(n > 0, "DSSInit: N <= 0");
   s->ns = n;
   s->m = 0;
   rvectorgrowto(&s->rawbndl, n);
   rvectorgrowto(&s->rawbndu, n);
   for (i = 0; i < n; i++) {
      s->rawbndl.xR[i] = 0.0;
      s->rawbndu.xR[i] = 0.0;
   }
   reviseddualsimplex_subprobleminit(n, &s->primary);
   reviseddualsimplex_basisinit(n, 0, &s->basis);
   rvectorgrowto(&s->repx, n);
   rvectorgrowto(&s->replagbc, n);
   ivectorgrowto(&s->repstats, n);
   for (i = 0; i < n; i++) {
      s->repx.xR[i] = 0.0;
      s->repstats.xZ[i] = 1;
   }
}

// This function specifies LP problem
//
// Inputs:
//     State   -   structure previously allocated with minlpcreate() call.
//
//     BndL    -   lower bounds, array[N].
//     BndU    -   upper bounds, array[N].
//
//     DenseA  -   dense array[K,N], dense linear constraints (not supported
//                 in present version)
//     SparseA -   sparse linear constraints, sparsematrix[K,N] in CRS format
//     AKind   -   type of A: 0 for dense, 1 for sparse
//     AL, AU  -   lower and upper bounds, array[K]
//     K       -   number of equality/inequality constraints, K >= 0.
//
//     ProposedBasis- basis to import from (if BasisType == 2)
//     BasisInitType-  what to do with basis:
//                 * 0 - set new basis to all-logicals
//                 * 1 - try to reuse previous basis as much as possible
//                 * 2 - try to import basis from ProposedBasis
//     Settings-   algorithm settings
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
void dsssetproblem(dualsimplexstate *state, RVector *c, RVector *bndl, RVector *bndu, RMatrix *densea, sparsematrix *sparsea, ae_int_t akind, RVector *al, RVector *au, ae_int_t k, dualsimplexbasis *proposedbasis, ae_int_t basisinittype, dualsimplexsettings *settings) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t jj;
   ae_int_t offs;
   ae_int_t ns;
   ae_int_t j0;
   ae_int_t j1;
   bool processed;
   ae_int_t oldm;
   bool basisinitialized;
   double v;
   ns = state->primary.ns;
   oldm = state->primary.m;
// Integrity checks
   ae_assert(bndl->cnt >= ns, "DSSSetProblem: Length(BndL) < N");
   ae_assert(bndu->cnt >= ns, "DSSSetProblem: Length(BndU) < N");
   ae_assert(c->cnt >= ns, "SubproblemSetCost: Length(C) < N");
   ae_assert(isfinitevector(c, ns), "SubproblemSetCost: C contains infinite or NaN elements");
   ae_assert(akind == 0 || akind == 1, "DSSSetProblem: incorrect AKind");
   ae_assert(basisinittype == 0 || basisinittype == 1 || basisinittype == 2, "DSSSetProblem: incorrect BasisInitType");
   ae_assert(k >= 0, "DSSSetProblem: K < 0");
   if (k > 0 && akind == 1) {
      ae_assert(sparsea->m == k, "DSSSetProblem: rows(A) != K");
      ae_assert(sparsea->n == ns, "DSSSetProblem: cols(A) != N");
   }
// Downgrade state
   reviseddualsimplex_downgradestate(&state->primary, reviseddualsimplex_ssinvalid);
// Reallocate storage
   rvectorgrowto(&state->primary.bndl, ns + k);
   rvectorgrowto(&state->primary.bndu, ns + k);
   ivectorgrowto(&state->primary.bndt, ns + k);
   rvectorgrowto(&state->primary.rawc, ns + k);
   rvectorgrowto(&state->primary.effc, ns + k);
   rvectorgrowto(&state->primary.xa, ns + k);
   rvectorgrowto(&state->primary.d, ns + k);
   rvectorgrowto(&state->primary.xb, k);
   rvectorgrowto(&state->primary.bndlb, k);
   rvectorgrowto(&state->primary.bndub, k);
   ivectorgrowto(&state->primary.bndtb, k);
   rvectorgrowto(&state->primary.bndtollb, k);
   rvectorgrowto(&state->primary.bndtolub, k);
// Save original problem formulation
   state->ns = ns;
   state->m = k;
   for (i = 0; i < ns; i++) {
      state->rawbndl.xR[i] = bndl->xR[i];
      state->rawbndu.xR[i] = bndu->xR[i];
   }
// Setup cost, scale and box constraints
   rsetv(ns + k, 0.0, &state->primary.rawc);
   rsetv(ns + k, 0.0, &state->primary.effc);
   for (i = 0; i < ns; i++) {
      state->primary.rawc.xR[i] = c->xR[i];
      state->primary.effc.xR[i] = c->xR[i];
   }
   for (i = 0; i < ns; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "DSSSetProblem: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "DSSSetProblem: BndU contains NAN or -INF");
      state->primary.bndl.xR[i] = bndl->xR[i];
      state->primary.bndu.xR[i] = bndu->xR[i];
   // Set bound type
      if (isfinite(bndl->xR[i]) && isfinite(bndu->xR[i])) {
         if (bndl->xR[i] > bndu->xR[i]) {
            state->primary.bndt.xZ[i] = reviseddualsimplex_ccinfeasible;
         }
         if (bndl->xR[i] < bndu->xR[i]) {
            state->primary.bndt.xZ[i] = reviseddualsimplex_ccrange;
         }
         if (bndl->xR[i] == bndu->xR[i]) {
            state->primary.bndt.xZ[i] = reviseddualsimplex_ccfixed;
         }
         continue;
      }
      if (isfinite(bndl->xR[i]) && !isfinite(bndu->xR[i])) {
         state->primary.bndt.xZ[i] = reviseddualsimplex_cclower;
         continue;
      }
      if (!isfinite(bndl->xR[i]) && isfinite(bndu->xR[i])) {
         state->primary.bndt.xZ[i] = reviseddualsimplex_ccupper;
         continue;
      }
      ae_assert(isneginf(bndl->xR[i]) && isposinf(bndu->xR[i]), "DSSSetProblem: integrity check failed");
      state->primary.bndt.xZ[i] = reviseddualsimplex_ccfree;
   }
// Quick exit if no linear constraints is present
   if (k == 0) {
      state->primary.m = 0;
      reviseddualsimplex_basisinit(state->primary.ns, state->primary.m, &state->basis);
      return;
   }
// Extend A with structural terms and transpose it:
// * allocate place for A^T extended with logical part.
// * copy with transposition
// * perform integrity check for array sizes
// * manually append new items
// * update DIdx/UIdx
   processed = false;
   state->primary.m = k;
   if (akind == 0) {
      ae_assert(false, "DSSSetProblem: does not support dense inputs yet");
   }
   if (akind == 1) {
   // Transpose constraints matrix, apply column and row scaling.
   // Extend it with identity submatrix.
   //
   // NOTE: in order to improve stability of LU factorization we
   //       normalize rows using 2-norm, not INF-norm. Having rows
   //       normalized with 2-norm makes every element less than
   //       1.0 in magnitude, which allows us later to move logical
   //       columns to the beginning of LU factors without losing
   //       stability.
      vectorsetlengthatleast(&state->at.vals, sparsea->ridx.xZ[k] + k);
      vectorsetlengthatleast(&state->at.idx, sparsea->ridx.xZ[k] + k);
      vectorsetlengthatleast(&state->at.ridx, ns + k + 1);
      vectorsetlengthatleast(&state->at.didx, ns + k);
      vectorsetlengthatleast(&state->at.uidx, ns + k);
      sparsecopytransposecrsbuf(sparsea, &state->at);
      vectorsetlengthatleast(&state->rowscales, k);
      for (i = 0; i < k; i++) {
         state->rowscales.xR[i] = 0.0;
      }
      for (i = 0; i < ns; i++) {
         j0 = state->at.ridx.xZ[i];
         j1 = state->at.ridx.xZ[i + 1] - 1;
         for (j = j0; j <= j1; j++) {
            v = state->at.vals.xR[j];
            jj = state->at.idx.xZ[j];
            state->at.vals.xR[j] = v;
            state->rowscales.xR[jj] += v * v;
         }
      }
      vectorsetlengthatleast(&state->tmp0, k);
      for (i = 0; i < k; i++) {
         state->rowscales.xR[i] = coalesce(sqrt(state->rowscales.xR[i]), 1.0);
         state->tmp0.xR[i] = 1.0 / state->rowscales.xR[i];
      }
      for (i = 0; i < ns; i++) {
         j0 = state->at.ridx.xZ[i];
         j1 = state->at.ridx.xZ[i + 1] - 1;
         for (j = j0; j <= j1; j++) {
            state->at.vals.xR[j] *= state->tmp0.xR[state->at.idx.xZ[j]];
         }
      }
      ae_assert(state->at.vals.cnt >= sparsea->ridx.xZ[k] + k, "DSSSetProblem: integrity check failed");
      ae_assert(state->at.idx.cnt >= sparsea->ridx.xZ[k] + k, "DSSSetProblem: integrity check failed");
      ae_assert(state->at.ridx.cnt > ns + k, "DSSSetProblem: integrity check failed");
      ae_assert(state->at.didx.cnt >= ns + k, "DSSSetProblem: integrity check failed");
      ae_assert(state->at.uidx.cnt >= ns + k, "DSSSetProblem: integrity check failed");
      offs = state->at.ridx.xZ[ns];
      for (i = 0; i < k; i++) {
         state->at.vals.xR[offs + i] = -1.0;
         state->at.idx.xZ[offs + i] = i;
         state->at.ridx.xZ[ns + i + 1] = state->at.ridx.xZ[ns + i] + 1;
         state->at.ninitialized++;
      }
      state->at.m += k;
      sparseinitduidx(&state->at);
      sparsecopytransposecrsbuf(&state->at, &state->a);
      processed = true;
   }
   ae_assert(processed, "DSSSetProblem: integrity check failed (akind)");
// Copy AL, AU to BndL/BndT
   for (i = 0; i < k; i++) {
      ae_assert(isfinite(al->xR[i]) || isneginf(al->xR[i]), "DSSSetProblem: AL contains NAN or +INF");
      ae_assert(isfinite(au->xR[i]) || isposinf(au->xR[i]), "DSSSetProblem: AU contains NAN or -INF");
      state->primary.bndl.xR[ns + i] = al->xR[i] / state->rowscales.xR[i];
      state->primary.bndu.xR[ns + i] = au->xR[i] / state->rowscales.xR[i];
   // Set bound type
      if (isfinite(al->xR[i]) && isfinite(au->xR[i])) {
         if (al->xR[i] > au->xR[i]) {
            state->primary.bndt.xZ[ns + i] = reviseddualsimplex_ccinfeasible;
         }
         if (al->xR[i] < au->xR[i]) {
            state->primary.bndt.xZ[ns + i] = reviseddualsimplex_ccrange;
         }
         if (al->xR[i] == au->xR[i]) {
            state->primary.bndt.xZ[ns + i] = reviseddualsimplex_ccfixed;
         }
         continue;
      }
      if (isfinite(al->xR[i]) && !isfinite(au->xR[i])) {
         state->primary.bndt.xZ[ns + i] = reviseddualsimplex_cclower;
         continue;
      }
      if (!isfinite(al->xR[i]) && isfinite(au->xR[i])) {
         state->primary.bndt.xZ[ns + i] = reviseddualsimplex_ccupper;
         continue;
      }
      ae_assert(isneginf(al->xR[i]) && isposinf(au->xR[i]), "DSSSetProblem: integrity check faoled");
      state->primary.bndt.xZ[ns + i] = reviseddualsimplex_ccfree;
   }
// Depending on BasisInitType either start from all-logical basis
// or try to reuse already existing basis.
//
// NOTE: current version does not support basis shrinkage, only
//       growing basis can be reused.
   basisinitialized = false;
   if (basisinittype == 2) {
   // Import basis from one proposed by caller
      ae_assert(proposedbasis->ns == state->primary.ns, "DSSSetProblemX: unable to import basis, sizes do not match");
      ae_assert(proposedbasis->m == state->primary.m, "DSSSetProblemX: unable to import basis, sizes do not match");
      basisinitialized = reviseddualsimplex_basistryimportfrom(&state->basis, proposedbasis, &state->at, settings);
   }
   if (basisinittype == 1 && state->primary.m >= oldm) {
   // New rows were added, try to reuse previous basis
      for (i = oldm; i < state->primary.m; i++) {
         state->primary.rawc.xR[ns + i] = 0.0;
         state->primary.effc.xR[ns + i] = 0.0;
         state->primary.xa.xR[ns + i] = 0.0;
         state->primary.d.xR[ns + i] = 0.0;
      }
      basisinitialized = reviseddualsimplex_basistryresize(&state->basis, state->primary.m, &state->at, settings);
   }
   if (!basisinitialized) {
   // Straightforward code for all-logicals basis
      for (i = 0; i < k; i++) {
         state->primary.rawc.xR[ns + i] = 0.0;
         state->primary.effc.xR[ns + i] = 0.0;
         state->primary.xa.xR[ns + i] = 0.0;
         state->primary.d.xR[ns + i] = 0.0;
      }
      reviseddualsimplex_basisinit(state->primary.ns, state->primary.m, &state->basis);
      reviseddualsimplex_basisfreshtrf(&state->basis, &state->at, settings);
   }
   rvectorgrowto(&state->replaglc, state->primary.m);
   ivectorgrowto(&state->repstats, state->primary.ns + state->primary.m);
}

// This function exports basis from the primary (phase II) subproblem.
//
// Inputs:
//     State   -   structure
//
// Outputs:
//     Basis   -   current basis exported (no factorization, only set of
//                 basis/nonbasic variables)
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
void dssexportbasis(dualsimplexstate *state, dualsimplexbasis *basis) {
   reviseddualsimplex_basisexportto(&state->basis, basis);
}

// This function solves LP problem with dual simplex solver.
//
// Inputs:
//     State   -   state
//
// Solution results can be found in fields  of  State  which  are  explicitly
// declared as accessible by external code.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
void dssoptimize(dualsimplexstate *state, dualsimplexsettings *settings) {
   ae_int_t i;
// Init report fields
   state->repiterationscount = 0;
   state->repiterationscount1 = 0;
   state->repiterationscount2 = 0;
   state->repiterationscount3 = 0;
   state->repterminationtype = 1;
   state->repfillpivotrow = 0.0;
   state->repfillpivotrowcnt = 0;
   state->repfillrhor = 0.0;
   state->repfillrhorcnt = 0;
   state->repfilldensemu = 0.0;
   state->repfilldensemucnt = 0;
   reviseddualsimplex_basisclearstats(&state->basis);
// Call actual workhorse function
   reviseddualsimplex_dssoptimizewrk(state, settings);
}

void dualsimplexsettings_init(void *_p, bool make_automatic) {
}

void dualsimplexsettings_copy(void *_dst, const void *_src, bool make_automatic) {
   dualsimplexsettings *dst = (dualsimplexsettings *)_dst;
   const dualsimplexsettings *src = (const dualsimplexsettings *)_src;
   dst->pivottol = src->pivottol;
   dst->perturbmag = src->perturbmag;
   dst->maxtrfage = src->maxtrfage;
   dst->trftype = src->trftype;
   dst->ratiotest = src->ratiotest;
   dst->pricing = src->pricing;
   dst->shifting = src->shifting;
   dst->xtolabs = src->xtolabs;
   dst->xtolrelabs = src->xtolrelabs;
   dst->dtolabs = src->dtolabs;
}

void dualsimplexsettings_free(void *_p, bool make_automatic) {
}

void dssvector_init(void *_p, bool make_automatic) {
   dssvector *p = (dssvector *)_p;
   ae_vector_init(&p->idx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->vals, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dense, 0, DT_REAL, make_automatic);
}

void dssvector_copy(void *_dst, const void *_src, bool make_automatic) {
   dssvector *dst = (dssvector *)_dst;
   const dssvector *src = (const dssvector *)_src;
   dst->n = src->n;
   dst->k = src->k;
   ae_vector_copy(&dst->idx, &src->idx, make_automatic);
   ae_vector_copy(&dst->vals, &src->vals, make_automatic);
   ae_vector_copy(&dst->dense, &src->dense, make_automatic);
}

void dssvector_free(void *_p, bool make_automatic) {
   dssvector *p = (dssvector *)_p;
   ae_vector_free(&p->idx, make_automatic);
   ae_vector_free(&p->vals, make_automatic);
   ae_vector_free(&p->dense, make_automatic);
}

void dualsimplexbasis_init(void *_p, bool make_automatic) {
   dualsimplexbasis *p = (dualsimplexbasis *)_p;
   ae_vector_init(&p->idx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->nidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->isbasic, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->denselu, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsel, make_automatic);
   sparsematrix_init(&p->sparseu, make_automatic);
   sparsematrix_init(&p->sparseut, make_automatic);
   ae_vector_init(&p->rowpermbwd, 0, DT_INT, make_automatic);
   ae_vector_init(&p->colpermbwd, 0, DT_INT, make_automatic);
   ae_vector_init(&p->densepfieta, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->densemu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rk, 0, DT_INT, make_automatic);
   ae_vector_init(&p->dk, 0, DT_INT, make_automatic);
   ae_vector_init(&p->dseweights, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wtmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wtmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->wtmp2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nrs, 0, DT_INT, make_automatic);
   ae_vector_init(&p->tcinvidx, 0, DT_INT, make_automatic);
   ae_matrix_init(&p->denselu2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->densep2, 0, DT_INT, make_automatic);
   ae_vector_init(&p->densep2c, 0, DT_INT, make_automatic);
   sparsematrix_init(&p->sparselu1, make_automatic);
   sparsematrix_init(&p->sparselu2, make_automatic);
   sluv2buffer_init(&p->lubuf2, make_automatic);
   ae_vector_init(&p->tmpi, 0, DT_INT, make_automatic);
   ae_vector_init(&p->utmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->utmpi, 0, DT_INT, make_automatic);
   sparsematrix_init(&p->sparseludbg, make_automatic);
}

void dualsimplexbasis_copy(void *_dst, const void *_src, bool make_automatic) {
   dualsimplexbasis *dst = (dualsimplexbasis *)_dst;
   const dualsimplexbasis *src = (const dualsimplexbasis *)_src;
   dst->ns = src->ns;
   dst->m = src->m;
   ae_vector_copy(&dst->idx, &src->idx, make_automatic);
   ae_vector_copy(&dst->nidx, &src->nidx, make_automatic);
   ae_vector_copy(&dst->isbasic, &src->isbasic, make_automatic);
   dst->trftype = src->trftype;
   dst->isvalidtrf = src->isvalidtrf;
   dst->trfage = src->trfage;
   ae_matrix_copy(&dst->denselu, &src->denselu, make_automatic);
   sparsematrix_copy(&dst->sparsel, &src->sparsel, make_automatic);
   sparsematrix_copy(&dst->sparseu, &src->sparseu, make_automatic);
   sparsematrix_copy(&dst->sparseut, &src->sparseut, make_automatic);
   ae_vector_copy(&dst->rowpermbwd, &src->rowpermbwd, make_automatic);
   ae_vector_copy(&dst->colpermbwd, &src->colpermbwd, make_automatic);
   ae_vector_copy(&dst->densepfieta, &src->densepfieta, make_automatic);
   ae_vector_copy(&dst->densemu, &src->densemu, make_automatic);
   ae_vector_copy(&dst->rk, &src->rk, make_automatic);
   ae_vector_copy(&dst->dk, &src->dk, make_automatic);
   ae_vector_copy(&dst->dseweights, &src->dseweights, make_automatic);
   dst->dsevalid = src->dsevalid;
   dst->eminu = src->eminu;
   dst->statfact = src->statfact;
   dst->statupdt = src->statupdt;
   dst->statoffdiag = src->statoffdiag;
   ae_vector_copy(&dst->wtmp0, &src->wtmp0, make_automatic);
   ae_vector_copy(&dst->wtmp1, &src->wtmp1, make_automatic);
   ae_vector_copy(&dst->wtmp2, &src->wtmp2, make_automatic);
   ae_vector_copy(&dst->nrs, &src->nrs, make_automatic);
   ae_vector_copy(&dst->tcinvidx, &src->tcinvidx, make_automatic);
   ae_matrix_copy(&dst->denselu2, &src->denselu2, make_automatic);
   ae_vector_copy(&dst->densep2, &src->densep2, make_automatic);
   ae_vector_copy(&dst->densep2c, &src->densep2c, make_automatic);
   sparsematrix_copy(&dst->sparselu1, &src->sparselu1, make_automatic);
   sparsematrix_copy(&dst->sparselu2, &src->sparselu2, make_automatic);
   sluv2buffer_copy(&dst->lubuf2, &src->lubuf2, make_automatic);
   ae_vector_copy(&dst->tmpi, &src->tmpi, make_automatic);
   ae_vector_copy(&dst->utmp0, &src->utmp0, make_automatic);
   ae_vector_copy(&dst->utmpi, &src->utmpi, make_automatic);
   sparsematrix_copy(&dst->sparseludbg, &src->sparseludbg, make_automatic);
}

void dualsimplexbasis_free(void *_p, bool make_automatic) {
   dualsimplexbasis *p = (dualsimplexbasis *)_p;
   ae_vector_free(&p->idx, make_automatic);
   ae_vector_free(&p->nidx, make_automatic);
   ae_vector_free(&p->isbasic, make_automatic);
   ae_matrix_free(&p->denselu, make_automatic);
   sparsematrix_free(&p->sparsel, make_automatic);
   sparsematrix_free(&p->sparseu, make_automatic);
   sparsematrix_free(&p->sparseut, make_automatic);
   ae_vector_free(&p->rowpermbwd, make_automatic);
   ae_vector_free(&p->colpermbwd, make_automatic);
   ae_vector_free(&p->densepfieta, make_automatic);
   ae_vector_free(&p->densemu, make_automatic);
   ae_vector_free(&p->rk, make_automatic);
   ae_vector_free(&p->dk, make_automatic);
   ae_vector_free(&p->dseweights, make_automatic);
   ae_vector_free(&p->wtmp0, make_automatic);
   ae_vector_free(&p->wtmp1, make_automatic);
   ae_vector_free(&p->wtmp2, make_automatic);
   ae_vector_free(&p->nrs, make_automatic);
   ae_vector_free(&p->tcinvidx, make_automatic);
   ae_matrix_free(&p->denselu2, make_automatic);
   ae_vector_free(&p->densep2, make_automatic);
   ae_vector_free(&p->densep2c, make_automatic);
   sparsematrix_free(&p->sparselu1, make_automatic);
   sparsematrix_free(&p->sparselu2, make_automatic);
   sluv2buffer_free(&p->lubuf2, make_automatic);
   ae_vector_free(&p->tmpi, make_automatic);
   ae_vector_free(&p->utmp0, make_automatic);
   ae_vector_free(&p->utmpi, make_automatic);
   sparsematrix_free(&p->sparseludbg, make_automatic);
}

void dualsimplexsubproblem_init(void *_p, bool make_automatic) {
   dualsimplexsubproblem *p = (dualsimplexsubproblem *)_p;
   ae_vector_init(&p->rawc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndt, 0, DT_INT, make_automatic);
   ae_vector_init(&p->xa, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndlb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndub, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndtb, 0, DT_INT, make_automatic);
   ae_vector_init(&p->bndtollb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndtolub, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->effc, 0, DT_REAL, make_automatic);
}

void dualsimplexsubproblem_copy(void *_dst, const void *_src, bool make_automatic) {
   dualsimplexsubproblem *dst = (dualsimplexsubproblem *)_dst;
   const dualsimplexsubproblem *src = (const dualsimplexsubproblem *)_src;
   dst->ns = src->ns;
   dst->m = src->m;
   ae_vector_copy(&dst->rawc, &src->rawc, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->bndt, &src->bndt, make_automatic);
   ae_vector_copy(&dst->xa, &src->xa, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->state = src->state;
   ae_vector_copy(&dst->xb, &src->xb, make_automatic);
   ae_vector_copy(&dst->bndlb, &src->bndlb, make_automatic);
   ae_vector_copy(&dst->bndub, &src->bndub, make_automatic);
   ae_vector_copy(&dst->bndtb, &src->bndtb, make_automatic);
   ae_vector_copy(&dst->bndtollb, &src->bndtollb, make_automatic);
   ae_vector_copy(&dst->bndtolub, &src->bndtolub, make_automatic);
   ae_vector_copy(&dst->effc, &src->effc, make_automatic);
}

void dualsimplexsubproblem_free(void *_p, bool make_automatic) {
   dualsimplexsubproblem *p = (dualsimplexsubproblem *)_p;
   ae_vector_free(&p->rawc, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->bndt, make_automatic);
   ae_vector_free(&p->xa, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->xb, make_automatic);
   ae_vector_free(&p->bndlb, make_automatic);
   ae_vector_free(&p->bndub, make_automatic);
   ae_vector_free(&p->bndtb, make_automatic);
   ae_vector_free(&p->bndtollb, make_automatic);
   ae_vector_free(&p->bndtolub, make_automatic);
   ae_vector_free(&p->effc, make_automatic);
}

void dualsimplexstate_init(void *_p, bool make_automatic) {
   dualsimplexstate *p = (dualsimplexstate *)_p;
   ae_vector_init(&p->rowscales, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawbndu, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->a, make_automatic);
   sparsematrix_init(&p->at, make_automatic);
   dualsimplexbasis_init(&p->basis, make_automatic);
   dualsimplexsubproblem_init(&p->primary, make_automatic);
   dualsimplexsubproblem_init(&p->phase1, make_automatic);
   dualsimplexsubproblem_init(&p->phase3, make_automatic);
   ae_vector_init(&p->repx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->replagbc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->replaglc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->repstats, 0, DT_INT, make_automatic);
   ae_vector_init(&p->btrantmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->btrantmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->btrantmp2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ftrantmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ftrantmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->possibleflips, 0, DT_INT, make_automatic);
   ae_vector_init(&p->dfctmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dfctmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dfctmp2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ustmpi, 0, DT_INT, make_automatic);
   apbuffers_init(&p->xydsbuf, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp2, 0, DT_REAL, make_automatic);
   dssvector_init(&p->alphar, make_automatic);
   dssvector_init(&p->rhor, make_automatic);
   ae_vector_init(&p->tau, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->alphaq, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->alphaqim, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->eligiblealphar, 0, DT_INT, make_automatic);
   ae_vector_init(&p->harrisset, 0, DT_INT, make_automatic);
}

void dualsimplexstate_copy(void *_dst, const void *_src, bool make_automatic) {
   dualsimplexstate *dst = (dualsimplexstate *)_dst;
   const dualsimplexstate *src = (const dualsimplexstate *)_src;
   ae_vector_copy(&dst->rowscales, &src->rowscales, make_automatic);
   ae_vector_copy(&dst->rawbndl, &src->rawbndl, make_automatic);
   ae_vector_copy(&dst->rawbndu, &src->rawbndu, make_automatic);
   dst->ns = src->ns;
   dst->m = src->m;
   sparsematrix_copy(&dst->a, &src->a, make_automatic);
   sparsematrix_copy(&dst->at, &src->at, make_automatic);
   dualsimplexbasis_copy(&dst->basis, &src->basis, make_automatic);
   dualsimplexsubproblem_copy(&dst->primary, &src->primary, make_automatic);
   dualsimplexsubproblem_copy(&dst->phase1, &src->phase1, make_automatic);
   dualsimplexsubproblem_copy(&dst->phase3, &src->phase3, make_automatic);
   ae_vector_copy(&dst->repx, &src->repx, make_automatic);
   ae_vector_copy(&dst->replagbc, &src->replagbc, make_automatic);
   ae_vector_copy(&dst->replaglc, &src->replaglc, make_automatic);
   ae_vector_copy(&dst->repstats, &src->repstats, make_automatic);
   dst->repterminationtype = src->repterminationtype;
   dst->repiterationscount = src->repiterationscount;
   dst->repiterationscount1 = src->repiterationscount1;
   dst->repiterationscount2 = src->repiterationscount2;
   dst->repiterationscount3 = src->repiterationscount3;
   dst->repfillpivotrow = src->repfillpivotrow;
   dst->repfillpivotrowcnt = src->repfillpivotrowcnt;
   dst->repfillrhor = src->repfillrhor;
   dst->repfillrhorcnt = src->repfillrhorcnt;
   dst->repfilldensemu = src->repfilldensemu;
   dst->repfilldensemucnt = src->repfilldensemucnt;
   ae_vector_copy(&dst->btrantmp0, &src->btrantmp0, make_automatic);
   ae_vector_copy(&dst->btrantmp1, &src->btrantmp1, make_automatic);
   ae_vector_copy(&dst->btrantmp2, &src->btrantmp2, make_automatic);
   ae_vector_copy(&dst->ftrantmp0, &src->ftrantmp0, make_automatic);
   ae_vector_copy(&dst->ftrantmp1, &src->ftrantmp1, make_automatic);
   ae_vector_copy(&dst->possibleflips, &src->possibleflips, make_automatic);
   dst->possibleflipscnt = src->possibleflipscnt;
   ae_vector_copy(&dst->dfctmp0, &src->dfctmp0, make_automatic);
   ae_vector_copy(&dst->dfctmp1, &src->dfctmp1, make_automatic);
   ae_vector_copy(&dst->dfctmp2, &src->dfctmp2, make_automatic);
   ae_vector_copy(&dst->ustmpi, &src->ustmpi, make_automatic);
   apbuffers_copy(&dst->xydsbuf, &src->xydsbuf, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->tmp2, &src->tmp2, make_automatic);
   dssvector_copy(&dst->alphar, &src->alphar, make_automatic);
   dssvector_copy(&dst->rhor, &src->rhor, make_automatic);
   ae_vector_copy(&dst->tau, &src->tau, make_automatic);
   ae_vector_copy(&dst->alphaq, &src->alphaq, make_automatic);
   ae_vector_copy(&dst->alphaqim, &src->alphaqim, make_automatic);
   ae_vector_copy(&dst->eligiblealphar, &src->eligiblealphar, make_automatic);
   ae_vector_copy(&dst->harrisset, &src->harrisset, make_automatic);
}

void dualsimplexstate_free(void *_p, bool make_automatic) {
   dualsimplexstate *p = (dualsimplexstate *)_p;
   ae_vector_free(&p->rowscales, make_automatic);
   ae_vector_free(&p->rawbndl, make_automatic);
   ae_vector_free(&p->rawbndu, make_automatic);
   sparsematrix_free(&p->a, make_automatic);
   sparsematrix_free(&p->at, make_automatic);
   dualsimplexbasis_free(&p->basis, make_automatic);
   dualsimplexsubproblem_free(&p->primary, make_automatic);
   dualsimplexsubproblem_free(&p->phase1, make_automatic);
   dualsimplexsubproblem_free(&p->phase3, make_automatic);
   ae_vector_free(&p->repx, make_automatic);
   ae_vector_free(&p->replagbc, make_automatic);
   ae_vector_free(&p->replaglc, make_automatic);
   ae_vector_free(&p->repstats, make_automatic);
   ae_vector_free(&p->btrantmp0, make_automatic);
   ae_vector_free(&p->btrantmp1, make_automatic);
   ae_vector_free(&p->btrantmp2, make_automatic);
   ae_vector_free(&p->ftrantmp0, make_automatic);
   ae_vector_free(&p->ftrantmp1, make_automatic);
   ae_vector_free(&p->possibleflips, make_automatic);
   ae_vector_free(&p->dfctmp0, make_automatic);
   ae_vector_free(&p->dfctmp1, make_automatic);
   ae_vector_free(&p->dfctmp2, make_automatic);
   ae_vector_free(&p->ustmpi, make_automatic);
   apbuffers_free(&p->xydsbuf, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->tmp2, make_automatic);
   dssvector_free(&p->alphar, make_automatic);
   dssvector_free(&p->rhor, make_automatic);
   ae_vector_free(&p->tau, make_automatic);
   ae_vector_free(&p->alphaq, make_automatic);
   ae_vector_free(&p->alphaqim, make_automatic);
   ae_vector_free(&p->eligiblealphar, make_automatic);
   ae_vector_free(&p->harrisset, make_automatic);
}
} // end of namespace alglib_impl

// === MINLP Package ===
// Depends on: VIPMSOLVER, REVISEDDUALSIMPLEX
namespace alglib_impl {
// This function sets LP algorithm to revised dual simplex method.
//
// ALGLIB implementation of dual simplex method supports advanced performance
// and stability improvements like DSE pricing , bounds flipping  ratio  test
// (aka long dual step), Forest-Tomlin update, shifting.
//
// Inputs:
//     State   -   optimizer
//     Eps     -   stopping condition, Eps >= 0:
//                 * should be small number about 1E-6 or 1E-7.
//                 * zero value means that solver automatically selects good
//                   value (can be different in different ALGLIB versions)
//                 * default value is zero
//                 Algorithm stops when relative error is less than Eps.
// ALGLIB: Copyright 08.11.2020 by Sergey Bochkanov
// API: void minlpsetalgodss(const minlpstate &state, const double eps);
void minlpsetalgodss(minlpstate *state, double eps) {
   ae_assert(isfinite(eps), "MinLPSetAlgoDSS: Eps is not finite number");
   ae_assert(eps >= 0.0, "MinLPSetAlgoDSS: Eps < 0");
   state->algokind = 1;
   if (eps == 0.0) {
      eps = 0.000001;
   }
   state->dsseps = eps;
}

// This function sets LP algorithm to sparse interior point method.
//
// ALGORITHM INFORMATION:
//
// * this  algorithm  is  our implementation  of  interior  point  method  as
//   formulated by  R.J.Vanderbei, with minor modifications to the  algorithm
//   (damped Newton directions are extensively used)
// * like all interior point methods, this algorithm  tends  to  converge  in
//   roughly same number of iterations (between 15 and 50) independently from
//   the problem dimensionality
//
// Inputs:
//     State   -   optimizer
//     Eps     -   stopping condition, Eps >= 0:
//                 * should be small number about 1E-6 or 1E-8.
//                 * zero value means that solver automatically selects good
//                   value (can be different in different ALGLIB versions)
//                 * default value is zero
//                 Algorithm  stops  when  primal  error  AND  dual error AND
//                 duality gap are less than Eps.
// ALGLIB: Copyright 08.11.2020 by Sergey Bochkanov
// API: void minlpsetalgoipm(const minlpstate &state, const double eps);
// API: void minlpsetalgoipm(const minlpstate &state);
void minlpsetalgoipm(minlpstate *state, double eps) {
   ae_assert(isfinite(eps), "MinLPSetAlgoIPM: Eps is not finite number");
   ae_assert(eps >= 0.0, "MinLPSetAlgoIPM: Eps < 0");
   state->algokind = 2;
   state->ipmeps = eps;
   state->ipmlambda = 0.0;
}

// This function sets cost term for LP solver.
//
// By default, cost term is zero.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     C       -   cost term, array[N].
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetcost(const minlpstate &state, const real_1d_array &c);
void minlpsetcost(minlpstate *state, RVector *c) {
   ae_int_t n;
   ae_int_t i;
   n = state->n;
   ae_assert(c->cnt >= n, "MinLPSetCost: Length(C) < N");
   ae_assert(isfinitevector(c, n), "MinLPSetCost: C contains infinite or NaN elements");
   for (i = 0; i < n; i++) {
      state->c.xR[i] = c->xR[i];
   }
}

// This function sets scaling coefficients.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions and as
// preconditioner.
//
// Scale of the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the
//    function
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetscale(const minlpstate &state, const real_1d_array &s);
void minlpsetscale(minlpstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinLPSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinLPSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinLPSetScale: S contains zero elements");
   }
   for (i = 0; i < state->n; i++) {
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// This function sets box constraints for LP solver (all variables  at  once,
// different constraints for different variables).
//
// The default state of constraints is to have all variables fixed  at  zero.
// You have to overwrite it by your own constraint vector. Constraint  status
// is preserved until constraints are  explicitly  overwritten  with  another
// minlpsetbc()  call,   overwritten   with  minlpsetbcall(),  or   partially
// overwritten with minlmsetbci() call.
//
// Following types of constraints are supported:
//
//     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
//     fixed variable      x[i] == Bnd[i]          BndL[i] == BndU[i]
//     lower bound         BndL[i] <= x[i]         BndU[i] == +INF
//     upper bound         x[i] <= BndU[i]         BndL[i] == -INF
//     range               BndL[i] <= x[i] <= BndU[i]  ...
//     free variable       -                       BndL[i] == -INF, BndU[i] == +INF
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//     BndU    -   upper bounds, array[N].
//
// NOTE: infinite values can be specified by means of Double.PositiveInfinity
//       and  Double.NegativeInfinity  (in  C#)  and  +INFINITY   and
//       -INFINITY (in C++).
//
// NOTE: you may replace infinities by very small/very large values,  but  it
//       is not recommended because large numbers may introduce large numerical
//       errors in the algorithm.
//
// NOTE: if constraints for all variables are same you may use minlpsetbcall()
//       which allows to specify constraints without using arrays.
//
// NOTE: BndL > BndU will result in LP problem being recognized as infeasible.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetbc(const minlpstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minlpsetbc(minlpstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(bndl->cnt >= n, "MinLPSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinLPSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinLPSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinLPSetBC: BndU contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->bndu.xR[i] = bndu->xR[i];
   }
}

// This function sets box constraints for LP solver (all variables  at  once,
// same constraints for all variables)
//
// The default state of constraints is to have all variables fixed  at  zero.
// You have to overwrite it by your own constraint vector. Constraint  status
// is preserved until constraints are  explicitly  overwritten  with  another
// minlpsetbc() call or partially overwritten with minlpsetbcall().
//
// Following types of constraints are supported:
//
//     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
//     fixed variable      x[i] == Bnd[i]          BndL[i] == BndU[i]
//     lower bound         BndL[i] <= x[i]         BndU[i] == +INF
//     upper bound         x[i] <= BndU[i]         BndL[i] == -INF
//     range               BndL[i] <= x[i] <= BndU[i]  ...
//     free variable       -                       BndL[i] == -INF, BndU[i] == +INF
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bound, same for all variables
//     BndU    -   upper bound, same for all variables
//
// NOTE: infinite values can be specified by means of Double.PositiveInfinity
//       and  Double.NegativeInfinity  (in  C#)  and  +INFINITY   and
//       -INFINITY (in C++).
//
// NOTE: you may replace infinities by very small/very large values,  but  it
//       is not recommended because large numbers may introduce large numerical
//       errors in the algorithm.
//
// NOTE: minlpsetbc() can  be  used  to  specify  different  constraints  for
//       different variables.
//
// NOTE: BndL > BndU will result in LP problem being recognized as infeasible.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetbcall(const minlpstate &state, const double bndl, const double bndu);
void minlpsetbcall(minlpstate *state, double bndl, double bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(isfinite(bndl) || isneginf(bndl), "MinLPSetBCAll: BndL is NAN or +INF");
   ae_assert(isfinite(bndu) || isposinf(bndu), "MinLPSetBCAll: BndU is NAN or -INF");
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = bndl;
      state->bndu.xR[i] = bndu;
   }
}

// This function sets box constraints for I-th variable (other variables are
// not modified).
//
// The default state of constraints is to have all variables fixed  at  zero.
// You have to overwrite it by your own constraint vector.
//
// Following types of constraints are supported:
//
//     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
//     fixed variable      x[i] == Bnd[i]          BndL[i] == BndU[i]
//     lower bound         BndL[i] <= x[i]         BndU[i] == +INF
//     upper bound         x[i] <= BndU[i]         BndL[i] == -INF
//     range               BndL[i] <= x[i] <= BndU[i]  ...
//     free variable       -                       BndL[i] == -INF, BndU[i] == +INF
//
// Inputs:
//     State   -   structure stores algorithm state
//     I       -   variable index, in [0,N)
//     BndL    -   lower bound for I-th variable
//     BndU    -   upper bound for I-th variable
//
// NOTE: infinite values can be specified by means of Double.PositiveInfinity
//       and  Double.NegativeInfinity  (in  C#)  and  +INFINITY   and
//       -INFINITY (in C++).
//
// NOTE: you may replace infinities by very small/very large values,  but  it
//       is not recommended because large numbers may introduce large numerical
//       errors in the algorithm.
//
// NOTE: minlpsetbc() can  be  used  to  specify  different  constraints  for
//       different variables.
//
// NOTE: BndL > BndU will result in LP problem being recognized as infeasible.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetbci(const minlpstate &state, const ae_int_t i, const double bndl, const double bndu);
void minlpsetbci(minlpstate *state, ae_int_t i, double bndl, double bndu) {
   ae_int_t n;
   n = state->n;
   ae_assert(i >= 0 && i < n, "MinLPSetBCi: I is outside of [0,N)");
   ae_assert(isfinite(bndl) || isneginf(bndl), "MinLPSetBCi: BndL is NAN or +INF");
   ae_assert(isfinite(bndu) || isposinf(bndu), "MinLPSetBCi: BndU is NAN or -INF");
   state->bndl.xR[i] = bndl;
   state->bndu.xR[i] = bndu;
}

// This function sets two-sided linear constraints AL <= A*x <= AU.
//
// This version accepts dense matrix as  input;  internally  LP  solver  uses
// sparse storage  anyway  (most  LP  problems  are  sparse),  but  for  your
// convenience it may accept dense inputs. This  function  overwrites  linear
// constraints set by previous calls (if such calls were made).
//
// We recommend you to use sparse version of this function unless  you  solve
// small-scale LP problem (less than few hundreds of variables).
//
// NOTE: there also exist several versions of this function:
//       * one-sided dense version which  accepts  constraints  in  the  same
//         format as one used by QP and  NLP solvers
//       * two-sided sparse version which accepts sparse matrix
//       * two-sided dense  version which allows you to add constraints row by row
//       * two-sided sparse version which allows you to add constraints row by row
//
// Inputs:
//     State   -   structure previously allocated with minlpcreate() call.
//     A       -   linear constraints, array[K,N]. Each row of  A  represents
//                 one  constraint. One-sided  inequality   constraints, two-
//                 sided inequality  constraints,  equality  constraints  are
//                 supported (see below)
//     AL, AU  -   lower and upper bounds, array[K];
//                 * AL[i] == AU[i] => equality constraint Ai*x
//                 * AL[i] < AU[i]  => two-sided constraint AL[i] <= Ai*x <= AU[i]
//                 * AL[i] == -INF  => one-sided constraint Ai*x <= AU[i]
//                 * AU[i] == +INF  => one-sided constraint AL[i] <= Ai*x
//                 * AL[i] == -INF, AU[i] == +INF => constraint is ignored
//     K       -   number of equality/inequality constraints,  K >= 0;  if  not
//                 given, inferred from sizes of A, AL, AU.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetlc2dense(const minlpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k);
// API: void minlpsetlc2dense(const minlpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au);
void minlpsetlc2dense(minlpstate *state, RMatrix *a, RVector *al, RVector *au, ae_int_t k) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t n;
   ae_int_t nz;
   EnFrame();
   NewZVector(nrs, 0);
   n = state->n;
   ae_assert(k >= 0, "MinLPSetLC2Dense: K < 0");
   ae_assert(k == 0 || a->cols >= n, "MinLPSetLC2Dense: Cols(A) < N");
   ae_assert(a->rows >= k, "MinLPSetLC2Dense: Rows(A) < K");
   ae_assert(al->cnt >= k, "MinLPSetLC2Dense: Length(AL) < K");
   ae_assert(au->cnt >= k, "MinLPSetLC2Dense: Length(AU) < K");
   ae_assert(apservisfinitematrix(a, k, n), "MinLPSetLC2Dense: A contains infinite or NaN values!");
// Count actual (different from -INF <= A*x <= +INF) constraints;
// count non-zero elements in each row.
   ae_vector_set_length(&nrs, k);
   state->m = k;
   if (state->m == 0) {
      DeFrame();
   }
   for (i = 0; i < k; i++) {
      ae_assert(isfinite(al->xR[i]) || isneginf(al->xR[i]), "MinLPSetLC2Dense: AL contains NAN or +INF");
      ae_assert(isfinite(au->xR[i]) || isposinf(au->xR[i]), "MinLPSetLC2Dense: AU contains NAN or -INF");
      nz = 0;
      for (j = 0; j < n; j++) {
         if (a->xyR[i][j] != 0.0) {
            nz++;
         }
      }
      nrs.xZ[i] = nz;
   }
// Allocate storage, copy
   vectorsetlengthatleast(&state->al, state->m);
   vectorsetlengthatleast(&state->au, state->m);
   sparsecreatecrsbuf(state->m, n, &nrs, &state->a);
   for (i = 0; i < k; i++) {
      for (j = 0; j < n; j++) {
         if (a->xyR[i][j] != 0.0) {
            sparseset(&state->a, i, j, a->xyR[i][j]);
         }
      }
      state->al.xR[i] = al->xR[i];
      state->au.xR[i] = au->xR[i];
   }
   DeFrame();
}

// This  function  sets  two-sided linear  constraints  AL <= A*x <= AU  with
// sparse constraining matrix A. Recommended for large-scale problems.
//
// This  function  overwrites  linear  (non-box)  constraints set by previous
// calls (if such calls were made).
//
// Inputs:
//     State   -   structure previously allocated with minlpcreate() call.
//     A       -   sparse matrix with size [K,N] (exactly!).
//                 Each row of A represents one general linear constraint.
//                 A can be stored in any sparse storage format.
//     AL, AU  -   lower and upper bounds, array[K];
//                 * AL[i] == AU[i] => equality constraint Ai*x
//                 * AL[i] < AU[i]  => two-sided constraint AL[i] <= Ai*x <= AU[i]
//                 * AL[i] == -INF  => one-sided constraint Ai*x <= AU[i]
//                 * AU[i] == +INF  => one-sided constraint AL[i] <= Ai*x
//                 * AL[i] == -INF, AU[i] == +INF => constraint is ignored
//     K       -   number  of equality/inequality constraints, K >= 0.  If  K == 0
//                 is specified, A, AL, AU are ignored.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetlc2(const minlpstate &state, const sparsematrix &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k);
void minlpsetlc2(minlpstate *state, sparsematrix *a, RVector *al, RVector *au, ae_int_t k) {
   ae_int_t n;
   ae_int_t i;
   n = state->n;
// Quick exit
   if (k == 0) {
      state->m = 0;
      return;
   }
// Integrity checks
   ae_assert(k > 0, "MinLPSetLC2: K < 0");
   ae_assert(sparsegetncols(a) == n, "MinLPSetLC2: Cols(A) != N");
   ae_assert(sparsegetnrows(a) == k, "MinLPSetLC2: Rows(A) != K");
   ae_assert(al->cnt >= k, "MinLPSetLC2: Length(AL) < K");
   ae_assert(au->cnt >= k, "MinLPSetLC2: Length(AU) < K");
   for (i = 0; i < k; i++) {
      ae_assert(isfinite(al->xR[i]) || isneginf(al->xR[i]), "MinLPSetLC2: AL contains NAN or +INF");
      ae_assert(isfinite(au->xR[i]) || isposinf(au->xR[i]), "MinLPSetLC2: AU contains NAN or -INF");
   }
// Copy
   state->m = k;
   sparsecopytocrsbuf(a, &state->a);
   vectorsetlengthatleast(&state->al, k);
   vectorsetlengthatleast(&state->au, k);
   for (i = 0; i < k; i++) {
      state->al.xR[i] = al->xR[i];
      state->au.xR[i] = au->xR[i];
   }
}

// This function sets one-sided linear constraints A*x ~ AU, where "~" can be
// a mix of "<=", "==" and ">=".
//
// IMPORTANT: this function is provided here for compatibility with the  rest
//            of ALGLIB optimizers which accept constraints  in  format  like
//            this one. Many real-life problems feature two-sided constraints
//            like a0 <= a*x <= a1. It is really inefficient to add them as a
//            pair of one-sided constraints.
//
//            Use minlpsetlc2dense(), minlpsetlc2(), minlpaddlc2()  (or   its
//            sparse version) wherever possible.
//
// Inputs:
//     State   -   structure previously allocated with minlpcreate() call.
//     A       -   linear constraints, array[K,N+1]. Each row of A represents
//                 one constraint, with first N elements being linear coefficients,
//                 and last element being right side.
//     CT      -   constraint types, array[K]:
//                 * if CT[i] > 0, then I-th constraint is A[i,*]*x >= A[i,n]
//                 * if CT[i] == 0, then I-th constraint is A[i,*]*x  = A[i,n]
//                 * if CT[i] < 0, then I-th constraint is A[i,*]*x <= A[i,n]
//     K       -   number of equality/inequality constraints,  K >= 0;  if  not
//                 given, inferred from sizes of A and CT.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpsetlc(const minlpstate &state, const real_2d_array &a, const integer_1d_array &ct, const ae_int_t k);
// API: void minlpsetlc(const minlpstate &state, const real_2d_array &a, const integer_1d_array &ct);
void minlpsetlc(minlpstate *state, RMatrix *a, ZVector *ct, ae_int_t k) {
   ae_int_t n;
   ae_int_t i;
   EnFrame();
   NewRVector(al, 0);
   NewRVector(au, 0);
   n = state->n;
   ae_assert(k >= 0, "MinLPSetLC: K < 0");
   ae_assert(k == 0 || a->cols > n, "MinLPSetLC: Cols(A) <= N");
   ae_assert(a->rows >= k, "MinLPSetLC: Rows(A) < K");
   ae_assert(ct->cnt >= k, "MinLPSetLC: Length(CT) < K");
   ae_assert(apservisfinitematrix(a, k, n + 1), "MinLPSetLC: A contains infinite or NaN values!");
// Handle zero K
   if (k == 0) {
      state->m = 0;
      DeFrame();
   }
// Convert constraints to two-sided storage format, call another function
   ae_vector_set_length(&al, k);
   ae_vector_set_length(&au, k);
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] > 0) {
         al.xR[i] = a->xyR[i][n];
         au.xR[i] = +INFINITY;
         continue;
      }
      if (ct->xZ[i] < 0) {
         al.xR[i] = -INFINITY;
         au.xR[i] = a->xyR[i][n];
         continue;
      }
      al.xR[i] = a->xyR[i][n];
      au.xR[i] = a->xyR[i][n];
   }
   minlpsetlc2dense(state, a, &al, &au, k);
   DeFrame();
}

// Clear report fields prior to the optimization.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
static void minlp_clearreportfields(minlpstate *state) {
   state->repf = 0.0;
   state->repprimalerror = 0.0;
   state->repdualerror = 0.0;
   state->repiterationscount = 0;
   state->repterminationtype = 0;
   state->repn = 0;
   state->repm = 0;
}

// LINEAR PROGRAMMING
// The subroutine creates LP  solver.  After  initial  creation  it  contains
// default optimization problem with zero cost vector and all variables being
// fixed to zero values and no constraints.
//
// In order to actually solve something you should:
// * set cost vector with minlpsetcost()
// * set variable bounds with minlpsetbc() or minlpsetbcall()
// * specify constraint matrix with one of the following functions:
//   [*] minlpsetlc()        for dense one-sided constraints
//   [*] minlpsetlc2dense()  for dense two-sided constraints
//   [*] minlpsetlc2()       for sparse two-sided constraints
//   [*] minlpaddlc2dense()  to add one dense row to constraint matrix
//   [*] minlpaddlc2()       to add one row to constraint matrix (compressed format)
// * call minlpoptimize() to run the solver and  minlpresults()  to  get  the
//   solution vector and additional information.
//
// By  default,  LP  solver uses best algorithm available. As of ALGLIB 3.17,
// sparse interior point (barrier) solver is used. Future releases of  ALGLIB
// may introduce other solvers.
//
// User may choose specific LP algorithm by calling:
// * minlpsetalgodss() for revised dual simplex method with DSE  pricing  and
//   bounds flipping ratio test (aka long dual step).  Large-scale  sparse LU
//   solverwith  Forest-Tomlin update is used internally  as  linear  algebra
//   driver.
// * minlpsetalgoipm() for sparse interior point method
//
// Inputs:
//     N       -   problem size
//
// Outputs:
//     State   -   optimizer in the default state
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpcreate(const ae_int_t n, minlpstate &state);
void minlpcreate(ae_int_t n, minlpstate *state) {
   ae_int_t i;
   SetObj(minlpstate, state);
   ae_assert(n >= 1, "MinLPCreate: N < 1");
// Initialize
   state->n = n;
   state->m = 0;
   minlpsetalgoipm(state, 0.0);
   state->ipmlambda = 0.0;
   ae_vector_set_length(&state->c, n);
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->xs, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = 0.0;
      state->bndu.xR[i] = 0.0;
      state->c.xR[i] = 0.0;
      state->s.xR[i] = 1.0;
      state->xs.xR[i] = 1.0;
   }
   minlp_clearreportfields(state);
}

// This function appends two-sided linear constraint  AL <= A*x <= AU  to the
// list of currently present constraints.
//
// Constraint is passed in compressed format: as list of non-zero entries  of
// coefficient vector A. Such approach is more efficient than  dense  storage
// for highly sparse constraint vectors.
//
// Inputs:
//     State   -   structure previously allocated with minlpcreate() call.
//     IdxA    -   array[NNZ], indexes of non-zero elements of A:
//                 * can be unsorted
//                 * can include duplicate indexes (corresponding entries  of
//                   ValA[] will be summed)
//     ValA    -   array[NNZ], values of non-zero elements of A
//     NNZ     -   number of non-zero coefficients in A
//     AL, AU  -   lower and upper bounds;
//                 * AL == AU   => equality constraint A*x
//                 * AL < AU    => two-sided constraint AL <= A*x <= AU
//                 * AL == -INF => one-sided constraint A*x <= AU
//                 * AU == +INF => one-sided constraint AL <= A*x
//                 * AL == -INF, AU == +INF => constraint is ignored
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpaddlc2(const minlpstate &state, const integer_1d_array &idxa, const real_1d_array &vala, const ae_int_t nnz, const double al, const double au);
void minlpaddlc2(minlpstate *state, ZVector *idxa, RVector *vala, ae_int_t nnz, double al, double au) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   ae_int_t offs;
   ae_int_t offsdst;
   ae_int_t m;
   ae_int_t n;
   ae_int_t didx;
   ae_int_t uidx;
   m = state->m;
   n = state->n;
// Check inputs
   ae_assert(nnz >= 0, "MinLPAddLC2: NNZ < 0");
   ae_assert(idxa->cnt >= nnz, "MinLPAddLC2: Length(IdxA) < NNZ");
   ae_assert(vala->cnt >= nnz, "MinLPAddLC2: Length(ValA) < NNZ");
   for (i = 0; i < nnz; i++) {
      ae_assert(idxa->xZ[i] >= 0 && idxa->xZ[i] < n, "MinLPAddLC2: IdxA contains indexes outside of [0,N) range");
   }
   ae_assert(isfinitevector(vala, nnz), "MinLPAddLC2: ValA contains infinite or NaN values!");
   ae_assert(isfinite(al) || isneginf(al), "MinLPAddLC2Dense: AL is NAN or +INF");
   ae_assert(isfinite(au) || isposinf(au), "MinLPAddLC2Dense: AU is NAN or -INF");
// If M == 0, it means that A is uninitialized.
// Prepare sparse matrix structure
   if (m == 0) {
      state->a.matrixtype = 1;
      state->a.m = 0;
      state->a.n = n;
      state->a.ninitialized = 0;
      vectorsetlengthatleast(&state->a.ridx, 1);
      state->a.ridx.xZ[0] = 0;
   }
// Reallocate storage
   offs = state->a.ridx.xZ[m];
   ivectorgrowto(&state->a.idx, offs + nnz);
   rvectorgrowto(&state->a.vals, offs + nnz);
   ivectorgrowto(&state->a.didx, m + 1);
   ivectorgrowto(&state->a.uidx, m + 1);
   ivectorgrowto(&state->a.ridx, m + 2);
   rvectorgrowto(&state->al, m + 1);
   rvectorgrowto(&state->au, m + 1);
// If NNZ == 0, perform quick and simple row append.
   if (nnz == 0) {
      state->a.didx.xZ[m] = state->a.ridx.xZ[m];
      state->a.uidx.xZ[m] = state->a.ridx.xZ[m];
      state->a.ridx.xZ[m + 1] = state->a.ridx.xZ[m];
      state->al.xR[m] = al;
      state->au.xR[m] = au;
      state->a.m = m + 1;
      state->m = m + 1;
      return;
   }
// Now we are sure that A contains properly initialized sparse
// matrix (or some appropriate dummy for M == 0) and we have NNZ > 0
// (no need to care about degenerate cases).
//
// Append rows to A:
// * append data
// * sort in place
// * merge duplicate indexes
// * compute DIdx and UIdx
//
   for (i = 0; i < nnz; i++) {
      state->a.idx.xZ[offs + i] = idxa->xZ[i];
      state->a.vals.xR[offs + i] = vala->xR[i];
   }
   tagsortmiddleir(&state->a.idx, &state->a.vals, nnz, offs);
   offsdst = offs;
   for (i = 1; i < nnz; i++) {
      if (state->a.idx.xZ[offsdst] != state->a.idx.xZ[offs + i]) {
         offsdst++;
         state->a.idx.xZ[offsdst] = state->a.idx.xZ[offs + i];
         state->a.vals.xR[offsdst] = state->a.vals.xR[offs + i];
      } else {
         state->a.vals.xR[offsdst] += state->a.vals.xR[offs + i];
      }
   }
   nnz = offsdst - offs + 1;
   uidx = -1;
   didx = -1;
   for (j = offs; j <= offsdst; j++) {
      k = state->a.idx.xZ[j];
      if (k == m) {
         didx = j;
      } else {
         if (k > m && uidx == -1) {
            uidx = j;
            break;
         }
      }
   }
   if (uidx == -1) {
      uidx = offsdst + 1;
   }
   if (didx == -1) {
      didx = uidx;
   }
   state->a.didx.xZ[m] = didx;
   state->a.uidx.xZ[m] = uidx;
   state->a.ridx.xZ[m + 1] = offsdst + 1;
   state->a.m = m + 1;
   state->a.ninitialized += nnz;
   state->al.xR[m] = al;
   state->au.xR[m] = au;
   state->m = m + 1;
}

// This function appends two-sided linear constraint  AL <= A*x <= AU  to the
// list of currently present constraints.
//
// This version accepts dense constraint vector as input, but  sparsifies  it
// for internal storage and processing. Thus, time to add one  constraint  in
// is O(N) - we have to scan entire array of length N. Sparse version of this
// function is order of magnitude faster for  constraints  with  just  a  few
// nonzeros per row.
//
// Inputs:
//     State   -   structure previously allocated with minlpcreate() call.
//     A       -   linear constraint coefficient, array[N], right side is NOT
//                 included.
//     AL, AU  -   lower and upper bounds;
//                 * AL == AU   => equality constraint Ai*x
//                 * AL < AU    => two-sided constraint AL <= A*x <= AU
//                 * AL == -INF => one-sided constraint Ai*x <= AU
//                 * AU == +INF => one-sided constraint AL <= Ai*x
//                 * AL == -INF, AU == +INF => constraint is ignored
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpaddlc2dense(const minlpstate &state, const real_1d_array &a, const double al, const double au);
void minlpaddlc2dense(minlpstate *state, RVector *a, double al, double au) {
   ae_int_t i;
   ae_int_t n;
   ae_int_t nnz;
   n = state->n;
   ae_assert(a->cnt >= n, "MinLPAddLC2Dense: Length(A) < N");
   ae_assert(isfinitevector(a, n), "MinLPAddLC2Dense: A contains infinite or NaN values!");
   ae_assert(isfinite(al) || isneginf(al), "MinLPAddLC2Dense: AL is NAN or +INF");
   ae_assert(isfinite(au) || isposinf(au), "MinLPAddLC2Dense: AU is NAN or -INF");
   vectorsetlengthatleast(&state->adddtmpi, n);
   vectorsetlengthatleast(&state->adddtmpr, n);
   nnz = 0;
   for (i = 0; i < n; i++) {
      if (a->xR[i] != 0.0) {
         state->adddtmpi.xZ[nnz] = i;
         state->adddtmpr.xR[nnz] = a->xR[i];
         nnz++;
      }
   }
   minlpaddlc2(state, &state->adddtmpi, &state->adddtmpr, nnz, al, au);
}

// This function solves LP problem.
//
// Inputs:
//     State   -   algorithm state
//
// You should use minlpresults() function to access results  after  calls  to
// this function.
// ALGLIB: Copyright 19.07.2018 by Sergey Bochkanov
// API: void minlpoptimize(const minlpstate &state);
void minlpoptimize(minlpstate *state) {
   const ae_int_t alllogicalsbasis = 0;
   ae_int_t n;
   ae_int_t m;
   ae_int_t i;
   double v;
   EnFrame();
   NewObj(dualsimplexsettings, settings);
   NewRVector(dummy1, 0);
   NewRMatrix(dummy, 0, 0);
   NewObj(dualsimplexbasis, dummybasis);
   n = state->n;
   m = state->m;
   minlp_clearreportfields(state);
// Run presolver
   presolvelp(&state->s, &state->c, &state->bndl, &state->bndu, n, &state->a, &state->al, &state->au, m, &state->presolver);
   if (state->presolver.problemstatus == -3 || state->presolver.problemstatus == -2) {
      state->repterminationtype = state->presolver.problemstatus;
      state->repn = n;
      state->repm = m;
      rsetallocv(n, 0.0, &state->xs);
      rsetallocv(n, 0.0, &state->lagbc);
      rsetallocv(m, 0.0, &state->laglc);
      isetallocv(n + m, 0, &state->cs);
      state->repf = 0.0;
      state->repprimalerror = 0.0;
      for (i = 0; i < n; i++) {
         if (isfinite(state->bndl.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, state->bndl.xR[i] - 0.0);
         }
         if (isfinite(state->bndu.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, 0.0 - state->bndu.xR[i]);
         }
      }
      for (i = 0; i < m; i++) {
         if (isfinite(state->al.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, state->al.xR[i] - 0.0);
         }
         if (isfinite(state->au.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, 0.0 - state->au.xR[i]);
         }
      }
      state->repdualerror = 0.0;
      for (i = 0; i < n; i++) {
         state->repdualerror = rmax2(state->repdualerror, fabs(state->c.xR[i]));
      }
      state->repslackerror = 0.0;
      DeFrame();
   }
   ae_assert(state->presolver.problemstatus == 0, "MINLP: integrity check 4432 failed");
// Call current solver
   if (state->algokind == 1 || state->algokind == 2) {
   // If presolver did NOT remove all variables (NewN > 0), call the current solver
      if (state->presolver.newn > 0) {
         if (state->algokind == 1) {
         // Dual simplex method with presolve
            dsssettingsinit(&settings);
            settings.xtolabs = state->dsseps;
            settings.dtolabs = state->dsseps;
            dssinit(state->presolver.newn, &state->dss);
            dsssetproblem(&state->dss, &state->presolver.c, &state->presolver.bndl, &state->presolver.bndu, &dummy, &state->presolver.sparsea, 1, &state->presolver.al, &state->presolver.au, state->presolver.newm, &dummybasis, alllogicalsbasis, &settings);
            dssoptimize(&state->dss, &settings);
         // Export results, convert from presolve
            rcopyallocv(state->presolver.newn, &state->dss.repx, &state->xs);
            rcopyallocv(state->presolver.newn, &state->dss.replagbc, &state->lagbc);
            rcopyallocv(state->presolver.newm, &state->dss.replaglc, &state->laglc);
            icopyallocv(state->presolver.newn + state->presolver.newm, &state->dss.repstats, &state->cs);
            state->repiterationscount = state->dss.repiterationscount;
            state->repterminationtype = state->dss.repterminationtype;
         }
         if (state->algokind == 2) {
         // Interior point method with presolve
            rsetallocv(state->presolver.newn, 1.0, &state->units);
            rsetallocv(state->presolver.newn, 0.0, &state->zeroorigin);
            sparsecreatesksbandbuf(state->presolver.newn, state->presolver.newn, 0, &state->ipmquadratic);
            for (i = 0; i < state->presolver.newn; i++) {
               sparseset(&state->ipmquadratic, i, i, state->ipmlambda);
            }
            sparseconverttocrs(&state->ipmquadratic);
            vipminitsparse(&state->ipm, &state->units, &state->zeroorigin, state->presolver.newn);
            vipmsetquadraticlinear(&state->ipm, &dummy, &state->ipmquadratic, 1, false, &state->presolver.c);
            vipmsetconstraints(&state->ipm, &state->presolver.bndl, &state->presolver.bndu, &state->presolver.sparsea, state->presolver.newm, &dummy, 0, &state->presolver.al, &state->presolver.au);
            vipmsetcond(&state->ipm, state->ipmeps, state->ipmeps, state->ipmeps);
            vipmoptimize(&state->ipm, true, &state->xs, &state->lagbc, &state->laglc, &state->repterminationtype);
            isetallocv(state->presolver.newn + state->presolver.newm, 0, &state->cs);
            state->repiterationscount = state->ipm.repiterationscount;
         }
      } else {
      // Presolver removed all variables, manually set up XS and Lagrange multipliers
         rsetallocv(state->presolver.newm, 0.0, &state->laglc);
         isetallocv(state->presolver.newn + state->presolver.newm, 0, &state->cs);
         state->repterminationtype = 1;
         state->repiterationscount = 0;
      }
   // Convert back from presolved format
      presolvebwd(&state->presolver, &state->xs, &state->cs, &state->lagbc, &state->laglc);
      state->repn = n;
      state->repm = m;
   // Compute F, primal and dual errors
      state->repf = rdotv(n, &state->xs, &state->c);
      state->repprimalerror = 0.0;
      state->repdualerror = 0.0;
      state->repslackerror = 0.0;
      rcopyallocv(n, &state->c, &state->tmpg);
      if (m > 0) {
         sparsemv(&state->a, &state->xs, &state->tmpax);
         sparsegemv(&state->a, 1.0, 1, &state->laglc, 0, 1.0, &state->tmpg, 0);
      }
      raddv(n, 1.0, &state->lagbc, &state->tmpg);
      for (i = 0; i < n; i++) {
         if (isfinite(state->bndl.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, state->bndl.xR[i] - state->xs.xR[i]);
            state->repslackerror = rmax2(state->repslackerror, rmax2(state->xs.xR[i] - state->bndl.xR[i], 0.0) * rmax2(-state->lagbc.xR[i], 0.0));
         }
         if (isfinite(state->bndu.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, state->xs.xR[i] - state->bndu.xR[i]);
            state->repslackerror = rmax2(state->repslackerror, rmax2(state->bndu.xR[i] - state->xs.xR[i], 0.0) * rmax2(state->lagbc.xR[i], 0.0));
         }
         state->repdualerror = rmax2(state->repdualerror, fabs(state->tmpg.xR[i]));
      }
      for (i = 0; i < m; i++) {
         v = state->tmpax.xR[i];
         if (isfinite(state->al.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, state->al.xR[i] - v);
            state->repslackerror = rmax2(state->repslackerror, rmax2(v - state->al.xR[i], 0.0) * rmax2(-state->laglc.xR[i], 0.0));
         }
         if (isfinite(state->au.xR[i])) {
            state->repprimalerror = rmax2(state->repprimalerror, v - state->au.xR[i]);
            state->repslackerror = rmax2(state->repslackerror, rmax2(state->au.xR[i] - v, 0.0) * rmax2(state->laglc.xR[i], 0.0));
         }
      }
      DeFrame();
   }
// Integrity check failed - unknown solver
   ae_assert(false, "MinLPOptimize: integrity check failed - unknown solver");
   DeFrame();
}

// LP results
//
// Buffered implementation of MinLPResults() which uses preallocated  buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minlpresultsbuf(const minlpstate &state, real_1d_array &x, minlpreport &rep);
void minlpresultsbuf(minlpstate *state, RVector *x, minlpreport *rep) {
   ae_int_t i;
   ae_int_t repn;
   ae_int_t repm;
   repn = state->repn;
   repm = state->repm;
   vectorsetlengthatleast(x, repn);
   ae_vector_set_length(&rep->y, repm);
   ae_vector_set_length(&rep->stats, repn + repm);
   rep->f = state->repf;
   rep->primalerror = state->repprimalerror;
   rep->dualerror = state->repdualerror;
   rep->slackerror = state->repslackerror;
   rep->iterationscount = state->repiterationscount;
   rep->terminationtype = state->repterminationtype;
   rcopyallocv(repm, &state->laglc, &rep->laglc);
   rcopyallocv(repn, &state->lagbc, &rep->lagbc);
   for (i = 0; i < repn; i++) {
      x->xR[i] = state->xs.xR[i];
   }
   for (i = 0; i < repm; i++) {
      rep->y.xR[i] = -rep->laglc.xR[i];
   }
   for (i = 0; i < repn + repm; i++) {
      rep->stats.xZ[i] = state->cs.xZ[i];
   }
}

// LP solver results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[N], solution (on failure: last trial point)
//     Rep     -   optimization report. You should check Rep.TerminationType,
//                 which contains completion code, and you may check  another
//                 fields which contain another information  about  algorithm
//                 functioning.
//
//                 Failure codes returned by algorithm are:
//                 * -4    LP problem is primal unbounded (dual infeasible)
//                 * -3    LP problem is primal infeasible (dual unbounded)
//                 * -2    IPM solver detected that problem is either
//                         infeasible or unbounded
//
//                 Success codes:
//                 *  1..4 successful completion
//                 *  5    MaxIts steps was taken
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void minlpresults(const minlpstate &state, real_1d_array &x, minlpreport &rep);
void minlpresults(minlpstate *state, RVector *x, minlpreport *rep) {
   SetVector(x);
   SetObj(minlpreport, rep);
   minlpresultsbuf(state, x, rep);
}

void minlpstate_init(void *_p, bool make_automatic) {
   minlpstate *p = (minlpstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->c, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->a, make_automatic);
   ae_vector_init(&p->al, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->au, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagbc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->laglc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cs, 0, DT_INT, make_automatic);
   dualsimplexstate_init(&p->dss, make_automatic);
   vipmstate_init(&p->ipm, make_automatic);
   ae_vector_init(&p->adddtmpi, 0, DT_INT, make_automatic);
   ae_vector_init(&p->adddtmpr, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpax, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpg, 0, DT_REAL, make_automatic);
   presolveinfo_init(&p->presolver, make_automatic);
   ae_vector_init(&p->zeroorigin, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->units, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->ipmquadratic, make_automatic);
}

void minlpstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minlpstate *dst = (minlpstate *)_dst;
   const minlpstate *src = (const minlpstate *)_src;
   dst->n = src->n;
   dst->algokind = src->algokind;
   dst->ipmlambda = src->ipmlambda;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->c, &src->c, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   dst->m = src->m;
   sparsematrix_copy(&dst->a, &src->a, make_automatic);
   ae_vector_copy(&dst->al, &src->al, make_automatic);
   ae_vector_copy(&dst->au, &src->au, make_automatic);
   ae_vector_copy(&dst->xs, &src->xs, make_automatic);
   ae_vector_copy(&dst->lagbc, &src->lagbc, make_automatic);
   ae_vector_copy(&dst->laglc, &src->laglc, make_automatic);
   ae_vector_copy(&dst->cs, &src->cs, make_automatic);
   dst->repf = src->repf;
   dst->repprimalerror = src->repprimalerror;
   dst->repdualerror = src->repdualerror;
   dst->repslackerror = src->repslackerror;
   dst->repiterationscount = src->repiterationscount;
   dst->repterminationtype = src->repterminationtype;
   dst->repn = src->repn;
   dst->repm = src->repm;
   dst->dsseps = src->dsseps;
   dst->ipmeps = src->ipmeps;
   dualsimplexstate_copy(&dst->dss, &src->dss, make_automatic);
   vipmstate_copy(&dst->ipm, &src->ipm, make_automatic);
   ae_vector_copy(&dst->adddtmpi, &src->adddtmpi, make_automatic);
   ae_vector_copy(&dst->adddtmpr, &src->adddtmpr, make_automatic);
   ae_vector_copy(&dst->tmpax, &src->tmpax, make_automatic);
   ae_vector_copy(&dst->tmpg, &src->tmpg, make_automatic);
   presolveinfo_copy(&dst->presolver, &src->presolver, make_automatic);
   ae_vector_copy(&dst->zeroorigin, &src->zeroorigin, make_automatic);
   ae_vector_copy(&dst->units, &src->units, make_automatic);
   sparsematrix_copy(&dst->ipmquadratic, &src->ipmquadratic, make_automatic);
}

void minlpstate_free(void *_p, bool make_automatic) {
   minlpstate *p = (minlpstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->c, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   sparsematrix_free(&p->a, make_automatic);
   ae_vector_free(&p->al, make_automatic);
   ae_vector_free(&p->au, make_automatic);
   ae_vector_free(&p->xs, make_automatic);
   ae_vector_free(&p->lagbc, make_automatic);
   ae_vector_free(&p->laglc, make_automatic);
   ae_vector_free(&p->cs, make_automatic);
   dualsimplexstate_free(&p->dss, make_automatic);
   vipmstate_free(&p->ipm, make_automatic);
   ae_vector_free(&p->adddtmpi, make_automatic);
   ae_vector_free(&p->adddtmpr, make_automatic);
   ae_vector_free(&p->tmpax, make_automatic);
   ae_vector_free(&p->tmpg, make_automatic);
   presolveinfo_free(&p->presolver, make_automatic);
   ae_vector_free(&p->zeroorigin, make_automatic);
   ae_vector_free(&p->units, make_automatic);
   sparsematrix_free(&p->ipmquadratic, make_automatic);
}

void minlpreport_init(void *_p, bool make_automatic) {
   minlpreport *p = (minlpreport *)_p;
   ae_vector_init(&p->lagbc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->laglc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->y, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stats, 0, DT_INT, make_automatic);
}

void minlpreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minlpreport *dst = (minlpreport *)_dst;
   const minlpreport *src = (const minlpreport *)_src;
   dst->f = src->f;
   ae_vector_copy(&dst->lagbc, &src->lagbc, make_automatic);
   ae_vector_copy(&dst->laglc, &src->laglc, make_automatic);
   ae_vector_copy(&dst->y, &src->y, make_automatic);
   ae_vector_copy(&dst->stats, &src->stats, make_automatic);
   dst->primalerror = src->primalerror;
   dst->dualerror = src->dualerror;
   dst->slackerror = src->slackerror;
   dst->iterationscount = src->iterationscount;
   dst->terminationtype = src->terminationtype;
}

void minlpreport_free(void *_p, bool make_automatic) {
   minlpreport *p = (minlpreport *)_p;
   ae_vector_free(&p->lagbc, make_automatic);
   ae_vector_free(&p->laglc, make_automatic);
   ae_vector_free(&p->y, make_automatic);
   ae_vector_free(&p->stats, make_automatic);
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores linear solver state.
// You should use functions provided by MinLP subpackage to work with this
// object
DefClass(minlpstate, )

// This structure stores optimization report:
// * f                         target function value
// * lagbc                     Lagrange coefficients for box constraints
// * laglc                     Lagrange coefficients for linear constraints
// * y                         dual variables
// * stats                     array[N+M], statuses of box (N) and linear (M)
//                             constraints. This array is filled only by  DSS
//                             algorithm because IPM always stops at INTERIOR
//                             point:
//                             * stats[i] > 0  => constraint at upper bound
//                                                (also used for free non-basic
//                                                variables set to zero)
//                             * stats[i] < 0  => constraint at lower bound
//                             * stats[i] == 0 => constraint is inactive, basic
//                                                variable
// * primalerror               primal feasibility error
// * dualerror                 dual feasibility error
// * slackerror                complementary slackness error
// * iterationscount           iteration count
// * terminationtype           completion code (see below)
//
// COMPLETION CODES
//
// Completion codes:
// * -4    LP problem is primal unbounded (dual infeasible)
// * -3    LP problem is primal infeasible (dual unbounded)
// *  1..4 successful completion
// *  5    MaxIts steps was taken
// *  7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//
// LAGRANGE COEFFICIENTS
//
// Positive Lagrange coefficient means that constraint is at its upper bound.
// Negative coefficient means that constraint is at its lower  bound.  It  is
// expected that at solution the dual feasibility condition holds:
//
//     C + SUM(Ei*LagBC[i],i = 0..n-1) + SUM(Ai*LagLC[i],i = 0..m-1) ~ 0
//
// where
// * C is a cost vector (linear term)
// * Ei is a vector with 1.0 at position I and 0 in other positions
// * Ai is an I-th row of linear constraint matrix
DefClass(minlpreport, DecVal(f) DecVar(lagbc) DecVar(laglc) DecVar(y) DecVar(stats) DecVal(primalerror) DecVal(dualerror) DecVal(slackerror) DecVal(iterationscount) DecVal(terminationtype))

void minlpsetalgodss(const minlpstate &state, const double eps) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetalgodss(ConstT(minlpstate, state), eps);
   alglib_impl::ae_state_clear();
}

void minlpsetalgoipm(const minlpstate &state, const double eps) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetalgoipm(ConstT(minlpstate, state), eps);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlpsetalgoipm(const minlpstate &state) {
   double eps = 0.0;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetalgoipm(ConstT(minlpstate, state), eps);
   alglib_impl::ae_state_clear();
}
#endif

void minlpsetcost(const minlpstate &state, const real_1d_array &c) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetcost(ConstT(minlpstate, state), ConstT(ae_vector, c));
   alglib_impl::ae_state_clear();
}

void minlpsetscale(const minlpstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetscale(ConstT(minlpstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minlpsetbc(const minlpstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetbc(ConstT(minlpstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minlpsetbcall(const minlpstate &state, const double bndl, const double bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetbcall(ConstT(minlpstate, state), bndl, bndu);
   alglib_impl::ae_state_clear();
}

void minlpsetbci(const minlpstate &state, const ae_int_t i, const double bndl, const double bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetbci(ConstT(minlpstate, state), i, bndl, bndu);
   alglib_impl::ae_state_clear();
}

void minlpsetlc2dense(const minlpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetlc2dense(ConstT(minlpstate, state), ConstT(ae_matrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlpsetlc2dense(const minlpstate &state, const real_2d_array &a, const real_1d_array &al, const real_1d_array &au) {
   ae_int_t k = a.rows();
   if (k != al.length() || k != au.length()) ThrowError("Error while calling 'minlpsetlc2dense': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetlc2dense(ConstT(minlpstate, state), ConstT(ae_matrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), k);
   alglib_impl::ae_state_clear();
}
#endif

void minlpsetlc2(const minlpstate &state, const sparsematrix &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetlc2(ConstT(minlpstate, state), ConstT(sparsematrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), k);
   alglib_impl::ae_state_clear();
}

void minlpsetlc(const minlpstate &state, const real_2d_array &a, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetlc(ConstT(minlpstate, state), ConstT(ae_matrix, a), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minlpsetlc(const minlpstate &state, const real_2d_array &a, const integer_1d_array &ct) {
   ae_int_t k = a.rows();
   if (k != ct.length()) ThrowError("Error while calling 'minlpsetlc': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpsetlc(ConstT(minlpstate, state), ConstT(ae_matrix, a), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#endif

void minlpcreate(const ae_int_t n, minlpstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpcreate(n, ConstT(minlpstate, state));
   alglib_impl::ae_state_clear();
}

void minlpaddlc2(const minlpstate &state, const integer_1d_array &idxa, const real_1d_array &vala, const ae_int_t nnz, const double al, const double au) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpaddlc2(ConstT(minlpstate, state), ConstT(ae_vector, idxa), ConstT(ae_vector, vala), nnz, al, au);
   alglib_impl::ae_state_clear();
}

void minlpaddlc2dense(const minlpstate &state, const real_1d_array &a, const double al, const double au) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpaddlc2dense(ConstT(minlpstate, state), ConstT(ae_vector, a), al, au);
   alglib_impl::ae_state_clear();
}

void minlpoptimize(const minlpstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpoptimize(ConstT(minlpstate, state));
   alglib_impl::ae_state_clear();
}

void minlpresultsbuf(const minlpstate &state, real_1d_array &x, minlpreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpresultsbuf(ConstT(minlpstate, state), ConstT(ae_vector, x), ConstT(minlpreport, rep));
   alglib_impl::ae_state_clear();
}

void minlpresults(const minlpstate &state, real_1d_array &x, minlpreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlpresults(ConstT(minlpstate, state), ConstT(ae_vector, x), ConstT(minlpreport, rep));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === NLCSLP Package ===
// Depends on: (AlgLibInternal) LINMIN
// Depends on: OPTSERV, REVISEDDUALSIMPLEX
namespace alglib_impl {
static const double nlcslp_slpstpclosetozero = 0.001;
static const double nlcslp_slpstpclosetoone = 0.95;
static const double nlcslp_slpdeltadecrease = 0.20;
static const double nlcslp_slpdeltaincrease = 0.80;
static const double nlcslp_bfgstol = 0.00001;
static const double nlcslp_defaultl1penalty = 0.1;
static const ae_int_t nlcslp_nonmonotonicphase2limit = 5;

// This function initializes SLP subproblem.
// Should be called once in the beginning of the optimization.
//
// Inputs:
//     SState          -   solver state
//     Subsolver       -   SLP subproblem to initialize
//
// Return Value:
//     True on success
//     False on failure of the LP solver (unexpected... but possible due to numerical errors)
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static void nlcslp_initlpsubsolver(minslpstate *sstate, minslpsubsolver *subsolver) {
   ae_int_t n;
   ae_int_t nslack;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t lccnt;
   ae_int_t nnz;
   ae_int_t offs;
   ae_int_t i;
   ae_int_t j;
   n = sstate->n;
   nec = sstate->nec;
   nic = sstate->nic;
   nlec = sstate->nlec;
   nlic = sstate->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   lccnt = nec + nic + nlec + nlic;
// Create simplex solver.
//
// NOTE: we disable DSE pricing because it interferes with our
//       warm-start strategy.
   dsssettingsinit(&subsolver->dsssettings);
   subsolver->dsssettings.pricing = 0;
// Allocate temporaries
   vectorsetlengthatleast(&subsolver->cural, lccnt + n);
   vectorsetlengthatleast(&subsolver->curau, lccnt + n);
   matrixsetlengthatleast(&subsolver->curd, n, n);
   matrixsetlengthatleast(&subsolver->curhd, n, n);
   vectorsetlengthatleast(&subsolver->curbndl, nslack);
   vectorsetlengthatleast(&subsolver->curbndu, nslack);
   vectorsetlengthatleast(&subsolver->curb, nslack);
   vectorsetlengthatleast(&subsolver->sk, n);
   vectorsetlengthatleast(&subsolver->yk, n);
// Initial state
   subsolver->basispresent = false;
   subsolver->curdcnt = 0;
   hessianinitbfgs(&subsolver->hess, n, 0, coalesce(sstate->epsx, sqrt(machineepsilon)));
// Linear constraints do not change across subiterations, that's
// why we allocate storage for them at the start of the program.
//
// A full set of "raw" constraints is stored; later we will filter
// out inequality ones which are inactive anywhere in the current
// trust region.
//
// NOTE: because sparserawlc object stores only linear constraint
//       (linearizations of nonlinear ones are not stored) we
//       allocate only minimum necessary space.
   nnz = 0;
   for (i = 0; i < nec + nic; i++) {
      for (j = 0; j < n; j++) {
         if (sstate->scaledcleic.xyR[i][j] != 0.0) {
            nnz++;
         }
      }
   }
   vectorsetlengthatleast(&subsolver->sparserawlc.ridx, nec + nic + 1);
   vectorsetlengthatleast(&subsolver->sparserawlc.vals, nnz);
   vectorsetlengthatleast(&subsolver->sparserawlc.idx, nnz);
   vectorsetlengthatleast(&subsolver->sparserawlc.didx, nec + nic);
   vectorsetlengthatleast(&subsolver->sparserawlc.uidx, nec + nic);
   offs = 0;
   subsolver->sparserawlc.ridx.xZ[0] = 0;
   for (i = 0; i < nec + nic; i++) {
      for (j = 0; j < n; j++) {
         if (sstate->scaledcleic.xyR[i][j] != 0.0) {
         // Primary part of the matrix
            subsolver->sparserawlc.vals.xR[offs] = sstate->scaledcleic.xyR[i][j];
            subsolver->sparserawlc.idx.xZ[offs] = j;
            offs++;
         }
      }
      subsolver->sparserawlc.ridx.xZ[i + 1] = offs;
   }
   subsolver->sparserawlc.matrixtype = 1;
   subsolver->sparserawlc.ninitialized = subsolver->sparserawlc.ridx.xZ[nec + nic];
   subsolver->sparserawlc.m = nec + nic;
   subsolver->sparserawlc.n = n;
   sparseinitduidx(&subsolver->sparserawlc);
}

// Restarts LP subproblem (cleans the matrix of internally stored directions)
//
// Inputs:
//     SState          -   solver state
//     Subsolver       -   SLP subproblem to initialize
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static void nlcslp_lpsubproblemrestart(minslpstate *sstate, minslpsubsolver *subsolver) {
   subsolver->curdcnt = 0;
}

// This function solves LP subproblem given by initial point X, function vector Fi
// and Jacobian Jac, and returns estimates of Lagrangian multipliers and search direction D[].
//
// This function does NOT append search direction D to conjugacy constraints,
// you have to use LPSubproblemAppendConjugacyConstraint().
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static bool nlcslp_lpsubproblemsolve(minslpstate *state, minslpsubsolver *subsolver, RVector *x, RVector *fi, RMatrix *jac, ae_int_t innerk, RVector *d, RVector *lagmult) {
   ae_int_t n;
   ae_int_t nslack;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   double vv;
   double vright;
   double vmax;
   ae_int_t basisinittype;
   ae_int_t lccnt;
   ae_int_t offsslackec;
   ae_int_t offsslacknlec;
   ae_int_t offsslackic;
   ae_int_t offsslacknlic;
   ae_int_t offs;
   ae_int_t nnz;
   ae_int_t j0;
   ae_int_t j1;
   bool result;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   lccnt = nec + nic + nlec + nlic;
// Locations of slack variables
   offsslackec = n;
   offsslacknlec = n + 2 * nec;
   offsslackic = n + 2 * nec + 2 * nlec;
   offsslacknlic = n + 2 * (nec + nlec) + nic;
// Prepare temporary structures
   rvectorgrowto(&subsolver->cural, lccnt + subsolver->curdcnt);
   rvectorgrowto(&subsolver->curau, lccnt + subsolver->curdcnt);
// Prepare default solution: all zeros
   result = true;
   for (i = 0; i < nslack; i++) {
      d->xR[i] = 0.0;
   }
   for (i = 0; i < lccnt; i++) {
      lagmult->xR[i] = 0.0;
   }
// Linear term B
//
// NOTE: elements [N,NSlack) are equal to bigC + perturbation to improve numeric properties of LP problem
   for (i = 0; i < n; i++) {
      subsolver->curb.xR[i] = jac->xyR[0][i];
   }
   v = 0.0;
   for (i = 0; i < n; i++) {
      v += sqr(jac->xyR[0][i]);
   }
   v = coalesce(sqrt(v), 1.0);
   for (i = n; i < nslack; i++) {
      subsolver->curb.xR[i] = (state->bigc + 1.0 / (1 + i)) * v;
   }
// Trust radius constraints for primary variables
   for (i = 0; i < n; i++) {
      subsolver->curbndl.xR[i] = -state->trustrad;
      subsolver->curbndu.xR[i] = state->trustrad;
      if (state->hasbndl.xB[i]) {
         subsolver->curbndl.xR[i] = rmax2(subsolver->curbndl.xR[i], state->scaledbndl.xR[i] - x->xR[i]);
      }
      if (state->hasbndu.xB[i]) {
         subsolver->curbndu.xR[i] = rmin2(subsolver->curbndu.xR[i], state->scaledbndu.xR[i] - x->xR[i]);
      }
   }
// Prepare storage for "effective" constraining matrix
   nnz = subsolver->sparserawlc.ridx.xZ[nec + nic];
   for (i = 0; i < nlec + nlic; i++) {
      for (j = 0; j < n; j++) {
         if (jac->xyR[1 + i][j] != 0.0) {
            nnz++;
         }
      }
   }
   nnz += 2 * nec + nic;
   nnz += 2 * nlec + nlic;
   nnz += subsolver->curdcnt * n;
   ivectorgrowto(&subsolver->sparseefflc.ridx, lccnt + n + 1);
   rvectorgrowto(&subsolver->sparseefflc.vals, nnz);
   ivectorgrowto(&subsolver->sparseefflc.idx, nnz);
   vectorsetlengthatleast(&subsolver->sparseefflc.didx, lccnt + n);
   vectorsetlengthatleast(&subsolver->sparseefflc.uidx, lccnt + n);
   subsolver->sparseefflc.m = 0;
   subsolver->sparseefflc.n = nslack;
   subsolver->sparseefflc.matrixtype = 1;
// Append linear equality/inequality constraints
//
// Scan sparsified linear constraints stored in sparserawlc[], skip ones
// which are inactive anywhere in the trust region.
   vectorsetlengthatleast(&subsolver->tmp0, nslack);
   for (i = 0; i < n; i++) {
      subsolver->tmp0.xR[i] = x->xR[i];
   }
   for (i = n; i < nslack; i++) {
      subsolver->tmp0.xR[i] = 0.0;
   }
   for (i = 0; i < nec + nic; i++) {
   // Calculate:
   // * VRight - product of X[] (extended with zeros up to NSlack elements)
   //            and AR[i] - Ith row of sparserawlc matrix.
   // * VMax   - maximum value of X*ARi computed over trust region
      vright = 0.0;
      vmax = 0.0;
      j0 = subsolver->sparserawlc.ridx.xZ[i];
      j1 = subsolver->sparserawlc.ridx.xZ[i + 1] - 1;
      for (k = j0; k <= j1; k++) {
         j = subsolver->sparserawlc.idx.xZ[k];
         v = subsolver->tmp0.xR[j];
         vv = subsolver->sparserawlc.vals.xR[k];
         vright += vv * v;
         if (vv >= 0.0) {
            vmax += vv * (v + subsolver->curbndu.xR[j]);
         } else {
            vmax += vv * (v + subsolver->curbndl.xR[j]);
         }
      }
   // If constraint is an inequality one and guaranteed to be inactive
   // within trust region, it is skipped (row itself is retained but
   // filled by zeros).
      if (i >= nec && vmax <= state->scaledcleic.xyR[i][n]) {
         offs = subsolver->sparseefflc.ridx.xZ[i];
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslackic + (i - nec);
         subsolver->sparseefflc.ridx.xZ[i + 1] = offs + 1;
         subsolver->cural.xR[i] = 0.0;
         subsolver->curau.xR[i] = 0.0;
         subsolver->curbndl.xR[offsslackic + (i - nec)] = 0.0;
         subsolver->curbndu.xR[offsslackic + (i - nec)] = 0.0;
         continue;
      }
   // Start working on row I
      offs = subsolver->sparseefflc.ridx.xZ[i];
   // Copy constraint from sparserawlc[] to sparseefflc[]
      j0 = subsolver->sparserawlc.ridx.xZ[i];
      j1 = subsolver->sparserawlc.ridx.xZ[i + 1] - 1;
      for (k = j0; k <= j1; k++) {
         subsolver->sparseefflc.idx.xZ[offs] = subsolver->sparserawlc.idx.xZ[k];
         subsolver->sparseefflc.vals.xR[offs] = subsolver->sparserawlc.vals.xR[k];
         offs++;
      }
   // Set up slack variables
      if (i < nec) {
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.vals.xR[offs + 1] = 1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslackec + 2 * i;
         subsolver->sparseefflc.idx.xZ[offs + 1] = offsslackec + 2 * i + 1;
         offs += 2;
      } else {
      // Slack variables for inequality constraints
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslackic + (i - nec);
         offs++;
      }
   // Finalize row
      subsolver->sparseefflc.ridx.xZ[i + 1] = offs;
   // Set up bounds.
   //
   // NOTE: bounds for equality and inequality constraints are
   //       handled differently
      v = vright - state->scaledcleic.xyR[i][n];
      if (i < nec) {
         subsolver->cural.xR[i] = -v;
         subsolver->curau.xR[i] = -v;
         subsolver->curbndl.xR[offsslackec + 2 * i] = 0.0;
         subsolver->curbndl.xR[offsslackec + 2 * i + 1] = 0.0;
         subsolver->curbndu.xR[offsslackec + 2 * i] = fabs(v);
         subsolver->curbndu.xR[offsslackec + 2 * i + 1] = fabs(v);
      } else {
         subsolver->cural.xR[i] = -INFINITY;
         subsolver->curau.xR[i] = -v;
         subsolver->curbndl.xR[offsslackic + (i - nec)] = 0.0;
         subsolver->curbndu.xR[offsslackic + (i - nec)] = rmax2(v, 0.0);
      }
   }
   subsolver->sparseefflc.m += nec + nic;
// Append nonlinear equality/inequality constraints
   for (i = 0; i < nlec + nlic; i++) {
   // Calculate scale coefficient
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = jac->xyR[1 + i][j];
         vv += v * v;
      }
      vv = 1.0 / coalesce(sqrt(vv), 1.0);
   // Copy scaled row
      offs = subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + i];
      for (j = 0; j < n; j++) {
         if (jac->xyR[1 + i][j] != 0.0) {
            subsolver->sparseefflc.vals.xR[offs] = vv * jac->xyR[1 + i][j];
            subsolver->sparseefflc.idx.xZ[offs] = j;
            offs++;
         }
      }
      if (i < nlec) {
      // Add slack terms for equality constraints
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.vals.xR[offs + 1] = 1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslacknlec + 2 * i;
         subsolver->sparseefflc.idx.xZ[offs + 1] = offsslacknlec + 2 * i + 1;
         offs += 2;
      } else {
      // Add slack terms for inequality constraints
         subsolver->sparseefflc.vals.xR[offs] = -1.0;
         subsolver->sparseefflc.idx.xZ[offs] = offsslacknlic + (i - nlec);
         offs++;
      }
      subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + i + 1] = offs;
   // Set box constraints on slack variables and bounds on linear equality/inequality constraints
      v = vv * fi->xR[1 + i];
      if (i < nlec) {
      // Equality constraint
         subsolver->cural.xR[subsolver->sparseefflc.m + i] = -v;
         subsolver->curau.xR[subsolver->sparseefflc.m + i] = -v;
         subsolver->curbndl.xR[offsslacknlec + 2 * i] = 0.0;
         subsolver->curbndl.xR[offsslacknlec + 2 * i + 1] = 0.0;
         subsolver->curbndu.xR[offsslacknlec + 2 * i] = fabs(v);
         subsolver->curbndu.xR[offsslacknlec + 2 * i + 1] = fabs(v);
      } else {
      // Inequality constraint
         subsolver->cural.xR[subsolver->sparseefflc.m + i] = -INFINITY;
         subsolver->curau.xR[subsolver->sparseefflc.m + i] = -v;
         subsolver->curbndl.xR[offsslacknlic + (i - nlec)] = 0.0;
         subsolver->curbndu.xR[offsslacknlic + (i - nlec)] = rmax2(v, 0.0);
      }
   }
   subsolver->sparseefflc.m += nlec + nlic;
// Append conjugacy constraints
   for (i = 0; i < subsolver->curdcnt; i++) {
   // Copy N elements of CurHD
   //
   // NOTE: we expect product of D and H to be dense, so we copy all N elements
      v = 0.0;
      for (j = 0; j < n; j++) {
         vv = subsolver->curhd.xyR[i][j];
         v += vv * vv;
      }
      v = 1.0 / coalesce(sqrt(v), 1.0);
      offs = subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m];
      for (j = 0; j < n; j++) {
         vv = subsolver->curhd.xyR[i][j];
         subsolver->sparseefflc.vals.xR[offs] = v * vv;
         subsolver->sparseefflc.idx.xZ[offs] = j;
         offs++;
      }
      subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m + 1] = offs;
   // Set bounds on linear constraints
      subsolver->cural.xR[subsolver->sparseefflc.m] = 0.0;
      subsolver->curau.xR[subsolver->sparseefflc.m] = 0.0;
   // Increase row count
      subsolver->sparseefflc.m++;
   }
// Finalize sparse matrix structure
   ae_assert(subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m] <= subsolver->sparseefflc.idx.cnt, "LPSubproblemSolve: critical integrity check failed");
   ae_assert(subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m] <= subsolver->sparseefflc.vals.cnt, "LPSubproblemSolve: critical integrity check failed");
   subsolver->sparseefflc.ninitialized = subsolver->sparseefflc.ridx.xZ[subsolver->sparseefflc.m];
   sparseinitduidx(&subsolver->sparseefflc);
// Choose dual simplex method basis initialization type
   if (innerk == 1 && subsolver->basispresent) {
      basisinittype = 2;
   } else {
      basisinittype = 1;
   }
// Solve linear program
   vectorsetlengthatleast(&subsolver->tmp0, nslack);
   for (i = 0; i < nslack; i++) {
      subsolver->tmp0.xR[i] = state->trustrad;
   }
   presolvenonescaleuser(&subsolver->tmp0, &subsolver->curb, &subsolver->curbndl, &subsolver->curbndu, nslack, &subsolver->sparseefflc, &subsolver->cural, &subsolver->curau, subsolver->sparseefflc.m, &subsolver->presolver);
   dssinit(subsolver->presolver.newn, &subsolver->dss);
   dsssetproblem(&subsolver->dss, &subsolver->presolver.c, &subsolver->presolver.bndl, &subsolver->presolver.bndu, &subsolver->densedummy, &subsolver->presolver.sparsea, 1, &subsolver->presolver.al, &subsolver->presolver.au, subsolver->presolver.newm, &subsolver->lastbasis, basisinittype, &subsolver->dsssettings);
   dssoptimize(&subsolver->dss, &subsolver->dsssettings);
   rcopyallocv(subsolver->presolver.newn, &subsolver->dss.repx, &subsolver->xs);
   rcopyallocv(subsolver->presolver.newn, &subsolver->dss.replagbc, &subsolver->lagbc);
   rcopyallocv(subsolver->presolver.newm, &subsolver->dss.replaglc, &subsolver->laglc);
   icopyallocv(subsolver->presolver.newn + subsolver->presolver.newm, &subsolver->dss.repstats, &subsolver->cs);
   presolvebwd(&subsolver->presolver, &subsolver->xs, &subsolver->cs, &subsolver->lagbc, &subsolver->laglc);
   state->repsimplexiterations += subsolver->dss.repiterationscount;
   state->repsimplexiterations1 += subsolver->dss.repiterationscount1;
   state->repsimplexiterations2 += subsolver->dss.repiterationscount2;
   state->repsimplexiterations3 += subsolver->dss.repiterationscount3;
   if (subsolver->dss.repterminationtype <= 0) {
   // LP solver failed due to numerical errors; exit
      result = false;
      return result;
   }
   if (innerk == 1) {
   // Store basis
      dssexportbasis(&subsolver->dss, &subsolver->lastbasis);
      subsolver->basispresent = true;
   }
// Extract direction D[] and Lagrange multipliers
   for (i = 0; i < nslack; i++) {
      d->xR[i] = subsolver->xs.xR[i];
   }
   for (i = 0; i < lccnt; i++) {
      lagmult->xR[i] = subsolver->laglc.xR[i];
   }
   return result;
}

// This function appends last search direction D to conjugacy constraints  of
// the LP subproblem.
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
static void nlcslp_lpsubproblemappendconjugacyconstraint(minslpstate *state, minslpsubsolver *subsolver, RVector *d) {
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   n = state->n;
// Conjugacy constraint d*H*Dprev == 0, only last row of (H*Dprev) is recomputed
   ae_assert(subsolver->curdcnt < subsolver->curd.rows, "SLP: CurD is too small");
   for (i = 0; i < n; i++) {
      subsolver->curd.xyR[subsolver->curdcnt][i] = d->xR[i];
   }
   subsolver->curdcnt++;
   hessianmv(&subsolver->hess, d, &subsolver->tmp0);
   for (j = 0; j < n; j++) {
      subsolver->curhd.xyR[subsolver->curdcnt - 1][j] = subsolver->tmp0.xR[j];
   }
}

// Copies X to State.X
static void nlcslp_slpsendx(minslpstate *state, RVector *xs) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i] && xs->xR[i] <= state->scaledbndl.xR[i]) {
         state->x.xR[i] = state->scaledbndl.xR[i];
         continue;
      }
      if (state->hasbndu.xB[i] && xs->xR[i] >= state->scaledbndu.xR[i]) {
         state->x.xR[i] = state->scaledbndu.xR[i];
         continue;
      }
      state->x.xR[i] = xs->xR[i];
   }
}

// Retrieves F-vector and scaled Jacobian, copies them to FiS and JS.
//
// Returns True on success, False on failure (when F or J are not finite numbers).
static bool nlcslp_slpretrievefij(minslpstate *state, RVector *fis, RMatrix *js) {
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   bool result;
   n = state->n;
   nlec = state->nlec;
   nlic = state->nlic;
   v = 0.0;
   for (i = 0; i <= nlec + nlic; i++) {
      vv = 1.0 / state->fscales.xR[i];
      fis->xR[i] = vv * state->fi.xR[i];
      v = 0.1 * v + fis->xR[i];
      for (j = 0; j < n; j++) {
         js->xyR[i][j] = vv * state->j.xyR[i][j];
         v = 0.1 * v + js->xyR[i][j];
      }
   }
   result = isfinite(v);
   return result;
}

// Copies state (X point, Fi vector, J jacobian) to preallocated storage.
static void nlcslp_slpcopystate(minslpstate *state, RVector *x0, RVector *fi0, RMatrix *j0, RVector *x1, RVector *fi1, RMatrix *j1) {
   ae_int_t nlec;
   ae_int_t nlic;
   ae_int_t n;
   ae_int_t i;
   ae_int_t j;
   n = state->n;
   nlec = state->nlec;
   nlic = state->nlic;
   for (i = 0; i < n; i++) {
      x1->xR[i] = x0->xR[i];
   }
   for (i = 0; i <= nlec + nlic; i++) {
      fi1->xR[i] = fi0->xR[i];
      for (j = 0; j < n; j++) {
         j1->xyR[i][j] = j0->xyR[i][j];
      }
   }
}

// This function calculates Lagrangian of the problem (in scaled variables):
// its value and gradient.
//
// Additionally it also estimates violation of linear constraints at the point
// as well as index of the most violated constraint
static void nlcslp_lagrangianfg(minslpstate *state, RVector *x, double trustrad, RVector *fi, RMatrix *j, RVector *lagmult, minslptmplagrangian *tmp, double *f, RVector *g, double *lcerr, ae_int_t *lcidx, double *nlcerr, ae_int_t *nlcidx) {
   const double inequalitydampingfactor = 10.0, augmentationfactor = 10.0;
   ae_int_t i;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   double v;
   double vlag;
   double vact;
   double vd;
   double vviolate;
   bool usesparsegemv;
   double dampingfactor;
   *f = 0.0;
   *lcerr = 0.0;
   *lcidx = 0;
   *nlcerr = 0.0;
   *nlcidx = 0;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   dampingfactor = inequalitydampingfactor / trustrad;
// Prepare constraint violation report
   *lcerr = 0.0;
   *lcidx = -1;
   *nlcerr = 0.0;
   *nlcidx = -1;
// Target function
   *f = fi->xR[0];
   for (i = 0; i < n; i++) {
      g->xR[i] = j->xyR[0][i];
   }
// Lagrangian terms for linear constraints, constraint violations
   if (nec + nic > 0) {
      usesparsegemv = state->subsolver.sparserawlc.ridx.xZ[nec + nic] < sparselevel2density() * n * (nec + nic);
      vectorsetlengthatleast(&tmp->sclagtmp0, imax2(nec + nic, n));
      vectorsetlengthatleast(&tmp->sclagtmp1, imax2(nec + nic, n));
      if (usesparsegemv) {
         sparsemv(&state->subsolver.sparserawlc, x, &tmp->sclagtmp0);
      } else {
         rmatrixgemv(nec + nic, n, 1.0, &state->scaledcleic, 0, 0, 0, x, 0, 0.0, &tmp->sclagtmp0, 0);
      }
      for (i = 0; i < nec + nic; i++) {
      // Estimate constraint value at the point, update violation info
      //
      // NOTE: here we expect that scaledCLEIC[] has normalized rows
         v = tmp->sclagtmp0.xR[i] - state->scaledcleic.xyR[i][n];
         if (i < nec || v > 0.0) {
         // Either equality constraint or violated inequality one.
         // Update violation report.
            vviolate = fabs(v);
            if (vviolate > *lcerr) {
               *lcerr = vviolate;
               *lcidx = state->lcsrcidx.xZ[i];
            }
         }
      // Prepare
         vlag = lagmult->xR[i];
         tmp->sclagtmp1.xR[i] = 0.0;
      // Primary Lagrangian term
         if (i < nec || v > 0.0) {
            vact = v;
            vd = 1.0;
         } else {
            vd = 1.0 / (1.0 - dampingfactor * v);
            vact = v * vd;
            vd *= vd;
         }
         *f += vlag * vact;
         tmp->sclagtmp1.xR[i] += vlag * vd;
      // Quadratic augmentation term
         if (i < nec || v > 0.0) {
            vact = v;
         } else {
            vact = 0.0;
         }
         *f += 0.5 * augmentationfactor * vact * vact;
         tmp->sclagtmp1.xR[i] += augmentationfactor * vact;
      }
      if (usesparsegemv) {
         sparsemtv(&state->subsolver.sparserawlc, &tmp->sclagtmp1, &tmp->sclagtmp0);
         for (i = 0; i < n; i++) {
            g->xR[i] += tmp->sclagtmp0.xR[i];
         }
      } else {
         rmatrixgemv(n, nec + nic, 1.0, &state->scaledcleic, 0, 0, 1, &tmp->sclagtmp1, 0, 1.0, g, 0);
      }
   }
// Lagrangian terms for nonlinear constraints
   vectorsetlengthatleast(&tmp->sclagtmp1, nlec + nlic);
   for (i = 0; i < nlec + nlic; i++) {
      v = fi->xR[1 + i];
      if (i < nlec || v > 0.0) {
      // Either equality constraint or violated inequality one.
      // Update violation report.
         vviolate = fabs(v) * state->fscales.xR[1 + i];
         if (vviolate > *nlcerr) {
            *nlcerr = vviolate;
            *nlcidx = i;
         }
      }
      vlag = lagmult->xR[nec + nic + i];
      tmp->sclagtmp1.xR[i] = 0.0;
   // Lagrangian term
      if (i < nlec || v > 0.0) {
         vact = v;
         vd = 1.0;
      } else {
         vd = 1.0 / (1.0 - dampingfactor * v);
         vact = v * vd;
         vd *= vd;
      }
      *f += vlag * vact;
      tmp->sclagtmp1.xR[i] += vlag * vd;
   // Augmentation term
      if (i < nlec || v > 0.0) {
         vact = v;
      } else {
         vact = 0.0;
      }
      *f += 0.5 * augmentationfactor * vact * vact;
      tmp->sclagtmp1.xR[i] += augmentationfactor * vact;
   }
   rmatrixgemv(n, nlec + nlic, 1.0, j, 1, 0, 1, &tmp->sclagtmp1, 0, 1.0, g, 0);
}

// This function calculates L1-penalized merit function and raw  (smooth  and
// un-augmented) Lagrangian
static void nlcslp_meritfunctionandrawlagrangian(minslpstate *state, RVector *x, RVector *fi, RVector *lagmult, double mu, minslptmpmerit *tmp, double *meritf, double *rawlag) {
   const double meritfunctionbase = 0.0, meritfunctiongain = 2.0;
   ae_int_t i;
   ae_int_t n;
   ae_int_t nec;
   ae_int_t nic;
   ae_int_t nlec;
   ae_int_t nlic;
   double v;
   *meritf = 0.0;
   *rawlag = 0.0;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
// Merit function and Lagrangian: primary term
   *meritf = fi->xR[0];
   *rawlag = fi->xR[0];
// Merit function: augmentation and penalty for linear constraints
   vectorsetlengthatleast(&tmp->mftmp0, nec + nic);
   rmatrixgemv(nec + nic, n, 1.0, &state->scaledcleic, 0, 0, 0, x, 0, 0.0, &tmp->mftmp0, 0);
   for (i = 0; i < nec + nic; i++) {
      v = tmp->mftmp0.xR[i] - state->scaledcleic.xyR[i][n];
      if (i < nec) {
      // Merit function: augmentation term + L1 penalty term
         *meritf += meritfunctionbase * fabs(v) + meritfunctiongain * mu * fabs(v);
      // Raw Lagrangian
         *rawlag += lagmult->xR[i] * v;
      } else {
      // Merit function: augmentation term + L1 penalty term
         *meritf += meritfunctionbase * rmax2(v, 0.0) + meritfunctiongain * mu * rmax2(v, 0.0);
      // Raw Lagrangian
         *rawlag += lagmult->xR[i] * v;
      }
   }
// Merit function: augmentation and penalty for nonlinear constraints
   for (i = 0; i < nlec + nlic; i++) {
      v = fi->xR[1 + i];
      if (i < nlec) {
      // Merit function: augmentation term + L1 penalty term
         *meritf += meritfunctionbase * fabs(v) + meritfunctiongain * mu * fabs(v);
      // Raw Lagrangian
         *rawlag += lagmult->xR[nec + nic + i] * v;
      } else {
      // Merit function: augmentation term + L1 penalty term
         *meritf += meritfunctionbase * rmax2(v, 0.0) + meritfunctiongain * mu * rmax2(v, 0.0);
      // Raw Lagrangian
         *rawlag += lagmult->xR[nec + nic + i] * v;
      }
   }
}

// This function calculates L1-penalized merit function
static double nlcslp_meritfunction(minslpstate *state, RVector *x, RVector *fi, RVector *lagmult, double mu, minslptmpmerit *tmp) {
   double tmp0;
   double tmp1;
   double result;
   nlcslp_meritfunctionandrawlagrangian(state, x, fi, lagmult, mu, tmp, &tmp0, &tmp1);
   result = tmp0;
   return result;
}

#if 0 //(@) Not used.
// This function calculates raw (unaugmented and smooth) Lagrangian
static double nlcslp_rawlagrangian(minslpstate *state, RVector *x, RVector *fi, RVector *lagmult, minslptmpmerit *tmp) {
   double tmp0;
   double tmp1;
   double result;
   nlcslp_meritfunctionandrawlagrangian(state, x, fi, lagmult, 0.0, tmp, &tmp0, &tmp1);
   result = tmp1;
   return result;
}
#endif

// This function initializes Phase13  temporaries. It should be called before
// beginning of each new iteration. You may call it multiple  times  for  the
// same instance of Phase13 temporaries.
//
// Inputs:
//     State13             -   instance to be initialized.
//     N                   -   problem dimensionality
//     NEC, NIC            -   linear equality/inequality constraint count
//     NLEC, NLIC          -   nonlinear equality/inequality constraint count
//     UseCorrection       -   True if we want to perform second order correction
//
// Outputs:
//     State13     -   instance being initialized
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static void nlcslp_phase13init(minslpphase13state *state13, ae_int_t n, ae_int_t nec, ae_int_t nic, ae_int_t nlec, ae_int_t nlic, bool usecorrection) {
   ae_int_t nslack;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   state13->usecorrection = usecorrection;
   vectorsetlengthatleast(&state13->d, nslack);
   vectorsetlengthatleast(&state13->dx, nslack);
   vectorsetlengthatleast(&state13->stepkxc, n);
   vectorsetlengthatleast(&state13->stepkxn, n);
   vectorsetlengthatleast(&state13->stepkfic, 1 + nlec + nlic);
   vectorsetlengthatleast(&state13->stepkfin, 1 + nlec + nlic);
   matrixsetlengthatleast(&state13->stepkjc, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&state13->stepkjn, 1 + nlec + nlic, n);
   vectorsetlengthatleast(&state13->dummylagmult, nec + nic + nlec + nlic);
   state13->Ph13PQ = -1;
}

// This function tries to perform either phase #1 or phase #3 step.
//
// Former corresponds to linear model step (without conjugacy constraints) with
// correction for nonlinearity ("second order correction").  Such  correction
// helps to overcome  Maratos  effect  (a  tendency  of  L1  penalized  merit
// functions to reject nonzero steps).
//
// Latter is a step using linear model with no second order correction.
//
// Inputs:
//     State       -   SLP solver state
//     SMonitor    -   smoothness monitor
//     UserTerminationNeeded-True if user requested termination
//     CurX        -   current point, array[N]
//     CurFi       -   function vector at CurX, array[1+NLEC+NLIC]
//     CurJ        -   Jacobian at CurX, array[1+NLEC+NLIC,N]
//     LagMult     -   array[NEC+NIC+NLEC+NLIC], contents ignored on input.
//
// Outputs:
//     State       -   RepTerminationType is set to current termination code (if Status == 0).
//     CurX        -   advanced to new point
//     CurFi       -   updated with function vector at CurX[]
//     CurJ        -   updated with Jacobian at CurX[]
//     LagMult     -   filled with current Lagrange multipliers
//     Status      -   when reverse communication is done, Status is set to:
//                     * negative value,  if   we  have   to  restart   outer
//                       iteration
//                     * positive value,  if we can proceed to the next stage
//                       of the outer iteration
//                     * zero, if algorithm is terminated (RepTerminationType
//                       is set to appropriate value)
//     DNrm        -   inf-norm of the proposed step vector D
//     Stp         -   step length (multiplier for D), in [0,1]
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static bool nlcslp_phase13iteration(minslpstate *state, minslpphase13state *state13, smoothnessmonitor *smonitor, bool userterminationneeded, RVector *curx, RVector *curfi, RMatrix *curj, RVector *lagmult, ae_int_t *status, double *dnrm, double *stp) {
   const ae_int_t lpfailureslimit = 20;
   AutoS ae_int_t n;
   AutoS ae_int_t nslack;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t nlec;
   AutoS ae_int_t nlic;
   AutoS ae_int_t innerk;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS double v;
   AutoS double f0;
   AutoS double f1;
   AutoS double nu;
   AutoS double localstp;
   AutoS double mu;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state13->Ph13PQ >= 0) switch (state13->Ph13PQ) {
      case 0: goto Resume0; case 1: goto Resume1;/* case 2: goto Resume2;*/ case 3: goto Resume3;
      default: goto Exit;
   }
Spawn:
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   innerk = 1;
   ae_assert(lagmult->cnt >= nec + nic + nlec + nlic, "Phase13Iteration: integrity check failed");
// Default decision is to continue algorithm
   *status = 1;
   *stp = 0.0;
   *dnrm = 0.0;
// Determine step direction using linearized model with no conjugacy terms
   nlcslp_lpsubproblemrestart(state, &state->subsolver);
   if (!nlcslp_lpsubproblemsolve(state, &state->subsolver, curx, curfi, curj, innerk, &state13->d, lagmult)) {
   // Increase failures counter.
   // Stop after too many subsequent failures
      state->lpfailurecnt++;
      if (state->lpfailurecnt >= lpfailureslimit) {
         state->repterminationtype = 7;
         *status = 0;
         goto Exit;
      }
   // Can not solve LP subproblem, decrease trust radius
      state->trustrad *= 0.5;
      if (state->trustrad < state->epsx) {
         state->repterminationtype = 2;
         *status = 0;
      } else {
         *status = -1;
      }
      goto Exit;
   }
   mu = rmax2(rmaxabsv(state->historylen, &state->maxlaghistory), rmaxabsv(nec + nic + nlec + nlic, lagmult));
   mu = coalesce(mu, nlcslp_defaultl1penalty);
// Compute second order correction if required. The issue we address here
// is a tendency of L1 penalized function to reject steps built using simple
// linearized model when nonlinear constraints change faster than the target.
//
// The idea is that we perform trial step (stp == 1) using simple linearized model,
// compute constraint vector at the new trial point - and use these updated
// constraint linearizations back at the initial point.
   if (state13->usecorrection) {
   // Perform trial step using vector D to StepKXC
      for (i = 0; i < n; i++) {
         state13->stepkxc.xR[i] = curx->xR[i] + state13->d.xR[i];
      }
      nlcslp_slpsendx(state, &state13->stepkxc);
      state->needfij = true, state13->Ph13PQ = 0; goto Pause; Resume0: state->needfij = false;
      if (!nlcslp_slpretrievefij(state, &state13->stepkfic, &state13->stepkjc)) {
      // Failed to retrieve func/Jac, infinities detected
         state->repterminationtype = -8;
         *status = 0;
         goto Exit;
      }
   // Move back to point CurX[], restore original linearization of the target
      state13->stepkfic.xR[0] = curfi->xR[0];
      for (j = 0; j < n; j++) {
         state13->stepkxc.xR[j] = curx->xR[j];
         state13->stepkjc.xyR[0][j] = curj->xyR[0][j];
      }
   // Extrapolate linearization of nonlinear constraints back to origin
      for (i = 1; i <= nlec + nlic; i++) {
         v = 0.0;
         for (j = 0; j < n; j++) {
            v += state13->d.xR[j] * state13->stepkjc.xyR[i][j];
         }
         state13->stepkfic.xR[i] -= v;
      }
   // Solve linearized problem one more time, now with new linearization of constraints
   // (but still old linearization of the target), obtain DX
   //
   // NOTE: because lpsubproblemrestart() call resets set of conjugate constraints, we
   //       have to re-add it after solve.
      nlcslp_lpsubproblemrestart(state, &state->subsolver);
      if (!nlcslp_lpsubproblemsolve(state, &state->subsolver, &state13->stepkxc, &state13->stepkfic, &state13->stepkjc, innerk, &state13->dx, &state13->dummylagmult)) {
      // Second LP subproblem failed.
      // Noncritical failure, can be ignored,
      } else {
      // Set D to new direction
         for (i = 0; i < n; i++) {
            state13->d.xR[i] = state13->dx.xR[i];
         }
      }
   }
// Now we have search direction in D:
// * compute DNrm
// * append D to the list of the conjugacy constraints, so next time when we use the solver we will
//   automatically produce conjugate direction
   *dnrm = rmaxabsv(n, &state13->d);
   nlcslp_lpsubproblemappendconjugacyconstraint(state, &state->subsolver, &state13->d);
// Perform merit function backtracking line search, with trial point being
// computed as XN = XK + Stp*D, with Stp in [0,1]
//
// NOTE: we use MeritLagMult - Lagrange multipliers computed for initial,
//       uncorrected task - for the merit function model.
//       Using DummyLagMult can destabilize algorithm.
   localstp = 1.0;
   nu = 0.5;
   f0 = nlcslp_meritfunction(state, curx, curfi, lagmult, mu, &state13->tmpmerit);
   f1 = f0;
   smoothnessmonitorstartlinesearch(smonitor, curx, curfi, curj, state->repinneriterationscount, state->repouteriterationscount);
   while (true) {
      for (i = 0; i < n; i++) {
         state13->stepkxn.xR[i] = curx->xR[i] + localstp * state13->d.xR[i];
      }
      nlcslp_slpsendx(state, &state13->stepkxn);
      state->needfij = true, state13->Ph13PQ = 1; goto Pause; Resume1: state->needfij = false;
      if (!nlcslp_slpretrievefij(state, &state13->stepkfin, &state13->stepkjn)) {
      // Failed to retrieve func/Jac, infinities detected
         state->repterminationtype = -8;
         *status = 0;
         goto Exit;
      }
      smoothnessmonitorenqueuepoint(smonitor, &state13->d, localstp, &state13->stepkxn, &state13->stepkfin, &state13->stepkjn);
      f1 = nlcslp_meritfunction(state, &state13->stepkxn, &state13->stepkfin, lagmult, mu, &state13->tmpmerit);
      if (f1 < f0) {
      // Step is found!
         break;
      }
      if (localstp < 0.001) {
      // Step is shorter than 0.001 times current search direction,
      // it means that no good step can be found.
         localstp = 0.0;
         nlcslp_slpcopystate(state, curx, curfi, curj, &state13->stepkxn, &state13->stepkfin, &state13->stepkjn);
         break;
      }
      localstp *= nu;
      nu = rmax2(0.1, 0.5 * nu);
   }
   smoothnessmonitorfinalizelinesearch(smonitor);
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i]) {
         state13->stepkxn.xR[i] = rmax2(state13->stepkxn.xR[i], state->scaledbndl.xR[i]);
      }
      if (state->hasbndu.xB[i]) {
         state13->stepkxn.xR[i] = rmin2(state13->stepkxn.xR[i], state->scaledbndu.xR[i]);
      }
   }
   if (userterminationneeded) {
   // User requested termination, break before we move to new point
      state->repterminationtype = 8;
      *status = 0;
      goto Exit;
   }
#if 0 //(@) Not used.
#   if 0 //(@) Not used.
   for (smoothnessmonitorstartlagrangianprobing(smonitor, curx, &state13->d, 1.0, 0, state->repouteriterationscount); smoothnessmonitorprobelagrangian(smonitor); ) {
      for (j = 0; j < n; j++) {
         state13->stepkxc.xR[j] = smonitor->lagprobx.xR[j];
         if (state->hasbndl.xB[j]) {
            state13->stepkxc.xR[j] = rmax2(state13->stepkxc.xR[j], state->scaledbndl.xR[j]);
         }
         if (state->hasbndu.xB[j]) {
            state13->stepkxc.xR[j] = rmin2(state13->stepkxc.xR[j], state->scaledbndu.xR[j]);
         }
      }
      nlcslp_slpsendx(state, &state13->stepkxc);
      state->needfij = true, state13->Ph13PQ = 2; goto Pause; Resume2: state->needfij = false;
      if (!nlcslp_slpretrievefij(state, &smonitor->lagprobfi, &smonitor->lagprobj)) {
         break;
      }
      smonitor->lagprobrawlag = nlcslp_rawlagrangian(state, &state13->stepkxc, &smonitor->lagprobfi, lagmult, &state13->tmpmerit);
   }
#   endif
   double mx = 0.0;
   for (i = 0; i < n; i++) {
      mx = rmax2(mx, fabs(state13->d.xR[i]) / state->trustrad);
   }
#endif
// Move to new point
   *stp = localstp;
   nlcslp_slpcopystate(state, &state13->stepkxn, &state13->stepkfin, &state13->stepkjn, curx, curfi, curj);
   if (localstp > 0.0) {
   // Report one more inner iteration
      state->repinneriterationscount++;
      nlcslp_slpsendx(state, curx);
      state->f = curfi->xR[0] * state->fscales.xR[0];
      state->xupdated = true, state13->Ph13PQ = 3; goto Pause; Resume3: state->xupdated = false;
   // Update constraint violations
      checklcviolation(&state->scaledcleic, &state->lcsrcidx, nec, nic, curx, n, &state->replcerr, &state->replcidx);
      unscaleandchecknlcviolation(curfi, &state->fscales, nlec, nlic, &state->repnlcerr, &state->repnlcidx);
   }
Exit:
   state13->Ph13PQ = -1;
   return false;
Pause:
   return true;
}

// This function initializes Phase2   temporaries. It should be called before
// beginning of each new iteration. You may call it multiple  times  for  the
// same instance of Phase2 temporaries.
//
// Inputs:
//     State2              -   instance to be initialized.
//     N                   -   problem dimensionality
//     NEC, NIC            -   linear equality/inequality constraint count
//     NLEC, NLIC          -   nonlinear equality/inequality constraint count
//     MeritLagMult        -   Lagrange multiplier estimates used by merit function
//                             (we could use ones computed during phase #2,
//                             but these may differ from ones computed
//                             initially at the beginning of the outer
//                             iteration, so it may confuse algorithm)
//
// Outputs:
//     State2              -   instance being initialized
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static void nlcslp_phase2init(minslpphase2state *state2, ae_int_t n, ae_int_t nec, ae_int_t nic, ae_int_t nlec, ae_int_t nlic, RVector *meritlagmult) {
   ae_int_t i;
   ae_int_t nslack;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   vectorsetlengthatleast(&state2->d, nslack);
   vectorsetlengthatleast(&state2->tmp0, nslack);
   vectorsetlengthatleast(&state2->stepkxn, n);
   vectorsetlengthatleast(&state2->stepkxc, n);
   vectorsetlengthatleast(&state2->stepkfin, 1 + nlec + nlic);
   vectorsetlengthatleast(&state2->stepkfic, 1 + nlec + nlic);
   matrixsetlengthatleast(&state2->stepkjn, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&state2->stepkjc, 1 + nlec + nlic, n);
   vectorsetlengthatleast(&state2->stepklaggrad, n);
   vectorsetlengthatleast(&state2->stepknlaggrad, n);
   vectorsetlengthatleast(&state2->stepknlagmult, nec + nic + nlec + nlic);
   vectorsetlengthatleast(&state2->meritlagmult, nec + nic + nlec + nlic);
   for (i = 0; i < nec + nic + nlec + nlic; i++) {
      state2->meritlagmult.xR[i] = meritlagmult->xR[i];
   }
   state2->Ph2PQ = -1;
}

// This function tries to perform phase #2 iterations.
//
// Phase #2 is  a  sequence  of  linearized  steps   minimizing  L2-penalized
// Lagrangian  performed  with  successively  increasing  set  of   conjugacy
// constraints (which make algorithm behavior similar to that of CG).
//
// Inputs:
//     State       -   SLP solver state
//     SMonitor    -   smoothness monitor
//     UserTerminationNeeded-True if user requested termination
//     CurX        -   current point, array[N]
//     CurFi       -   function vector at CurX, array[1+NLEC+NLIC]
//     CurJ        -   Jacobian at CurX, array[1+NLEC+NLIC,N]
//     LagMult     -   array[NEC+NIC+NLEC+NLIC], contents ignored on input.
//     GammaMax    -   current estimate of the Hessian norm
//
// Outputs:
//     State       -   RepTerminationType is set to current termination code (if Status == 0).
//     CurX        -   advanced to new point
//     CurFi       -   updated with function vector at CurX[]
//     CurJ        -   updated with Jacobian at CurX[]
//     LagMult     -   filled with current Lagrange multipliers
//     GammaMax    -   updated estimate of the Hessian norm
//     Status      -   when reverse communication is done, Status is set to:
//                     * negative value,  if   we  have   to  restart   outer
//                       iteration
//                     * positive value,  if we can proceed to the next stage
//                       of the outer iteration
//                     * zero, if algorithm is terminated (RepTerminationType
//                       is set to appropriate value)
// ALGLIB: Copyright 05.02.2019 by Sergey Bochkanov
static bool nlcslp_phase2iteration(minslpstate *state, minslpphase2state *state2, smoothnessmonitor *smonitor, bool userterminationneeded, RVector *curx, RVector *curfi, RMatrix *curj, RVector *lagmult, double *gammamax, ae_int_t *status) {
   const double slpgtol = 0.4;
   const ae_int_t nondescentlimit = 99999;
   AutoS ae_int_t n;
   AutoS ae_int_t nslack;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t nlec;
   AutoS ae_int_t nlic;
   AutoS double stp;
   AutoS ae_int_t mcinfo;
   AutoS ae_int_t mcnfev;
   AutoS ae_int_t mcstage;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t innerk;
   AutoS double v;
   AutoS double vv;
   AutoS double mx;
   AutoS ae_int_t nondescentcnt;
   AutoS double stepklagval;
   AutoS double stepknlagval;
   AutoS double gammaprev;
   AutoS double f0;
   AutoS double f1;
   AutoS double mu;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state2->Ph2PQ >= 0) switch (state2->Ph2PQ) {
      case 0: goto Resume0;/* case 1: goto Resume1;*/ case 2: goto Resume2;
      default: goto Exit;
   }
Spawn:
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
   ae_assert(lagmult->cnt >= nec + nic + nlec + nlic, "Phase2Iteration: integrity check failed");
// The default decision is to continue iterations
   *status = 1;
// Perform inner LP subiterations.
//
// During this process we maintain information about several points:
// * point #0, initial one, with "step0" prefix
// * point #K, last one of current LP session, with "stepk" prefix
// * additionally we have point #KN, current candidate during line search at step K.
//
// For each point we store:
// * location X (scaled coordinates)
// * function vector Fi (target function + nonlinear constraints)
// * scaled Jacobian J
   mu = rmax2(rmaxabsv(state->historylen, &state->maxlaghistory), rmaxabsv(nec + nic + nlec + nlic, &state->meritlagmult));
   mu = coalesce(mu, nlcslp_defaultl1penalty);
   nondescentcnt = 0;
   nlcslp_lpsubproblemrestart(state, &state->subsolver);
   for (innerk = 1; innerk <= n; innerk++) {
   // Formulate LP subproblem and solve it
      if (!nlcslp_lpsubproblemsolve(state, &state->subsolver, curx, curfi, curj, innerk, &state2->d, lagmult)) {
      // LP solver failed due to numerical errors; exit.
      // It may happen when we solve problem with LOTS of conjugacy constraints.
         goto Exit;
      }
      mx = 0.0;
      for (i = 0; i < n; i++) {
         mx = rmax2(mx, fabs(state2->d.xR[i]) / state->trustrad);
      }
      if (mx == 0.0) {
      // Nearly-zero direction is suggested (maybe we arrived exactly to the solution), stop iterations
         *status = 1;
         nlcslp_slpcopystate(state, curx, curfi, curj, &state2->stepkxn, &state2->stepkfin, &state2->stepkjn);
         goto Exit;
      }
      nlcslp_lpsubproblemappendconjugacyconstraint(state, &state->subsolver, &state2->d);
   // Perform line search to minimize Lagrangian along D.
   // Post-normalize StepKXN with respect to box constraints.
   //
   // MCSRCH can fail in the following cases:
   // * rounding errors prevent optimization
   // * non-descent direction is specified (MCINFO == 0 is returned)
   // In the latter case we proceed to minimization of merit function.
   //
   // NOTE: constraint violation reports are updated during Lagrangian computation
      state2->lastlcerr = 0.0;
      state2->lastlcidx = -1;
      state2->lastnlcerr = 0.0;
      state2->lastnlcidx = -1;
      vectorsetlengthatleast(&state2->tmp0, n);
      nlcslp_lagrangianfg(state, curx, state->trustrad, curfi, curj, lagmult, &state2->tmplagrangianfg, &stepklagval, &state2->stepklaggrad, &state2->lastlcerr, &state2->lastlcidx, &state2->lastnlcerr, &state2->lastnlcidx);
      nlcslp_slpcopystate(state, curx, curfi, curj, &state2->stepkxn, &state2->stepkfin, &state2->stepkjn);
      v = 0.0;
      for (i = 0; i < n; i++) {
         state2->stepknlaggrad.xR[i] = state2->stepklaggrad.xR[i];
         v += state2->d.xR[i] * state2->stepklaggrad.xR[i];
      }
      if (v >= 0.0) {
      // Non-descent direction D was specified; it may happen because LP subproblem favors
      // directions which decrease L1 penalty and default augmentation of Lagrangian involves
      // only L2 term.
      //
      // Append direction to the conjugacy constraints and retry direction generation.
      //
      // We make several retries with conjugate directions before giving up.
         nondescentcnt++;
         if (nondescentlimit > 0 && nondescentcnt > nondescentlimit) {
            *status = 1;
            goto Exit;
         }
         continue;
      }
      smoothnessmonitorstartlinesearch(smonitor, curx, curfi, curj, state->repinneriterationscount, state->repouteriterationscount);
      stepknlagval = stepklagval;
      mcnfev = 0;
      mcstage = 0;
      stp = 1.0;
      while (mcsrch(n, &state2->stepkxn, stepknlagval, &state2->stepknlaggrad, &state2->d, &stp, 1.0, slpgtol, &mcinfo, &mcnfev, &state2->tmp0, &state2->mcstate, &mcstage)) {
         nlcslp_slpsendx(state, &state2->stepkxn);
         state->needfij = true, state2->Ph2PQ = 0; goto Pause; Resume0: state->needfij = false;
         if (!nlcslp_slpretrievefij(state, &state2->stepkfin, &state2->stepkjn)) {
         // Failed to retrieve func/Jac, infinities detected
            *status = 0;
            state->repterminationtype = -8;
            goto Exit;
         }
         smoothnessmonitorenqueuepoint(smonitor, &state2->d, stp, &state2->stepkxn, &state2->stepkfin, &state2->stepkjn);
         nlcslp_lagrangianfg(state, &state2->stepkxn, state->trustrad, &state2->stepkfin, &state2->stepkjn, lagmult, &state2->tmplagrangianfg, &stepknlagval, &state2->stepknlaggrad, &state2->lastlcerr, &state2->lastlcidx, &state2->lastnlcerr, &state2->lastnlcidx);
      }
      smoothnessmonitorfinalizelinesearch(smonitor);
      for (i = 0; i < n; i++) {
         if (state->hasbndl.xB[i]) {
            state2->stepkxn.xR[i] = rmax2(state2->stepkxn.xR[i], state->scaledbndl.xR[i]);
         }
         if (state->hasbndu.xB[i]) {
            state2->stepkxn.xR[i] = rmin2(state2->stepkxn.xR[i], state->scaledbndu.xR[i]);
         }
      }
      if (mcinfo <= 0) {
      // Line search failed miserably, terminate
         *status = 1;
         if (innerk == 1) {
         // The very first iteration failed, really strange.
         // Let's decrease trust radius and try one more time.
            state->trustrad *= 0.5;
            if (state->trustrad < state->epsx) {
               state->repterminationtype = 2;
               *status = 0;
            }
         }
         goto Exit;
      }
      if (mcinfo == 1) {
         hessianupdate(&state->subsolver.hess, curx, &state2->stepklaggrad, &state2->stepkxn, &state2->stepknlaggrad);
      }
   // Update GammaMax - estimate of the function Hessian norm
      v = 0.0;
      vv = 0.0;
      mx = 0.0;
      for (i = 0; i < n; i++) {
         mx = rmax2(mx, fabs(state2->stepkxn.xR[i] - curx->xR[i]));
         v += sqr(state2->stepkxn.xR[i] - curx->xR[i]);
         vv += (state2->stepkjn.xyR[0][i] - curj->xyR[0][i]) * (state2->stepkxn.xR[i] - curx->xR[i]);
      }
      gammaprev = *gammamax;
      if (mx > nlcslp_bfgstol) {
         *gammamax = rmax2(*gammamax, fabs(vv / v));
      }
#if 0 //(@) Not used.
#   if 0 //(@) Not used.
      for (smoothnessmonitorstartlagrangianprobing(smonitor, curx, &state2->d, 1.0, innerk, state->repouteriterationscount); smoothnessmonitorprobelagrangian(smonitor); ) {
         for (j = 0; j < n; j++) {
            state2->stepkxc.xR[j] = smonitor->lagprobx.xR[j];
            if (state->hasbndl.xB[j]) {
               state2->stepkxc.xR[j] = rmax2(state2->stepkxc.xR[j], state->scaledbndl.xR[j]);
            }
            if (state->hasbndu.xB[j]) {
               state2->stepkxc.xR[j] = rmin2(state2->stepkxc.xR[j], state->scaledbndu.xR[j]);
            }
         }
         nlcslp_slpsendx(state, &state2->stepkxc);
         state->needfij = true, state2->Ph2PQ = 1; goto Pause; Resume1: state->needfij = false;
         if (!nlcslp_slpretrievefij(state, &smonitor->lagprobfi, &smonitor->lagprobj)) {
            break;
         }
         smonitor->lagprobrawlag = nlcslp_rawlagrangian(state, &state2->stepkxc, &smonitor->lagprobfi, lagmult, &state2->tmpmerit);
      }
#   endif
      mx = 0.0;
      for (i = 0; i < n; i++) {
         mx = rmax2(mx, fabs(state2->d.xR[i]) / state->trustrad);
      }
      f0 = nlcslp_meritfunction(state, curx, curfi, &state2->meritlagmult, mu, &state2->tmpmerit);
      f1 = nlcslp_meritfunction(state, &state2->stepkxn, &state2->stepkfin, &state2->meritlagmult, mu, &state2->tmpmerit);
#endif
   // Check status of the termination request
   // Update current point
   // Update constraint status.
   // Report iteration.
      if (userterminationneeded) {
      // User requested termination, break before we move to new point
         *status = 0;
         state->repterminationtype = 8;
         goto Exit;
      }
      nlcslp_slpcopystate(state, &state2->stepkxn, &state2->stepkfin, &state2->stepkjn, curx, curfi, curj);
      state->replcerr = state2->lastlcerr;
      state->replcidx = state2->lastlcidx;
      state->repnlcerr = state2->lastnlcerr;
      state->repnlcidx = state2->lastnlcidx;
      state->repinneriterationscount++;
      nlcslp_slpsendx(state, curx);
      state->f = curfi->xR[0] * state->fscales.xR[0];
      state->xupdated = true, state2->Ph2PQ = 2; goto Pause; Resume2: state->xupdated = false;
   // Terminate inner LP subiterations
      if (state->maxits > 0 && state->repinneriterationscount >= state->maxits) {
      // Iteration limit exhausted
         *status = 1;
         goto Exit;
      }
      if (stp >= nlcslp_slpstpclosetoone) {
      // Step is close to 1.0, either of two is likely:
      // * we move through nearly linear region of F()
      // * we try to enforce some strongly violated constraint
      //
      // In any case, authors of the original algorithm recommend to break inner LP
      // iteration and proceed to test of sufficient decrease of merit function.
         *status = 1;
         goto Exit;
      }
      if (mcinfo != 1 && mcinfo != 3 && mcinfo != 5) {
      // Line search ended with "bad" MCINFO
      // (neither sufficient decrease, neither maximum step);
      // terminate.
         *status = 1;
         goto Exit;
      }
   }
Exit:
   state2->Ph2PQ = -1;
   return false;
Pause:
   return true;
}

void minslpinitbuf(RVector *bndl, RVector *bndu, RVector *s, RVector *x0, ae_int_t n, RMatrix *cleic, ZVector *lcsrcidx, ae_int_t nec, ae_int_t nic, ae_int_t nlec, ae_int_t nlic, double epsx, ae_int_t maxits, minslpstate *state) {
   ae_int_t i;
   ae_int_t j;
   double v;
   double vv;
   state->n = n;
   state->nec = nec;
   state->nic = nic;
   state->nlec = nlec;
   state->nlic = nlic;
// Prepare RCOMM state
   state->PQ = -1;
   ae_vector_set_length(&state->x, n);
   ae_vector_set_length(&state->fi, 1 + nlec + nlic);
   ae_matrix_set_length(&state->j, 1 + nlec + nlic, n);
// Allocate memory.
   vectorsetlengthatleast(&state->s, n);
   vectorsetlengthatleast(&state->step0x, n);
   vectorsetlengthatleast(&state->stepkx, n);
   vectorsetlengthatleast(&state->backupx, n);
   vectorsetlengthatleast(&state->step0fi, 1 + nlec + nlic);
   vectorsetlengthatleast(&state->stepkfi, 1 + nlec + nlic);
   vectorsetlengthatleast(&state->backupfi, 1 + nlec + nlic);
   matrixsetlengthatleast(&state->step0j, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&state->stepkj, 1 + nlec + nlic, n);
   matrixsetlengthatleast(&state->backupj, 1 + nlec + nlic, n);
   vectorsetlengthatleast(&state->fscales, 1 + nlec + nlic);
   vectorsetlengthatleast(&state->meritlagmult, nec + nic + nlec + nlic);
   vectorsetlengthatleast(&state->dummylagmult, nec + nic + nlec + nlic);
   vectorsetlengthatleast(&state->hasbndl, n);
   vectorsetlengthatleast(&state->hasbndu, n);
   vectorsetlengthatleast(&state->scaledbndl, n);
   vectorsetlengthatleast(&state->scaledbndu, n);
   matrixsetlengthatleast(&state->scaledcleic, nec + nic, n + 1);
   vectorsetlengthatleast(&state->lcsrcidx, nec + nic);
   vectorsetlengthatleast(&state->meritfunctionhistory, nlcslp_nonmonotonicphase2limit + 1);
   vectorsetlengthatleast(&state->maxlaghistory, nlcslp_nonmonotonicphase2limit + 1);
// Prepare scaled problem
   for (i = 0; i < n; i++) {
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
      if (state->hasbndl.xB[i]) {
         state->scaledbndl.xR[i] = bndl->xR[i] / s->xR[i];
      }
      if (state->hasbndu.xB[i]) {
         state->scaledbndu.xR[i] = bndu->xR[i] / s->xR[i];
      }
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i]) {
         ae_assert(bndl->xR[i] <= bndu->xR[i], "SLP: integrity check failed, box constraints are inconsistent");
      }
      state->step0x.xR[i] = x0->xR[i] / s->xR[i];
      state->s.xR[i] = s->xR[i];
   }
   for (i = 0; i < nec + nic; i++) {
   // Permutation
      state->lcsrcidx.xZ[i] = lcsrcidx->xZ[i];
   // Scale and normalize linear constraints
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = cleic->xyR[i][j] * s->xR[j];
         state->scaledcleic.xyR[i][j] = v;
         vv += v * v;
      }
      vv = sqrt(vv);
      state->scaledcleic.xyR[i][n] = cleic->xyR[i][n];
      if (vv > 0.0) {
         for (j = 0; j <= n; j++) {
            state->scaledcleic.xyR[i][j] /= vv;
         }
      }
   }
// Initial enforcement of box constraints
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i]) {
         state->step0x.xR[i] = rmax2(state->step0x.xR[i], state->scaledbndl.xR[i]);
      }
      if (state->hasbndu.xB[i]) {
         state->step0x.xR[i] = rmin2(state->step0x.xR[i], state->scaledbndu.xR[i]);
      }
   }
// Stopping criteria
   state->epsx = epsx;
   state->maxits = maxits;
// Report fields
   state->repsimplexiterations = 0;
   state->repsimplexiterations1 = 0;
   state->repsimplexiterations2 = 0;
   state->repsimplexiterations3 = 0;
   state->repterminationtype = 0;
   state->repbcerr = 0.0;
   state->repbcidx = -1;
   state->replcerr = 0.0;
   state->replcidx = -1;
   state->repnlcerr = 0.0;
   state->repnlcidx = -1;
   state->repinneriterationscount = 0;
   state->repouteriterationscount = 0;
// Integrity checks:
// * it is important that significant step length is large enough that
//   we do not decrease trust regiod radius; it should also be small,
//   so we won't treat large steps as insignificant
   ae_assert(nlcslp_slpstpclosetozero < nlcslp_slpdeltadecrease, "MinSLP: integrity check failed");
   ae_assert(nlcslp_slpdeltadecrease < nlcslp_slpdeltaincrease, "MinSLP: integrity check failed");
   ae_assert(nlcslp_slpdeltaincrease < nlcslp_slpstpclosetoone, "MinSLP: integrity check failed");
}

// This function performs actual processing for  SLP  algorithm.  It  expects
// that caller redirects its reverse communication  requests NeedFiJ/XUpdated
// to external user who will provide analytic derivative (or  handle  reports
// about progress).
//
// In case external user does not have analytic derivative, it is responsibility
// of caller to intercept NeedFiJ request and  replace  it  with  appropriate
// numerical differentiation scheme.
//
// Results are stored:
// * point - in State.StepKX
//
// IMPORTANT: this function works with scaled problem formulation; it is
//            responsibility of the caller to unscale request and scale
//            Jacobian.
//
// NOTE: SMonitor is expected to be correctly initialized smoothness monitor.
// ALGLIB: Copyright 05.03.2018 by Sergey Bochkanov
bool minslpiteration(minslpstate *state, smoothnessmonitor *smonitor, bool userterminationneeded) {
   const double maxtrustraddecay = 0.1, maxtrustradgrowth = 1.333;
   const double initbigc = 500.0, maxbigc = 100000.0;
   const double inittrustrad = 0.1, stagnationepsf = 1.0E-12;
   const ae_int_t fstagnationlimit = 20;
   const double slpbigscale = 5.0, slpsmallscale = 0.2;
   const double defaultmaglagdecay = 0.85;
   AutoS ae_int_t n;
   AutoS ae_int_t nslack;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t nlec;
   AutoS ae_int_t nlic;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t innerk;
   AutoS double v;
   AutoS double vv;
   AutoS double mx;
   AutoS bool lpstagesuccess;
   AutoS double gammamax;
   AutoS double f1;
   AutoS double f2;
   AutoS ae_int_t status;
   AutoS double stp;
   AutoS double deltamax;
   AutoS double multiplyby;
   AutoS double setscaleto;
   AutoS double prevtrustrad;
   AutoS bool increasebigc;
   AutoS double d1nrm;
   AutoS double mu;
   AutoS double expandedrad;
   AutoS double tol;
   AutoS double maxlag;
   AutoS double maxhist;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume0; case 1: goto Resume1; case 2: goto Resume2;
      case 3: goto Resume3; case 4: goto Resume4;
      default: goto Exit;
   }
Spawn:
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   nlec = state->nlec;
   nlic = state->nlic;
   nslack = n + 2 * (nec + nlec) + (nic + nlic);
// Prepare RComm interface
   state->xupdated = state->needfij = false;
// Initialize algorithm data:
// * Lagrangian and "Big C" estimates
// * trust region
// * initial function scales (vector of 1's)
// * current approximation of the Hessian matrix H (unit matrix)
// * initial linearized constraints
// * initial violation of linear/nonlinear constraints
   state->lpfailurecnt = 0;
   state->fstagnationcnt = 0;
   state->bigc = initbigc;
   state->trustrad = inittrustrad;
   for (i = 0; i <= nlec + nlic; i++) {
      state->fscales.xR[i] = 1.0;
   }
   for (i = 0; i <= nlcslp_nonmonotonicphase2limit; i++) {
      state->meritfunctionhistory.xR[i] = maxrealnumber;
      state->maxlaghistory.xR[i] = 0.0;
   }
   state->historylen = 0;
   gammamax = 0.0;
// Avoid spurious warnings about possibly uninitialized vars
   status = 0;
   stp = 0.0;
// Evaluate function vector and Jacobian at Step0X, send first location report.
// Compute initial violation of constraints.
   nlcslp_slpsendx(state, &state->step0x);
   state->needfij = true, state->PQ = 0; goto Pause; Resume0: state->needfij = false;
   if (!nlcslp_slpretrievefij(state, &state->step0fi, &state->step0j)) {
   // Failed to retrieve function/Jaconian, infinities detected!
      for (i = 0; i < n; i++) {
         state->stepkx.xR[i] = state->step0x.xR[i];
      }
      state->repterminationtype = -8;
      goto Exit;
   }
   nlcslp_slpcopystate(state, &state->step0x, &state->step0fi, &state->step0j, &state->stepkx, &state->stepkfi, &state->stepkj);
   nlcslp_slpsendx(state, &state->stepkx);
   state->f = state->stepkfi.xR[0] * state->fscales.xR[0];
   state->xupdated = true, state->PQ = 1; goto Pause; Resume1: state->xupdated = false;
   checklcviolation(&state->scaledcleic, &state->lcsrcidx, nec, nic, &state->stepkx, n, &state->replcerr, &state->replcidx);
   unscaleandchecknlcviolation(&state->stepkfi, &state->fscales, nlec, nlic, &state->repnlcerr, &state->repnlcidx);
// Perform outer (NLC) iterations
   nlcslp_initlpsubsolver(state, &state->subsolver);
   while (true) {
   // Before beginning new outer iteration:
   // * renormalize target function and/or constraints, if some of them have too large magnitudes
   // * save initial point for the outer iteration
      for (i = 0; i <= nlec + nlic; i++) {
      // Determine (a) multiplicative coefficient applied to function value
      // and Jacobian row, and (b) new value of the function scale.
         mx = 0.0;
         for (j = 0; j < n; j++) {
            mx = rmax2(mx, fabs(state->stepkj.xyR[i][j]));
         }
         multiplyby = 1.0;
         setscaleto = state->fscales.xR[i];
         if (mx >= slpbigscale) {
            multiplyby = 1.0 / mx;
            setscaleto = state->fscales.xR[i] * mx;
         }
         if (mx <= slpsmallscale && state->fscales.xR[i] > 1.0) {
            if (state->fscales.xR[i] * mx > 1.0) {
               multiplyby = 1.0 / mx;
               setscaleto = state->fscales.xR[i] * mx;
            } else {
               multiplyby = state->fscales.xR[i];
               setscaleto = 1.0;
            }
         }
         if (multiplyby != 1.0) {
         // Function #I needs renormalization:
         // * update function vector element and Jacobian matrix row
         // * update FScales[] array
            state->stepkfi.xR[i] *= multiplyby;
            for (j = 0; j < n; j++) {
               state->stepkj.xyR[i][j] *= multiplyby;
            }
            state->fscales.xR[i] = setscaleto;
         }
      }
   // Save initial point for the outer iteration
      nlcslp_slpcopystate(state, &state->stepkx, &state->stepkfi, &state->stepkj, &state->step0x, &state->step0fi, &state->step0j);
   // PHASE 1:
   //
   // * perform step using linear model with second order correction
   // * compute "reference" Lagrange multipliers
   // * compute merit function at the end of the phase 1 and push it to the history queue
   //
   // NOTE: a second order correction helps to overcome Maratos effect - a tendency
   //       of L1 penalized merit function to reject nonzero steps along steepest
   //       descent direction.
   //
   //       The idea (explained in more details in the Phase13Iteration() body)
   //       is to perform one look-ahead step and use updated constraint values
   //       back at the initial point.
      for (
         nlcslp_phase13init(&state->state13, n, nec, nic, nlec, nlic, false);
         nlcslp_phase13iteration(state, &state->state13, smonitor, userterminationneeded, &state->stepkx, &state->stepkfi, &state->stepkj, &state->meritlagmult, &status, &d1nrm, &stp);
      ) {
         state->PQ = 2; goto Pause; Resume2: ;
      }
      if (status < 0) {
         continue;
      } else if (status == 0) {
         break;
      }
      maxlag = rmaxabsv(nec + nic + nlec + nlic, &state->meritlagmult);
      maxhist = rmaxabsv(state->historylen, &state->maxlaghistory);
      mu = coalesce(rmax2(maxhist, maxlag), nlcslp_defaultl1penalty);
      for (i = state->historylen; i >= 1; i--) {
         state->meritfunctionhistory.xR[i] = state->meritfunctionhistory.xR[i - 1];
         state->maxlaghistory.xR[i] = state->maxlaghistory.xR[i - 1];
      }
      state->meritfunctionhistory.xR[0] = nlcslp_meritfunction(state, &state->stepkx, &state->stepkfi, &state->meritlagmult, mu, &state->tmpmerit);
      state->maxlaghistory.xR[0] = coalesce(maxlag, defaultmaglagdecay * maxhist);
      state->historylen = imin2(state->historylen + 1, nlcslp_nonmonotonicphase2limit);
   // Decide whether we need to increase BigC (penalty for the constraint violation that
   // is used by the linear subsolver) or not. BigC is increased if all of the following
   // holds true:
   // * BigC can be increased (it is below upper limit)
   // * a short step was performed (shorter than the current trust region)
   // * at least one of the constraints is infeasible within current trust region
      if (d1nrm * stp < 0.99 * state->trustrad && state->bigc < 0.9 * maxbigc) {
         increasebigc = false;
         expandedrad = 1.1 * state->trustrad;
         tol = rmax2(sqrt(machineepsilon) * state->trustrad, 1000.0 * machineepsilon);
         for (i = 0; i < nec + nic; i++) {
            v = 0.0;
            vv = 0.0;
            for (j = 0; j < n; j++) {
               v += state->scaledcleic.xyR[i][j] * state->stepkx.xR[j];
               vv += fabs(state->scaledcleic.xyR[i][j] * expandedrad);
            }
            v -= state->scaledcleic.xyR[i][n];
            if (i >= nec) {
               v = rmax2(v, 0.0);
            }
            increasebigc = increasebigc || !SmallAtR(v, vv + tol);
         }
         for (i = 1; i <= nlec + nlic; i++) {
            v = state->stepkfi.xR[i];
            vv = 0.0;
            for (j = 0; j < n; j++) {
               vv += fabs(state->stepkj.xyR[i][j] * expandedrad);
            }
            if (i > nlec) {
               v = rmax2(v, 0.0);
            }
            increasebigc = increasebigc || !SmallAtR(v, vv + tol);
         }
         if (increasebigc) {
            state->bigc = rmin2(10.0 * state->bigc, maxbigc);
         }
      }
   // PHASE 2: conjugate subiterations
   //
   // If step with second order correction is shorter than 1.0, it means
   // that target is sufficiently nonlinear to use advanced iterations.
   // * perform inner LP subiterations with additional conjugacy constraints
   // * check changes in merit function, discard iteration results if merit function increased
      if (stp < nlcslp_slpstpclosetoone) {
         nlcslp_slpcopystate(state, &state->stepkx, &state->stepkfi, &state->stepkj, &state->backupx, &state->backupfi, &state->backupj);
      // LP subiterations
         for (
            nlcslp_phase2init(&state->state2, n, nec, nic, nlec, nlic, &state->meritlagmult);
            nlcslp_phase2iteration(state, &state->state2, smonitor, userterminationneeded, &state->stepkx, &state->stepkfi, &state->stepkj, &state->dummylagmult, &gammamax, &status);
         ) {
            state->PQ = 3; goto Pause; Resume3: ;
         }
         if (status == 0) {
         // Save progress so far and stop
            break;
         }
      // Evaluating step
      //
      // This step is essential because previous step (which minimizes Lagrangian) may fail
      // to produce descent direction for L1-penalized merit function and will increase it
      // instead of decreasing.
      //
      // During evaluation we compare merit function at new location with maximum computed
      // over last NonmonotonicPhase2Limit+1 previous ones (as suggested in 'A Sequential
      // Quadratic Programming Algorithm with Non-Monotone Line Search' by Yu-Hong Dai).
      //
      // Settings NonmonotonicPhase2Limit to 0 will result in strictly monotonic line search,
      // whilst having nonzero limits means that we perform more robust nonmonotonic search.
         ae_assert(state->historylen >= 1, "SLP: integrity check 6559 failed");
         f1 = state->meritfunctionhistory.xR[0];
         for (i = 1; i <= state->historylen; i++) {
            f1 = rmax2(f1, state->meritfunctionhistory.xR[i]);
         }
         f2 = nlcslp_meritfunction(state, &state->stepkx, &state->stepkfi, &state->meritlagmult, mu, &state->tmpmerit);
         if (f2 >= f1) {
         // Merit function does not decrease, discard phase results and report is as one
         // more "fake" inner iteration.
         //
         // NOTE: it is important that F2 == F1 is considered as "does not decrease"
            nlcslp_slpcopystate(state, &state->backupx, &state->backupfi, &state->backupj, &state->stepkx, &state->stepkfi, &state->stepkj);
            state->repinneriterationscount++;
            nlcslp_slpsendx(state, &state->stepkx);
            state->f = state->stepkfi.xR[0] * state->fscales.xR[0];
            state->xupdated = true, state->PQ = 4; goto Pause; Resume4: state->xupdated = false;
            checklcviolation(&state->scaledcleic, &state->lcsrcidx, nec, nic, &state->stepkx, n, &state->replcerr, &state->replcidx);
            unscaleandchecknlcviolation(&state->stepkfi, &state->fscales, nlec, nlic, &state->repnlcerr, &state->repnlcidx);
         } else {
         // Merit function decreased, accept phase
            state->meritfunctionhistory.xR[0] = f2;
         }
      } else {
      // No phase #2
      }
   // Update trust region
      prevtrustrad = state->trustrad;
      deltamax = 0.0;
      for (i = 0; i < n; i++) {
         deltamax = rmax2(deltamax, fabs(state->step0x.xR[i] - state->stepkx.xR[i]) / state->trustrad);
      }
      if (deltamax <= nlcslp_slpdeltadecrease) {
         state->trustrad *= rmax2(deltamax / nlcslp_slpdeltadecrease, maxtrustraddecay);
      }
      if (deltamax >= nlcslp_slpdeltaincrease) {
         state->trustrad *= rmin2(deltamax / nlcslp_slpdeltaincrease, maxtrustradgrowth);
      }
   // Advance outer iteration counter, test stopping criteria
      state->repouteriterationscount++;
      if (NearAtR(state->stepkfi.xR[0], state->step0fi.xR[0], stagnationepsf * fabs(state->step0fi.xR[0]))) {
         state->fstagnationcnt++;
      } else {
         state->fstagnationcnt = 0;
      }
      if (state->trustrad <= state->epsx) {
         state->repterminationtype = 2;
         break;
      } else if (state->maxits > 0 && state->repinneriterationscount >= state->maxits) {
         state->repterminationtype = 5;
         break;
      } else if (state->fstagnationcnt >= fstagnationlimit) {
         state->repterminationtype = 7;
         break;
      }
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

void minslpsubsolver_init(void *_p, bool make_automatic) {
   minslpsubsolver *p = (minslpsubsolver *)_p;
   presolveinfo_init(&p->presolver, make_automatic);
   dualsimplexstate_init(&p->dss, make_automatic);
   dualsimplexsettings_init(&p->dsssettings, make_automatic);
   dualsimplexbasis_init(&p->lastbasis, make_automatic);
   ae_matrix_init(&p->curd, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curb, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cural, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->curau, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparserawlc, make_automatic);
   sparsematrix_init(&p->sparseefflc, make_automatic);
   xbfgshessian_init(&p->hess, make_automatic);
   ae_matrix_init(&p->curhd, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->densedummy, 0, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->sparsedummy, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->yk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xs, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->laglc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lagbc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cs, 0, DT_INT, make_automatic);
}

void minslpsubsolver_copy(void *_dst, const void *_src, bool make_automatic) {
   minslpsubsolver *dst = (minslpsubsolver *)_dst;
   const minslpsubsolver *src = (const minslpsubsolver *)_src;
   presolveinfo_copy(&dst->presolver, &src->presolver, make_automatic);
   dualsimplexstate_copy(&dst->dss, &src->dss, make_automatic);
   dualsimplexsettings_copy(&dst->dsssettings, &src->dsssettings, make_automatic);
   dualsimplexbasis_copy(&dst->lastbasis, &src->lastbasis, make_automatic);
   dst->basispresent = src->basispresent;
   ae_matrix_copy(&dst->curd, &src->curd, make_automatic);
   dst->curdcnt = src->curdcnt;
   ae_vector_copy(&dst->curb, &src->curb, make_automatic);
   ae_vector_copy(&dst->curbndl, &src->curbndl, make_automatic);
   ae_vector_copy(&dst->curbndu, &src->curbndu, make_automatic);
   ae_vector_copy(&dst->cural, &src->cural, make_automatic);
   ae_vector_copy(&dst->curau, &src->curau, make_automatic);
   sparsematrix_copy(&dst->sparserawlc, &src->sparserawlc, make_automatic);
   sparsematrix_copy(&dst->sparseefflc, &src->sparseefflc, make_automatic);
   xbfgshessian_copy(&dst->hess, &src->hess, make_automatic);
   ae_matrix_copy(&dst->curhd, &src->curhd, make_automatic);
   ae_matrix_copy(&dst->densedummy, &src->densedummy, make_automatic);
   sparsematrix_copy(&dst->sparsedummy, &src->sparsedummy, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_vector_copy(&dst->sk, &src->sk, make_automatic);
   ae_vector_copy(&dst->yk, &src->yk, make_automatic);
   ae_vector_copy(&dst->xs, &src->xs, make_automatic);
   ae_vector_copy(&dst->laglc, &src->laglc, make_automatic);
   ae_vector_copy(&dst->lagbc, &src->lagbc, make_automatic);
   ae_vector_copy(&dst->cs, &src->cs, make_automatic);
}

void minslpsubsolver_free(void *_p, bool make_automatic) {
   minslpsubsolver *p = (minslpsubsolver *)_p;
   presolveinfo_free(&p->presolver, make_automatic);
   dualsimplexstate_free(&p->dss, make_automatic);
   dualsimplexsettings_free(&p->dsssettings, make_automatic);
   dualsimplexbasis_free(&p->lastbasis, make_automatic);
   ae_matrix_free(&p->curd, make_automatic);
   ae_vector_free(&p->curb, make_automatic);
   ae_vector_free(&p->curbndl, make_automatic);
   ae_vector_free(&p->curbndu, make_automatic);
   ae_vector_free(&p->cural, make_automatic);
   ae_vector_free(&p->curau, make_automatic);
   sparsematrix_free(&p->sparserawlc, make_automatic);
   sparsematrix_free(&p->sparseefflc, make_automatic);
   xbfgshessian_free(&p->hess, make_automatic);
   ae_matrix_free(&p->curhd, make_automatic);
   ae_matrix_free(&p->densedummy, make_automatic);
   sparsematrix_free(&p->sparsedummy, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_vector_free(&p->sk, make_automatic);
   ae_vector_free(&p->yk, make_automatic);
   ae_vector_free(&p->xs, make_automatic);
   ae_vector_free(&p->laglc, make_automatic);
   ae_vector_free(&p->lagbc, make_automatic);
   ae_vector_free(&p->cs, make_automatic);
}

void minslptmplagrangian_init(void *_p, bool make_automatic) {
   minslptmplagrangian *p = (minslptmplagrangian *)_p;
   ae_vector_init(&p->sclagtmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->sclagtmp1, 0, DT_REAL, make_automatic);
}

void minslptmplagrangian_copy(void *_dst, const void *_src, bool make_automatic) {
   minslptmplagrangian *dst = (minslptmplagrangian *)_dst;
   const minslptmplagrangian *src = (const minslptmplagrangian *)_src;
   ae_vector_copy(&dst->sclagtmp0, &src->sclagtmp0, make_automatic);
   ae_vector_copy(&dst->sclagtmp1, &src->sclagtmp1, make_automatic);
}

void minslptmplagrangian_free(void *_p, bool make_automatic) {
   minslptmplagrangian *p = (minslptmplagrangian *)_p;
   ae_vector_free(&p->sclagtmp0, make_automatic);
   ae_vector_free(&p->sclagtmp1, make_automatic);
}

void minslptmpmerit_init(void *_p, bool make_automatic) {
   minslptmpmerit *p = (minslptmpmerit *)_p;
   ae_vector_init(&p->mftmp0, 0, DT_REAL, make_automatic);
}

void minslptmpmerit_copy(void *_dst, const void *_src, bool make_automatic) {
   minslptmpmerit *dst = (minslptmpmerit *)_dst;
   const minslptmpmerit *src = (const minslptmpmerit *)_src;
   ae_vector_copy(&dst->mftmp0, &src->mftmp0, make_automatic);
}

void minslptmpmerit_free(void *_p, bool make_automatic) {
   minslptmpmerit *p = (minslptmpmerit *)_p;
   ae_vector_free(&p->mftmp0, make_automatic);
}

void minslpphase13state_init(void *_p, bool make_automatic) {
   minslpphase13state *p = (minslpphase13state *)_p;
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkxc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkxn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfic, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfin, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkjc, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkjn, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dummylagmult, 0, DT_REAL, make_automatic);
   minslptmpmerit_init(&p->tmpmerit, make_automatic);
}

void minslpphase13state_copy(void *_dst, const void *_src, bool make_automatic) {
   minslpphase13state *dst = (minslpphase13state *)_dst;
   const minslpphase13state *src = (const minslpphase13state *)_src;
   dst->usecorrection = src->usecorrection;
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_vector_copy(&dst->dx, &src->dx, make_automatic);
   ae_vector_copy(&dst->stepkxc, &src->stepkxc, make_automatic);
   ae_vector_copy(&dst->stepkxn, &src->stepkxn, make_automatic);
   ae_vector_copy(&dst->stepkfic, &src->stepkfic, make_automatic);
   ae_vector_copy(&dst->stepkfin, &src->stepkfin, make_automatic);
   ae_matrix_copy(&dst->stepkjc, &src->stepkjc, make_automatic);
   ae_matrix_copy(&dst->stepkjn, &src->stepkjn, make_automatic);
   ae_vector_copy(&dst->dummylagmult, &src->dummylagmult, make_automatic);
   minslptmpmerit_copy(&dst->tmpmerit, &src->tmpmerit, make_automatic);
   dst->Ph13PQ = src->Ph13PQ;
}

void minslpphase13state_free(void *_p, bool make_automatic) {
   minslpphase13state *p = (minslpphase13state *)_p;
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->dx, make_automatic);
   ae_vector_free(&p->stepkxc, make_automatic);
   ae_vector_free(&p->stepkxn, make_automatic);
   ae_vector_free(&p->stepkfic, make_automatic);
   ae_vector_free(&p->stepkfin, make_automatic);
   ae_matrix_free(&p->stepkjc, make_automatic);
   ae_matrix_free(&p->stepkjn, make_automatic);
   ae_vector_free(&p->dummylagmult, make_automatic);
   minslptmpmerit_free(&p->tmpmerit, make_automatic);
}

void minslpphase2state_init(void *_p, bool make_automatic) {
   minslpphase2state *p = (minslpphase2state *)_p;
   ae_vector_init(&p->stepkxn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkxc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfin, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfic, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkjn, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkjc, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepklaggrad, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepknlaggrad, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepknlagmult, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->meritlagmult, 0, DT_REAL, make_automatic);
   minslptmplagrangian_init(&p->tmplagrangianfg, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   linminstate_init(&p->mcstate, make_automatic);
   minslptmpmerit_init(&p->tmpmerit, make_automatic);
}

void minslpphase2state_copy(void *_dst, const void *_src, bool make_automatic) {
   minslpphase2state *dst = (minslpphase2state *)_dst;
   const minslpphase2state *src = (const minslpphase2state *)_src;
   ae_vector_copy(&dst->stepkxn, &src->stepkxn, make_automatic);
   ae_vector_copy(&dst->stepkxc, &src->stepkxc, make_automatic);
   ae_vector_copy(&dst->stepkfin, &src->stepkfin, make_automatic);
   ae_vector_copy(&dst->stepkfic, &src->stepkfic, make_automatic);
   ae_matrix_copy(&dst->stepkjn, &src->stepkjn, make_automatic);
   ae_matrix_copy(&dst->stepkjc, &src->stepkjc, make_automatic);
   ae_vector_copy(&dst->stepklaggrad, &src->stepklaggrad, make_automatic);
   ae_vector_copy(&dst->stepknlaggrad, &src->stepknlaggrad, make_automatic);
   ae_vector_copy(&dst->stepknlagmult, &src->stepknlagmult, make_automatic);
   ae_vector_copy(&dst->meritlagmult, &src->meritlagmult, make_automatic);
   minslptmplagrangian_copy(&dst->tmplagrangianfg, &src->tmplagrangianfg, make_automatic);
   dst->lastlcerr = src->lastlcerr;
   dst->lastlcidx = src->lastlcidx;
   dst->lastnlcerr = src->lastnlcerr;
   dst->lastnlcidx = src->lastnlcidx;
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   linminstate_copy(&dst->mcstate, &src->mcstate, make_automatic);
   minslptmpmerit_copy(&dst->tmpmerit, &src->tmpmerit, make_automatic);
   dst->Ph2PQ = src->Ph2PQ;
}

void minslpphase2state_free(void *_p, bool make_automatic) {
   minslpphase2state *p = (minslpphase2state *)_p;
   ae_vector_free(&p->stepkxn, make_automatic);
   ae_vector_free(&p->stepkxc, make_automatic);
   ae_vector_free(&p->stepkfin, make_automatic);
   ae_vector_free(&p->stepkfic, make_automatic);
   ae_matrix_free(&p->stepkjn, make_automatic);
   ae_matrix_free(&p->stepkjc, make_automatic);
   ae_vector_free(&p->stepklaggrad, make_automatic);
   ae_vector_free(&p->stepknlaggrad, make_automatic);
   ae_vector_free(&p->stepknlagmult, make_automatic);
   ae_vector_free(&p->meritlagmult, make_automatic);
   minslptmplagrangian_free(&p->tmplagrangianfg, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   linminstate_free(&p->mcstate, make_automatic);
   minslptmpmerit_free(&p->tmpmerit, make_automatic);
}

void minslpstate_init(void *_p, bool make_automatic) {
   minslpstate *p = (minslpstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->scaledcleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lcsrcidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->scaledbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->scaledbndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j, 0, 0, DT_REAL, make_automatic);
   minslpphase13state_init(&p->state13, make_automatic);
   minslpphase2state_init(&p->state2, make_automatic);
   ae_vector_init(&p->step0x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->backupx, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->step0fi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->stepkfi, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->backupfi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->step0j, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->stepkj, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->backupj, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->meritlagmult, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dummylagmult, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fscales, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->meritfunctionhistory, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->maxlaghistory, 0, DT_REAL, make_automatic);
   minslpsubsolver_init(&p->subsolver, make_automatic);
   minslptmpmerit_init(&p->tmpmerit, make_automatic);
}

void minslpstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minslpstate *dst = (minslpstate *)_dst;
   const minslpstate *src = (const minslpstate *)_src;
   dst->n = src->n;
   dst->nec = src->nec;
   dst->nic = src->nic;
   dst->nlec = src->nlec;
   dst->nlic = src->nlic;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_matrix_copy(&dst->scaledcleic, &src->scaledcleic, make_automatic);
   ae_vector_copy(&dst->lcsrcidx, &src->lcsrcidx, make_automatic);
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_vector_copy(&dst->scaledbndl, &src->scaledbndl, make_automatic);
   ae_vector_copy(&dst->scaledbndu, &src->scaledbndu, make_automatic);
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   ae_matrix_copy(&dst->j, &src->j, make_automatic);
   dst->f = src->f;
   dst->needfij = src->needfij;
   dst->xupdated = src->xupdated;
   minslpphase13state_copy(&dst->state13, &src->state13, make_automatic);
   minslpphase2state_copy(&dst->state2, &src->state2, make_automatic);
   dst->trustrad = src->trustrad;
   dst->bigc = src->bigc;
   dst->lpfailurecnt = src->lpfailurecnt;
   dst->fstagnationcnt = src->fstagnationcnt;
   ae_vector_copy(&dst->step0x, &src->step0x, make_automatic);
   ae_vector_copy(&dst->stepkx, &src->stepkx, make_automatic);
   ae_vector_copy(&dst->backupx, &src->backupx, make_automatic);
   ae_vector_copy(&dst->step0fi, &src->step0fi, make_automatic);
   ae_vector_copy(&dst->stepkfi, &src->stepkfi, make_automatic);
   ae_vector_copy(&dst->backupfi, &src->backupfi, make_automatic);
   ae_matrix_copy(&dst->step0j, &src->step0j, make_automatic);
   ae_matrix_copy(&dst->stepkj, &src->stepkj, make_automatic);
   ae_matrix_copy(&dst->backupj, &src->backupj, make_automatic);
   ae_vector_copy(&dst->meritlagmult, &src->meritlagmult, make_automatic);
   ae_vector_copy(&dst->dummylagmult, &src->dummylagmult, make_automatic);
   ae_vector_copy(&dst->fscales, &src->fscales, make_automatic);
   ae_vector_copy(&dst->meritfunctionhistory, &src->meritfunctionhistory, make_automatic);
   ae_vector_copy(&dst->maxlaghistory, &src->maxlaghistory, make_automatic);
   dst->historylen = src->historylen;
   minslpsubsolver_copy(&dst->subsolver, &src->subsolver, make_automatic);
   minslptmpmerit_copy(&dst->tmpmerit, &src->tmpmerit, make_automatic);
   dst->repsimplexiterations = src->repsimplexiterations;
   dst->repsimplexiterations1 = src->repsimplexiterations1;
   dst->repsimplexiterations2 = src->repsimplexiterations2;
   dst->repsimplexiterations3 = src->repsimplexiterations3;
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repterminationtype = src->repterminationtype;
   dst->repbcerr = src->repbcerr;
   dst->repbcidx = src->repbcidx;
   dst->replcerr = src->replcerr;
   dst->replcidx = src->replcidx;
   dst->repnlcerr = src->repnlcerr;
   dst->repnlcidx = src->repnlcidx;
   dst->PQ = src->PQ;
}

void minslpstate_free(void *_p, bool make_automatic) {
   minslpstate *p = (minslpstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_matrix_free(&p->scaledcleic, make_automatic);
   ae_vector_free(&p->lcsrcidx, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_vector_free(&p->scaledbndl, make_automatic);
   ae_vector_free(&p->scaledbndu, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_matrix_free(&p->j, make_automatic);
   minslpphase13state_free(&p->state13, make_automatic);
   minslpphase2state_free(&p->state2, make_automatic);
   ae_vector_free(&p->step0x, make_automatic);
   ae_vector_free(&p->stepkx, make_automatic);
   ae_vector_free(&p->backupx, make_automatic);
   ae_vector_free(&p->step0fi, make_automatic);
   ae_vector_free(&p->stepkfi, make_automatic);
   ae_vector_free(&p->backupfi, make_automatic);
   ae_matrix_free(&p->step0j, make_automatic);
   ae_matrix_free(&p->stepkj, make_automatic);
   ae_matrix_free(&p->backupj, make_automatic);
   ae_vector_free(&p->meritlagmult, make_automatic);
   ae_vector_free(&p->dummylagmult, make_automatic);
   ae_vector_free(&p->fscales, make_automatic);
   ae_vector_free(&p->meritfunctionhistory, make_automatic);
   ae_vector_free(&p->maxlaghistory, make_automatic);
   minslpsubsolver_free(&p->subsolver, make_automatic);
   minslptmpmerit_free(&p->tmpmerit, make_automatic);
}
} // end of namespace alglib_impl

// === MINNLC Package ===
// Depends on: MINBLEIC, NLCSQP, NLCSLP
namespace alglib_impl {
// This function sets boundary constraints for NLC optimizer.
//
// Boundary constraints are inactive by  default  (after  initial  creation).
// They are preserved after algorithm restart with  MinNLCRestartFrom().
//
// You may combine boundary constraints with  general  linear ones - and with
// nonlinear ones! Boundary constraints are  handled  more  efficiently  than
// other types.  Thus,  if  your  problem  has  mixed  constraints,  you  may
// explicitly specify some of them as boundary and save some time/space.
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF.
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF.
//
// NOTE 1:  it is possible to specify  BndL[i] == BndU[i].  In  this  case  I-th
// variable will be "frozen" at X[i] == BndL[i] == BndU[i].
//
// NOTE 2:  when you solve your problem  with  augmented  Lagrangian  solver,
//          boundary constraints are  satisfied  only  approximately!  It  is
//          possible   that  algorithm  will  evaluate  function  outside  of
//          feasible area!
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcsetbc(const minnlcstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minnlcsetbc(minnlcstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(bndl->cnt >= n, "MinNLCSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinNLCSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinNLCSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinNLCSetBC: BndL contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
   }
}

// This function sets linear constraints for MinNLC optimizer.
//
// Linear constraints are inactive by default (after initial creation).  They
// are preserved after algorithm restart with MinNLCRestartFrom().
//
// You may combine linear constraints with boundary ones - and with nonlinear
// ones! If your problem has mixed constraints, you  may  explicitly  specify
// some of them as linear. It  may  help  optimizer   to   handle  them  more
// efficiently.
//
// Inputs:
//     State   -   structure previously allocated with MinNLCCreate call.
//     C       -   linear constraints, array[K,N+1].
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n+1]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n+1]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n+1]
//     K       -   number of equality/inequality constraints, K >= 0:
//                 * if given, only leading K elements of C/CT are used
//                 * if not given, automatically determined from sizes of C/CT
//
// NOTE 1: when you solve your problem  with  augmented  Lagrangian   solver,
//         linear constraints are  satisfied  only   approximately!   It   is
//         possible   that  algorithm  will  evaluate  function  outside   of
//         feasible area!
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcsetlc(const minnlcstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k);
// API: void minnlcsetlc(const minnlcstate &state, const real_2d_array &c, const integer_1d_array &ct);
void minnlcsetlc(minnlcstate *state, RMatrix *c, ZVector *ct, ae_int_t k) {
   ae_int_t n;
   ae_int_t i;
   n = state->n;
// First, check for errors in the inputs
   ae_assert(k >= 0, "MinNLCSetLC: K < 0");
   ae_assert(c->cols > n || k == 0, "MinNLCSetLC: Cols(C) <= N");
   ae_assert(c->rows >= k, "MinNLCSetLC: Rows(C) < K");
   ae_assert(ct->cnt >= k, "MinNLCSetLC: Length(CT) < K");
   ae_assert(apservisfinitematrix(c, k, n + 1), "MinNLCSetLC: C contains infinite or NaN values!");
// Handle zero K
   if (k == 0) {
      state->nec = 0;
      state->nic = 0;
      return;
   }
// Equality constraints are stored first, in the upper
// NEC rows of State.CLEIC matrix. Inequality constraints
// are stored in the next NIC rows.
//
// NOTE: we convert inequality constraints to the form
// A*x <= b before copying them.
   matrixsetlengthatleast(&state->cleic, k, n + 1);
   vectorsetlengthatleast(&state->lcsrcidx, k);
   state->nec = 0;
   state->nic = 0;
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] == 0) {
         ae_v_move(state->cleic.xyR[state->nec], 1, c->xyR[i], 1, n + 1);
         state->lcsrcidx.xZ[state->nec] = i;
         state->nec++;
      }
   }
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] != 0) {
         if (ct->xZ[i] > 0) {
            ae_v_moveneg(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         } else {
            ae_v_move(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         }
         state->lcsrcidx.xZ[state->nec + state->nic] = i;
         state->nic++;
      }
   }
}

// This function sets nonlinear constraints for MinNLC optimizer.
//
// In fact, this function sets NUMBER of nonlinear  constraints.  Constraints
// itself (constraint functions) are passed to MinNLCOptimize() method.  This
// method requires user-defined vector function F[]  and  its  Jacobian  J[],
// where:
// * first component of F[] and first row  of  Jacobian  J[]  corresponds  to
//   function being minimized
// * next NLEC components of F[] (and rows  of  J)  correspond  to  nonlinear
//   equality constraints G_i(x) == 0
// * next NLIC components of F[] (and rows  of  J)  correspond  to  nonlinear
//   inequality constraints H_i(x) <= 0
//
// NOTE: you may combine nonlinear constraints with linear/boundary ones.  If
//       your problem has mixed constraints, you  may explicitly specify some
//       of them as linear ones. It may help optimizer to  handle  them  more
//       efficiently.
//
// Inputs:
//     State   -   structure previously allocated with MinNLCCreate call.
//     NLEC    -   number of Non-Linear Equality Constraints (NLEC), >= 0
//     NLIC    -   number of Non-Linear Inquality Constraints (NLIC), >= 0
//
// NOTE 1: when you solve your problem  with  augmented  Lagrangian   solver,
//         nonlinear constraints are satisfied only  approximately!   It   is
//         possible   that  algorithm  will  evaluate  function  outside   of
//         feasible area!
//
// NOTE 2: algorithm scales variables  according  to   scale   specified   by
//         MinNLCSetScale()  function,  so  it can handle problems with badly
//         scaled variables (as long as we KNOW their scales).
//
//         However,  there  is  no  way  to  automatically  scale   nonlinear
//         constraints Gi(x) and Hi(x). Inappropriate scaling  of  Gi/Hi  may
//         ruin convergence. Solving problem with  constraint  "1000*G0(x) == 0"
//         is NOT same as solving it with constraint "0.001*G0(x) == 0".
//
//         It  means  that  YOU  are  the  one who is responsible for correct
//         scaling of nonlinear constraints Gi(x) and Hi(x). We recommend you
//         to scale nonlinear constraints in such way that I-th component  of
//         dG/dX (or dH/dx) has approximately unit  magnitude  (for  problems
//         with unit scale)  or  has  magnitude approximately equal to 1/S[i]
//         (where S is a scale set by MinNLCSetScale() function).
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcsetnlc(const minnlcstate &state, const ae_int_t nlec, const ae_int_t nlic);
void minnlcsetnlc(minnlcstate *state, ae_int_t nlec, ae_int_t nlic) {
   ae_assert(nlec >= 0, "MinNLCSetNLC: NLEC < 0");
   ae_assert(nlic >= 0, "MinNLCSetNLC: NLIC < 0");
   state->ng = nlec;
   state->nh = nlic;
   ae_vector_set_length(&state->fi, 1 + state->ng + state->nh);
   ae_matrix_set_length(&state->j, 1 + state->ng + state->nh, state->n);
}

// This function sets stopping conditions for inner iterations of  optimizer.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsX    -   >= 0
//                 The subroutine finishes its work if  on  k+1-th  iteration
//                 the condition |v| <= EpsX is fulfilled, where:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - step vector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinNLCSetScale()
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited.
//
// Passing EpsX == 0 and MaxIts == 0 (simultaneously) will lead to automatic
// selection of the stopping condition.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcsetcond(const minnlcstate &state, const double epsx, const ae_int_t maxits);
void minnlcsetcond(minnlcstate *state, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsx), "MinNLCSetCond: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinNLCSetCond: negative EpsX");
   ae_assert(maxits >= 0, "MinNLCSetCond: negative MaxIts!");
   if (epsx == 0.0 && maxits == 0) {
      epsx = 0.00000001;
   }
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function sets scaling coefficients for NLC optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Scaling is also used by finite difference variant of the optimizer  - step
// along I-th axis is equal to DiffStep*S[I].
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcsetscale(const minnlcstate &state, const real_1d_array &s);
void minnlcsetscale(minnlcstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinNLCSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinNLCSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinNLCSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// This function sets preconditioner to "inexact LBFGS-based" mode.
//
// Preconditioning is very important for convergence of  Augmented Lagrangian
// algorithm because presence of penalty term makes problem  ill-conditioned.
// Difference between  performance  of  preconditioned  and  unpreconditioned
// methods can be as large as 100x!
//
// MinNLC optimizer may use following preconditioners,  each  with   its  own
// benefits and drawbacks:
//     a) inexact LBFGS-based, with O(N*K) evaluation time
//     b) exact low rank one,  with O(N*K^2) evaluation time
//     c) exact robust one,    with O(N^3+K*N^2) evaluation time
// where K is a total number of general linear and nonlinear constraints (box
// ones are not counted).
//
// Inexact  LBFGS-based  preconditioner  uses L-BFGS  formula  combined  with
// orthogonality assumption to perform very fast updates. For a N-dimensional
// problem with K general linear or nonlinear constraints (boundary ones  are
// not counted) it has O(N*K) cost per iteration.  This   preconditioner  has
// best  quality  (less  iterations)  when   general   linear  and  nonlinear
// constraints are orthogonal to each other (orthogonality  with  respect  to
// boundary constraints is not required). Number of iterations increases when
// constraints  are  non-orthogonal, because algorithm assumes orthogonality,
// but still it is better than no preconditioner at all.
//
// Inputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 26.09.2014 by Sergey Bochkanov
// API: void minnlcsetprecinexact(const minnlcstate &state);
void minnlcsetprecinexact(minnlcstate *state) {
   state->updatefreq = 0;
   state->prectype = 1;
}

// This function sets preconditioner to "exact low rank" mode.
//
// Preconditioning is very important for convergence of  Augmented Lagrangian
// algorithm because presence of penalty term makes problem  ill-conditioned.
// Difference between  performance  of  preconditioned  and  unpreconditioned
// methods can be as large as 100x!
//
// MinNLC optimizer may use following preconditioners,  each  with   its  own
// benefits and drawbacks:
//     a) inexact LBFGS-based, with O(N*K) evaluation time
//     b) exact low rank one,  with O(N*K^2) evaluation time
//     c) exact robust one,    with O(N^3+K*N^2) evaluation time
// where K is a total number of general linear and nonlinear constraints (box
// ones are not counted).
//
// It also provides special unpreconditioned mode of operation which  can  be
// used for test purposes. Comments below discuss low rank preconditioner.
//
// Exact low-rank preconditioner  uses  Woodbury  matrix  identity  to  build
// quadratic model of the penalized function. It has following features:
// * no special assumptions about orthogonality of constraints
// * preconditioner evaluation is optimized for K << N. Its cost  is  O(N*K^2),
//   so it may become prohibitively slow for K >= N.
// * finally, stability of the process is guaranteed only for K << N.  Woodbury
//   update often fail for K >= N due to degeneracy of  intermediate  matrices.
//   That's why we recommend to use "exact robust"  preconditioner  for  such
//   cases.
//
// RECOMMENDATIONS
//
// We  recommend  to  choose  between  "exact  low  rank"  and "exact robust"
// preconditioners, with "low rank" version being chosen  when  you  know  in
// advance that total count of non-box constraints won't exceed N, and "robust"
// version being chosen when you need bulletproof solution.
//
// Inputs:
//     State   -   structure stores algorithm state
//     UpdateFreq- update frequency. Preconditioner is  rebuilt  after  every
//                 UpdateFreq iterations. Recommended value: 10 or higher.
//                 Zero value means that good default value will be used.
// ALGLIB: Copyright 26.09.2014 by Sergey Bochkanov
// API: void minnlcsetprecexactlowrank(const minnlcstate &state, const ae_int_t updatefreq);
void minnlcsetprecexactlowrank(minnlcstate *state, ae_int_t updatefreq) {
   ae_assert(updatefreq >= 0, "MinNLCSetPrecExactLowRank: UpdateFreq < 0");
   if (updatefreq == 0) {
      updatefreq = 10;
   }
   state->prectype = 2;
   state->updatefreq = updatefreq;
}

// This function sets preconditioner to "exact robust" mode.
//
// Preconditioning is very important for convergence of  Augmented Lagrangian
// algorithm because presence of penalty term makes problem  ill-conditioned.
// Difference between  performance  of  preconditioned  and  unpreconditioned
// methods can be as large as 100x!
//
// MinNLC optimizer may use following preconditioners,  each  with   its  own
// benefits and drawbacks:
//     a) inexact LBFGS-based, with O(N*K) evaluation time
//     b) exact low rank one,  with O(N*K^2) evaluation time
//     c) exact robust one,    with O(N^3+K*N^2) evaluation time
// where K is a total number of general linear and nonlinear constraints (box
// ones are not counted).
//
// It also provides special unpreconditioned mode of operation which  can  be
// used for test purposes. Comments below discuss robust preconditioner.
//
// Exact  robust  preconditioner   uses   Cholesky  decomposition  to  invert
// approximate Hessian matrix H == D+W'*C*W (where D stands for  diagonal  terms
// of Hessian, combined result of initial scaling matrix and penalty from box
// constraints; W stands for general linear constraints and linearization  of
// nonlinear ones; C stands for diagonal matrix of penalty coefficients).
//
// This preconditioner has following features:
// * no special assumptions about constraint structure
// * preconditioner is optimized  for  stability;  unlike  "exact  low  rank"
//   version which fails for K >= N, this one works well for any value of K.
// * the only drawback is that is takes O(N^3+K*N^2) time  to  build  it.  No
//   economical  Woodbury update is applied even when it  makes  sense,  thus
//   there  are  exist situations (K << N) when "exact low rank" preconditioner
//   outperforms this one.
//
// RECOMMENDATIONS
//
// We  recommend  to  choose  between  "exact  low  rank"  and "exact robust"
// preconditioners, with "low rank" version being chosen  when  you  know  in
// advance that total count of non-box constraints won't exceed N, and "robust"
// version being chosen when you need bulletproof solution.
//
// Inputs:
//     State   -   structure stores algorithm state
//     UpdateFreq- update frequency. Preconditioner is  rebuilt  after  every
//                 UpdateFreq iterations. Recommended value: 10 or higher.
//                 Zero value means that good default value will be used.
// ALGLIB: Copyright 26.09.2014 by Sergey Bochkanov
// API: void minnlcsetprecexactrobust(const minnlcstate &state, const ae_int_t updatefreq);
void minnlcsetprecexactrobust(minnlcstate *state, ae_int_t updatefreq) {
   ae_assert(updatefreq >= 0, "MinNLCSetPrecExactLowRank: UpdateFreq < 0");
   if (updatefreq == 0) {
      updatefreq = 10;
   }
   state->prectype = 3;
   state->updatefreq = updatefreq;
}

// This function sets preconditioner to "turned off" mode.
//
// Preconditioning is very important for convergence of  Augmented Lagrangian
// algorithm because presence of penalty term makes problem  ill-conditioned.
// Difference between  performance  of  preconditioned  and  unpreconditioned
// methods can be as large as 100x!
//
// MinNLC optimizer may  utilize  two  preconditioners,  each  with  its  own
// benefits and drawbacks: a) inexact LBFGS-based, and b) exact low rank one.
// It also provides special unpreconditioned mode of operation which  can  be
// used for test purposes.
//
// This function activates this test mode. Do not use it in  production  code
// to solve real-life problems.
//
// Inputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 26.09.2014 by Sergey Bochkanov
// API: void minnlcsetprecnone(const minnlcstate &state);
void minnlcsetprecnone(minnlcstate *state) {
   state->updatefreq = 0;
   state->prectype = 0;
}

// This function sets maximum step length (after scaling of step vector  with
// respect to variable scales specified by minnlcsetscale() call).
//
// Inputs:
//     State   -   structure which stores algorithm state
//     StpMax  -   maximum step length, >= 0. Set StpMax to 0.0 (default),  if
//                 you don't want to limit step length.
//
// Use this subroutine when you optimize target function which contains exp()
// or  other  fast  growing  functions,  and optimization algorithm makes too
// large  steps  which  leads  to overflow. This function allows us to reject
// steps  that  are  too  large  (and  therefore  expose  us  to the possible
// overflow) without actually calculating function value at the x+stp*d.
//
// NOTE: different solvers employed by MinNLC optimizer use  different  norms
//       for step; AUL solver uses 2-norm, whilst SLP solver uses INF-norm.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minnlcsetstpmax(const minnlcstate &state, const double stpmax);
void minnlcsetstpmax(minnlcstate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinNLCSetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinNLCSetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// This  function  tells MinNLC unit to use  Augmented  Lagrangian  algorithm
// for nonlinearly constrained  optimization.  This  algorithm  is  a  slight
// modification of one described in "A Modified Barrier-Augmented  Lagrangian
// Method for  Constrained  Minimization  (1999)"  by  D.GOLDFARB,  R.POLYAK,
// K. SCHEINBERG, I.YUZEFOVICH.
//
// AUL solver can be significantly faster than SQP on easy  problems  due  to
// cheaper iterations, although it needs more function evaluations.
//
// Augmented Lagrangian algorithm works by converting problem  of  minimizing
// F(x) subject to equality/inequality constraints   to unconstrained problem
// of the form
//
//     min[ f(x) +
//         + Rho*PENALTY_EQ(x)   + SHIFT_EQ(x,Nu1) +
//         + Rho*PENALTY_INEQ(x) + SHIFT_INEQ(x,Nu2) ]
//
// where:
// * Rho is a fixed penalization coefficient
// * PENALTY_EQ(x) is a penalty term, which is used to APPROXIMATELY  enforce
//   equality constraints
// * SHIFT_EQ(x) is a special "shift"  term  which  is  used  to  "fine-tune"
//   equality constraints, greatly increasing precision
// * PENALTY_INEQ(x) is a penalty term which is used to approximately enforce
//   inequality constraints
// * SHIFT_INEQ(x) is a special "shift"  term  which  is  used to "fine-tune"
//   inequality constraints, greatly increasing precision
// * Nu1/Nu2 are vectors of Lagrange coefficients which are fine-tuned during
//   outer iterations of algorithm
//
// This  version  of  AUL  algorithm  uses   preconditioner,  which   greatly
// accelerates convergence. Because this  algorithm  is  similar  to  penalty
// methods,  it  may  perform  steps  into  infeasible  area.  All  kinds  of
// constraints (boundary, linear and nonlinear ones) may   be   violated   in
// intermediate points - and in the solution.  However,  properly  configured
// AUL method is significantly better at handling  constraints  than  barrier
// and/or penalty methods.
//
// The very basic outline of algorithm is given below:
// 1) first outer iteration is performed with "default"  values  of  Lagrange
//    multipliers Nu1/Nu2. Solution quality is low (candidate  point  can  be
//    too  far  away  from  true  solution; large violation of constraints is
//    possible) and is comparable with that of penalty methods.
// 2) subsequent outer iterations  refine  Lagrange  multipliers  and improve
//    quality of the solution.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     Rho     -   penalty coefficient, Rho > 0:
//                 * large enough  that  algorithm  converges  with   desired
//                   precision. Minimum value is 10*max(S'*diag(H)*S),  where
//                   S is a scale matrix (set by MinNLCSetScale) and H  is  a
//                   Hessian of the function being minimized. If you can  not
//                   easily estimate Hessian norm,  see  our  recommendations
//                   below.
//                 * not TOO large to prevent ill-conditioning
//                 * for unit-scale problems (variables and Hessian have unit
//                   magnitude), Rho == 100 or Rho == 1000 can be used.
//                 * it is important to note that Rho is internally multiplied
//                   by scaling matrix, i.e. optimum value of Rho depends  on
//                   scale of variables specified  by  MinNLCSetScale().
//     ItsCnt  -   number of outer iterations:
//                 * ItsCnt == 0 means that small number of outer iterations  is
//                   automatically chosen (10 iterations in current version).
//                 * ItsCnt == 1 means that AUL algorithm performs just as usual
//                   barrier method.
//                 * ItsCnt > 1 means that  AUL  algorithm  performs  specified
//                   number of outer iterations
//
// HOW TO CHOOSE PARAMETERS
//
// Nonlinear optimization is a tricky area and Augmented Lagrangian algorithm
// is sometimes hard to tune. Good values of  Rho  and  ItsCnt  are  problem-
// specific.  In  order  to  help  you   we   prepared   following   set   of
// recommendations:
//
// * for  unit-scale  problems  (variables  and Hessian have unit magnitude),
//   Rho == 100 or Rho == 1000 can be used.
//
// * start from  some  small  value of Rho and solve problem  with  just  one
//   outer iteration (ItcCnt == 1). In this case algorithm behaves like  penalty
//   method. Increase Rho in 2x or 10x steps until you  see  that  one  outer
//   iteration returns point which is "rough approximation to solution".
//
//   It is very important to have Rho so  large  that  penalty  term  becomes
//   constraining i.e. modified function becomes highly convex in constrained
//   directions.
//
//   From the other side, too large Rho may prevent you  from  converging  to
//   the solution. You can diagnose it by studying number of inner iterations
//   performed by algorithm: too few (5-10 on  1000-dimensional  problem)  or
//   too many (orders of magnitude more than  dimensionality)  usually  means
//   that Rho is too large.
//
// * with just one outer iteration you  usually  have  low-quality  solution.
//   Some constraints can be violated with very  large  margin,  while  other
//   ones (which are NOT violated in the true solution) can push final  point
//   too far in the inner area of the feasible set.
//
//   For example, if you have constraint x0 >= 0 and true solution  x0 == 1,  then
//   merely a presence of "x0 >= 0" will introduce a bias towards larger values
//   of x0. Say, algorithm may stop at x0 == 1.5 instead of 1.0.
//
// * after you found good Rho, you may increase number of  outer  iterations.
//   ItsCnt == 10 is a good value. Subsequent outer iteration will refine values
//   of  Lagrange  multipliers.  Constraints  which  were  violated  will  be
//   enforced, inactive constraints will be dropped (corresponding multipliers
//   will be decreased). Ideally, you  should  see  10-1000x  improvement  in
//   constraint handling (constraint violation is reduced).
//
// * if  you  see  that  algorithm  converges  to  vicinity  of solution, but
//   additional outer iterations do not refine solution,  it  may  mean  that
//   algorithm is unstable - it wanders around true  solution,  but  can  not
//   approach it. Sometimes algorithm may be stabilized by increasing Rho one
//   more time, making it 5x or 10x larger.
//
// SCALING OF CONSTRAINTS [IMPORTANT]
//
// AUL optimizer scales   variables   according   to   scale   specified   by
// MinNLCSetScale() function, so it can handle  problems  with  badly  scaled
// variables (as long as we KNOW their scales).   However,  because  function
// being optimized is a mix  of  original  function and  constraint-dependent
// penalty  functions, it  is   important  to   rescale  both  variables  AND
// constraints.
//
// Say,  if  you  minimize f(x) == x^2 subject to 1000000*x >= 0,  then  you  have
// constraint whose scale is different from that of target  function (another
// example is 0.000001*x >= 0). It is also possible to have constraints   whose
// scales  are   misaligned:   1000000*x0 >= 0, 0.000001*x1 <= 0.   Inappropriate
// scaling may ruin convergence because minimizing x^2 subject to x >= 0 is NOT
// same as minimizing it subject to 1000000*x >= 0.
//
// Because we  know  coefficients  of  boundary/linear  constraints,  we  can
// automatically rescale and normalize them. However,  there  is  no  way  to
// automatically rescale nonlinear constraints Gi(x) and  Hi(x)  -  they  are
// black boxes.
//
// It means that YOU are the one who is  responsible  for  correct scaling of
// nonlinear constraints  Gi(x)  and  Hi(x).  We  recommend  you  to  rescale
// nonlinear constraints in such way that I-th component of dG/dX (or  dH/dx)
// has magnitude approximately equal to 1/S[i] (where S  is  a  scale  set by
// MinNLCSetScale() function).
//
// WHAT IF IT DOES NOT CONVERGE?
//
// It is possible that AUL algorithm fails to converge to precise  values  of
// Lagrange multipliers. It stops somewhere around true solution, but candidate
// point is still too far from solution, and some constraints  are  violated.
// Such kind of failure is specific for Lagrangian algorithms -  technically,
// they stop at some point, but this point is not constrained solution.
//
// There are exist several reasons why algorithm may fail to converge:
// a) too loose stopping criteria for inner iteration
// b) degenerate, redundant constraints
// c) target function has unconstrained extremum exactly at the  boundary  of
//    some constraint
// d) numerical noise in the target function
//
// In all these cases algorithm is unstable - each outer iteration results in
// large and almost random step which improves handling of some  constraints,
// but violates other ones (ideally  outer iterations should form a  sequence
// of progressively decreasing steps towards solution).
//
// First reason possible is  that  too  loose  stopping  criteria  for  inner
// iteration were specified. Augmented Lagrangian algorithm solves a sequence
// of intermediate problems, and requries each of them to be solved with high
// precision. Insufficient precision results in incorrect update of  Lagrange
// multipliers.
//
// Another reason is that you may have specified degenerate constraints: say,
// some constraint was repeated twice. In most cases AUL algorithm gracefully
// handles such situations, but sometimes it may spend too much time figuring
// out subtle degeneracies in constraint matrix.
//
// Third reason is tricky and hard to diagnose. Consider situation  when  you
// minimize  f == x^2  subject to constraint x >= 0.  Unconstrained   extremum  is
// located  exactly  at  the  boundary  of  constrained  area.  In  this case
// algorithm will tend to oscillate between negative  and  positive  x.  Each
// time it stops at x < 0 it "reinforces" constraint x >= 0, and each time it  is
// bounced to x > 0 it "relaxes" constraint (and is  attracted  to  x < 0).
//
// Such situation  sometimes  happens  in  problems  with  hidden  symetries.
// Algorithm  is  got  caught  in  a  loop with  Lagrange  multipliers  being
// continuously increased/decreased. Luckily, such loop forms after at  least
// three iterations, so this problem can be solved by  DECREASING  number  of
// outer iterations down to 1-2 and increasing  penalty  coefficient  Rho  as
// much as possible.
//
// Final reason is numerical noise. AUL algorithm is robust against  moderate
// noise (more robust than, say, active set methods),  but  large  noise  may
// destabilize algorithm.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcsetalgoaul(const minnlcstate &state, const double rho, const ae_int_t itscnt);
void minnlcsetalgoaul(minnlcstate *state, double rho, ae_int_t itscnt) {
   ae_assert(itscnt >= 0, "MinNLCSetAlgoAUL: negative ItsCnt");
   ae_assert(isfinite(rho), "MinNLCSetAlgoAUL: Rho is not finite");
   ae_assert(rho > 0.0, "MinNLCSetAlgoAUL: Rho <= 0");
   if (itscnt == 0) {
      itscnt = 10;
   }
   state->aulitscnt = itscnt;
   state->rho = rho;
   state->solvertype = 0;
}

// This   function  tells  MinNLC  optimizer  to  use  SLP (Successive Linear
// Programming) algorithm for  nonlinearly  constrained   optimization.  This
// algorithm  is  a  slight  modification  of  one  described  in  "A  Linear
// programming-based optimization algorithm for solving nonlinear programming
// problems" (2010) by Claus Still and Tapio Westerlund.
//
// This solver is the slowest one in ALGLIB, it requires more target function
// evaluations that SQP and AUL. However it is somewhat more robust in tricky
// cases, so it can be used as a backup plan. We recommend to use  this  algo
// when SQP/AUL do not work (does not return  the  solution  you  expect). If
// trying different approach gives same  results,  then  MAYBE  something  is
// wrong with your optimization problem.
//
// Despite its name ("linear" = "first order method") this algorithm performs
// steps similar to that of conjugate gradients method;  internally  it  uses
// orthogonality/conjugacy requirement for subsequent steps  which  makes  it
// closer to second order methods in terms of convergence speed.
//
// Convergence is proved for the following case:
// * function and constraints are continuously differentiable (C1 class)
// * extended MangasarianFromovitz constraint qualification  (EMFCQ)  holds;
//   in the context of this algorithm EMFCQ  means  that  one  can,  for  any
//   infeasible  point,  find  a  search  direction  such that the constraint
//   infeasibilities are reduced.
//
// This algorithm has following nice properties:
// * no parameters to tune
// * no convexity requirements for target function or constraints
// * initial point can be infeasible
// * algorithm respects box constraints in all intermediate points  (it  does
//   not even evaluate function outside of box constrained area)
// * once linear constraints are enforced, algorithm will not violate them
// * no such guarantees can be provided for nonlinear constraints,  but  once
//   nonlinear constraints are enforced, algorithm will try  to  respect them
//   as much as possible
// * numerical differentiation does not  violate  box  constraints  (although
//   general linear and nonlinear ones can be violated during differentiation)
// * from our experience, this algorithm is somewhat more  robust  in  really
//   difficult cases
//
// Inputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 02.04.2018 by Sergey Bochkanov
// API: void minnlcsetalgoslp(const minnlcstate &state);
void minnlcsetalgoslp(minnlcstate *state) {
   state->solvertype = 1;
}

// This   function  tells  MinNLC  optimizer to use SQP (Successive Quadratic
// Programming) algorithm for nonlinearly constrained optimization.
//
// This algorithm needs order of magnitude (5x-10x) less function evaluations
// than AUL solver, but has higher overhead because each  iteration  involves
// solution of quadratic programming problem.
//
// Convergence is proved for the following case:
// * function and constraints are continuously differentiable (C1 class)
//
// This algorithm has following nice properties:
// * no parameters to tune
// * no convexity requirements for target function or constraints
// * initial point can be infeasible
// * algorithm respects box constraints in all intermediate points  (it  does
//   not even evaluate function outside of box constrained area)
// * once linear constraints are enforced, algorithm will not violate them
// * no such guarantees can be provided for nonlinear constraints,  but  once
//   nonlinear constraints are enforced, algorithm will try  to  respect them
//   as much as possible
// * numerical differentiation does not  violate  box  constraints  (although
//   general linear and nonlinear ones can be violated during differentiation)
//
// We recommend this algorithm as a default option for medium-scale  problems
// (less than thousand of variables) or problems with target  function  being
// hard to evaluate.
//
// For   large-scale  problems  or  ones  with very  cheap  target   function
// AUL solver can be better option.
//
// Inputs:
//     State   -   structure which stores algorithm state
//
// ==== INTERACTION WITH OPTGUARD ====
//
// OptGuard integrity  checker  allows us to catch problems  like  errors  in
// gradients   and  discontinuity/nonsmoothness  of  the  target/constraints.
// The latter kind of problems can be detected  by looking upon line searches
// performed during optimization and searching for signs of nonsmoothness.
//
// The problem with SQP is that it is too good for OptGuard to work - it does
// not perform line searches. It typically  needs  1-2  function  evaluations
// per step, and it is not enough for OptGuard to detect nonsmoothness.
//
// So, if you suspect that your problem is  nonsmooth  and  if  you  want  to
// confirm or deny it, we recommend you to use AUL or SLP solvers,  which can
// detect nonsmoothness of the problem.
// ALGLIB: Copyright 02.12.2019 by Sergey Bochkanov
// API: void minnlcsetalgosqp(const minnlcstate &state);
void minnlcsetalgosqp(minnlcstate *state) {
   state->solvertype = 2;
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to MinNLCOptimize().
//
// NOTE: algorithm passes two parameters to rep() callback  -  current  point
//       and penalized function value at current point. Important -  function
//       value which is returned is NOT function being minimized. It  is  sum
//       of the value of the function being minimized - and penalty term.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minnlcsetxrep(const minnlcstate &state, const bool needxrep);
void minnlcsetxrep(minnlcstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This subroutine restarts algorithm from new point.
// All optimization parameters (including constraints) are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have  same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure previously allocated with MinNLCCreate call.
//     X       -   new starting point.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minnlcrestartfrom(const minnlcstate &state, const real_1d_array &x);
void minnlcrestartfrom(minnlcstate *state, RVector *x) {
   ae_int_t n;
   n = state->n;
// First, check for errors in the inputs
   ae_assert(x->cnt >= n, "MinNLCRestartFrom: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinNLCRestartFrom: X contains infinite or NaN values!");
// Set XC
   ae_v_move(state->xstart.xR, 1, x->xR, 1, n);
// prepare RComm facilities
   state->PQ = -1;
}

// Internal initialization subroutine.
// Sets default NLC solver with default criteria.
static void minnlc_minnlcinitinternal(ae_int_t n, RVector *x, double diffstep, minnlcstate *state) {
   const ae_int_t lbfgsfactor = 10;
   ae_int_t i;
   EnFrame();
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
// Default params
   state->stabilizingpoint = -2.0;
   state->initialinequalitymultiplier = 1.0;
// Smoothness monitor, default init
   state->teststep = 0.0;
   state->smoothnessguardlevel = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, 0, 0, false);
// Initialize other params
   state->n = n;
   state->diffstep = diffstep;
   state->userterminationneeded = false;
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->hasbndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->hasbndu, n);
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->lastscaleused, n);
   ae_vector_set_length(&state->xstart, n);
   ae_vector_set_length(&state->xc, n);
   ae_vector_set_length(&state->x, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = -INFINITY;
      state->hasbndl.xB[i] = false;
      state->bndu.xR[i] = +INFINITY;
      state->hasbndu.xB[i] = false;
      state->s.xR[i] = 1.0;
      state->lastscaleused.xR[i] = 1.0;
      state->xstart.xR[i] = x->xR[i];
      state->xc.xR[i] = x->xR[i];
   }
   minnlcsetlc(state, &c, &ct, 0);
   minnlcsetnlc(state, 0, 0);
   minnlcsetcond(state, 0.0, 0);
   minnlcsetxrep(state, false);
   minnlcsetalgosqp(state);
   minnlcsetprecexactrobust(state, 0);
   minnlcsetstpmax(state, 0.0);
   minlbfgscreate(n, imin2(lbfgsfactor, n), x, &state->auloptimizer);
   minnlcrestartfrom(state, x);
   DeFrame();
}

// NONLINEARLY CONSTRAINED OPTIMIZATION
// WITH PRECONDITIONED AUGMENTED LAGRANGIAN ALGORITHM
// The  subroutine  minimizes  function   F(x)  of N arguments subject to any
// combination of:
// * bound constraints
// * linear inequality constraints
// * linear equality constraints
// * nonlinear equality constraints Gi(x) == 0
// * nonlinear inequality constraints Hi(x) <= 0
//
// REQUIREMENTS:
// * user must provide function value and gradient for F(), H(), G()
// * starting point X0 must be feasible or not too far away from the feasible
//   set
// * F(), G(), H() are continuously differentiable on the  feasible  set  and
//   its neighborhood
// * nonlinear constraints G() and H() must have non-zero gradient at  G(x) == 0
//   and at H(x) == 0. Say, constraint like x^2 >= 1 is supported, but x^2 >= 0   is
//   NOT supported.
//
// USAGE:
//
// Constrained optimization if far more complex than the  unconstrained  one.
// Nonlinearly constrained optimization is one of the most esoteric numerical
// procedures.
//
// Here we give very brief outline  of  the  MinNLC  optimizer.  We  strongly
// recommend you to study examples in the ALGLIB Reference Manual and to read
// ALGLIB User Guide on optimization, which is available at
// http://www.alglib.net/optimization/
//
// 1. User initializes algorithm state with MinNLCCreate() call  and  chooses
//    what NLC solver to use. There is some solver which is used by  default,
//    with default settings, but you should NOT rely on  default  choice.  It
//    may change in future releases of ALGLIB without notice, and no one  can
//    guarantee that new solver will be  able  to  solve  your  problem  with
//    default settings.
//
//    From the other side, if you choose solver explicitly, you can be pretty
//    sure that it will work with new ALGLIB releases.
//
//    In the current release following solvers can be used:
//    * SQP solver, recommended for medium-scale problems (less than thousand
//      of variables) with hard-to-evaluate target functions.  Requires  less
//      function  evaluations  than  other  solvers  but  each  step involves
//      solution of QP subproblem, so running time may be higher than that of
//      AUL (another recommended option). Activated  with  minnlcsetalgosqp()
//      function.
//    * AUL solver with dense  preconditioner,  recommended  for  large-scale
//      problems or for problems  with  cheap  target  function.  Needs  more
//      function evaluations that SQP (about  5x-10x  times  more),  but  its
//      iterations  are  much  cheaper  that  that  of  SQP.  Activated  with
//      minnlcsetalgoaul() function.
//    * SLP solver, successive linear programming. The slowest one,  requires
//      more target function evaluations that SQP and  AUL.  However,  it  is
//      somewhat more robust in tricky cases, so it can be used  as  a backup
//      plan. Activated with minnlcsetalgoslp() function.
//
// 2. [optional] user activates OptGuard  integrity checker  which  tries  to
//    detect possible errors in the user-supplied callbacks:
//    * discontinuity/nonsmoothness of the target/nonlinear constraints
//    * errors in the analytic gradient provided by user
//    This feature is essential for early prototyping stages because it helps
//    to catch common coding and problem statement errors.
//    OptGuard can be activated with following functions (one per each  check
//    performed):
//    * minnlcoptguardsmoothness()
//    * minnlcoptguardgradient()
//
// 3. User adds boundary and/or linear and/or nonlinear constraints by  means
//    of calling one of the following functions:
//    a) minnlcsetbc() for boundary constraints
//    b) minnlcsetlc() for linear constraints
//    c) minnlcsetnlc() for nonlinear constraints
//    You may combine (a), (b) and (c) in one optimization problem.
//
// 4. User sets scale of the variables with minnlcsetscale() function. It  is
//    VERY important to set  scale  of  the  variables,  because  nonlinearly
//    constrained problems are hard to solve when variables are badly scaled.
//
// 5. User sets  stopping  conditions  with  minnlcsetcond(). If  NLC  solver
//    uses  inner/outer  iteration  layout,  this  function   sets   stopping
//    conditions for INNER iterations.
//
// 6. Finally, user calls minnlcoptimize()  function  which  takes  algorithm
//    state and pointer (delegate, etc.) to callback function which calculates
//    F/G/H.
//
// 7. User calls  minnlcresults()  to  get  solution;  additionally  you  can
//    retrieve OptGuard report with minnlcoptguardresults(), and get detailed
//    report about purported errors in the target function with:
//    * minnlcoptguardnonc1test0results()
//    * minnlcoptguardnonc1test1results()
//
// 8. Optionally user may call minnlcrestartfrom() to solve  another  problem
//    with same N but another starting point. minnlcrestartfrom()  allows  to
//    reuse already initialized structure.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size ofX
//     X       -   starting point, array[N]:
//                 * it is better to set X to a feasible point
//                 * but X can be infeasible, in which case algorithm will try
//                   to find feasible point first, using X as initial
//                   approximation.
//
// Outputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlccreate(const ae_int_t n, const real_1d_array &x, minnlcstate &state);
// API: void minnlccreate(const real_1d_array &x, minnlcstate &state);
void minnlccreate(ae_int_t n, RVector *x, minnlcstate *state) {
   SetObj(minnlcstate, state);
   ae_assert(n >= 1, "MinNLCCreate: N < 1");
   ae_assert(x->cnt >= n, "MinNLCCreate: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinNLCCreate: X contains infinite or NaN values");
   minnlc_minnlcinitinternal(n, x, 0.0, state);
}

// This subroutine is a finite  difference variant of MinNLCCreate(). It uses
// finite differences in order to differentiate target function.
//
// Description below contains information which is specific to this  function
// only. We recommend to read comments on MinNLCCreate() in order to get more
// information about creation of NLC optimizer.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size ofX
//     X       -   starting point, array[N]:
//                 * it is better to set X to a feasible point
//                 * but X can be infeasible, in which case algorithm will try
//                   to find feasible point first, using X as initial
//                   approximation.
//     DiffStep-   differentiation step, > 0
//
// Outputs:
//     State   -   structure stores algorithm state
//
// NOTES:
// 1. algorithm uses 4-point central formula for differentiation.
// 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
//    S[] is scaling vector which can be set by MinNLCSetScale() call.
// 3. we recommend you to use moderate values of  differentiation  step.  Too
//    large step will result in too large TRUNCATION  errors, while too small
//    step will result in too large NUMERICAL  errors.  0.0001  can  be  good
//    value to start from.
// 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
//    calculation needs 4*N function evaluations. This function will work for
//    any N - either small (1...10), moderate (10...100) or  large  (100...).
//    However, performance penalty will be too severe for any N's except  for
//    small ones.
//    We should also say that code which relies on numerical  differentiation
//    is  less   robust   and  precise.  Imprecise  gradient  may  slow  down
//    convergence, especially on highly nonlinear problems.
//    Thus  we  recommend to use this function for fast prototyping on small-
//    dimensional problems only, and to implement analytical gradient as soon
//    as possible.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlccreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minnlcstate &state);
// API: void minnlccreatef(const real_1d_array &x, const double diffstep, minnlcstate &state);
void minnlccreatef(ae_int_t n, RVector *x, double diffstep, minnlcstate *state) {
   SetObj(minnlcstate, state);
   ae_assert(n >= 1, "MinNLCCreateF: N < 1");
   ae_assert(x->cnt >= n, "MinNLCCreateF: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinNLCCreateF: X contains infinite or NaN values");
   ae_assert(isfinite(diffstep), "MinNLCCreateF: DiffStep is infinite or NaN!");
   ae_assert(diffstep > 0.0, "MinNLCCreateF: DiffStep is non-positive!");
   minnlc_minnlcinitinternal(n, x, diffstep, state);
}

// Penalty function for equality constraints.
// Inputs:
//     Alpha   -   function argument. Penalty function becomes large when
//                 Alpha approaches -1 or +1. It is defined for Alpha <= -1 or
//                 Alpha >= +1 - in this case infinite value is returned.
//
// Outputs:
//     F       -   depending on Alpha:
//                 * for Alpha in (-1+eps,+1-eps), F == F(Alpha)
//                 * for Alpha outside of interval, F is some very large number
//     DF      -   depending on Alpha:
//                 * for Alpha in (-1+eps,+1-eps), DF == dF(Alpha)/dAlpha, exact
//                   numerical derivative.
//                 * otherwise, it is zero
//     D2F     -   second derivative
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
void minnlcequalitypenaltyfunction(double alpha, double *f, double *df, double *d2f) {
   *f = 0.0;
   *df = 0.0;
   *d2f = 0.0;
   *f = 0.5 * alpha * alpha;
   *df = alpha;
   *d2f = 1.0;
}

// "Penalty" function  for  inequality  constraints,  which  is multiplied by
// penalty coefficient Rho.
//
// "Penalty" function plays only supplementary role - it helps  to  stabilize
// algorithm when solving non-convex problems. Because it  is  multiplied  by
// fixed and large  Rho  -  not  Lagrange  multiplier  Nu  which  may  become
// arbitrarily small! - it enforces  convexity  of  the  problem  behind  the
// boundary of the feasible area.
//
// This function is zero at the feasible area and in the close  neighborhood,
// it becomes non-zero only at some distance (scaling is essential!) and grows
// quadratically.
//
// Penalty function must enter augmented Lagrangian as
//     Rho*PENALTY(x-lowerbound)
// with corresponding changes being made for upper bound or  other  kinds  of
// constraints.
//
// Inputs:
//     Alpha   -   function argument. Typically, if we have active constraint
//                 with precise Lagrange multiplier, we have Alpha  around 1.
//                 Large positive Alpha's correspond to  inner  area  of  the
//                 feasible set. Alpha < 1 corresponds to  outer  area  of  the
//                 feasible set.
//     StabilizingPoint- point where F becomes  non-zero.  Must  be  negative
//                 value, at least -1, large values (hundreds) are possible.
//
// Outputs:
//     F       -   F(Alpha)
//     DF      -   DF == dF(Alpha)/dAlpha, exact derivative
//     D2F     -   second derivative
//
// NOTE: it is important to  have  significantly  non-zero  StabilizingPoint,
//       because when it  is  large,  shift  term  does  not  interfere  with
//       Lagrange  multipliers  converging  to  their  final  values.   Thus,
//       convergence of such modified AUL algorithm is  still  guaranteed  by
//       same set of theorems.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
void minnlcinequalitypenaltyfunction(double alpha, double stabilizingpoint, double *f, double *df, double *d2f) {
   *f = 0.0;
   *df = 0.0;
   *d2f = 0.0;
   if (alpha >= stabilizingpoint) {
      *f = 0.0;
      *df = 0.0;
      *d2f = 0.0;
   } else {
      alpha -= stabilizingpoint;
      *f = 0.5 * alpha * alpha;
      *df = alpha;
      *d2f = 1.0;
   }
}

// "Shift" function  for  inequality  constraints,  which  is  multiplied  by
// corresponding Lagrange multiplier.
//
// "Shift" function is a main factor which enforces  inequality  constraints.
// Inequality penalty function plays only supplementary role  -  it  prevents
// accidental step deep into infeasible area  when  working  with  non-convex
// problems (read comments on corresponding function for more information).
//
// Shift function must enter augmented Lagrangian as
//     Nu/Rho*SHIFT((x-lowerbound)*Rho+1)
// with corresponding changes being made for upper bound or  other  kinds  of
// constraints.
//
// Inputs:
//     Alpha   -   function argument. Typically, if we have active constraint
//                 with precise Lagrange multiplier, we have Alpha  around 1.
//                 Large positive Alpha's correspond to  inner  area  of  the
//                 feasible set. Alpha < 1 corresponds to  outer  area  of  the
//                 feasible set.
//
// Outputs:
//     F       -   F(Alpha)
//     DF      -   DF == dF(Alpha)/dAlpha, exact derivative
//     D2F     -   second derivative
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
void minnlcinequalityshiftfunction(double alpha, double *f, double *df, double *d2f) {
   *f = 0.0;
   *df = 0.0;
   *d2f = 0.0;
   if (alpha >= 0.5) {
      *f = -log(alpha);
      *df = -1.0 / alpha;
      *d2f = 1.0 / (alpha * alpha);
   } else {
      *f = 2.0 * alpha * alpha - 4.0 * alpha + (log(2.0) + 1.5);
      *df = 4.0 * alpha - 4.0;
      *d2f = 4.0;
   }
}

// This function clears preconditioner for L-BFGS optimizer (sets it do default
// state);
//
// Parameter:
//     AULOptimizer    -   optimizer to tune
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
static void minnlc_clearpreconditioner(minlbfgsstate *auloptimizer) {
   minlbfgssetprecdefault(auloptimizer);
}

// This function updates preconditioner for L-BFGS optimizer.
//
// Parameters:
//     PrecType        -   preconditioner type:
//                         * 0 for unpreconditioned iterations
//                         * 1 for inexact LBFGS
//                         * 2 for exact low rank preconditioner update after each UpdateFreq its
//                         * 3 for exact robust preconditioner update after each UpdateFreq its
//     UpdateFreq      -   update frequency
//     PrecCounter     -   iterations counter, must be zero on the first call,
//                         automatically increased  by  this  function.  This
//                         counter is used to implement "update-once-in-X-iterations"
//                         scheme.
//     AULOptimizer    -   optimizer to tune
//     X               -   current point
//     Rho             -   penalty term
//     GammaK          -   current  estimate  of  Hessian  norm   (used   for
//                         initialization of preconditioner). Can be zero, in
//                         which case Hessian is assumed to be unit.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
static void minnlc_updatepreconditioner(ae_int_t prectype, ae_int_t updatefreq, ae_int_t *preccounter, minlbfgsstate *auloptimizer, RVector *x, double rho, double gammak, RVector *bndl, BVector *hasbndl, RVector *bndu, BVector *hasbndu, RVector *nubc, RMatrix *cleic, RVector *nulc, RVector *fi, RMatrix *jac, RVector *nunlc, RVector *bufd, RVector *bufc, RMatrix *bufw, RMatrix *bufz, RVector *tmp0, ae_int_t n, ae_int_t nec, ae_int_t nic, ae_int_t ng, ae_int_t nh) {
   const double regprec = 0.000001;
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   double p;
   double dp;
   double d2p;
   bool bflag;
   ae_assert(rho > 0.0, "MinNLC: integrity check failed");
   vectorsetlengthatleast(bufd, n);
   vectorsetlengthatleast(bufc, nec + nic + ng + nh);
   matrixsetlengthatleast(bufw, nec + nic + ng + nh, n);
   vectorsetlengthatleast(tmp0, n);
// Preconditioner before update from barrier/penalty functions
   if (gammak == 0.0) {
      gammak = 1.0;
   }
   for (i = 0; i < n; i++) {
      bufd->xR[i] = gammak;
   }
// Update diagonal Hessian using nonlinearity from boundary constraints:
// * penalty term from equality constraints
// * shift term from inequality constraints
//
// NOTE: penalty term for inequality constraints is ignored because it
//       is large only in exceptional cases.
   for (i = 0; i < n; i++) {
      if (hasbndl->xB[i] && hasbndu->xB[i] && bndl->xR[i] == bndu->xR[i]) {
         minnlcequalitypenaltyfunction((x->xR[i] - bndl->xR[i]) * rho, &p, &dp, &d2p);
         bufd->xR[i] += d2p * rho;
         continue;
      }
      if (hasbndl->xB[i]) {
         minnlcinequalityshiftfunction((x->xR[i] - bndl->xR[i]) * rho + 1.0, &p, &dp, &d2p);
         bufd->xR[i] += nubc->xR[2 * i] * d2p * rho;
      }
      if (hasbndu->xB[i]) {
         minnlcinequalityshiftfunction((bndu->xR[i] - x->xR[i]) * rho + 1.0, &p, &dp, &d2p);
         bufd->xR[i] += nubc->xR[2 * i + 1] * d2p * rho;
      }
   }
// Process linear constraints
   for (i = 0; i < nec + nic; i++) {
      ae_v_move(bufw->xyR[i], 1, cleic->xyR[i], 1, n);
      v = ae_v_dotproduct(cleic->xyR[i], 1, x->xR, 1, n);
      v -= cleic->xyR[i][n];
      if (i < nec) {
      // Equality constraint
         minnlcequalitypenaltyfunction(v * rho, &p, &dp, &d2p);
         bufc->xR[i] = d2p * rho;
      } else {
      // Inequality constraint
         minnlcinequalityshiftfunction(-v * rho + 1.0, &p, &dp, &d2p);
         bufc->xR[i] = nulc->xR[i] * d2p * rho;
      }
   }
// Process nonlinear constraints
   for (i = 0; i < ng + nh; i++) {
      ae_v_move(bufw->xyR[nec + nic + i], 1, jac->xyR[1 + i], 1, n);
      v = fi->xR[1 + i];
      if (i < ng) {
      // Equality constraint
         minnlcequalitypenaltyfunction(v * rho, &p, &dp, &d2p);
         bufc->xR[nec + nic + i] = d2p * rho;
      } else {
      // Inequality constraint
         minnlcinequalityshiftfunction(-v * rho + 1.0, &p, &dp, &d2p);
         bufc->xR[nec + nic + i] = nunlc->xR[i] * d2p * rho;
      }
   }
// Add regularizer (large Rho often result in nearly-degenerate matrices;
// sometimes Cholesky decomposition fails without regularization).
//
// We use RegPrec*diag(W'*W) as preconditioner.
   k = nec + nic + ng + nh;
   for (j = 0; j < n; j++) {
      tmp0->xR[j] = 0.0;
   }
   for (i = 0; i < k; i++) {
      v = bufc->xR[i];
      for (j = 0; j < n; j++) {
         tmp0->xR[j] += v * bufw->xyR[i][j] * bufw->xyR[i][j];
      }
   }
   for (j = 0; j < n; j++) {
      bufd->xR[j] += regprec * tmp0->xR[j];
   }
// Apply preconditioner
   if (prectype == 1) {
      minlbfgssetprecrankklbfgsfast(auloptimizer, bufd, bufc, bufw, nec + nic + ng + nh);
   }
   if (prectype == 2 && *preccounter % updatefreq == 0) {
      minlbfgssetpreclowrankexact(auloptimizer, bufd, bufc, bufw, nec + nic + ng + nh);
   }
   if (prectype == 3 && *preccounter % updatefreq == 0) {
   // Generate full NxN dense Hessian
      matrixsetlengthatleast(bufz, n, n);
      for (i = 0; i < n; i++) {
         for (j = 0; j < n; j++) {
            bufz->xyR[i][j] = 0.0;
         }
         bufz->xyR[i][i] = bufd->xR[i];
      }
      if (nec + nic + ng + nh > 0) {
         for (i = 0; i < nec + nic + ng + nh; i++) {
            ae_assert(bufc->xR[i] >= 0.0, "MinNLC: updatepreconditioner() integrity failure");
            v = sqrt(bufc->xR[i]);
            for (j = 0; j < n; j++) {
               bufw->xyR[i][j] *= v;
            }
         }
         rmatrixsyrk(n, nec + nic + ng + nh, 1.0, bufw, 0, 0, 2, 1.0, bufz, 0, 0, true);
      }
   // Evaluate Cholesky decomposition, set preconditioner
      bflag = spdmatrixcholeskyrec(bufz, 0, n, true, bufd);
      ae_assert(bflag, "MinNLC: updatepreconditioner() failure, Cholesky failed");
      minlbfgssetpreccholesky(auloptimizer, bufz, true);
   }
   ++*preccounter;
}

// This subroutine adds penalty from boundary constraints to target  function
// and its gradient. Penalty function is one which is used for main AUL cycle
// - with Lagrange multipliers and infinite at the barrier and beyond.
//
// Parameters:
//     X[] - current point
//     BndL[], BndU[] - boundary constraints
//     HasBndL[], HasBndU[] - I-th element is True if corresponding constraint is present
//     NuBC[] - Lagrange multipliers corresponding to constraints
//     Rho - penalty term
//     StabilizingPoint - branch point for inequality stabilizing term
//     F - function value to modify
//     G - gradient to modify
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
static void minnlc_penaltybc(RVector *x, RVector *bndl, BVector *hasbndl, RVector *bndu, BVector *hasbndu, RVector *nubc, ae_int_t n, double rho, double stabilizingpoint, double *f, RVector *g) {
   ae_int_t i;
   double p;
   double dp;
   double d2p;
   for (i = 0; i < n; i++) {
      if (hasbndl->xB[i] && hasbndu->xB[i] && bndl->xR[i] == bndu->xR[i]) {
      // I-th boundary constraint is of equality-type
         minnlcequalitypenaltyfunction((x->xR[i] - bndl->xR[i]) * rho, &p, &dp, &d2p);
         *f += p / rho - nubc->xR[2 * i] * (x->xR[i] - bndl->xR[i]);
         g->xR[i] += dp - nubc->xR[2 * i];
         continue;
      }
      if (hasbndl->xB[i]) {
      // Handle lower bound
         minnlcinequalitypenaltyfunction(x->xR[i] - bndl->xR[i], stabilizingpoint, &p, &dp, &d2p);
         *f += rho * p;
         g->xR[i] += rho * dp;
         minnlcinequalityshiftfunction((x->xR[i] - bndl->xR[i]) * rho + 1.0, &p, &dp, &d2p);
         *f += p / rho * nubc->xR[2 * i];
         g->xR[i] += dp * nubc->xR[2 * i];
      }
      if (hasbndu->xB[i]) {
      // Handle upper bound
         minnlcinequalitypenaltyfunction(bndu->xR[i] - x->xR[i], stabilizingpoint, &p, &dp, &d2p);
         *f += rho * p;
         g->xR[i] -= rho * dp;
         minnlcinequalityshiftfunction((bndu->xR[i] - x->xR[i]) * rho + 1.0, &p, &dp, &d2p);
         *f += p / rho * nubc->xR[2 * i + 1];
         g->xR[i] -= dp * nubc->xR[2 * i + 1];
      }
   }
}

// This subroutine adds penalty from  linear  constraints to target  function
// and its gradient. Penalty function is one which is used for main AUL cycle
// - with Lagrange multipliers and infinite at the barrier and beyond.
//
// Parameters:
//     X[] - current point
//     CLEIC[] -   constraints matrix, first NEC rows are equality ones, next
//                 NIC rows are inequality ones. array[NEC+NIC,N+1]
//     NuLC[]  -   Lagrange multipliers corresponding to constraints,
//                 array[NEC+NIC]
//     N       -   dimensionalty
//     NEC     -   number of equality constraints
//     NIC     -   number of inequality constraints.
//     Rho - penalty term
//     StabilizingPoint - branch point for inequality stabilizing term
//     F - function value to modify
//     G - gradient to modify
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
static void minnlc_penaltylc(RVector *x, RMatrix *cleic, RVector *nulc, ae_int_t n, ae_int_t nec, ae_int_t nic, double rho, double stabilizingpoint, double *f, RVector *g) {
   ae_int_t i;
   double v;
   double p;
   double dp;
   double d2p;
   double fupd;
   double gupd;
   for (i = 0; i < nec + nic; i++) {
      v = ae_v_dotproduct(cleic->xyR[i], 1, x->xR, 1, n);
      v -= cleic->xyR[i][n];
      fupd = 0.0;
      gupd = 0.0;
      if (i < nec) {
      // Equality constraint
         minnlcequalitypenaltyfunction(v * rho, &p, &dp, &d2p);
         fupd += p / rho;
         gupd += dp;
         fupd -= nulc->xR[i] * v;
         gupd -= nulc->xR[i];
      } else {
      // Inequality constraint
         minnlcinequalitypenaltyfunction(-v, stabilizingpoint, &p, &dp, &d2p);
         fupd += p * rho;
         gupd -= dp * rho;
         minnlcinequalityshiftfunction(-v * rho + 1.0, &p, &dp, &d2p);
         fupd += p / rho * nulc->xR[i];
         gupd -= dp * nulc->xR[i];
      }
      *f += fupd;
      ae_v_addd(g->xR, 1, cleic->xyR[i], 1, n, gupd);
   }
}

// This subroutine adds penalty from nonlinear constraints to target function
// and its gradient. Penalty function is one which is used for main AUL cycle
// - with Lagrange multipliers and infinite at the barrier and beyond.
//
// Parameters:
//     Fi[] - function vector:
//           * 1 component for function being minimized
//           * NG components for equality constraints G_i(x) == 0
//           * NH components for inequality constraints H_i(x) <= 0
//     J[]  - Jacobian matrix, array[1+NG+NH,N]
//     NuNLC[]  -   Lagrange multipliers corresponding to constraints,
//                 array[NG+NH]
//     N - number of dimensions
//     NG - number of equality constraints
//     NH - number of inequality constraints
//     Rho - penalty term
//     StabilizingPoint - branch point for inequality stabilizing term
//     F - function value to modify
//     G - gradient to modify
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
static void minnlc_penaltynlc(RVector *fi, RMatrix *j, RVector *nunlc, ae_int_t n, ae_int_t ng, ae_int_t nh, double rho, double stabilizingpoint, double *f, RVector *g) {
   ae_int_t i;
   double v;
   double p;
   double dp;
   double d2p;
   double fupd;
   double gupd;
// IMPORTANT: loop starts from 1, not zero!
   for (i = 1; i <= ng + nh; i++) {
      v = fi->xR[i];
      fupd = 0.0;
      gupd = 0.0;
      if (i <= ng) {
      // Equality constraint
         minnlcequalitypenaltyfunction(v * rho, &p, &dp, &d2p);
         fupd += p / rho;
         gupd += dp;
         fupd -= nunlc->xR[i - 1] * v;
         gupd -= nunlc->xR[i - 1];
      } else {
      // Inequality constraint
         minnlcinequalitypenaltyfunction(-v, stabilizingpoint, &p, &dp, &d2p);
         fupd += p * rho;
         gupd -= dp * rho;
         minnlcinequalityshiftfunction(-v * rho + 1.0, &p, &dp, &d2p);
         fupd += p / rho * nunlc->xR[i - 1];
         gupd -= dp * nunlc->xR[i - 1];
      }
      *f += fupd;
      ae_v_addd(g->xR, 1, j->xyR[i], 1, n, gupd);
   }
}

// This function performs actual processing for AUL algorithm. It expects that
// caller redirects its reverse communication  requests  NeedFiJ/XUpdated  to
// external user who will provide analytic derivative (or handle reports about
// progress).
//
// In case external user does not have analytic derivative, it is responsibility
// of caller to intercept NeedFiJ request and  replace  it  with  appropriate
// numerical differentiation scheme.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
static bool minnlc_auliteration(minnlcstate *state, smoothnessmonitor *smonitor) {
   const double aulmaxgrowth = 10.0, maxlagmult = 10000000.0, hessesttol = 0.000001, initgamma = 0.000001;
   AutoS ae_int_t n;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t ng;
   AutoS ae_int_t nh;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t outerit;
   AutoS ae_int_t preccounter;
   AutoS double v;
   AutoS double vv;
   AutoS double p;
   AutoS double dp;
   AutoS double d2p;
   AutoS double v0;
   AutoS double v1;
   AutoS double v2;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->AulPQ >= 0) switch (state->AulPQ) {
      case 0: goto Resume0; case 1: goto Resume1; case 2: goto Resume2;
      default: goto Exit;
   }
Spawn:
   ae_assert(state->solvertype == 0, "MinNLC: internal error");
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   ng = state->ng;
   nh = state->nh;
// Prepare scaled problem
   vectorsetlengthatleast(&state->scaledbndl, n);
   vectorsetlengthatleast(&state->scaledbndu, n);
   matrixsetlengthatleast(&state->scaledcleic, nec + nic, n + 1);
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i]) {
         state->scaledbndl.xR[i] = state->bndl.xR[i] / state->s.xR[i];
      }
      if (state->hasbndu.xB[i]) {
         state->scaledbndu.xR[i] = state->bndu.xR[i] / state->s.xR[i];
      }
      state->xc.xR[i] = state->xstart.xR[i] / state->s.xR[i];
   }
   for (i = 0; i < nec + nic; i++) {
   // Scale and normalize linear constraints
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = state->cleic.xyR[i][j] * state->s.xR[j];
         state->scaledcleic.xyR[i][j] = v;
         vv += v * v;
      }
      vv = sqrt(vv);
      state->scaledcleic.xyR[i][n] = state->cleic.xyR[i][n];
      if (vv > 0.0) {
         for (j = 0; j <= n; j++) {
            state->scaledcleic.xyR[i][j] /= vv;
         }
      }
   }
// Prepare stopping criteria
   minlbfgssetcond(&state->auloptimizer, 0.0, 0.0, state->epsx, state->maxits);
   minlbfgssetstpmax(&state->auloptimizer, state->stpmax);
// Main AUL cycle:
// * prepare Lagrange multipliers NuNB/NuLC
// * set GammaK (current estimate of Hessian norm) to InitGamma and XKPresent to False
   vectorsetlengthatleast(&state->nubc, 2 * n);
   vectorsetlengthatleast(&state->nulc, nec + nic);
   vectorsetlengthatleast(&state->nunlc, ng + nh);
   vectorsetlengthatleast(&state->xk, n);
   vectorsetlengthatleast(&state->gk, n);
   vectorsetlengthatleast(&state->xk1, n);
   vectorsetlengthatleast(&state->gk1, n);
   for (i = 0; i < n; i++) {
      state->nubc.xR[2 * i] = 0.0;
      state->nubc.xR[2 * i + 1] = 0.0;
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
         continue;
      }
      if (state->hasbndl.xB[i]) {
         state->nubc.xR[2 * i] = state->initialinequalitymultiplier;
      }
      if (state->hasbndu.xB[i]) {
         state->nubc.xR[2 * i + 1] = state->initialinequalitymultiplier;
      }
   }
   for (i = 0; i < nec; i++) {
      state->nulc.xR[i] = 0.0;
   }
   for (i = 0; i < nic; i++) {
      state->nulc.xR[nec + i] = state->initialinequalitymultiplier;
   }
   for (i = 0; i < ng; i++) {
      state->nunlc.xR[i] = 0.0;
   }
   for (i = 0; i < nh; i++) {
      state->nunlc.xR[ng + i] = state->initialinequalitymultiplier;
   }
   state->gammak = initgamma;
   state->xkpresent = false;
   ae_assert(state->aulitscnt > 0, "MinNLC: integrity check failed");
   minnlc_clearpreconditioner(&state->auloptimizer);
   for (outerit = 0; outerit < state->aulitscnt; outerit++) {
   // Optimize with current Lagrange multipliers
   //
   // NOTE: this code expects and checks that line search ends in the
   //       point which is used as beginning for the next search. Such
   //       guarantee is given by MCSRCH function.  L-BFGS  optimizer
   //       does not formally guarantee it, but it follows same rule.
   //       Below we a) rely on such property of the optimizer, and b)
   //       assert that it is true, in order to fail loudly if it is
   //       not true.
   //
   // NOTE: security check for NAN/INF in F/G is responsibility of
   //       LBFGS optimizer. AUL optimizer checks for NAN/INF only
   //       when we update Lagrange multipliers.
      preccounter = 0;
      minlbfgssetxrep(&state->auloptimizer, true);
      for (minlbfgsrestartfrom(&state->auloptimizer, &state->xc); minlbfgsiteration(&state->auloptimizer); )
         if (state->auloptimizer.needfg) {
         // Un-scale X, evaluate F/G/H, re-scale Jacobian
            for (i = 0; i < n; i++) {
               state->x.xR[i] = state->auloptimizer.x.xR[i] * state->s.xR[i];
            }
            state->needfij = true, state->AulPQ = 0; goto Pause; Resume0: state->needfij = false;
            for (i = 0; i <= ng + nh; i++) {
               for (j = 0; j < n; j++) {
                  state->j.xyR[i][j] *= state->s.xR[j];
               }
            }
         // Store data for estimation of Hessian norm:
         // * current point (re-scaled)
         // * gradient of the target function (re-scaled, unmodified)
            ae_v_move(state->xk1.xR, 1, state->auloptimizer.x.xR, 1, n);
            ae_v_move(state->gk1.xR, 1, state->j.xyR[0], 1, n);
         // Function being optimized
            state->auloptimizer.f = state->fi.xR[0];
            for (i = 0; i < n; i++) {
               state->auloptimizer.g.xR[i] = state->j.xyR[0][i];
            }
         // Send information to OptGuard monitor
            smoothnessmonitorenqueuepoint(smonitor, &state->auloptimizer.d, state->auloptimizer.stp, &state->auloptimizer.x, &state->fi, &state->j);
         // Penalty for violation of boundary/linear/nonlinear constraints
            minnlc_penaltybc(&state->auloptimizer.x, &state->scaledbndl, &state->hasbndl, &state->scaledbndu, &state->hasbndu, &state->nubc, n, state->rho, state->stabilizingpoint, &state->auloptimizer.f, &state->auloptimizer.g);
            minnlc_penaltylc(&state->auloptimizer.x, &state->scaledcleic, &state->nulc, n, nec, nic, state->rho, state->stabilizingpoint, &state->auloptimizer.f, &state->auloptimizer.g);
            minnlc_penaltynlc(&state->fi, &state->j, &state->nunlc, n, ng, nh, state->rho, state->stabilizingpoint, &state->auloptimizer.f, &state->auloptimizer.g);
         // Forward termination request if needed
            if (state->userterminationneeded) {
               minlbfgsrequesttermination(&state->auloptimizer);
            }
         // To optimizer
         // continue;
         } else if (state->auloptimizer.xupdated) {
         // Report current point (if needed)
            if (state->xrep) {
               for (i = 0; i < n; i++) {
                  state->x.xR[i] = state->auloptimizer.x.xR[i] * state->s.xR[i];
               }
               state->f = state->auloptimizer.f;
               state->xupdated = true, state->AulPQ = 1; goto Pause; Resume1: state->xupdated = false;
            }
         // Send information to OptGuard monitor
            smoothnessmonitorfinalizelinesearch(smonitor);
            smoothnessmonitorstartlinesearch(smonitor, &state->auloptimizer.x, &state->fi, &state->j, state->repinneriterationscount, state->repouteriterationscount);
         // Forward termination request if needed
            if (state->userterminationneeded) {
               minlbfgsrequesttermination(&state->auloptimizer);
            }
         // Update constraints violation
            checkbcviolation(&state->hasbndl, &state->scaledbndl, &state->hasbndu, &state->scaledbndu, &state->auloptimizer.x, n, &state->s, false, &state->repbcerr, &state->repbcidx);
            checklcviolation(&state->scaledcleic, &state->lcsrcidx, nec, nic, &state->auloptimizer.x, n, &state->replcerr, &state->replcidx);
            checknlcviolation(&state->fi, ng, nh, &state->repnlcerr, &state->repnlcidx);
         // Update GammaK
            if (state->xkpresent) {
            // XK/GK store beginning of current line search, and XK1/GK1
            // store data for the end of the line search:
            // * first, we Assert() that XK1 (last point where function
            //   was evaluated) is same as AULOptimizer.X (what is
            //   reported by RComm interface
            // * calculate step length V2.
            //
            // If V2 > HessEstTol, then:
            // * calculate V0 - directional derivative at XK,
            //   and V1 - directional derivative at XK1
            // * set GammaK to Max(GammaK, |V1-V0|/V2)
               for (i = 0; i < n; i++) {
                  ae_assert(NearAtR(state->auloptimizer.x.xR[i], state->xk1.xR[i], 100.0 * machineepsilon) || !(isfinite(state->auloptimizer.x.xR[i]) && isfinite(state->xk1.xR[i])), "MinNLC: integrity check failed, unexpected behavior of LBFGS optimizer");
               }
               v2 = 0.0;
               for (i = 0; i < n; i++) {
                  v2 += sqr(state->xk.xR[i] - state->xk1.xR[i]);
               }
               v2 = sqrt(v2);
               if (v2 > hessesttol) {
                  v0 = 0.0;
                  v1 = 0.0;
                  for (i = 0; i < n; i++) {
                     v = (state->xk.xR[i] - state->xk1.xR[i]) / v2;
                     v0 += state->gk.xR[i] * v;
                     v1 += state->gk1.xR[i] * v;
                  }
                  state->gammak = rmax2(state->gammak, fabs(v1 - v0) / v2);
               }
            } else {
            // Beginning of the first line search, XK is not yet initialized.
               ae_v_move(state->xk.xR, 1, state->xk1.xR, 1, n);
               ae_v_move(state->gk.xR, 1, state->gk1.xR, 1, n);
               state->xkpresent = true;
            }
         // Update preconsitioner using current GammaK
            minnlc_updatepreconditioner(state->prectype, state->updatefreq, &preccounter, &state->auloptimizer, &state->auloptimizer.x, state->rho, state->gammak, &state->scaledbndl, &state->hasbndl, &state->scaledbndu, &state->hasbndu, &state->nubc, &state->scaledcleic, &state->nulc, &state->fi, &state->j, &state->nunlc, &state->bufd, &state->bufc, &state->bufw, &state->bufz, &state->tmp0, n, nec, nic, ng, nh);
         } else ae_assert(false, "MinNLC: integrity check failed");
      minlbfgsresultsbuf(&state->auloptimizer, &state->xc, &state->aulreport);
      state->repinneriterationscount += state->aulreport.iterationscount;
      state->repnfev += state->aulreport.nfev;
      state->repterminationtype = state->aulreport.terminationtype;
      state->repouteriterationscount++;
      if (state->repterminationtype <= 0 || state->repterminationtype == 8) {
         break;
      }
   // 1. Evaluate F/J
   // 2. Check for NAN/INF in F/J: we just calculate sum of their
   //    components, it should be enough to reduce vector/matrix to
   //    just one value which either "normal" (all summands were "normal")
   //    or NAN/INF (at least one summand was NAN/INF).
   // 3. Update Lagrange multipliers
      for (i = 0; i < n; i++) {
         state->x.xR[i] = state->xc.xR[i] * state->s.xR[i];
      }
      state->needfij = true, state->AulPQ = 2; goto Pause; Resume2: state->needfij = false;
      v = 0.0;
      for (i = 0; i <= ng + nh; i++) {
         v = 0.1 * v + state->fi.xR[i];
         for (j = 0; j < n; j++) {
            v = 0.1 * v + state->j.xyR[i][j];
         }
      }
      if (!isfinite(v)) {
      // Abnormal termination - infinities in function/gradient
         state->repterminationtype = -8;
         goto Exit;
      }
      for (i = 0; i <= ng + nh; i++) {
         for (j = 0; j < n; j++) {
            state->j.xyR[i][j] *= state->s.xR[j];
         }
      }
      for (i = 0; i < n; i++) {
      // Process coefficients corresponding to equality-type
      // constraints.
         if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
            minnlcequalitypenaltyfunction((state->xc.xR[i] - state->scaledbndl.xR[i]) * state->rho, &p, &dp, &d2p);
            state->nubc.xR[2 * i] = rboundval(state->nubc.xR[2 * i] - dp, -maxlagmult, maxlagmult);
            continue;
         }
      // Process coefficients corresponding to inequality-type
      // constraints. These coefficients have limited growth/decay
      // per iteration which helps to stabilize algorithm.
         ae_assert(aulmaxgrowth > 1.0, "MinNLC: integrity error");
         if (state->hasbndl.xB[i]) {
            minnlcinequalityshiftfunction((state->xc.xR[i] - state->scaledbndl.xR[i]) * state->rho + 1.0, &p, &dp, &d2p);
            v = fabs(dp);
            v = rmin2(v, aulmaxgrowth);
            v = rmax2(v, 1.0 / aulmaxgrowth);
            state->nubc.xR[2 * i] = rboundval(state->nubc.xR[2 * i] * v, -maxlagmult, maxlagmult);
         }
         if (state->hasbndu.xB[i]) {
            minnlcinequalityshiftfunction((state->scaledbndu.xR[i] - state->xc.xR[i]) * state->rho + 1.0, &p, &dp, &d2p);
            v = fabs(dp);
            v = rmin2(v, aulmaxgrowth);
            v = rmax2(v, 1.0 / aulmaxgrowth);
            state->nubc.xR[2 * i + 1] = rboundval(state->nubc.xR[2 * i + 1] * v, -maxlagmult, maxlagmult);
         }
      }
      for (i = 0; i < nec + nic; i++) {
         v = ae_v_dotproduct(state->scaledcleic.xyR[i], 1, state->xc.xR, 1, n);
         v -= state->scaledcleic.xyR[i][n];
         if (i < nec) {
            minnlcequalitypenaltyfunction(v * state->rho, &p, &dp, &d2p);
            state->nulc.xR[i] = rboundval(state->nulc.xR[i] - dp, -maxlagmult, maxlagmult);
         } else {
            minnlcinequalityshiftfunction(-v * state->rho + 1.0, &p, &dp, &d2p);
            v = fabs(dp);
            v = rmin2(v, aulmaxgrowth);
            v = rmax2(v, 1.0 / aulmaxgrowth);
            state->nulc.xR[i] = rboundval(state->nulc.xR[i] * v, -maxlagmult, maxlagmult);
         }
      }
      for (i = 1; i <= ng + nh; i++) {
      // NOTE: loop index must start from 1, not zero!
         v = state->fi.xR[i];
         if (i <= ng) {
            minnlcequalitypenaltyfunction(v * state->rho, &p, &dp, &d2p);
            state->nunlc.xR[i - 1] = rboundval(state->nunlc.xR[i - 1] - dp, -maxlagmult, maxlagmult);
         } else {
            minnlcinequalityshiftfunction(-v * state->rho + 1.0, &p, &dp, &d2p);
            v = fabs(dp);
            v = rmin2(v, aulmaxgrowth);
            v = rmax2(v, 1.0 / aulmaxgrowth);
            state->nunlc.xR[i - 1] = rboundval(state->nunlc.xR[i - 1] * v, -maxlagmult, maxlagmult);
         }
      }
   }
   for (i = 0; i < n; i++) {
      state->xc.xR[i] *= state->s.xR[i];
   }
Exit:
   state->AulPQ = -1;
   return false;
Pause:
   return true;
}

// Unscales X (converts from scaled variables to original ones), paying special
// attention to box constraints (output is always feasible; active constraints
// are mapped to active ones).
static void minnlc_unscale(minnlcstate *state, RVector *xs, RVector *scaledbndl, RVector *scaledbndu, RVector *xu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i] && xs->xR[i] <= scaledbndl->xR[i]) {
         xu->xR[i] = state->bndl.xR[i];
         continue;
      }
      if (state->hasbndu.xB[i] && xs->xR[i] >= scaledbndu->xR[i]) {
         xu->xR[i] = state->bndu.xR[i];
         continue;
      }
      xu->xR[i] = xs->xR[i] * state->s.xR[i];
      if (state->hasbndl.xB[i] && xu->xR[i] < state->bndl.xR[i]) {
         xu->xR[i] = state->bndl.xR[i];
      }
      if (state->hasbndu.xB[i] && xu->xR[i] > state->bndu.xR[i]) {
         xu->xR[i] = state->bndu.xR[i];
      }
   }
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions minnlcoptimize() listed below.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: bool minnlciteration(const minnlcstate &state);
// API: void minnlcoptimize(minnlcstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minnlcoptimize(minnlcstate &state, void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minnlciteration(minnlcstate *state) {
   AutoS ae_int_t i;
   AutoS ae_int_t k;
   AutoS ae_int_t n;
   AutoS ae_int_t ng;
   AutoS ae_int_t nh;
   AutoS double vleft;
   AutoS double vright;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14; case 15: goto Resume15;
      case 16: goto Resume16; case 17: goto Resume17; case 18: goto Resume18; case 19: goto Resume19;
      case 20: goto Resume20; case 21: goto Resume21; case 22: goto Resume22;
      case 23: goto Resume23; case 24: goto Resume24;
      default: goto Exit;
   }
Spawn:
// Init
   state->xupdated = state->needfij = state->needfi = false;
   state->userterminationneeded = false;
   state->repterminationtype = 0;
   state->repinneriterationscount = 0;
   state->repouteriterationscount = 0;
   state->repnfev = 0;
   state->repdbgphase0its = 0;
   state->repbcerr = 0.0;
   state->repbcidx = -1;
   state->replcerr = 0.0;
   state->replcidx = -1;
   state->repnlcerr = 0.0;
   state->repnlcidx = -1;
   n = state->n;
   ng = state->ng;
   nh = state->nh;
   ae_assert(state->smoothnessguardlevel == 0 || state->smoothnessguardlevel == 1, "MinNLCIteration: integrity check failed");
   smoothnessmonitorinit(&state->smonitor, &state->s, n, 1 + ng + nh, state->smoothnessguardlevel > 0);
   for (i = 0; i < n; i++) {
      state->lastscaleused.xR[i] = state->s.xR[i];
   }
// Check correctness of box constraints
   for (i = 0; i < n; i++) {
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i]) {
         if (state->bndl.xR[i] > state->bndu.xR[i]) {
            state->repterminationtype = -3;
            state->repbcerr = state->bndl.xR[i] - state->bndu.xR[i];
            state->repbcidx = i;
            goto Exit;
         }
      }
   }
// Test gradient
   if (state->diffstep == 0.0 && state->teststep > 0.0) {
      while (smoothnessmonitorcheckgradientatx0(&state->smonitor, &state->xstart, &state->s, &state->bndl, &state->bndu, true, state->teststep)) {
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->smonitor.x.xR[i];
         }
         state->needfij = true, state->PQ = 0; goto Pause; Resume00: state->needfij = false;
         for (i = 0; i <= ng + nh; i++) {
            state->smonitor.fi.xR[i] = state->fi.xR[i];
            for (k = 0; k < n; k++) {
               state->smonitor.j.xyR[i][k] = state->j.xyR[i][k];
            }
         }
      }
   }
   if (state->solvertype == 0) { // AUL solver
      if (state->diffstep != 0.0) {
         vectorsetlengthatleast(&state->xbase, n);
         vectorsetlengthatleast(&state->fbase, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm2, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm1, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp1, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp2, 1 + ng + nh);
      }
      for (state->AulPQ = -1; minnlc_auliteration(state, &state->smonitor); ) {
      // Numerical differentiation (if needed) - intercept NeedFiJ
      // request and replace it by sequence of NeedFi requests
         if (state->diffstep != 0.0 && state->needfij) {
            state->needfij = false, state->needfi = true;
            ae_v_move(state->xbase.xR, 1, state->x.xR, 1, n);
            for (k = 0; k < n; k++) {
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->x.xR[k] -= state->s.xR[k] * state->diffstep;
               state->PQ = 1; goto Pause; Resume01:
               ae_v_move(state->fm2.xR, 1, state->fi.xR, 1, ng + nh + 1);
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->x.xR[k] -= 0.5 * state->s.xR[k] * state->diffstep;
               state->PQ = 2; goto Pause; Resume02:
               ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, ng + nh + 1);
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->x.xR[k] += 0.5 * state->s.xR[k] * state->diffstep;
               state->PQ = 3; goto Pause; Resume03:
               ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, ng + nh + 1);
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->x.xR[k] += state->s.xR[k] * state->diffstep;
               state->PQ = 4; goto Pause; Resume04:
               ae_v_move(state->fp2.xR, 1, state->fi.xR, 1, ng + nh + 1);
               for (i = 0; i <= ng + nh; i++) {
                  state->j.xyR[i][k] = (8.0 * (state->fp1.xR[i] - state->fm1.xR[i]) - (state->fp2.xR[i] - state->fm2.xR[i])) / (6.0 * state->diffstep * state->s.xR[k]);
               }
            }
            ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
            state->PQ = 5; goto Pause; Resume05:
         // Restore previous values of fields and continue
            state->needfi = false, state->needfij = true;
         } else {
         // Forward request to caller.
            state->PQ = 6; goto Pause; Resume06: ;
         }
      }
   } else if (state->solvertype == 1) { // SLP solver
      if (state->diffstep != 0.0) {
         vectorsetlengthatleast(&state->xbase, n);
         vectorsetlengthatleast(&state->fbase, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm2, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm1, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp1, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp2, 1 + ng + nh);
      }
      minslpinitbuf(&state->bndl, &state->bndu, &state->s, &state->xstart, n, &state->cleic, &state->lcsrcidx, state->nec, state->nic, state->ng, state->nh, state->epsx, state->maxits, &state->slpsolverstate);
      while (minslpiteration(&state->slpsolverstate, &state->smonitor, state->userterminationneeded))
      // Forward request to caller.
         if (state->slpsolverstate.needfij) {
         // Evaluate target function/Jacobian
            if (state->diffstep == 0.0) {
            // Analytic Jacobian is provided
               minnlc_unscale(state, &state->slpsolverstate.x, &state->slpsolverstate.scaledbndl, &state->slpsolverstate.scaledbndu, &state->x);
               state->needfij = true, state->PQ = 7; goto Pause; Resume07: state->needfij = false;
               for (i = 0; i <= ng + nh; i++) {
                  state->slpsolverstate.fi.xR[i] = state->fi.xR[i];
                  for (k = 0; k < n; k++) {
                     state->slpsolverstate.j.xyR[i][k] = state->j.xyR[i][k] * state->s.xR[k];
                  }
               }
            } else {
            // Numerical differentiation
               state->needfi = true;
               minnlc_unscale(state, &state->slpsolverstate.x, &state->slpsolverstate.scaledbndl, &state->slpsolverstate.scaledbndu, &state->xbase);
               for (k = 0; k < n; k++) {
                  vleft = state->xbase.xR[k] - state->s.xR[k] * state->diffstep;
                  vright = state->xbase.xR[k] + state->s.xR[k] * state->diffstep;
                  if (state->hasbndl.xB[k] && vleft < state->bndl.xR[k] || state->hasbndu.xB[k] && vright > state->bndu.xR[k]) {
                  // Box constraint is violated by 4-point centered formula, use 2-point uncentered one
                     if (state->hasbndl.xB[k] && vleft < state->bndl.xR[k]) {
                        vleft = state->bndl.xR[k];
                     }
                     if (state->hasbndu.xB[k] && vright > state->bndu.xR[k]) {
                        vright = state->bndu.xR[k];
                     }
                     ae_assert(vleft <= vright, "MinNLC: integrity check failed");
                     if (vleft == vright) {
                     // Fixed variable
                        for (i = 0; i <= ng + nh; i++) {
                           state->j.xyR[i][k] = 0.0;
                        }
                        continue;
                     }
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] = vleft;
                     state->PQ = 8; goto Pause; Resume08:
                     ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] = vright;
                     state->PQ = 9; goto Pause; Resume09:
                     ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     for (i = 0; i <= ng + nh; i++) {
                        state->j.xyR[i][k] = (state->fp1.xR[i] - state->fm1.xR[i]) / (vright - vleft);
                     }
                  } else {
                  // 4-point centered formula does not violate box constraints
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] -= state->s.xR[k] * state->diffstep;
                     state->PQ = 10; goto Pause; Resume10:
                     ae_v_move(state->fm2.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] -= 0.5 * state->s.xR[k] * state->diffstep;
                     state->PQ = 11; goto Pause; Resume11:
                     ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] += 0.5 * state->s.xR[k] * state->diffstep;
                     state->PQ = 12; goto Pause; Resume12:
                     ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] += state->s.xR[k] * state->diffstep;
                     state->PQ = 13; goto Pause; Resume13:
                     ae_v_move(state->fp2.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     for (i = 0; i <= ng + nh; i++) {
                        state->j.xyR[i][k] = (8.0 * (state->fp1.xR[i] - state->fm1.xR[i]) - (state->fp2.xR[i] - state->fm2.xR[i])) / (6.0 * state->diffstep * state->s.xR[k]);
                     }
                  }
               }
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->PQ = 14; goto Pause; Resume14:
               state->needfi = false;
               for (i = 0; i <= ng + nh; i++) {
                  state->slpsolverstate.fi.xR[i] = state->fi.xR[i];
                  for (k = 0; k < n; k++) {
                     state->slpsolverstate.j.xyR[i][k] = state->j.xyR[i][k] * state->s.xR[k];
                  }
               }
            }
            state->repnfev++;
         } else if (state->slpsolverstate.xupdated) {
         // Report current point
            if (state->xrep) {
               minnlc_unscale(state, &state->slpsolverstate.x, &state->slpsolverstate.scaledbndl, &state->slpsolverstate.scaledbndu, &state->x);
               state->f = state->slpsolverstate.f;
               state->xupdated = true, state->PQ = 15; goto Pause; Resume15: state->xupdated = false;
            }
         } else ae_assert(state->slpsolverstate.needfij, "NLC:SLP:request");
      state->repterminationtype = state->slpsolverstate.repterminationtype;
      state->repouteriterationscount = state->slpsolverstate.repouteriterationscount;
      state->repinneriterationscount = state->slpsolverstate.repinneriterationscount;
      state->repbcerr = state->slpsolverstate.repbcerr;
      state->repbcidx = state->slpsolverstate.repbcidx;
      state->replcerr = state->slpsolverstate.replcerr;
      state->replcidx = state->slpsolverstate.replcidx;
      state->repnlcerr = state->slpsolverstate.repnlcerr;
      state->repnlcidx = state->slpsolverstate.repnlcidx;
      minnlc_unscale(state, &state->slpsolverstate.stepkx, &state->slpsolverstate.scaledbndl, &state->slpsolverstate.scaledbndu, &state->xc);
   } else if (state->solvertype == 2) { // SQP solver
      if (state->diffstep != 0.0) {
         vectorsetlengthatleast(&state->xbase, n);
         vectorsetlengthatleast(&state->fbase, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm2, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm1, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp1, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp2, 1 + ng + nh);
      }
      minsqpinitbuf(&state->bndl, &state->bndu, &state->s, &state->xstart, n, &state->cleic, &state->lcsrcidx, state->nec, state->nic, state->ng, state->nh, state->epsx, state->maxits, &state->sqpsolverstate);
      while (minsqpiteration(&state->sqpsolverstate, &state->smonitor, state->userterminationneeded))
      // Forward request to caller.
         if (state->sqpsolverstate.needfij) {
         // Evaluate target function/Jacobian
            if (state->diffstep == 0.0) {
            // Analytic Jacobian is provided
               minnlc_unscale(state, &state->sqpsolverstate.x, &state->sqpsolverstate.scaledbndl, &state->sqpsolverstate.scaledbndu, &state->x);
               state->needfij = true, state->PQ = 16; goto Pause; Resume16: state->needfij = false;
               for (i = 0; i <= ng + nh; i++) {
                  state->sqpsolverstate.fi.xR[i] = state->fi.xR[i];
                  for (k = 0; k < n; k++) {
                     state->sqpsolverstate.j.xyR[i][k] = state->j.xyR[i][k] * state->s.xR[k];
                  }
               }
            } else {
            // Numerical differentiation
               state->needfi = true;
               minnlc_unscale(state, &state->sqpsolverstate.x, &state->sqpsolverstate.scaledbndl, &state->sqpsolverstate.scaledbndu, &state->xbase);
               for (k = 0; k < n; k++) {
                  vleft = state->xbase.xR[k] - state->s.xR[k] * state->diffstep;
                  vright = state->xbase.xR[k] + state->s.xR[k] * state->diffstep;
                  if (state->hasbndl.xB[k] && vleft < state->bndl.xR[k] || state->hasbndu.xB[k] && vright > state->bndu.xR[k]) {
                  // Box constraint is violated by 4-point centered formula, use 2-point uncentered one
                     if (state->hasbndl.xB[k] && vleft < state->bndl.xR[k]) {
                        vleft = state->bndl.xR[k];
                     }
                     if (state->hasbndu.xB[k] && vright > state->bndu.xR[k]) {
                        vright = state->bndu.xR[k];
                     }
                     ae_assert(vleft <= vright, "MinNLC: integrity check failed");
                     if (vleft == vright) {
                     // Fixed variable
                        for (i = 0; i <= ng + nh; i++) {
                           state->j.xyR[i][k] = 0.0;
                        }
                        continue;
                     }
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] = vleft;
                     state->PQ = 17; goto Pause; Resume17:
                     ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] = vright;
                     state->PQ = 18; goto Pause; Resume18:
                     ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     for (i = 0; i <= ng + nh; i++) {
                        state->j.xyR[i][k] = (state->fp1.xR[i] - state->fm1.xR[i]) / (vright - vleft);
                     }
                  } else {
                  // 4-point centered formula does not violate box constraints
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] -= state->s.xR[k] * state->diffstep;
                     state->PQ = 19; goto Pause; Resume19:
                     ae_v_move(state->fm2.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] -= 0.5 * state->s.xR[k] * state->diffstep;
                     state->PQ = 20; goto Pause; Resume20:
                     ae_v_move(state->fm1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] += 0.5 * state->s.xR[k] * state->diffstep;
                     state->PQ = 21; goto Pause; Resume21:
                     ae_v_move(state->fp1.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
                     state->x.xR[k] += state->s.xR[k] * state->diffstep;
                     state->PQ = 22; goto Pause; Resume22:
                     ae_v_move(state->fp2.xR, 1, state->fi.xR, 1, ng + nh + 1);
                     for (i = 0; i <= ng + nh; i++) {
                        state->j.xyR[i][k] = (8.0 * (state->fp1.xR[i] - state->fm1.xR[i]) - (state->fp2.xR[i] - state->fm2.xR[i])) / (6.0 * state->diffstep * state->s.xR[k]);
                     }
                  }
               }
               ae_v_move(state->x.xR, 1, state->xbase.xR, 1, n);
               state->PQ = 23; goto Pause; Resume23:
               state->needfi = false;
               for (i = 0; i <= ng + nh; i++) {
                  state->sqpsolverstate.fi.xR[i] = state->fi.xR[i];
                  for (k = 0; k < n; k++) {
                     state->sqpsolverstate.j.xyR[i][k] = state->j.xyR[i][k] * state->s.xR[k];
                  }
               }
            }
            state->repnfev++;
         } else if (state->sqpsolverstate.xupdated) {
         // Report current point
            if (state->xrep) {
               minnlc_unscale(state, &state->sqpsolverstate.x, &state->sqpsolverstate.scaledbndl, &state->sqpsolverstate.scaledbndu, &state->x);
               state->f = state->sqpsolverstate.f;
               state->xupdated = true, state->PQ = 24; goto Pause; Resume24: state->xupdated = false;
            }
         } else ae_assert(state->sqpsolverstate.needfij, "NLC:SQP:request");
      state->repterminationtype = state->sqpsolverstate.repterminationtype;
      state->repouteriterationscount = state->sqpsolverstate.repiterationscount;
      state->repinneriterationscount = state->sqpsolverstate.repiterationscount;
      state->repbcerr = state->sqpsolverstate.repbcerr;
      state->repbcidx = state->sqpsolverstate.repbcidx;
      state->replcerr = state->sqpsolverstate.replcerr;
      state->replcidx = state->sqpsolverstate.replcidx;
      state->repnlcerr = state->sqpsolverstate.repnlcerr;
      state->repnlcidx = state->sqpsolverstate.repnlcidx;
      minnlc_unscale(state, &state->sqpsolverstate.stepkx, &state->sqpsolverstate.scaledbndl, &state->sqpsolverstate.scaledbndu, &state->xc);
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This  function  activates/deactivates verification  of  the  user-supplied
// analytic gradient/Jacobian.
//
// Upon  activation  of  this  option  OptGuard  integrity  checker  performs
// numerical differentiation of your target  function  (constraints)  at  the
// initial point (note: future versions may also perform check  at  the final
// point) and compares numerical gradient/Jacobian with analytic one provided
// by you.
//
// If difference is too large, an error flag is set and optimization  session
// continues. After optimization session is over, you can retrieve the report
// which stores both gradients/Jacobians, and specific components highlighted
// as suspicious by the OptGuard.
//
// The primary OptGuard report can be retrieved with minnlcoptguardresults().
//
// IMPORTANT: gradient check is a high-overhead option which  will  cost  you
//            about 3*N additional function evaluations. In many cases it may
//            cost as much as the rest of the optimization session.
//
//            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
//            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
//
// NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
//       does NOT interrupt optimization even if it discovers bad gradient.
//
// Inputs:
//     State       -   structure used to store algorithm state
//     TestStep    -   verification step used for numerical differentiation:
//                     * TestStep == 0 turns verification off
//                     * TestStep > 0 activates verification
//                     You should carefully choose TestStep. Value  which  is
//                     too large (so large that  function  behavior  is  non-
//                     cubic at this scale) will lead  to  false  alarms. Too
//                     short step will result in rounding  errors  dominating
//                     numerical derivative.
//
//                     You may use different step for different parameters by
//                     means of setting scale with minnlcsetscale().
//
// ==== EXPLANATION ====
//
// In order to verify gradient algorithm performs following steps:
//   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
//     where X[i] is i-th component of the initial point and S[i] is a  scale
//     of i-th parameter
//   * F(X) is evaluated at these trial points
//   * we perform one more evaluation in the middle point of the interval
//   * we  build  cubic  model using function values and derivatives at trial
//     points and we compare its prediction with actual value in  the  middle
//     point
// ALGLIB: Copyright 15.06.2014 by Sergey Bochkanov
// API: void minnlcoptguardgradient(const minnlcstate &state, const double teststep);
void minnlcoptguardgradient(minnlcstate *state, double teststep) {
   ae_assert(isfinite(teststep), "MinNLCOptGuardGradient: TestStep contains NaN or INF");
   ae_assert(teststep >= 0.0, "MinNLCOptGuardGradient: invalid argument TestStep(TestStep < 0)");
   state->teststep = teststep;
}

// This  function  activates/deactivates nonsmoothness monitoring  option  of
// the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
// solution process and tries to detect ill-posed problems, i.e. ones with:
// a) discontinuous target function (non-C0) and/or constraints
// b) nonsmooth     target function (non-C1) and/or constraints
//
// Smoothness monitoring does NOT interrupt optimization  even if it suspects
// that your problem is nonsmooth. It just sets corresponding  flags  in  the
// OptGuard report which can be retrieved after optimization is over.
//
// Smoothness monitoring is a moderate overhead option which often adds  less
// than 1% to the optimizer running time. Thus, you can use it even for large
// scale problems.
//
// NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
//       continuity violations.
//
//       First, minor errors are hard to  catch - say, a 0.0001 difference in
//       the model values at two sides of the gap may be due to discontinuity
//       of the model - or simply because the model has changed.
//
//       Second, C1-violations  are  especially  difficult  to  detect  in  a
//       noninvasive way. The optimizer usually  performs  very  short  steps
//       near the nonsmoothness, and differentiation  usually   introduces  a
//       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
//       discontinuity in the slope is due to real nonsmoothness or just  due
//       to numerical noise alone.
//
//       Our top priority was to avoid false positives, so in some rare cases
//       minor errors may went unnoticed (however, in most cases they can  be
//       spotted with restart from different initial point).
//
// Inputs:
//     state   -   algorithm state
//     level   -   monitoring level:
//                 * 0 - monitoring is disabled
//                 * 1 - noninvasive low-overhead monitoring; function values
//                       and/or gradients are recorded, but OptGuard does not
//                       try to perform additional evaluations  in  order  to
//                       get more information about suspicious locations.
//                       This kind of monitoring does not work well with  SQP
//                       because SQP solver needs just 1-2 function evaluations
//                       per step, which is not enough for OptGuard  to  make
//                       any conclusions.
//
// ==== EXPLANATION ====
//
// One major source of headache during optimization  is  the  possibility  of
// the coding errors in the target function/constraints (or their gradients).
// Such  errors   most   often   manifest   themselves  as  discontinuity  or
// nonsmoothness of the target/constraints.
//
// Another frequent situation is when you try to optimize something involving
// lots of min() and max() operations, i.e. nonsmooth target. Although not  a
// coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
// stop right after encountering nonsmoothness, well before reaching solution.
//
// OptGuard integrity checker helps you to catch such situations: it monitors
// function values/gradients being passed  to  the  optimizer  and  tries  to
// errors. Upon discovering suspicious pair of points it  raises  appropriate
// flag (and allows you to continue optimization). When optimization is done,
// you can study OptGuard result.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minnlcoptguardsmoothness(const minnlcstate &state, const ae_int_t level);
// API: void minnlcoptguardsmoothness(const minnlcstate &state);
void minnlcoptguardsmoothness(minnlcstate *state, ae_int_t level) {
   ae_assert(level == 0 || level == 1, "MinNLCOptGuardSmoothness: unexpected value of level parameter");
   state->smoothnessguardlevel = level;
}

// Results of OptGuard integrity check, should be called  after  optimization
// session is over.
//
// ==== PRIMARY REPORT ====
//
// OptGuard performs several checks which are intended to catch common errors
// in the implementation of nonlinear function/gradient:
// * incorrect analytic gradient
// * discontinuous (non-C0) target functions (constraints)
// * nonsmooth     (non-C1) target functions (constraints)
//
// Each of these checks is activated with appropriate function:
// * minnlcoptguardgradient() for gradient verification
// * minnlcoptguardsmoothness() for C0/C1 checks
//
// Following flags are set when these errors are suspected:
// * rep.badgradsuspected, and additionally:
//   * rep.badgradfidx for specific function (Jacobian row) suspected
//   * rep.badgradvidx for specific variable (Jacobian column) suspected
//   * rep.badgradxbase, a point where gradient/Jacobian is tested
//   * rep.badgraduser, user-provided gradient/Jacobian
//   * rep.badgradnum, reference gradient/Jacobian obtained via numerical
//     differentiation
// * rep.nonc0suspected, and additionally:
//   * rep.nonc0fidx - an index of specific function violating C0 continuity
// * rep.nonc1suspected, and additionally
//   * rep.nonc1fidx - an index of specific function violating C1 continuity
// Here function index 0 means  target function, index 1  or  higher  denotes
// nonlinear constraints.
//
// ==== ADDITIONAL REPORTS/LOGS ====
//
// Several different tests are performed to catch C0/C1 errors, you can  find
// out specific test signaled error by looking to:
// * rep.nonc0test0positive, for non-C0 test #0
// * rep.nonc1test0positive, for non-C1 test #0
// * rep.nonc1test1positive, for non-C1 test #1
//
// Additional information (including line search logs)  can  be  obtained  by
// means of:
// * minnlcoptguardnonc1test0results()
// * minnlcoptguardnonc1test1results()
// which return detailed error reports, specific points where discontinuities
// were found, and so on.
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     rep     -   generic OptGuard report;  more  detailed  reports  can  be
//                 retrieved with other functions.
//
// NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
//       ones) are possible although unlikely.
//
//       The reason  is  that  you  need  to  make several evaluations around
//       nonsmoothness  in  order  to  accumulate  enough  information  about
//       function curvature. Say, if you start right from the nonsmooth point,
//       optimizer simply won't get enough data to understand what  is  going
//       wrong before it terminates due to abrupt changes in the  derivative.
//       It is also  possible  that  "unlucky"  step  will  move  us  to  the
//       termination too quickly.
//
//       Our current approach is to have less than 0.1%  false  negatives  in
//       our test examples  (measured  with  multiple  restarts  from  random
//       points), and to have exactly 0% false positives.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minnlcoptguardresults(const minnlcstate &state, optguardreport &rep);
void minnlcoptguardresults(minnlcstate *state, optguardreport *rep) {
   SetObj(optguardreport, rep);
   smoothnessmonitorexportreport(&state->smonitor, rep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #0
//
// Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
// obtained during line searches and monitors  behavior  of  the  directional
// derivative estimate.
//
// This test is less powerful than test #1, but it does  not  depend  on  the
// gradient values and thus it is more robust against artifacts introduced by
// numerical differentiation.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * fidx - is an index of the function (0 for  target  function, 1 or higher
//   for nonlinear constraints) which is suspected of being "non-C1"
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #0 "strong" report
//     lngrep  -   C1 test #0 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minnlcoptguardnonc1test0results(const minnlcstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep);
void minnlcoptguardnonc1test0results(minnlcstate *state, optguardnonc1test0report *strrep, optguardnonc1test0report *lngrep) {
   SetObj(optguardnonc1test0report, strrep);
   SetObj(optguardnonc1test0report, lngrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0lngrep, &state->lastscaleused, lngrep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #1
//
// Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
// gradient computed during line search.
//
// When precise analytic gradient is provided this test is more powerful than
// test #0  which  works  with  function  values  and  ignores  user-provided
// gradient.  However,  test  #0  becomes  more   powerful   when   numerical
// differentiation is employed (in such cases test #1 detects  higher  levels
// of numerical noise and becomes too conservative).
//
// This test also tells specific components of the gradient which violate  C1
// continuity, which makes it more informative than #0, which just tells that
// continuity is violated.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * fidx - is an index of the function (0 for  target  function, 1 or higher
//   for nonlinear constraints) which is suspected of being "non-C1"
// * vidx - is an index of the variable in [0,N) with nonsmooth derivative
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], g[] - arrays of length CNT which store step lengths and  gradient
//   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
//   vidx-th component of the gradient.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #1 "strong" report
//     lngrep  -   C1 test #1 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minnlcoptguardnonc1test1results(const minnlcstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep);
void minnlcoptguardnonc1test1results(minnlcstate *state, optguardnonc1test1report *strrep, optguardnonc1test1report *lngrep) {
   SetObj(optguardnonc1test1report, strrep);
   SetObj(optguardnonc1test1report, lngrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1lngrep, &state->lastscaleused, lngrep);
}

// NLC results
//
// Buffered implementation of MinNLCResults() which uses preallocated buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minnlcresultsbuf(const minnlcstate &state, real_1d_array &x, minnlcreport &rep);
void minnlcresultsbuf(minnlcstate *state, RVector *x, minnlcreport *rep) {
   ae_int_t i;
   vectorsetlengthatleast(x, state->n);
   rep->iterationscount = state->repinneriterationscount;
   rep->nfev = state->repnfev;
   rep->terminationtype = state->repterminationtype;
   rep->bcerr = state->repbcerr;
   rep->bcidx = state->repbcidx;
   rep->lcerr = state->replcerr;
   rep->lcidx = state->replcidx;
   rep->nlcerr = state->repnlcerr;
   rep->nlcidx = state->repnlcidx;
   rep->dbgphase0its = state->repdbgphase0its;
   if (state->repterminationtype > 0) {
      ae_v_move(x->xR, 1, state->xc.xR, 1, state->n);
   } else {
      for (i = 0; i < state->n; i++) {
         x->xR[i] = NAN;
      }
   }
}

// MinNLC results:  the  solution  found,  completion  codes  and  additional
// information.
//
// If you activated OptGuard integrity checking functionality and want to get
// OptGuard report, it can be retrieved with:
// * minnlcoptguardresults() - for a primary report about (a) suspected C0/C1
//   continuity violations and (b) errors in the analytic gradient.
// * minnlcoptguardnonc1test0results() - for C1 continuity violation test #0,
//   detailed line search log
// * minnlcoptguardnonc1test1results() - for C1 continuity violation test #1,
//   detailed line search log
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization report, contains information about completion
//                 code, constraint violation at the solution and so on.
//
//                 You   should   check   rep.terminationtype  in  order   to
//                 distinguish successful termination from unsuccessful one:
//
//                 ==== FAILURE CODES ====
//                 * -8    internal  integrity control  detected  infinite or
//                         NAN   values    in   function/gradient.   Abnormal
//                         termination signalled.
//                 * -3    box  constraints are infeasible.
//                         Note: infeasibility of  non-box  constraints  does
//                               NOT trigger emergency completion;  you  have
//                               to examine rep.bcerr/rep.lcerr/rep.nlcerr to
//                               detect possibly inconsistent constraints.
//
//                 ==== SUCCESS CODES ====
//                 *  2   scaled step is no more than EpsX.
//                 *  5   MaxIts steps were taken.
//                 *  8   user   requested    algorithm    termination    via
//                        minnlcrequesttermination(), last accepted point  is
//                        returned.
//
//                 More information about fields of this  structure  can  be
//                 found in the comments on minnlcreport datatype.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
// API: void minnlcresults(const minnlcstate &state, real_1d_array &x, minnlcreport &rep);
void minnlcresults(minnlcstate *state, RVector *x, minnlcreport *rep) {
   SetVector(x);
   SetObj(minnlcreport, rep);
   minnlcresultsbuf(state, x, rep);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 08.10.2014 by Sergey Bochkanov
// API: void minnlcrequesttermination(const minnlcstate &state);
void minnlcrequesttermination(minnlcstate *state) {
   state->userterminationneeded = true;
}

void minnlcstate_init(void *_p, bool make_automatic) {
   minnlcstate *p = (minnlcstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->cleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->lcsrcidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->scaledbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->scaledbndu, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->scaledcleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xstart, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dfbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fm2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fm1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fp2, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dfm1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dfp1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufd, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->bufw, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->bufz, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xk1, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gk1, 0, DT_REAL, make_automatic);
   minlbfgsstate_init(&p->auloptimizer, make_automatic);
   minlbfgsreport_init(&p->aulreport, make_automatic);
   ae_vector_init(&p->nubc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nulc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->nunlc, 0, DT_REAL, make_automatic);
   minslpstate_init(&p->slpsolverstate, make_automatic);
   minsqpstate_init(&p->sqpsolverstate, make_automatic);
   smoothnessmonitor_init(&p->smonitor, make_automatic);
   ae_vector_init(&p->lastscaleused, 0, DT_REAL, make_automatic);
}

void minnlcstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minnlcstate *dst = (minnlcstate *)_dst;
   const minnlcstate *src = (const minnlcstate *)_src;
   dst->stabilizingpoint = src->stabilizingpoint;
   dst->initialinequalitymultiplier = src->initialinequalitymultiplier;
   dst->solvertype = src->solvertype;
   dst->prectype = src->prectype;
   dst->updatefreq = src->updatefreq;
   dst->rho = src->rho;
   dst->n = src->n;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->aulitscnt = src->aulitscnt;
   dst->xrep = src->xrep;
   dst->stpmax = src->stpmax;
   dst->diffstep = src->diffstep;
   dst->teststep = src->teststep;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   dst->nec = src->nec;
   dst->nic = src->nic;
   ae_matrix_copy(&dst->cleic, &src->cleic, make_automatic);
   ae_vector_copy(&dst->lcsrcidx, &src->lcsrcidx, make_automatic);
   dst->ng = src->ng;
   dst->nh = src->nh;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   ae_matrix_copy(&dst->j, &src->j, make_automatic);
   dst->needfij = src->needfij;
   dst->needfi = src->needfi;
   dst->xupdated = src->xupdated;
   dst->PQ = src->PQ;
   dst->AulPQ = src->AulPQ;
   ae_vector_copy(&dst->scaledbndl, &src->scaledbndl, make_automatic);
   ae_vector_copy(&dst->scaledbndu, &src->scaledbndu, make_automatic);
   ae_matrix_copy(&dst->scaledcleic, &src->scaledcleic, make_automatic);
   ae_vector_copy(&dst->xc, &src->xc, make_automatic);
   ae_vector_copy(&dst->xstart, &src->xstart, make_automatic);
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   ae_vector_copy(&dst->fbase, &src->fbase, make_automatic);
   ae_vector_copy(&dst->dfbase, &src->dfbase, make_automatic);
   ae_vector_copy(&dst->fm2, &src->fm2, make_automatic);
   ae_vector_copy(&dst->fm1, &src->fm1, make_automatic);
   ae_vector_copy(&dst->fp1, &src->fp1, make_automatic);
   ae_vector_copy(&dst->fp2, &src->fp2, make_automatic);
   ae_vector_copy(&dst->dfm1, &src->dfm1, make_automatic);
   ae_vector_copy(&dst->dfp1, &src->dfp1, make_automatic);
   ae_vector_copy(&dst->bufd, &src->bufd, make_automatic);
   ae_vector_copy(&dst->bufc, &src->bufc, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_matrix_copy(&dst->bufw, &src->bufw, make_automatic);
   ae_matrix_copy(&dst->bufz, &src->bufz, make_automatic);
   ae_vector_copy(&dst->xk, &src->xk, make_automatic);
   ae_vector_copy(&dst->xk1, &src->xk1, make_automatic);
   ae_vector_copy(&dst->gk, &src->gk, make_automatic);
   ae_vector_copy(&dst->gk1, &src->gk1, make_automatic);
   dst->gammak = src->gammak;
   dst->xkpresent = src->xkpresent;
   minlbfgsstate_copy(&dst->auloptimizer, &src->auloptimizer, make_automatic);
   minlbfgsreport_copy(&dst->aulreport, &src->aulreport, make_automatic);
   ae_vector_copy(&dst->nubc, &src->nubc, make_automatic);
   ae_vector_copy(&dst->nulc, &src->nulc, make_automatic);
   ae_vector_copy(&dst->nunlc, &src->nunlc, make_automatic);
   dst->userterminationneeded = src->userterminationneeded;
   minslpstate_copy(&dst->slpsolverstate, &src->slpsolverstate, make_automatic);
   minsqpstate_copy(&dst->sqpsolverstate, &src->sqpsolverstate, make_automatic);
   dst->smoothnessguardlevel = src->smoothnessguardlevel;
   smoothnessmonitor_copy(&dst->smonitor, &src->smonitor, make_automatic);
   ae_vector_copy(&dst->lastscaleused, &src->lastscaleused, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repnfev = src->repnfev;
   dst->repterminationtype = src->repterminationtype;
   dst->repbcerr = src->repbcerr;
   dst->repbcidx = src->repbcidx;
   dst->replcerr = src->replcerr;
   dst->replcidx = src->replcidx;
   dst->repnlcerr = src->repnlcerr;
   dst->repnlcidx = src->repnlcidx;
   dst->repdbgphase0its = src->repdbgphase0its;
}

void minnlcstate_free(void *_p, bool make_automatic) {
   minnlcstate *p = (minnlcstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_matrix_free(&p->cleic, make_automatic);
   ae_vector_free(&p->lcsrcidx, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_matrix_free(&p->j, make_automatic);
   ae_vector_free(&p->scaledbndl, make_automatic);
   ae_vector_free(&p->scaledbndu, make_automatic);
   ae_matrix_free(&p->scaledcleic, make_automatic);
   ae_vector_free(&p->xc, make_automatic);
   ae_vector_free(&p->xstart, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_vector_free(&p->fbase, make_automatic);
   ae_vector_free(&p->dfbase, make_automatic);
   ae_vector_free(&p->fm2, make_automatic);
   ae_vector_free(&p->fm1, make_automatic);
   ae_vector_free(&p->fp1, make_automatic);
   ae_vector_free(&p->fp2, make_automatic);
   ae_vector_free(&p->dfm1, make_automatic);
   ae_vector_free(&p->dfp1, make_automatic);
   ae_vector_free(&p->bufd, make_automatic);
   ae_vector_free(&p->bufc, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_matrix_free(&p->bufw, make_automatic);
   ae_matrix_free(&p->bufz, make_automatic);
   ae_vector_free(&p->xk, make_automatic);
   ae_vector_free(&p->xk1, make_automatic);
   ae_vector_free(&p->gk, make_automatic);
   ae_vector_free(&p->gk1, make_automatic);
   minlbfgsstate_free(&p->auloptimizer, make_automatic);
   minlbfgsreport_free(&p->aulreport, make_automatic);
   ae_vector_free(&p->nubc, make_automatic);
   ae_vector_free(&p->nulc, make_automatic);
   ae_vector_free(&p->nunlc, make_automatic);
   minslpstate_free(&p->slpsolverstate, make_automatic);
   minsqpstate_free(&p->sqpsolverstate, make_automatic);
   smoothnessmonitor_free(&p->smonitor, make_automatic);
   ae_vector_free(&p->lastscaleused, make_automatic);
}

void minnlcreport_init(void *_p, bool make_automatic) {
}

void minnlcreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minnlcreport *dst = (minnlcreport *)_dst;
   const minnlcreport *src = (const minnlcreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->terminationtype = src->terminationtype;
   dst->bcerr = src->bcerr;
   dst->bcidx = src->bcidx;
   dst->lcerr = src->lcerr;
   dst->lcidx = src->lcidx;
   dst->nlcerr = src->nlcerr;
   dst->nlcidx = src->nlcidx;
   dst->dbgphase0its = src->dbgphase0its;
}

void minnlcreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores nonlinear optimizer state.
// You should use functions provided by MinNLC subpackage to work  with  this
// object
DefClass(minnlcstate, DecVal(needfi) DecVal(needfij) DecVal(xupdated) DecVal(f) DecVar(fi) DecVar(j) DecVar(x))

// These fields store optimization report:
// * iterationscount           total number of inner iterations
// * nfev                      number of gradient evaluations
// * terminationtype           termination type (see below)
//
// Scaled constraint violations are reported:
// * bcerr                     maximum violation of the box constraints
// * bcidx                     index of the most violated box  constraint (or
//                             -1, if all box constraints  are  satisfied  or
//                             there is no box constraint)
// * lcerr                     maximum violation of the  linear  constraints,
//                             computed as maximum  scaled  distance  between
//                             final point and constraint boundary.
// * lcidx                     index of the most violated  linear  constraint
//                             (or -1, if all constraints  are  satisfied  or
//                             there is no general linear constraints)
// * nlcerr                    maximum violation of the nonlinear constraints
// * nlcidx                    index of the most violated nonlinear constraint
//                             (or -1, if all constraints  are  satisfied  or
//                             there is no nonlinear constraints)
//
// Violations of box constraints are scaled on per-component basis  according
// to  the  scale  vector s[] as specified by minnlcsetscale(). Violations of
// the general linear  constraints  are  also  computed  using  user-supplied
// variable scaling. Violations of nonlinear constraints are computed "as is"
//
// TERMINATION CODES
//
// TerminationType field contains completion code, which can be either:
//
// ==== FAILURE CODES ====
//   -8    internal integrity control detected  infinite  or  NAN  values  in
//         function/gradient. Abnormal termination signaled.
//   -3    box  constraints  are  infeasible.  Note: infeasibility of non-box
//         constraints does NOT trigger emergency  completion;  you  have  to
//         examine  bcerr/lcerr/nlcerr   to  detect   possibly   inconsistent
//         constraints.
//
// ==== SUCCESS CODES ====
//    2    relative step is no more than EpsX.
//    5    MaxIts steps was taken
//    7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//    8    user requested algorithm termination via minnlcrequesttermination(),
//         last accepted point is returned
//
// Other fields of this structure are not documented and should not be used!
DefClass(minnlcreport, DecVal(iterationscount) DecVal(nfev) DecVal(terminationtype) DecVal(bcerr) DecVal(bcidx) DecVal(lcerr) DecVal(lcidx) DecVal(nlcerr) DecVal(nlcidx) DecVal(dbgphase0its))

void minnlcsetbc(const minnlcstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetbc(ConstT(minnlcstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minnlcsetlc(const minnlcstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetlc(ConstT(minnlcstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnlcsetlc(const minnlcstate &state, const real_2d_array &c, const integer_1d_array &ct) {
   ae_int_t k = c.rows();
   if (k != ct.length()) ThrowError("Error while calling 'minnlcsetlc': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetlc(ConstT(minnlcstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#endif

void minnlcsetnlc(const minnlcstate &state, const ae_int_t nlec, const ae_int_t nlic) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetnlc(ConstT(minnlcstate, state), nlec, nlic);
   alglib_impl::ae_state_clear();
}

void minnlcsetcond(const minnlcstate &state, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetcond(ConstT(minnlcstate, state), epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minnlcsetscale(const minnlcstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetscale(ConstT(minnlcstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minnlcsetprecinexact(const minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetprecinexact(ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}

void minnlcsetprecexactlowrank(const minnlcstate &state, const ae_int_t updatefreq) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetprecexactlowrank(ConstT(minnlcstate, state), updatefreq);
   alglib_impl::ae_state_clear();
}

void minnlcsetprecexactrobust(const minnlcstate &state, const ae_int_t updatefreq) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetprecexactrobust(ConstT(minnlcstate, state), updatefreq);
   alglib_impl::ae_state_clear();
}

void minnlcsetprecnone(const minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetprecnone(ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}

void minnlcsetstpmax(const minnlcstate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetstpmax(ConstT(minnlcstate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void minnlcsetalgoaul(const minnlcstate &state, const double rho, const ae_int_t itscnt) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetalgoaul(ConstT(minnlcstate, state), rho, itscnt);
   alglib_impl::ae_state_clear();
}

void minnlcsetalgoslp(const minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetalgoslp(ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}

void minnlcsetalgosqp(const minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetalgosqp(ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}

void minnlcsetxrep(const minnlcstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcsetxrep(ConstT(minnlcstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minnlcrestartfrom(const minnlcstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcrestartfrom(ConstT(minnlcstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minnlccreate(const ae_int_t n, const real_1d_array &x, minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlccreate(n, ConstT(ae_vector, x), ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnlccreate(const real_1d_array &x, minnlcstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlccreate(n, ConstT(ae_vector, x), ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minnlccreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlccreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnlccreatef(const real_1d_array &x, const double diffstep, minnlcstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlccreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}
#endif

bool minnlciteration(const minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minnlciteration(ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     fvec    -   callback which calculates function vector fi[]
//                 at given point x
//     jac     -   callback which calculates function vector fi[]
//                 and Jacobian jac at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. This function has two different implementations: one which  uses  exact
//    (analytical) user-supplied Jacobian, and one which uses  only  function
//    vector and numerically  differentiates  function  in  order  to  obtain
//    gradient.
//
//    Depending  on  the  specific  function  used to create optimizer object
//    you should choose appropriate variant of MinNLCOptimize() -  one  which
//    accepts function AND Jacobian or one which accepts ONLY function.
//
//    Be careful to choose variant of MinNLCOptimize()  which  corresponds to
//    your optimization scheme! Table below lists different  combinations  of
//    callback (function/gradient) passed to MinNLCOptimize()   and  specific
//    function used to create optimizer.
//
//                      |         USER PASSED TO MinNLCOptimize()
//    CREATED WITH      |  function only   |  function and gradient
//    ------------------------------------------------------------
//    MinNLCCreateF()   |     works               FAILS
//    MinNLCCreate()    |     FAILS               works
//
//    Here "FAILS" denotes inappropriate combinations  of  optimizer creation
//    function  and  MinNLCOptimize()  version.   Attemps   to    use    such
//    combination will lead to exception. Either  you  did  not pass gradient
//    when it WAS needed or you passed gradient when it was NOT needed.
// ALGLIB: Copyright 06.06.2014 by Sergey Bochkanov
void minnlcoptimize(minnlcstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(fvec != NULL, "minnlcoptimize: fvec is NULL");
   while (alglib_impl::minnlciteration(state.c_ptr()))
   BegPoll
      if (state.needfi) fvec(state.x, state.fi, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minnlcoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minnlcoptimize(minnlcstate &state, void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(jac != NULL, "minnlcoptimize: jac is NULL");
   while (alglib_impl::minnlciteration(state.c_ptr()))
   BegPoll
      if (state.needfij) jac(state.x, state.fi, state.j, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minnlcoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minnlcoptguardgradient(const minnlcstate &state, const double teststep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcoptguardgradient(ConstT(minnlcstate, state), teststep);
   alglib_impl::ae_state_clear();
}

void minnlcoptguardsmoothness(const minnlcstate &state, const ae_int_t level) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcoptguardsmoothness(ConstT(minnlcstate, state), level);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnlcoptguardsmoothness(const minnlcstate &state) {
   ae_int_t level = 1;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcoptguardsmoothness(ConstT(minnlcstate, state), level);
   alglib_impl::ae_state_clear();
}
#endif

void minnlcoptguardresults(const minnlcstate &state, optguardreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcoptguardresults(ConstT(minnlcstate, state), ConstT(optguardreport, rep));
   alglib_impl::ae_state_clear();
}

void minnlcoptguardnonc1test0results(const minnlcstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcoptguardnonc1test0results(ConstT(minnlcstate, state), ConstT(optguardnonc1test0report, strrep), ConstT(optguardnonc1test0report, lngrep));
   alglib_impl::ae_state_clear();
}

void minnlcoptguardnonc1test1results(const minnlcstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcoptguardnonc1test1results(ConstT(minnlcstate, state), ConstT(optguardnonc1test1report, strrep), ConstT(optguardnonc1test1report, lngrep));
   alglib_impl::ae_state_clear();
}

void minnlcresultsbuf(const minnlcstate &state, real_1d_array &x, minnlcreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcresultsbuf(ConstT(minnlcstate, state), ConstT(ae_vector, x), ConstT(minnlcreport, rep));
   alglib_impl::ae_state_clear();
}

void minnlcresults(const minnlcstate &state, real_1d_array &x, minnlcreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcresults(ConstT(minnlcstate, state), ConstT(ae_vector, x), ConstT(minnlcreport, rep));
   alglib_impl::ae_state_clear();
}

void minnlcrequesttermination(const minnlcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnlcrequesttermination(ConstT(minnlcstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === MINNS Package ===
// Depends on: MINBLEIC
namespace alglib_impl {
// This function sets boundary constraints.
//
// Boundary constraints are inactive by default (after initial creation).
// They are preserved after algorithm restart with minnsrestartfrom().
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF.
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF.
//
// NOTE 1: it is possible to specify BndL[i] == BndU[i]. In this case I-th
// variable will be "frozen" at X[i] == BndL[i] == BndU[i].
//
// NOTE 2: AGS solver has following useful properties:
// * bound constraints are always satisfied exactly
// * function is evaluated only INSIDE area specified by  bound  constraints,
//   even  when  numerical  differentiation is used (algorithm adjusts  nodes
//   according to boundary constraints)
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnssetbc(const minnsstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minnssetbc(minnsstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->n;
   ae_assert(bndl->cnt >= n, "MinNSSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinNSSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinNSSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinNSSetBC: BndL contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
   }
}

// This function sets linear constraints.
//
// Linear constraints are inactive by default (after initial creation).
// They are preserved after algorithm restart with minnsrestartfrom().
//
// Inputs:
//     State   -   structure previously allocated with minnscreate() call.
//     C       -   linear constraints, array[K,N+1].
//                 Each row of C represents one constraint, either equality
//                 or inequality (see below):
//                 * first N elements correspond to coefficients,
//                 * last element corresponds to the right part.
//                 All elements of C (including right part) must be finite.
//     CT      -   type of constraints, array[K]:
//                 * if CT[i] > 0, then I-th constraint is C[i,*]*x >= C[i,n+1]
//                 * if CT[i] == 0, then I-th constraint is C[i,*]*x  = C[i,n+1]
//                 * if CT[i] < 0, then I-th constraint is C[i,*]*x <= C[i,n+1]
//     K       -   number of equality/inequality constraints, K >= 0:
//                 * if given, only leading K elements of C/CT are used
//                 * if not given, automatically determined from sizes of C/CT
//
// NOTE: linear (non-bound) constraints are satisfied only approximately:
//
// * there always exists some minor violation (about current sampling  radius
//   in magnitude during optimization, about EpsX in the solution) due to use
//   of penalty method to handle constraints.
// * numerical differentiation, if used, may  lead  to  function  evaluations
//   outside  of the feasible  area,   because   algorithm  does  NOT  change
//   numerical differentiation formula according to linear constraints.
//
// If you want constraints to be  satisfied  exactly, try to reformulate your
// problem  in  such  manner  that  all constraints will become boundary ones
// (this kind of constraints is always satisfied exactly, both in  the  final
// solution and in all intermediate points).
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnssetlc(const minnsstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k);
// API: void minnssetlc(const minnsstate &state, const real_2d_array &c, const integer_1d_array &ct);
void minnssetlc(minnsstate *state, RMatrix *c, ZVector *ct, ae_int_t k) {
   ae_int_t n;
   ae_int_t i;
   n = state->n;
// First, check for errors in the inputs
   ae_assert(k >= 0, "MinNSSetLC: K < 0");
   ae_assert(c->cols > n || k == 0, "MinNSSetLC: Cols(C) <= N");
   ae_assert(c->rows >= k, "MinNSSetLC: Rows(C) < K");
   ae_assert(ct->cnt >= k, "MinNSSetLC: Length(CT) < K");
   ae_assert(apservisfinitematrix(c, k, n + 1), "MinNSSetLC: C contains infinite or NaN values!");
// Handle zero K
   if (k == 0) {
      state->nec = 0;
      state->nic = 0;
      return;
   }
// Equality constraints are stored first, in the upper
// NEC rows of State.CLEIC matrix. Inequality constraints
// are stored in the next NIC rows.
//
// NOTE: we convert inequality constraints to the form
// A*x <= b before copying them.
   matrixsetlengthatleast(&state->cleic, k, n + 1);
   state->nec = 0;
   state->nic = 0;
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] == 0) {
         ae_v_move(state->cleic.xyR[state->nec], 1, c->xyR[i], 1, n + 1);
         state->nec++;
      }
   }
   for (i = 0; i < k; i++) {
      if (ct->xZ[i] != 0) {
         if (ct->xZ[i] > 0) {
            ae_v_moveneg(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         } else {
            ae_v_move(state->cleic.xyR[state->nec + state->nic], 1, c->xyR[i], 1, n + 1);
         }
         state->nic++;
      }
   }
}

// This function sets nonlinear constraints.
//
// In fact, this function sets NUMBER of nonlinear  constraints.  Constraints
// itself (constraint functions) are passed to minnsoptimize() method.   This
// method requires user-defined vector function F[]  and  its  Jacobian  J[],
// where:
// * first component of F[] and first row  of  Jacobian  J[]  correspond   to
//   function being minimized
// * next NLEC components of F[] (and rows  of  J)  correspond  to  nonlinear
//   equality constraints G_i(x) == 0
// * next NLIC components of F[] (and rows  of  J)  correspond  to  nonlinear
//   inequality constraints H_i(x) <= 0
//
// NOTE: you may combine nonlinear constraints with linear/boundary ones.  If
//       your problem has mixed constraints, you  may explicitly specify some
//       of them as linear ones. It may help optimizer to  handle  them  more
//       efficiently.
//
// Inputs:
//     State   -   structure previously allocated with minnscreate() call.
//     NLEC    -   number of Non-Linear Equality Constraints (NLEC), >= 0
//     NLIC    -   number of Non-Linear Inquality Constraints (NLIC), >= 0
//
// NOTE 1: nonlinear constraints are satisfied only  approximately!   It   is
//         possible   that  algorithm  will  evaluate  function  outside   of
//         the feasible area!
//
// NOTE 2: algorithm scales variables  according  to   scale   specified   by
//         minnssetscale()  function,  so  it can handle problems with  badly
//         scaled variables (as long as we KNOW their scales).
//
//         However,  there  is  no  way  to  automatically  scale   nonlinear
//         constraints Gi(x) and Hi(x). Inappropriate scaling  of  Gi/Hi  may
//         ruin convergence. Solving problem with  constraint  "1000*G0(x) == 0"
//         is NOT same as solving it with constraint "0.001*G0(x) == 0".
//
//         It  means  that  YOU  are  the  one who is responsible for correct
//         scaling of nonlinear constraints Gi(x) and Hi(x). We recommend you
//         to scale nonlinear constraints in such way that I-th component  of
//         dG/dX (or dH/dx) has approximately unit  magnitude  (for  problems
//         with unit scale)  or  has  magnitude approximately equal to 1/S[i]
//         (where S is a scale set by minnssetscale() function).
//
// NOTE 3: nonlinear constraints are always hard to handle,  no  matter  what
//         algorithm you try to use. Even basic box/linear constraints modify
//         function  curvature   by  adding   valleys  and  ridges.  However,
//         nonlinear constraints add valleys which are very  hard  to  follow
//         due to their "curved" nature.
//
//         It means that optimization with single nonlinear constraint may be
//         significantly slower than optimization with multiple linear  ones.
//         It is normal situation, and we recommend you to  carefully  choose
//         Rho parameter of minnssetalgoags(), because too  large  value  may
//         slow down convergence.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnssetnlc(const minnsstate &state, const ae_int_t nlec, const ae_int_t nlic);
void minnssetnlc(minnsstate *state, ae_int_t nlec, ae_int_t nlic) {
   ae_assert(nlec >= 0, "MinNSSetNLC: NLEC < 0");
   ae_assert(nlic >= 0, "MinNSSetNLC: NLIC < 0");
   state->ng = nlec;
   state->nh = nlic;
   ae_vector_set_length(&state->fi, 1 + state->ng + state->nh);
   ae_matrix_set_length(&state->j, 1 + state->ng + state->nh, state->n);
}

// This function sets stopping conditions for iterations of optimizer.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsX    -   >= 0
//                 The AGS solver finishes its work if  on  k+1-th  iteration
//                 sampling radius decreases below EpsX.
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited.
//
// Passing EpsX == 0  and  MaxIts == 0  (simultaneously)  will  lead  to  automatic
// stopping criterion selection. We do not recommend you to rely  on  default
// choice in production code.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnssetcond(const minnsstate &state, const double epsx, const ae_int_t maxits);
void minnssetcond(minnsstate *state, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsx), "MinNSSetCond: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinNSSetCond: negative EpsX");
   ae_assert(maxits >= 0, "MinNSSetCond: negative MaxIts!");
   if (epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function sets scaling coefficients for NLC optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Scaling is also used by finite difference variant of the optimizer  - step
// along I-th axis is equal to DiffStep*S[I].
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnssetscale(const minnsstate &state, const real_1d_array &s);
void minnssetscale(minnsstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->n, "MinNSSetScale: Length(S) < N");
   for (i = 0; i < state->n; i++) {
      ae_assert(isfinite(s->xR[i]), "MinNSSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinNSSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// This function tells MinNS unit to use  AGS  (adaptive  gradient  sampling)
// algorithm for nonsmooth constrained  optimization.  This  algorithm  is  a
// slight modification of one described in  "An  Adaptive  Gradient  Sampling
// Algorithm for Nonsmooth Optimization" by Frank E. Curtisy and Xiaocun Quez.
//
// This optimizer has following benefits and drawbacks:
// + robustness; it can be used with nonsmooth and nonconvex functions.
// + relatively easy tuning; most of the metaparameters are easy to select.
// - it has convergence of steepest descent, slower than CG/LBFGS.
// - each iteration involves evaluation of ~2N gradient values  and  solution
//   of 2Nx2N quadratic programming problem, which  limits  applicability  of
//   algorithm by small-scale problems (up to 50-100).
//
// IMPORTANT: this  algorithm  has  convergence  guarantees,   i.e.  it  will
//            steadily move towards some stationary point of the function.
//
//            However, "stationary point" does not  always  mean  "solution".
//            Nonsmooth problems often have "flat spots",  i.e.  areas  where
//            function do not change at all. Such "flat spots" are stationary
//            points by definition, and algorithm may be caught here.
//
//            Nonsmooth CONVEX tasks are not prone to  this  problem. Say, if
//            your function has form f() == MAX(f0,f1,...), and f_i are  convex,
//            then f() is convex too and you have guaranteed  convergence  to
//            solution.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     Radius  -   initial sampling radius, >= 0.
//
//                 Internally multiplied  by  vector of  per-variable  scales
//                 specified by minnssetscale()).
//
//                 You should select relatively large sampling radius, roughly
//                 proportional to scaled length of the first  steps  of  the
//                 algorithm. Something close to 0.1 in magnitude  should  be
//                 good for most problems.
//
//                 AGS solver can automatically decrease radius, so too large
//                 radius is  not a problem (assuming that you  won't  choose
//                 so large radius that algorithm  will  sample  function  in
//                 too far away points, where gradient value is irrelevant).
//
//                 Too small radius won't cause algorithm to fail, but it may
//                 slow down algorithm (it may  have  to  perform  too  short
//                 steps).
//     Penalty -   penalty coefficient for nonlinear constraints:
//                 * for problem with nonlinear constraints  should  be  some
//                   problem-specific  positive   value,  large  enough  that
//                   penalty term changes shape of the function.
//                   Starting  from  some  problem-specific   value   penalty
//                   coefficient becomes  large  enough  to  exactly  enforce
//                   nonlinear constraints;  larger  values  do  not  improve
//                   precision.
//                   Increasing it too much may slow down convergence, so you
//                   should choose it carefully.
//                 * can be zero for problems WITHOUT  nonlinear  constraints
//                   (i.e. for unconstrained ones or ones with  just  box  or
//                   linear constraints)
//                 * if you specify zero value for problem with at least  one
//                   nonlinear  constraint,  algorithm  will  terminate  with
//                   error code -1.
//
// ALGORITHM OUTLINE
//
// The very basic outline of unconstrained AGS algorithm is given below:
//
// 0. If sampling radius is below EpsX  or  we  performed  more  then  MaxIts
//    iterations - STOP.
// 1. sample O(N) gradient values at random locations  around  current point;
//    informally speaking, this sample is an implicit piecewise  linear model
//    of the function, although algorithm formulation does  not  mention that
//    explicitly
// 2. solve quadratic programming problem in order to find descent direction
// 3. if QP solver tells us that we  are  near  solution,  decrease  sampling
//    radius and move to (0)
// 4. perform backtracking line search
// 5. after moving to new point, goto (0)
//
// Constraint handling details:
// * box constraints are handled exactly by algorithm
// * linear/nonlinear constraints are handled by adding L1  penalty.  Because
//   our solver can handle nonsmoothness, we can  use  L1  penalty  function,
//   which is an exact one  (i.e.  exact  solution  is  returned  under  such
//   penalty).
// * penalty coefficient for  linear  constraints  is  chosen  automatically;
//   however, penalty coefficient for nonlinear constraints must be specified
//   by user.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnssetalgoags(const minnsstate &state, const double radius, const double penalty);
void minnssetalgoags(minnsstate *state, double radius, double penalty) {
   ae_assert(isfinite(radius), "MinNSSetAlgoAGS: Radius is not finite");
   ae_assert(radius > 0.0, "MinNSSetAlgoAGS: Radius <= 0");
   ae_assert(isfinite(penalty), "MinNSSetAlgoAGS: Penalty is not finite");
   ae_assert(penalty >= 0.0, "MinNSSetAlgoAGS: Penalty < 0");
   state->agsrhononlinear = penalty;
   state->agsradius = radius;
   state->solvertype = 0;
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to minnsoptimize().
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minnssetxrep(const minnsstate &state, const bool needxrep);
void minnssetxrep(minnsstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This subroutine restarts algorithm from new point.
// All optimization parameters (including constraints) are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have  same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure previously allocated with minnscreate() call.
//     X       -   new starting point.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnsrestartfrom(const minnsstate &state, const real_1d_array &x);
void minnsrestartfrom(minnsstate *state, RVector *x) {
   ae_int_t n;
   n = state->n;
// First, check for errors in the inputs
   ae_assert(x->cnt >= n, "MinNSRestartFrom: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinNSRestartFrom: X contains infinite or NaN values!");
// Set XC
   ae_v_move(state->xstart.xR, 1, x->xR, 1, n);
// prepare RComm facilities
   state->PQ = -1;
}

// Internal initialization subroutine.
// Sets default NLC solver with default criteria.
static void minns_minnsinitinternal(ae_int_t n, RVector *x, double diffstep, minnsstate *state) {
   ae_int_t i;
   EnFrame();
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
   state->agsinitstp = 0.2;
   state->agsstattold = sqrt(machineepsilon);
   state->agsshortstpabs = 1.0E-10;
   state->agsshortstprel = 0.75;
   state->agsshortf = 10.0 * machineepsilon;
   state->agsrhononlinear = 0.0;
   state->agsraddecay = 0.2;
   state->agsalphadecay = 0.5;
   state->agsdecrease = 0.1;
   state->agsmaxraddecays = 50;
   state->agsmaxbacktrack = 20;
   state->agsmaxbacktracknonfull = 8;
   state->agspenaltylevel = 50.0;
   state->agspenaltyincrease = 100.0;
   state->agsminupdate = imax2(5, n / 2);
   state->agssamplesize = imax2(2 * n + 1, state->agsminupdate + 1);
   state->agsshortlimit = 4 + state->agssamplesize / state->agsminupdate;
// Initialize other params
   state->n = n;
   state->diffstep = diffstep;
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->hasbndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->hasbndu, n);
   ae_vector_set_length(&state->s, n);
   ae_vector_set_length(&state->xstart, n);
   ae_vector_set_length(&state->xc, n);
   ae_vector_set_length(&state->xn, n);
   ae_vector_set_length(&state->d, n);
   ae_vector_set_length(&state->x, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = -INFINITY;
      state->hasbndl.xB[i] = false;
      state->bndu.xR[i] = +INFINITY;
      state->hasbndu.xB[i] = false;
      state->s.xR[i] = 1.0;
      state->xstart.xR[i] = x->xR[i];
      state->xc.xR[i] = x->xR[i];
   }
   minnssetlc(state, &c, &ct, 0);
   minnssetnlc(state, 0, 0);
   minnssetcond(state, 0.0, 0);
   minnssetxrep(state, false);
   minnssetalgoags(state, 0.1, 1000.0);
   minnsrestartfrom(state, x);
   DeFrame();
}

// NONSMOOTH NONCONVEX OPTIMIZATION
// SUBJECT TO BOX/LINEAR/NONLINEAR-NONSMOOTH CONSTRAINTS
// The  subroutine  minimizes  function   F(x)  of N arguments subject to any
// combination of:
// * bound constraints
// * linear inequality constraints
// * linear equality constraints
// * nonlinear equality constraints Gi(x) == 0
// * nonlinear inequality constraints Hi(x) <= 0
//
// IMPORTANT: see MinNSSetAlgoAGS for important  information  on  performance
//            restrictions of AGS solver.
//
// REQUIREMENTS:
// * starting point X0 must be feasible or not too far away from the feasible
//   set
// * F(), G(), H() are continuous, locally Lipschitz  and  continuously  (but
//   not necessarily twice) differentiable in an open dense  subset  of  R^N.
//   Functions F(), G() and H() may be nonsmooth and non-convex.
//   Informally speaking, it means  that  functions  are  composed  of  large
//   differentiable "patches" with nonsmoothness having  place  only  at  the
//   boundaries between these "patches".
//   Most real-life nonsmooth  functions  satisfy  these  requirements.  Say,
//   anything which involves finite number of abs(), min() and max() is  very
//   likely to pass the test.
//   Say, it is possible to optimize anything of the following:
//   * f == abs(x0)+2*abs(x1)
//   * f == max(x0,x1)
//   * f == sin(max(x0,x1)+abs(x2))
// * for nonlinearly constrained problems: F()  must  be  bounded from  below
//   without nonlinear constraints (this requirement is due to the fact that,
//   contrary to box and linear constraints, nonlinear ones  require  special
//   handling).
// * user must provide function value and gradient for F(), H(), G()  at  all
//   points where function/gradient can be calculated. If optimizer  requires
//   value exactly at the boundary between "patches" (say, at x == 0 for f == abs(x)),
//   where gradient is not defined, user may resolve tie arbitrarily (in  our
//   case - return +1 or -1 at its discretion).
// * NS solver supports numerical differentiation, i.e. it may  differentiate
//   your function for you,  but  it  results  in  2N  increase  of  function
//   evaluations. Not recommended unless you solve really small problems. See
//   minnscreatef() for more information on this functionality.
//
// USAGE:
//
// 1. User initializes algorithm state with MinNSCreate() call  and   chooses
//    what NLC solver to use. There is some solver which is used by  default,
//    with default settings, but you should NOT rely on  default  choice.  It
//    may change in future releases of ALGLIB without notice, and no one  can
//    guarantee that new solver will be  able  to  solve  your  problem  with
//    default settings.
//
//    From the other side, if you choose solver explicitly, you can be pretty
//    sure that it will work with new ALGLIB releases.
//
//    In the current release following solvers can be used:
//    * AGS solver (activated with MinNSSetAlgoAGS() function)
//
// 2. User adds boundary and/or linear and/or nonlinear constraints by  means
//    of calling one of the following functions:
//    a) MinNSSetBC() for boundary constraints
//    b) MinNSSetLC() for linear constraints
//    c) MinNSSetNLC() for nonlinear constraints
//    You may combine (a), (b) and (c) in one optimization problem.
//
// 3. User sets scale of the variables with MinNSSetScale() function. It   is
//    VERY important to set  scale  of  the  variables,  because  nonlinearly
//    constrained problems are hard to solve when variables are badly scaled.
//
// 4. User sets stopping conditions with MinNSSetCond().
//
// 5. Finally, user calls MinNSOptimize()  function  which  takes   algorithm
//    state and pointer (delegate, etc) to callback function which calculates
//    F/G/H.
//
// 7. User calls MinNSResults() to get solution
//
// 8. Optionally user may call MinNSRestartFrom() to solve   another  problem
//    with same N but another starting point. MinNSRestartFrom()  allows   to
//    reuse already initialized structure.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   starting point, array[N]:
//                 * it is better to set X to a feasible point
//                 * but X can be infeasible, in which case algorithm will try
//                   to find feasible point first, using X as initial
//                   approximation.
//
// Outputs:
//     State   -   structure stores algorithm state
//
// NOTE: minnscreatef() function may be used if  you  do  not  have  analytic
//       gradient.   This   function  creates  solver  which  uses  numerical
//       differentiation with user-specified step.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnscreate(const ae_int_t n, const real_1d_array &x, minnsstate &state);
// API: void minnscreate(const real_1d_array &x, minnsstate &state);
void minnscreate(ae_int_t n, RVector *x, minnsstate *state) {
   SetObj(minnsstate, state);
   ae_assert(n >= 1, "MinNSCreate: N < 1");
   ae_assert(x->cnt >= n, "MinNSCreate: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinNSCreate: X contains infinite or NaN values");
   minns_minnsinitinternal(n, x, 0.0, state);
}

// Version of minnscreatef() which uses numerical differentiation. I.e.,  you
// do not have to calculate derivatives yourself. However, this version needs
// 2N times more function evaluations.
//
// 2-point differentiation formula is  used,  because  more  precise  4-point
// formula is unstable when used on non-smooth functions.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   starting point, array[N]:
//                 * it is better to set X to a feasible point
//                 * but X can be infeasible, in which case algorithm will try
//                   to find feasible point first, using X as initial
//                   approximation.
//     DiffStep-   differentiation  step,  DiffStep > 0.   Algorithm   performs
//                 numerical differentiation  with  step  for  I-th  variable
//                 being equal to DiffStep*S[I] (here S[] is a  scale vector,
//                 set by minnssetscale() function).
//                 Do not use  too  small  steps,  because  it  may  lead  to
//                 catastrophic cancellation during intermediate calculations.
//
// Outputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnscreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minnsstate &state);
// API: void minnscreatef(const real_1d_array &x, const double diffstep, minnsstate &state);
void minnscreatef(ae_int_t n, RVector *x, double diffstep, minnsstate *state) {
   SetObj(minnsstate, state);
   ae_assert(n >= 1, "MinNSCreateF: N < 1");
   ae_assert(x->cnt >= n, "MinNSCreateF: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinNSCreateF: X contains infinite or NaN values");
   ae_assert(isfinite(diffstep), "MinNSCreateF: DiffStep is infinite or NaN!");
   ae_assert(diffstep > 0.0, "MinNSCreateF: DiffStep is non-positive!");
   minns_minnsinitinternal(n, x, diffstep, state);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnsrequesttermination(const minnsstate &state);
void minnsrequesttermination(minnsstate *state) {
   state->userterminationneeded = true;
}

// This function performs transformation of  X  from  scaled  coordinates  to
// unscaled ones, paying special attention to box constraints:
// * points which were exactly at the boundary before scaling will be  mapped
//   to corresponding boundary after scaling
// * in any case, unscaled box constraints will be satisfied
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
static void minns_unscalepointbc(minnsstate *state, RVector *x) {
   ae_int_t i;
   for (i = 0; i < state->n; i++) {
      if (state->hasbndl.xB[i] && x->xR[i] <= state->scaledbndl.xR[i]) {
         x->xR[i] = state->bndl.xR[i];
         continue;
      }
      if (state->hasbndu.xB[i] && x->xR[i] >= state->scaledbndu.xR[i]) {
         x->xR[i] = state->bndu.xR[i];
         continue;
      }
      x->xR[i] *= state->s.xR[i];
      if (state->hasbndl.xB[i] && x->xR[i] <= state->bndl.xR[i]) {
         x->xR[i] = state->bndl.xR[i];
      }
      if (state->hasbndu.xB[i] && x->xR[i] >= state->bndu.xR[i]) {
         x->xR[i] = state->bndu.xR[i];
      }
   }
}

// Function/gradient calculation for QP solver.
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
static void minns_qpcalculategradfunc(RMatrix *sampleg, RVector *diagh, ae_int_t nsample, ae_int_t nvars, RVector *coeffs, RVector *g, double *f, RVector *tmp) {
   ae_int_t i;
   ae_int_t j;
   double v;
   *f = 0.0;
   vectorsetlengthatleast(g, nsample);
   vectorsetlengthatleast(tmp, nvars);
// Calculate GS*p
   for (j = 0; j < nvars; j++) {
      tmp->xR[j] = 0.0;
   }
   for (i = 0; i < nsample; i++) {
      v = coeffs->xR[i];
      ae_v_addd(tmp->xR, 1, sampleg->xyR[i], 1, nvars, v);
   }
// Calculate F
   *f = 0.0;
   for (i = 0; i < nvars; i++) {
      *f += 0.5 * sqr(tmp->xR[i]) / diagh->xR[i];
   }
// Multiply by inverse Hessian
   for (i = 0; i < nvars; i++) {
      tmp->xR[i] /= diagh->xR[i];
   }
// Function gradient
   for (i = 0; i < nsample; i++) {
      v = ae_v_dotproduct(sampleg->xyR[i], 1, tmp->xR, 1, nvars);
      g->xR[i] = v;
   }
}

// Function calculation for QP solver.
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
static void minns_qpcalculatefunc(RMatrix *sampleg, RVector *diagh, ae_int_t nsample, ae_int_t nvars, RVector *coeffs, double *f, RVector *tmp) {
   ae_int_t i;
   ae_int_t j;
   double v;
   *f = 0.0;
   vectorsetlengthatleast(tmp, nvars);
// Calculate GS*p
   for (j = 0; j < nvars; j++) {
      tmp->xR[j] = 0.0;
   }
   for (i = 0; i < nsample; i++) {
      v = coeffs->xR[i];
      ae_v_addd(tmp->xR, 1, sampleg->xyR[i], 1, nvars, v);
   }
// Calculate F
   *f = 0.0;
   for (i = 0; i < nvars; i++) {
      *f += 0.5 * sqr(tmp->xR[i]) / diagh->xR[i];
   }
}

// Triangular solver for QP solver.
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
static void minns_qpsolveu(RMatrix *a, ae_int_t n, RVector *x) {
   ae_int_t i;
   ae_int_t j;
   double v;
// A^(-1)*X
   for (i = n - 1; i >= 0; i--) {
      v = x->xR[i];
      for (j = i + 1; j < n; j++) {
         v -= a->xyR[i][j] * x->xR[j];
      }
      x->xR[i] = v / a->xyR[i][i];
   }
}

// Triangular solver for QP solver.
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
static void minns_qpsolveut(RMatrix *a, ae_int_t n, RVector *x) {
   ae_int_t i;
   ae_int_t j;
   double v;
// A^(-T)*X
   for (i = 0; i < n; i++) {
      x->xR[i] /= a->xyR[i][i];
      v = x->xR[i];
      for (j = i + 1; j < n; j++) {
         x->xR[j] -= a->xyR[i][j] * v;
      }
   }
}

// This function solves QP problem of the form
//
//         [                        ]
//     min [ 0.5*c'*(G*inv(H)*G')*c ] s.t. c[i] >= 0, SUM(c[i]) == 1.0
//         [                        ]
//
// where G is stored in SampleG[] array, diagonal H is stored in DiagH[].
//
// DbgNCholesky is incremented every time we perform Cholesky decomposition.
// ALGLIB: Copyright 02.06.2015 by Sergey Bochkanov
static void minns_solveqp(RMatrix *sampleg, RVector *diagh, ae_int_t nsample, ae_int_t nvars, RVector *coeffs, ae_int_t *dbgncholesky, minnsqp *state) {
   ae_int_t i;
   ae_int_t j;
   ae_int_t k;
   double v;
   double vv;
   ae_int_t n;
   ae_int_t idx0;
   ae_int_t idx1;
   ae_int_t ncandbnd;
   ae_int_t innerits;
   ae_int_t outerits;
   double dnrm;
   double stp;
   double stpmax;
   ae_int_t actidx;
   double dtol;
   bool kickneeded;
   double kicklength;
   double lambdav;
   double maxdiag;
   bool wasactivation;
   bool werechanges;
   ae_int_t termcnt;
   n = nsample;
// Allocate arrays, prepare data
   vectorsetlengthatleast(coeffs, n);
   vectorsetlengthatleast(&state->xc, n);
   vectorsetlengthatleast(&state->xn, n);
   vectorsetlengthatleast(&state->x0, n);
   vectorsetlengthatleast(&state->gc, n);
   vectorsetlengthatleast(&state->d, n);
   matrixsetlengthatleast(&state->uh, n, n);
   matrixsetlengthatleast(&state->ch, n, n);
   matrixsetlengthatleast(&state->rk, nsample, nvars);
   vectorsetlengthatleast(&state->invutc, n);
   vectorsetlengthatleast(&state->tmp0, n);
   vectorsetlengthatleast(&state->tmpb, n);
   for (i = 0; i < n; i++) {
      state->xc.xR[i] = 1.0 / n;
      coeffs->xR[i] = 1.0 / n;
   }
   for (i = 0; i < nsample; i++) {
      for (j = 0; j < nvars; j++) {
         state->rk.xyR[i][j] = sampleg->xyR[i][j] / sqrt(diagh->xR[j]);
      }
   }
   rmatrixsyrk(nsample, nvars, 1.0, &state->rk, 0, 0, 0, 0.0, &state->uh, 0, 0, true);
   maxdiag = 0.0;
   for (i = 0; i < nsample; i++) {
      maxdiag = rmax2(maxdiag, state->uh.xyR[i][i]);
   }
   maxdiag = coalesce(maxdiag, 1.0);
// Main cycle:
   innerits = 0;
   outerits = 0;
   dtol = 100000.0 * machineepsilon;
   kicklength = machineepsilon;
   lambdav = 100000.0 * machineepsilon;
   termcnt = 0;
   while (true) {
   // Save current point to X0
      ae_v_move(state->x0.xR, 1, state->xc.xR, 1, n);
   // Calculate gradient at initial point, solve NNLS problem
   // to determine descent direction D subject to constraints.
   //
   // In order to do so we solve following constrained
   // minimization problem:
   //         (                         )^2
   //     min ( SUM(lambda[i]*A[i]) + G )
   //         (                         )
   // Here:
   // * G is a gradient (column vector)
   // * A[i] is a column vector of I-th constraint
   // * lambda[i] is a Lagrange multiplier corresponding to I-th constraint
   //
   // NOTE: all A[i] except for last one have only one element being set,
   //       so we rely on sparse capabilities of NNLS solver. However,
   //       in order to use these capabilities we have to reorder variables
   //       in such way that sparse ones come first.
   //
   // After finding lambda[] coefficients, we can find constrained descent
   // direction by subtracting lambda[i]*A[i] from D == -G. We make use of the
   // fact that first NCandBnd columns are just columns of identity matrix,
   // so we can perform exact projection by explicitly setting elements of D
   // to zeros.
      minns_qpcalculategradfunc(sampleg, diagh, nsample, nvars, &state->xc, &state->gc, &state->fc, &state->tmp0);
      vectorsetlengthatleast(&state->tmpidx, n);
      vectorsetlengthatleast(&state->tmpd, n);
      matrixsetlengthatleast(&state->tmpc2, n, 1);
      idx0 = 0;
      ncandbnd = 0;
      for (i = 0; i < n; i++) {
         if (state->xc.xR[i] == 0.0) {
            ncandbnd++;
         }
      }
      idx1 = ncandbnd;
      for (i = 0; i < n; i++) {
         if (state->xc.xR[i] == 0.0) {
         // Candidate for activation of boundary constraint,
         // comes first.
         //
         // NOTE: multiplication by -1 is due to the fact that
         //       it is lower bound, and has specific direction
         //       of constraint gradient.
            state->tmpidx.xZ[idx0] = i;
            state->tmpd.xR[idx0] = (-state->gc.xR[i]) * (-1);
            state->tmpc2.xyR[idx0][0] = 1.0 * (-1);
            idx0++;
         } else {
         // We are far away from boundary.
            state->tmpidx.xZ[idx1] = i;
            state->tmpd.xR[idx1] = -state->gc.xR[i];
            state->tmpc2.xyR[idx1][0] = 1.0;
            idx1++;
         }
      }
      ae_assert(idx0 == ncandbnd, "MinNSQP: integrity check failed (2346)");
      ae_assert(idx1 == n, "MinNSQP: integrity check failed (4535)");
      snnlsinit(n, 1, n, &state->nnls);
      snnlssetproblem(&state->nnls, &state->tmpc2, &state->tmpd, ncandbnd, 1, n);
      snnlsdropnnc(&state->nnls, ncandbnd);
      snnlssolve(&state->nnls, &state->tmplambdas);
      for (i = 0; i < n; i++) {
         state->d.xR[i] = -state->gc.xR[i] - state->tmplambdas.xR[ncandbnd];
      }
      for (i = 0; i < ncandbnd; i++) {
         if (state->tmplambdas.xR[i] > 0.0) {
            state->d.xR[state->tmpidx.xZ[i]] = 0.0;
         }
      }
   // Additional stage to "polish" D (improve situation
   // with sum-to-one constraint and boundary constraints)
   // and to perform additional integrity check.
   //
   // After this stage we are pretty sure that:
   // * if x[i] == 0.0, then d[i] >= 0.0
   // * if d[i] < 0.0, then x[i] > 0.0
      for (i = 0; i < n; i++) {
         if (state->xc.xR[i] == 0.0 && state->d.xR[i] < 0.0) {
            state->d.xR[i] = 0.0;
         }
      }
   // Decide whether we need "kick" stage: special stage
   // that moves us away from boundary constraints which are
   // not strictly active (i.e. such constraints that x[i] == 0.0 and d[i] > 0).
   //
   // If we need kick stage, we make a kick - and restart iteration.
   // If not, after this block we can rely on the fact that
   // for all x[i] == 0.0 we have d[i] == 0.0
      kickneeded = false;
      for (i = 0; i < n; i++) {
         if (state->xc.xR[i] == 0.0 && state->d.xR[i] > 0.0) {
            kickneeded = true;
         }
      }
      if (kickneeded) {
      // Perform kick.
      // Restart.
      // Do not increase outer iterations counter.
         v = 0.0;
         for (i = 0; i < n; i++) {
            if (state->xc.xR[i] == 0.0 && state->d.xR[i] > 0.0) {
               state->xc.xR[i] += kicklength;
            }
            v += state->xc.xR[i];
         }
         ae_assert(v > 0.0, "MinNSQP: integrity check failed (2572)");
         for (i = 0; i < n; i++) {
            state->xc.xR[i] /= v;
         }
         innerits++;
         continue;
      }
   // Calculate Cholesky decomposition of constrained Hessian
   // for Newton phase.
      while (true) {
         for (i = 0; i < n; i++) {
         // Diagonal element
            if (state->xc.xR[i] > 0.0) {
               state->ch.xyR[i][i] = state->uh.xyR[i][i] + lambdav * maxdiag;
            } else {
               state->ch.xyR[i][i] = 1.0;
            }
         // Offdiagonal elements
            for (j = i + 1; j < n; j++) {
               if (state->xc.xR[i] > 0.0 && state->xc.xR[j] > 0.0) {
                  state->ch.xyR[i][j] = state->uh.xyR[i][j];
               } else {
                  state->ch.xyR[i][j] = 0.0;
               }
            }
         }
         ++*dbgncholesky;
         if (!spdmatrixcholeskyrec(&state->ch, 0, n, true, &state->tmp0)) {
         // Cholesky decomposition failed.
         // Increase LambdaV and repeat iteration.
         // Do not increase outer iterations counter.
            lambdav *= 10.0;
            continue;
         }
         break;
      }
   // Newton phase
      while (true) {
      // Calculate constrained (equality and sum-to-one) descent direction D.
      //
      // Here we use Sherman-Morrison update to calculate direction subject to
      // sum-to-one constraint.
         minns_qpcalculategradfunc(sampleg, diagh, nsample, nvars, &state->xc, &state->gc, &state->fc, &state->tmp0);
         for (i = 0; i < n; i++) {
            if (state->xc.xR[i] > 0.0) {
               state->invutc.xR[i] = 1.0;
               state->d.xR[i] = -state->gc.xR[i];
            } else {
               state->invutc.xR[i] = 0.0;
               state->d.xR[i] = 0.0;
            }
         }
         minns_qpsolveut(&state->ch, n, &state->invutc);
         minns_qpsolveut(&state->ch, n, &state->d);
         v = 0.0;
         vv = 0.0;
         for (i = 0; i < n; i++) {
            vv += sqr(state->invutc.xR[i]);
            v += state->invutc.xR[i] * state->d.xR[i];
         }
         for (i = 0; i < n; i++) {
            state->d.xR[i] -= v / vv * state->invutc.xR[i];
         }
         minns_qpsolveu(&state->ch, n, &state->d);
         v = 0.0;
         k = 0;
         for (i = 0; i < n; i++) {
            v += state->d.xR[i];
            if (state->d.xR[i] != 0.0) {
               k++;
            }
         }
         if (k > 0 && v > 0.0) {
            vv = v / k;
            for (i = 0; i < n; i++) {
               if (state->d.xR[i] != 0.0) {
                  state->d.xR[i] -= vv;
               }
            }
         }
      // Calculate length of D, maximum step and component which is
      // activated by this step.
      //
      // Break if D is exactly zero. We do not break here if DNrm is
      // small - this check is performed later. It is important to
      // perform last step with nearly-zero D, it allows us to have
      // extra-precision in solution which is often needed for convergence
      // of AGS algorithm.
         dnrm = 0.0;
         for (i = 0; i < n; i++) {
            dnrm += sqr(state->d.xR[i]);
         }
         dnrm = sqrt(dnrm);
         actidx = -1;
         stpmax = 1.0E50;
         for (i = 0; i < n; i++) {
            if (state->d.xR[i] < 0.0) {
               v = stpmax;
               stpmax = safeminposrv(state->xc.xR[i], -state->d.xR[i], stpmax);
               if (stpmax < v) {
                  actidx = i;
               }
            }
         }
         if (dnrm == 0.0) {
            break;
         }
      // Calculate trial function value at unconstrained full step.
      // If trial value is greater or equal to FC, terminate iterations.
         for (i = 0; i < n; i++) {
            state->xn.xR[i] = state->xc.xR[i] + 1.0 * state->d.xR[i];
         }
         minns_qpcalculatefunc(sampleg, diagh, nsample, nvars, &state->xn, &state->fn, &state->tmp0);
         if (state->fn >= state->fc) {
            break;
         }
      // Perform step
      // Update Hessian
      // Update XC
      //
      // Break if:
      // a) no constraint was activated
      // b) norm of D is small enough
         stp = rmin2(1.0, stpmax);
         for (i = 0; i < n; i++) {
            state->xn.xR[i] = rmax2(state->xc.xR[i] + stp * state->d.xR[i], 0.0);
         }
         if (stp == stpmax && actidx >= 0) {
            state->xn.xR[actidx] = 0.0;
         }
         wasactivation = false;
         for (i = 0; i < n; i++) {
            state->tmpb.xB[i] = state->xn.xR[i] == 0.0 && state->xc.xR[i] != 0.0;
            wasactivation = wasactivation || state->tmpb.xB[i];
         }
         ae_v_move(state->xc.xR, 1, state->xn.xR, 1, n);
         if (!wasactivation) {
            break;
         }
         if (dnrm <= dtol) {
            break;
         }
         spdmatrixcholeskyupdatefixbuf(&state->ch, n, true, &state->tmpb, &state->tmp0);
      }
   // Compare status of boundary constraints - if nothing changed during
   // last outer iteration, TermCnt is increased. Otherwise it is reset
   // to zero.
   //
   // When TermCnt is large enough, we terminate algorithm.
      werechanges = false;
      for (i = 0; i < n; i++) {
         werechanges = werechanges || sign(state->x0.xR[i]) != sign(state->xc.xR[i]);
      }
      if (!werechanges) {
         termcnt++;
      } else {
         termcnt = 0;
      }
      if (termcnt >= 2) {
         break;
      }
   // Increase number of outer iterations.
   // Break if we performed too many.
      outerits++;
      if (outerits == 10) {
         break;
      }
   }
// Store result
   for (i = 0; i < n; i++) {
      coeffs->xR[i] = state->xc.xR[i];
   }
}

// This function performs actual processing for AUL algorith. It expects that
// caller redirects its reverse communication  requests  NeedFiJ/XUpdated  to
// external user who will provide analytic derivative (or handle reports about
// progress).
//
// In case external user does not have analytic derivative, it is responsibility
// of caller to intercept NeedFiJ request and  replace  it  with  appropriate
// numerical differentiation scheme.
// ALGLIB: Copyright 06.06.2015 by Sergey Bochkanov
static bool minns_agsiteration(minnsstate *state) {
   AutoS ae_int_t n;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t ng;
   AutoS ae_int_t nh;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t k;
   AutoS double radius0;
   AutoS double radius;
   AutoS ae_int_t radiusdecays;
   AutoS double alpha;
   AutoS double recommendedstep;
   AutoS double dhd;
   AutoS double dnrminf;
   AutoS double v;
   AutoS double vv;
   AutoS ae_int_t maxsamplesize;
   AutoS ae_int_t cursamplesize;
   AutoS double v0;
   AutoS double v1;
   AutoS bool b;
   AutoS bool alphadecreased;
   AutoS ae_int_t shortstepscnt;
   AutoS ae_int_t backtrackits;
   AutoS ae_int_t maxbacktrackits;
   AutoS bool fullsample;
   AutoS double currentf0;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->AgsPQ >= 0) switch (state->AgsPQ) {
      case 0: goto Resume0; case 1: goto Resume1; case 2: goto Resume2; case 3: goto Resume3;
      default: goto Exit;
   }
Spawn:
   ae_assert(state->solvertype == 0, "MinNS: internal error");
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   ng = state->ng;
   nh = state->nh;
// Check consistency of parameters
   if (ng + nh > 0 && state->agsrhononlinear == 0.0) {
      state->repterminationtype = -1;
      goto Exit;
   }
// Allocate arrays.
   vectorsetlengthatleast(&state->colmax, n);
   vectorsetlengthatleast(&state->diagh, n);
   vectorsetlengthatleast(&state->signmin, n);
   vectorsetlengthatleast(&state->signmax, n);
   maxsamplesize = state->agssamplesize;
   matrixsetlengthatleast(&state->samplex, maxsamplesize + 1, n);
   matrixsetlengthatleast(&state->samplegm, maxsamplesize + 1, n);
   matrixsetlengthatleast(&state->samplegmbc, maxsamplesize + 1, n);
   vectorsetlengthatleast(&state->samplef, maxsamplesize + 1);
// Prepare optimizer
   vectorsetlengthatleast(&state->tmp0, maxsamplesize);
   vectorsetlengthatleast(&state->tmp1, maxsamplesize);
   vectorsetlengthatleast(&state->tmp3, 1);
   matrixsetlengthatleast(&state->tmp2, 1, maxsamplesize + 1);
   for (i = 0; i < maxsamplesize; i++) {
      state->tmp0.xR[i] = 0.0;
      state->tmp1.xR[i] = +INFINITY;
   }
// Prepare RNG, seed it with fixed values so
// that each run on same problem yeilds same results
   hqrndseed(7235, 98532, &state->agsrs);
// Prepare initial point subject to current bound constraints and
// perform scaling of bound constraints, linear constraints, point itself
   vectorsetlengthatleast(&state->scaledbndl, n);
   vectorsetlengthatleast(&state->scaledbndu, n);
   for (i = 0; i < n; i++) {
   // Check and scale constraints
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndu.xR[i] < state->bndl.xR[i]) {
         state->repterminationtype = -3;
         goto Exit;
      }
      if (state->hasbndl.xB[i]) {
         state->scaledbndl.xR[i] = state->bndl.xR[i] / state->s.xR[i];
      } else {
         state->scaledbndl.xR[i] = -INFINITY;
      }
      if (state->hasbndu.xB[i]) {
         state->scaledbndu.xR[i] = state->bndu.xR[i] / state->s.xR[i];
      } else {
         state->scaledbndu.xR[i] = +INFINITY;
      }
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i]) {
         ae_assert(state->scaledbndl.xR[i] <= state->scaledbndu.xR[i], "MinNS: integrity check failed (dfdf)");
      }
      if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->bndl.xR[i] == state->bndu.xR[i]) {
         ae_assert(state->scaledbndl.xR[i] == state->scaledbndu.xR[i], "MinNS: integrity check failed (dsgh)");
      }
   // Scale and constrain point
      state->xc.xR[i] = state->xstart.xR[i];
      if (state->hasbndl.xB[i] && state->xc.xR[i] <= state->bndl.xR[i]) {
         state->xc.xR[i] = state->scaledbndl.xR[i];
         continue;
      }
      if (state->hasbndu.xB[i] && state->xc.xR[i] >= state->bndu.xR[i]) {
         state->xc.xR[i] = state->scaledbndu.xR[i];
         continue;
      }
      state->xc.xR[i] /= state->s.xR[i];
      if (state->hasbndl.xB[i] && state->xc.xR[i] <= state->scaledbndl.xR[i]) {
         state->xc.xR[i] = state->scaledbndl.xR[i];
      }
      if (state->hasbndu.xB[i] && state->xc.xR[i] >= state->scaledbndu.xR[i]) {
         state->xc.xR[i] = state->scaledbndu.xR[i];
      }
   }
   matrixsetlengthatleast(&state->scaledcleic, nec + nic, n + 1);
   for (i = 0; i < nec + nic; i++) {
   // Scale and normalize linear constraints
      vv = 0.0;
      for (j = 0; j < n; j++) {
         v = state->cleic.xyR[i][j] * state->s.xR[j];
         state->scaledcleic.xyR[i][j] = v;
         vv += v * v;
      }
      vv = sqrt(vv);
      state->scaledcleic.xyR[i][n] = state->cleic.xyR[i][n];
      if (vv > 0.0) {
         for (j = 0; j <= n; j++) {
            state->scaledcleic.xyR[i][j] /= vv;
         }
      }
   }
// Main cycle
//
// We maintain several variables during iteration:
// * RecommendedStep-   current estimate of recommended step length;
//                      must be Radius0 on first entry
// * Radius         -   current sampling radius
// * CurSampleSize  -   current sample size (may change in future versions)
// * FullSample     -   whether we have full sample, or only partial one
// * RadiusDecays   -   total number of decreases performed for sampling radius
   radius = state->agsradius;
   radius0 = radius;
   recommendedstep = rmin2(radius0, state->agsinitstp);
   cursamplesize = 1;
   radiusdecays = 0;
   shortstepscnt = 0;
   fullsample = false;
   state->rholinear = 0.0;
   while (true) {
   // First phase of iteration - central point:
   //
   // 1. evaluate function at central point - first entry in sample.
   //    Its status is ignored, it is always recalculated.
   // 2. report point and check gradient/function value for NAN/INF
   // 3. check penalty coefficients for linear terms; increase them
   //    if directional derivative of function being optimized (not
   //    merit function!) is larger than derivative of penalty.
   // 4. update report on constraint violation
      cursamplesize = imax2(cursamplesize, 1);
      ae_v_move(state->samplex.xyR[0], 1, state->xc.xR, 1, n);
      ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
      state->needfij = true, state->AgsPQ = 0; goto Pause; Resume0: state->needfij = false;
      currentf0 = state->rawf;
      state->replcerr = 0.0;
      for (i = 0; i < nec + nic; i++) {
         v = -state->scaledcleic.xyR[i][n];
         for (j = 0; j < n; j++) {
            v += state->scaledcleic.xyR[i][j] * state->xc.xR[j];
         }
         if (i >= nec && v <= 0.0) {
            continue;
         }
         state->replcerr = rmax2(state->replcerr, fabs(v));
      }
      state->repnlcerr = 0.0;
      for (i = 1; i <= ng + nh; i++) {
         v = state->fi.xR[i];
         if (i > ng && v <= 0.0) {
            continue;
         }
         state->repnlcerr = rmax2(state->repnlcerr, fabs(v));
      }
      state->samplef.xR[0] = state->meritf;
      rcopyvr(n, &state->meritg, &state->samplegm, 0);
      if (state->xrep) {
         ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
         state->f = currentf0;
         state->xupdated = true, state->AgsPQ = 1; goto Pause; Resume1: state->xupdated = false;
      }
      if (state->userterminationneeded) {
      // User requested termination
         state->repterminationtype = 8;
         break;
      }
      v = 0.0;
      for (i = 0; i < n; i++) {
         v += sqr(state->samplegm.xyR[0][i]);
      }
      if (!isfinite(v) || !isfinite(state->samplef.xR[0])) {
      // Abnormal termination - infinities in function/gradient
         state->repterminationtype = -8;
         break;
      }
      ae_assert(state->agspenaltylevel > 1.0, "MinNS: integrity error");
      ae_assert(state->agspenaltyincrease > state->agspenaltylevel, "MinNS: integrity error");
      if (sqrt(rdotv2(n, &state->rawg)) * state->agspenaltylevel > state->rholinear) {
         state->rholinear = sqrt(rdotv2(n, &state->rawg)) * state->agspenaltyincrease;
         cursamplesize = 0;
         continue;
      }
   // Check stopping conditions.
      if (radiusdecays >= state->agsmaxraddecays) {
      // Too many attempts to decrease radius
         state->repterminationtype = 7;
         break;
      } else if (state->repinneriterationscount >= state->maxits && state->maxits > 0) {
      // Too many iterations
         state->repterminationtype = 5;
         break;
      } else if (radius <= state->epsx * state->agsraddecay) {
      // Radius is smaller than required step tolerance multiplied by radius decay.
      //
      // Additional decay is required in order to make sure that optimization session
      // with radius equal to EpsX was successfully done.
         state->repterminationtype = 2;
         break;
      }
   // Update sample:
   //
   // 1. invalidate entries which are too far away from XC
   //    and move all valid entries to beginning of the sample.
   // 2. add new entries until we have AGSSampleSize
   //    items in our sample. We remove oldest entries from
   //    sample until we have enough place to add at least
   //    AGSMinUpdate items.
   // 3. prepare "modified" gradient sample with respect to
   //    boundary constraints.
      ae_assert(cursamplesize >= 1, "MinNS: integrity check failed (2367)");
      k = 1;
      for (i = 1; i < cursamplesize; i++) {
      // If entry is outside of Radius-ball around XC, discard it.
         v = 0.0;
         for (j = 0; j < n; j++) {
            v = rmax2(v, fabs(state->samplex.xyR[i][j] - state->xc.xR[j]));
         }
         if (v > radius) {
            continue;
         }
      // Move to the beginning
         rcopyrr(n, &state->samplex, i, &state->samplex, k);
         rcopyrr(n, &state->samplegm, i, &state->samplegm, k);
         state->samplef.xR[k] = state->samplef.xR[i];
         k++;
      }
      cursamplesize = k;
      if (state->agssamplesize - cursamplesize < state->agsminupdate) {
      // Remove oldest entries
         k = state->agsminupdate - (state->agssamplesize - cursamplesize);
         ae_assert(k < cursamplesize, "MinNS: integrity check failed (2662)");
         for (i = 1; i < cursamplesize - k; i++) {
            rcopyrr(n, &state->samplex, i + k, &state->samplex, i);
            rcopyrr(n, &state->samplegm, i + k, &state->samplegm, i);
            state->samplef.xR[i] = state->samplef.xR[i + k];
         }
         cursamplesize -= k;
      }
      for (k = 0, i = cursamplesize; i < imin2(cursamplesize + state->agsminupdate, state->agssamplesize); k++, i++) {
         for (j = 0; j < n; j++) {
         // Undistorted position
            state->samplex.xyR[i][j] = state->xc.xR[j];
         // Do not apply distortion if the variable is fixed
            if (state->hasbndl.xB[j] && state->hasbndu.xB[j] && state->scaledbndl.xR[j] == state->scaledbndu.xR[j]) {
               continue;
            }
         // Apply distortion
            if (hqrnduniformr(&state->agsrs) >= 0.5) {
            // Sample at the left side with 50% probability
               v0 = state->samplex.xyR[i][j] - radius;
               v1 = state->samplex.xyR[i][j];
               if (state->hasbndl.xB[j]) {
                  v0 = rmax2(state->scaledbndl.xR[j], v0);
               }
            } else {
            // Sample at the right side with 50% probability
               v0 = state->samplex.xyR[i][j];
               v1 = state->samplex.xyR[i][j] + radius;
               if (state->hasbndu.xB[j]) {
                  v1 = rmin2(state->scaledbndu.xR[j], v1);
               }
            }
            ae_assert(v1 >= v0, "MinNS: integrity check failed (9743)");
            state->samplex.xyR[i][j] = rboundval(v0 + (v1 - v0) * hqrnduniformr(&state->agsrs), v0, v1);
         }
         ae_v_move(state->x.xR, 1, state->samplex.xyR[i], 1, n);
         state->needfij = true, state->AgsPQ = 2; goto Pause; Resume2: state->needfij = false;
         state->samplef.xR[i] = state->meritf;
         rcopyvr(n, &state->meritg, &state->samplegm, i);
      }
      cursamplesize += k;
      fullsample = cursamplesize == state->agssamplesize;
      for (j = 0; j < cursamplesize; j++) {
      // For J-th element in gradient sample, process all of its components
      // and modify them according to status of box constraints
         for (i = 0; i < n; i++) {
            ae_assert(!state->hasbndl.xB[i] || state->xc.xR[i] >= state->scaledbndl.xR[i], "MinNS: integrity error");
            ae_assert(!state->hasbndu.xB[i] || state->xc.xR[i] <= state->scaledbndu.xR[i], "MinNS: integrity error");
            state->samplegmbc.xyR[j][i] = state->samplegm.xyR[j][i];
            if (state->hasbndl.xB[i] && state->hasbndu.xB[i] && state->scaledbndl.xR[i] == state->scaledbndu.xR[i]) {
            // I-th box constraint is of equality type (lower bound matches upper one).
            // Simplest case, always active.
               state->samplegmbc.xyR[j][i] = 0.0;
               continue;
            }
            if (state->hasbndl.xB[i] && state->xc.xR[i] == state->scaledbndl.xR[i]) {
            // We are at lower bound: activate/deactivate constraint depending on gradient at XC
               if (state->samplegm.xyR[0][i] >= 0.0) {
                  state->samplegmbc.xyR[j][i] = 0.0;
               }
               continue;
            }
            if (state->hasbndu.xB[i] && state->xc.xR[i] == state->scaledbndu.xR[i]) {
            // We are at upper bound: activate/deactivate constraint depending on gradient at XC
               if (state->samplegm.xyR[0][i] <= 0.0) {
                  state->samplegmbc.xyR[j][i] = 0.0;
               }
               continue;
            }
         }
      }
   // Calculate diagonal Hessian.
   //
   // This Hessian serves two purposes:
   // * first, it improves performance of gradient descent step
   // * second, it improves condition number of QP subproblem
   //   solved to determine step
   //
   // The idea is that for each variable we check whether sample
   // includes entries with alternating sign of gradient:
   // * if gradients with different signs are present, Hessian
   //   component is set to M/R, where M is a maximum magnitude
   //   of corresponding gradient component, R is a sampling radius.
   //   Note that sign == 0 and sign == 1 are treated as different ones
   // * if all gradients have same sign, Hessian component is
   //   set to M/R0, where R0 is initial sampling radius.
      for (j = 0; j < n; j++) {
         state->colmax.xR[j] = 0.0;
         state->signmin.xR[j] = 1.0;
         state->signmax.xR[j] = -1.0;
      }
      for (i = 0; i < cursamplesize; i++) {
         for (j = 0; j < n; j++) {
            v = state->samplegmbc.xyR[i][j];
            state->colmax.xR[j] = rmax2(state->colmax.xR[j], fabs(v));
            state->signmin.xR[j] = rmin2(state->signmin.xR[j], sign(v));
            state->signmax.xR[j] = rmax2(state->signmax.xR[j], sign(v));
         }
      }
      for (j = 0; j < n; j++) {
         if (state->signmin.xR[j] != state->signmax.xR[j]) {
         // Alternating signs of gradient - step is proportional to current sampling radius
            ae_assert(state->colmax.xR[j] != 0.0, "MinNS: integrity check failed (2975)");
            ae_assert(radius != 0.0, "MinNS: integrity check failed (8473)");
            state->diagh.xR[j] = state->colmax.xR[j] / radius;
            continue;
         }
         if (state->colmax.xR[j] != 0.0) {
         // Non-alternating sign of gradient, but non-zero.
         // Step is proportional to recommended step
            ae_assert(recommendedstep != 0.0, "MinNS: integrity check failed (3274)");
            state->diagh.xR[j] = state->colmax.xR[j] / recommendedstep;
            continue;
         }
         state->diagh.xR[j] = 1.0;
      }
   // PROJECTION PHASE
   //
   // We project zero vector on convex hull of gradient sample.
   // If projection is small enough, we decrease radius and restart.
   // Otherwise, this phase returns search direction in State.D.
   //
   // NOTE: because we use iterative solver, it may have trouble
   //       dealing with ill-conditioned problems. So we also employ
   //       second, backup test for stationarity - when too many
   //       subsequent backtracking searches resulted in short steps.
      minns_solveqp(&state->samplegmbc, &state->diagh, cursamplesize, n, &state->tmp0, &state->dbgncholesky, &state->nsqp);
      for (j = 0; j < n; j++) {
         state->d.xR[j] = 0.0;
      }
      for (i = 0; i < cursamplesize; i++) {
         v = state->tmp0.xR[i];
         ae_v_addd(state->d.xR, 1, state->samplegmbc.xyR[i], 1, n, v);
      }
      v = 0.0;
      for (j = 0; j < n; j++) {
         v = rmax2(v, fabs(state->d.xR[j] / coalesce(state->colmax.xR[j], 1.0)));
      }
      if (v <= state->agsstattold) {
      // Stationarity test succeeded.
      // Decrease radius and restart.
      //
      // NOTE: we also clear ShortStepsCnt on restart
         radius *= state->agsraddecay;
         shortstepscnt = 0;
         radiusdecays++;
         state->repinneriterationscount++;
         continue;
      }
      for (i = 0; i < n; i++) {
         state->d.xR[i] /= -state->diagh.xR[i];
      }
   // Perform backtracking line search.
   // Update initial step length depending on search results.
   // Here we assume that D is non-zero.
   //
   // NOTE: if AGSShortLimit subsequent line searches resulted
   //       in steps shorter than AGSStatTolStp, we decrease radius.
      dhd = 0.0;
      for (i = 0; i < n; i++) {
         dhd += state->d.xR[i] * state->diagh.xR[i] * state->d.xR[i];
      }
      dnrminf = rmaxabsv(n, &state->d);
      ae_assert(dnrminf > 0.0, "MinNS: integrity error (2752)");
      alpha = recommendedstep / dnrminf;
      alphadecreased = false;
      backtrackits = 0;
      if (fullsample) {
         maxbacktrackits = state->agsmaxbacktrack;
      } else {
         maxbacktrackits = state->agsmaxbacktracknonfull;
      }
      while (true) {
      // Prepare XN and evaluate merit function at XN
         ae_v_move(state->xn.xR, 1, state->xc.xR, 1, n);
         ae_v_addd(state->xn.xR, 1, state->d.xR, 1, n, alpha);
         enforceboundaryconstraints(&state->xn, &state->scaledbndl, &state->hasbndl, &state->scaledbndu, &state->hasbndu, n, 0);
         ae_v_move(state->samplex.xyR[maxsamplesize], 1, state->xn.xR, 1, n);
         ae_v_move(state->x.xR, 1, state->xn.xR, 1, n);
         state->needfij = true, state->AgsPQ = 3; goto Pause; Resume3: state->needfij = false;
         state->samplef.xR[maxsamplesize] = state->meritf;
         rcopyvr(n, &state->meritg, &state->samplegm, maxsamplesize);
      // Check sufficient decrease condition
         ae_assert(dnrminf > 0.0, "MinNS: integrity error (9642)");
         if (state->samplef.xR[maxsamplesize] <= state->samplef.xR[0] - alpha * state->agsdecrease * dhd) {
            break;
         }
      // Decrease Alpha
         alpha *= state->agsalphadecay;
         alphadecreased = true;
      // Update and check iterations counter.
         backtrackits++;
         if (backtrackits >= maxbacktrackits) {
         // Too many backtracking searches performed without success.
         // Terminate iterations.
            alpha = 0.0;
            alphadecreased = true;
            ae_v_move(state->xn.xR, 1, state->xc.xR, 1, n);
            break;
         }
      }
      if (alpha * dnrminf <= state->agsshortstpabs || alpha * dnrminf <= state->agsshortstprel * radius || NearAtR(state->samplef.xR[0], state->samplef.xR[maxsamplesize], state->agsshortf)) {
         shortstepscnt++;
      } else {
         shortstepscnt = 0;
      }
      if (shortstepscnt >= state->agsshortlimit) {
      // Too many subsequent short steps.
      //
      // It may be possible that optimizer is unable to find out
      // that we have to decrease radius because of ill-conditioned
      // gradients.
      //
      // Decrease radius and restart.
         radius *= state->agsraddecay;
         shortstepscnt = 0;
         radiusdecays++;
         state->repinneriterationscount++;
         continue;
      }
      if (!alphadecreased) {
         recommendedstep *= 2.0;
      }
      if (alphadecreased && fullsample) {
         recommendedstep *= 0.5;
      }
   // Next iteration
      ae_v_move(state->xc.xR, 1, state->xn.xR, 1, n);
      state->repinneriterationscount++;
   }
// Convert back from scaled to unscaled representation
   minns_unscalepointbc(state, &state->xc);
Exit:
   state->AgsPQ = -1;
   return false;
Pause:
   return true;
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions minnsoptimize() listed below.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: bool minnsiteration(const minnsstate &state);
// API: void minnsoptimize(minnsstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minnsoptimize(minnsstate &state, void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minnsiteration(minnsstate *state) {
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS ae_int_t k;
   AutoS ae_int_t n;
   AutoS ae_int_t nec;
   AutoS ae_int_t nic;
   AutoS ae_int_t ng;
   AutoS ae_int_t nh;
   AutoS double v;
   AutoS double xp;
   AutoS double xm;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume0; case 1: goto Resume1; case 2: goto Resume2; case 3: goto Resume3;
      default: goto Exit;
   }
Spawn:
// Init
   state->xupdated = state->needfij = state->needfi = false;
   state->replcerr = 0.0;
   state->repnlcerr = 0.0;
   state->repterminationtype = 0;
   state->repinneriterationscount = 0;
   state->repouteriterationscount = 0;
   state->repnfev = 0;
   state->repvaridx = 0;
   state->repfuncidx = 0;
   state->userterminationneeded = false;
   state->dbgncholesky = 0;
   n = state->n;
   nec = state->nec;
   nic = state->nic;
   ng = state->ng;
   nh = state->nh;
// AGS solver
   if (state->solvertype == 0) {
      if (state->diffstep != 0.0) {
         vectorsetlengthatleast(&state->xbase, n);
         vectorsetlengthatleast(&state->fbase, 1 + ng + nh);
         vectorsetlengthatleast(&state->fm, 1 + ng + nh);
         vectorsetlengthatleast(&state->fp, 1 + ng + nh);
      }
      vectorsetlengthatleast(&state->xscaled, n);
      vectorsetlengthatleast(&state->rawg, n);
      vectorsetlengthatleast(&state->meritg, n);
      for (state->AgsPQ = -1; minns_agsiteration(state); ) {
         rcopyv(n, &state->x, &state->xscaled);
         minns_unscalepointbc(state, &state->x);
      // Numerical differentiation (if needed) - intercept NeedFiJ
      // request and replace it by sequence of NeedFi requests
         if (state->diffstep != 0.0 && state->needfij) {
            state->needfij = false, state->needfi = true;
            ae_v_move(state->xbase.xR, 1, state->x.xR, 1, n);
            state->PQ = 0; goto Pause; Resume0:
            ae_v_move(state->fbase.xR, 1, state->fi.xR, 1, ng + nh + 1);
            state->repnfev++;
            for (k = 0; k < n; k++) {
               v = state->xbase.xR[k];
               xm = v - state->diffstep * state->s.xR[k];
               xp = v + state->diffstep * state->s.xR[k];
               if (state->hasbndl.xB[k] && xm < state->bndl.xR[k]) {
                  xm = state->bndl.xR[k];
               }
               if (state->hasbndu.xB[k] && xp > state->bndu.xR[k]) {
                  xp = state->bndu.xR[k];
               }
               ae_assert(xm <= xp, "MinNS: integrity check failed (3y634)");
               if (xm != xp) {
               // Compute F(XM) and F(XP)
                  rcopyv(n, &state->xbase, &state->x);
                  state->x.xR[k] = xm;
                  state->PQ = 1; goto Pause; Resume1:
                  rcopyv(1 + ng + nh, &state->fi, &state->fm);
                  rcopyv(n, &state->xbase, &state->x);
                  state->x.xR[k] = xp;
                  state->PQ = 2; goto Pause; Resume2:
                  rcopyv(1 + ng + nh, &state->fi, &state->fp);
               // Compute subgradient at XBase
                  rcopymulvc(1 + ng + nh, 1.0 / (xp - xm), &state->fp, &state->j, k);
                  raddvc(1 + ng + nh, -1.0 / (xp - xm), &state->fm, &state->j, k);
                  state->repnfev += 2;
               } else {
                  rsetc(1 + ng + nh, 0.0, &state->j, k);
               }
            }
         // Restore previous values of fields and continue
            rcopyv(n, &state->xscaled, &state->x);
            rcopyv(1 + ng + nh, &state->fbase, &state->fi);
            state->needfi = false, state->needfij = true;
         } else {
         // Forward request to caller.
            state->PQ = 3; goto Pause; Resume3:
            state->repnfev++;
            rcopyv(n, &state->xscaled, &state->x);
         }
      // Postprocess Jacobian: scale and produce 'raw' and 'merit' functions
         for (i = 0; i <= ng + nh; i++) {
            rmergemulvr(n, &state->s, &state->j, i);
         }
         state->rawf = state->fi.xR[0];
         state->meritf = state->fi.xR[0];
         rcopyrv(n, &state->j, 0, &state->rawg);
         rcopyrv(n, &state->j, 0, &state->meritg);
         for (i = 0; i < nec + nic; i++) {
            v = rdotvr(n, &state->x, &state->scaledcleic, i) - state->scaledcleic.xyR[i][n];
            if (i >= nec && v < 0.0) {
               continue;
            }
            state->meritf += state->rholinear * fabs(v);
            raddrv(n, state->rholinear * sign(v), &state->scaledcleic, i, &state->meritg);
         }
         for (i = 1; i <= ng + nh; i++) {
            v = state->fi.xR[i];
            if (i <= ng && v == 0.0) {
               continue;
            } else if (i > ng && v <= 0.0) {
               continue;
            }
            state->meritf += state->agsrhononlinear * fabs(v);
            raddrv(n, state->agsrhononlinear * sign(v), &state->j, i, &state->meritg);
         }
      // Done
      // continue;
      }
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// Buffered implementation of minnsresults() which uses preallocated  buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnsresultsbuf(const minnsstate &state, real_1d_array &x, minnsreport &rep);
void minnsresultsbuf(minnsstate *state, RVector *x, minnsreport *rep) {
   ae_int_t i;
   vectorsetlengthatleast(x, state->n);
   rep->iterationscount = state->repinneriterationscount;
   rep->nfev = state->repnfev;
   rep->varidx = state->repvaridx;
   rep->funcidx = state->repfuncidx;
   rep->terminationtype = state->repterminationtype;
   rep->cerr = rmax2(state->replcerr, state->repnlcerr);
   rep->lcerr = state->replcerr;
   rep->nlcerr = state->repnlcerr;
   if (state->repterminationtype > 0) {
      ae_v_move(x->xR, 1, state->xc.xR, 1, state->n);
   } else {
      for (i = 0; i < state->n; i++) {
         x->xR[i] = NAN;
      }
   }
}

// MinNS results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization report. You should check Rep.TerminationType
//                 in  order  to  distinguish  successful  termination  from
//                 unsuccessful one:
//                 * -8   internal integrity control  detected  infinite  or
//                        NAN   values   in   function/gradient.    Abnormal
//                        termination signalled.
//                 * -3   box constraints are inconsistent
//                 * -1   inconsistent parameters were passed:
//                        * penalty parameter for minnssetalgoags() is zero,
//                          but we have nonlinear constraints set by minnssetnlc()
//                 *  2   sampling radius decreased below epsx
//                 *  7    stopping conditions are too stringent,
//                         further improvement is impossible,
//                         X contains best point found so far.
//                 *  8    User requested termination via minnsrequesttermination()
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
// API: void minnsresults(const minnsstate &state, real_1d_array &x, minnsreport &rep);
void minnsresults(minnsstate *state, RVector *x, minnsreport *rep) {
   SetVector(x);
   SetObj(minnsreport, rep);
   minnsresultsbuf(state, x, rep);
}

void minnsqp_init(void *_p, bool make_automatic) {
   minnsqp *p = (minnsqp *)_p;
   ae_vector_init(&p->xc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->uh, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->ch, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->rk, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->invutc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpidx, 0, DT_INT, make_automatic);
   ae_vector_init(&p->tmpd, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmplambdas, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmpc2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpb, 0, DT_BOOL, make_automatic);
   snnlssolver_init(&p->nnls, make_automatic);
}

void minnsqp_copy(void *_dst, const void *_src, bool make_automatic) {
   minnsqp *dst = (minnsqp *)_dst;
   const minnsqp *src = (const minnsqp *)_src;
   dst->fc = src->fc;
   dst->fn = src->fn;
   ae_vector_copy(&dst->xc, &src->xc, make_automatic);
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->x0, &src->x0, make_automatic);
   ae_vector_copy(&dst->gc, &src->gc, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_matrix_copy(&dst->uh, &src->uh, make_automatic);
   ae_matrix_copy(&dst->ch, &src->ch, make_automatic);
   ae_matrix_copy(&dst->rk, &src->rk, make_automatic);
   ae_vector_copy(&dst->invutc, &src->invutc, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmpidx, &src->tmpidx, make_automatic);
   ae_vector_copy(&dst->tmpd, &src->tmpd, make_automatic);
   ae_vector_copy(&dst->tmpc, &src->tmpc, make_automatic);
   ae_vector_copy(&dst->tmplambdas, &src->tmplambdas, make_automatic);
   ae_matrix_copy(&dst->tmpc2, &src->tmpc2, make_automatic);
   ae_vector_copy(&dst->tmpb, &src->tmpb, make_automatic);
   snnlssolver_copy(&dst->nnls, &src->nnls, make_automatic);
}

void minnsqp_free(void *_p, bool make_automatic) {
   minnsqp *p = (minnsqp *)_p;
   ae_vector_free(&p->xc, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->x0, make_automatic);
   ae_vector_free(&p->gc, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_matrix_free(&p->uh, make_automatic);
   ae_matrix_free(&p->ch, make_automatic);
   ae_matrix_free(&p->rk, make_automatic);
   ae_vector_free(&p->invutc, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmpidx, make_automatic);
   ae_vector_free(&p->tmpd, make_automatic);
   ae_vector_free(&p->tmpc, make_automatic);
   ae_vector_free(&p->tmplambdas, make_automatic);
   ae_matrix_free(&p->tmpc2, make_automatic);
   ae_vector_free(&p->tmpb, make_automatic);
   snnlssolver_free(&p->nnls, make_automatic);
}

void minnsstate_init(void *_p, bool make_automatic) {
   minnsstate *p = (minnsstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_matrix_init(&p->cleic, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fi, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->j, 0, 0, DT_REAL, make_automatic);
   hqrndstate_init(&p->agsrs, make_automatic);
   ae_vector_init(&p->xstart, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->rawg, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->meritg, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->colmax, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagh, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->signmin, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->signmax, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->scaledbndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->scaledbndu, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->scaledcleic, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->samplex, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->samplegm, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->samplegmbc, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->samplef, 0, DT_REAL, make_automatic);
   minnsqp_init(&p->nsqp, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp1, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->tmp2, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp3, 0, DT_INT, make_automatic);
   ae_vector_init(&p->xbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fbase, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->fm, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xscaled, 0, DT_REAL, make_automatic);
}

void minnsstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minnsstate *dst = (minnsstate *)_dst;
   const minnsstate *src = (const minnsstate *)_src;
   dst->solvertype = src->solvertype;
   dst->n = src->n;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->xrep = src->xrep;
   dst->diffstep = src->diffstep;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   dst->nec = src->nec;
   dst->nic = src->nic;
   ae_matrix_copy(&dst->cleic, &src->cleic, make_automatic);
   dst->ng = src->ng;
   dst->nh = src->nh;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->fi, &src->fi, make_automatic);
   ae_matrix_copy(&dst->j, &src->j, make_automatic);
   dst->needfij = src->needfij;
   dst->needfi = src->needfi;
   dst->xupdated = src->xupdated;
   dst->PQ = src->PQ;
   dst->AgsPQ = src->AgsPQ;
   hqrndstate_copy(&dst->agsrs, &src->agsrs, make_automatic);
   dst->agsradius = src->agsradius;
   dst->agssamplesize = src->agssamplesize;
   dst->agsraddecay = src->agsraddecay;
   dst->agsalphadecay = src->agsalphadecay;
   dst->agsdecrease = src->agsdecrease;
   dst->agsinitstp = src->agsinitstp;
   dst->agsstattold = src->agsstattold;
   dst->agsshortstpabs = src->agsshortstpabs;
   dst->agsshortstprel = src->agsshortstprel;
   dst->agsshortf = src->agsshortf;
   dst->agsshortlimit = src->agsshortlimit;
   dst->agsrhononlinear = src->agsrhononlinear;
   dst->agsminupdate = src->agsminupdate;
   dst->agsmaxraddecays = src->agsmaxraddecays;
   dst->agsmaxbacktrack = src->agsmaxbacktrack;
   dst->agsmaxbacktracknonfull = src->agsmaxbacktracknonfull;
   dst->agspenaltylevel = src->agspenaltylevel;
   dst->agspenaltyincrease = src->agspenaltyincrease;
   ae_vector_copy(&dst->xstart, &src->xstart, make_automatic);
   ae_vector_copy(&dst->xc, &src->xc, make_automatic);
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->rawg, &src->rawg, make_automatic);
   ae_vector_copy(&dst->meritg, &src->meritg, make_automatic);
   dst->rawf = src->rawf;
   dst->meritf = src->meritf;
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   ae_vector_copy(&dst->colmax, &src->colmax, make_automatic);
   ae_vector_copy(&dst->diagh, &src->diagh, make_automatic);
   ae_vector_copy(&dst->signmin, &src->signmin, make_automatic);
   ae_vector_copy(&dst->signmax, &src->signmax, make_automatic);
   dst->userterminationneeded = src->userterminationneeded;
   ae_vector_copy(&dst->scaledbndl, &src->scaledbndl, make_automatic);
   ae_vector_copy(&dst->scaledbndu, &src->scaledbndu, make_automatic);
   ae_matrix_copy(&dst->scaledcleic, &src->scaledcleic, make_automatic);
   dst->rholinear = src->rholinear;
   ae_matrix_copy(&dst->samplex, &src->samplex, make_automatic);
   ae_matrix_copy(&dst->samplegm, &src->samplegm, make_automatic);
   ae_matrix_copy(&dst->samplegmbc, &src->samplegmbc, make_automatic);
   ae_vector_copy(&dst->samplef, &src->samplef, make_automatic);
   minnsqp_copy(&dst->nsqp, &src->nsqp, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   ae_vector_copy(&dst->tmp1, &src->tmp1, make_automatic);
   ae_matrix_copy(&dst->tmp2, &src->tmp2, make_automatic);
   ae_vector_copy(&dst->tmp3, &src->tmp3, make_automatic);
   ae_vector_copy(&dst->xbase, &src->xbase, make_automatic);
   ae_vector_copy(&dst->fbase, &src->fbase, make_automatic);
   ae_vector_copy(&dst->fp, &src->fp, make_automatic);
   ae_vector_copy(&dst->fm, &src->fm, make_automatic);
   ae_vector_copy(&dst->xscaled, &src->xscaled, make_automatic);
   dst->repinneriterationscount = src->repinneriterationscount;
   dst->repouteriterationscount = src->repouteriterationscount;
   dst->repnfev = src->repnfev;
   dst->repvaridx = src->repvaridx;
   dst->repfuncidx = src->repfuncidx;
   dst->repterminationtype = src->repterminationtype;
   dst->replcerr = src->replcerr;
   dst->repnlcerr = src->repnlcerr;
   dst->dbgncholesky = src->dbgncholesky;
}

void minnsstate_free(void *_p, bool make_automatic) {
   minnsstate *p = (minnsstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_matrix_free(&p->cleic, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->fi, make_automatic);
   ae_matrix_free(&p->j, make_automatic);
   hqrndstate_free(&p->agsrs, make_automatic);
   ae_vector_free(&p->xstart, make_automatic);
   ae_vector_free(&p->xc, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->rawg, make_automatic);
   ae_vector_free(&p->meritg, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->colmax, make_automatic);
   ae_vector_free(&p->diagh, make_automatic);
   ae_vector_free(&p->signmin, make_automatic);
   ae_vector_free(&p->signmax, make_automatic);
   ae_vector_free(&p->scaledbndl, make_automatic);
   ae_vector_free(&p->scaledbndu, make_automatic);
   ae_matrix_free(&p->scaledcleic, make_automatic);
   ae_matrix_free(&p->samplex, make_automatic);
   ae_matrix_free(&p->samplegm, make_automatic);
   ae_matrix_free(&p->samplegmbc, make_automatic);
   ae_vector_free(&p->samplef, make_automatic);
   minnsqp_free(&p->nsqp, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->tmp1, make_automatic);
   ae_matrix_free(&p->tmp2, make_automatic);
   ae_vector_free(&p->tmp3, make_automatic);
   ae_vector_free(&p->xbase, make_automatic);
   ae_vector_free(&p->fbase, make_automatic);
   ae_vector_free(&p->fp, make_automatic);
   ae_vector_free(&p->fm, make_automatic);
   ae_vector_free(&p->xscaled, make_automatic);
}

void minnsreport_init(void *_p, bool make_automatic) {
}

void minnsreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minnsreport *dst = (minnsreport *)_dst;
   const minnsreport *src = (const minnsreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->cerr = src->cerr;
   dst->lcerr = src->lcerr;
   dst->nlcerr = src->nlcerr;
   dst->terminationtype = src->terminationtype;
   dst->varidx = src->varidx;
   dst->funcidx = src->funcidx;
}

void minnsreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores nonlinear optimizer state.
// You should use functions provided by MinNS subpackage to work  with  this
// object
DefClass(minnsstate, DecVal(needfi) DecVal(needfij) DecVal(xupdated) DecVal(f) DecVar(fi) DecVar(j) DecVar(x))

// This structure stores optimization report:
// * IterationsCount           total number of inner iterations
// * NFEV                      number of gradient evaluations
// * TerminationType           termination type (see below)
// * CErr                      maximum violation of all types of constraints
// * LCErr                     maximum violation of linear constraints
// * NLCErr                    maximum violation of nonlinear constraints
//
// TERMINATION CODES
//
// TerminationType field contains completion code, which can be:
//   -8    internal integrity control detected  infinite  or  NAN  values  in
//         function/gradient. Abnormal termination signalled.
//   -3    box constraints are inconsistent
//   -1    inconsistent parameters were passed:
//         * penalty parameter for minnssetalgoags() is zero,
//           but we have nonlinear constraints set by minnssetnlc()
//    2    sampling radius decreased below epsx
//    5    MaxIts steps was taken
//    7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//    8    User requested termination via MinNSRequestTermination()
//
// Other fields of this structure are not documented and should not be used!
DefClass(minnsreport, DecVal(iterationscount) DecVal(nfev) DecVal(cerr) DecVal(lcerr) DecVal(nlcerr) DecVal(terminationtype) DecVal(varidx) DecVal(funcidx))

void minnssetbc(const minnsstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetbc(ConstT(minnsstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minnssetlc(const minnsstate &state, const real_2d_array &c, const integer_1d_array &ct, const ae_int_t k) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetlc(ConstT(minnsstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnssetlc(const minnsstate &state, const real_2d_array &c, const integer_1d_array &ct) {
   ae_int_t k = c.rows();
   if (k != ct.length()) ThrowError("Error while calling 'minnssetlc': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetlc(ConstT(minnsstate, state), ConstT(ae_matrix, c), ConstT(ae_vector, ct), k);
   alglib_impl::ae_state_clear();
}
#endif

void minnssetnlc(const minnsstate &state, const ae_int_t nlec, const ae_int_t nlic) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetnlc(ConstT(minnsstate, state), nlec, nlic);
   alglib_impl::ae_state_clear();
}

void minnssetcond(const minnsstate &state, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetcond(ConstT(minnsstate, state), epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minnssetscale(const minnsstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetscale(ConstT(minnsstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minnssetalgoags(const minnsstate &state, const double radius, const double penalty) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetalgoags(ConstT(minnsstate, state), radius, penalty);
   alglib_impl::ae_state_clear();
}

void minnssetxrep(const minnsstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnssetxrep(ConstT(minnsstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minnsrestartfrom(const minnsstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnsrestartfrom(ConstT(minnsstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minnscreate(const ae_int_t n, const real_1d_array &x, minnsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnscreate(n, ConstT(ae_vector, x), ConstT(minnsstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnscreate(const real_1d_array &x, minnsstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnscreate(n, ConstT(ae_vector, x), ConstT(minnsstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minnscreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minnsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnscreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minnsstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minnscreatef(const real_1d_array &x, const double diffstep, minnsstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnscreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minnsstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minnsrequesttermination(const minnsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnsrequesttermination(ConstT(minnsstate, state));
   alglib_impl::ae_state_clear();
}

bool minnsiteration(const minnsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minnsiteration(ConstT(minnsstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     fvec    -   callback which calculates function vector fi[]
//                 at given point x
//     jac     -   callback which calculates function vector fi[]
//                 and Jacobian jac at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. This function has two different implementations: one which  uses  exact
//    (analytical) user-supplied Jacobian, and one which uses  only  function
//    vector and numerically  differentiates  function  in  order  to  obtain
//    gradient.
//
//    Depending  on  the  specific  function  used to create optimizer object
//    you should choose appropriate variant of  minnsoptimize() -  one  which
//    accepts function AND Jacobian or one which accepts ONLY function.
//
//    Be careful to choose variant of minnsoptimize()  which  corresponds  to
//    your optimization scheme! Table below lists different  combinations  of
//    callback (function/gradient) passed to minnsoptimize()    and  specific
//    function used to create optimizer.
//
//                      |         USER PASSED TO minnsoptimize()
//    CREATED WITH      |  function only   |  function and gradient
//    ------------------------------------------------------------
//    minnscreatef()    |     works               FAILS
//    minnscreate()     |     FAILS               works
//
//    Here "FAILS" denotes inappropriate combinations  of  optimizer creation
//    function  and  minnsoptimize()  version.   Attemps   to    use     such
//    combination will lead to exception. Either  you  did  not pass gradient
//    when it WAS needed or you passed gradient when it was NOT needed.
// ALGLIB: Copyright 18.05.2015 by Sergey Bochkanov
void minnsoptimize(minnsstate &state, void (*fvec)(const real_1d_array &x, real_1d_array &fi, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(fvec != NULL, "minnsoptimize: fvec is NULL");
   while (alglib_impl::minnsiteration(state.c_ptr()))
   BegPoll
      if (state.needfi) fvec(state.x, state.fi, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minnsoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minnsoptimize(minnsstate &state, void (*jac)(const real_1d_array &x, real_1d_array &fi, real_2d_array &jac, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(jac != NULL, "minnsoptimize: jac is NULL");
   while (alglib_impl::minnsiteration(state.c_ptr()))
   BegPoll
      if (state.needfij) jac(state.x, state.fi, state.j, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minnsoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minnsresultsbuf(const minnsstate &state, real_1d_array &x, minnsreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnsresultsbuf(ConstT(minnsstate, state), ConstT(ae_vector, x), ConstT(minnsreport, rep));
   alglib_impl::ae_state_clear();
}

void minnsresults(const minnsstate &state, real_1d_array &x, minnsreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minnsresults(ConstT(minnsstate, state), ConstT(ae_vector, x), ConstT(minnsreport, rep));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === MINCOMP Package ===
// Depends on: MINLBFGS, MINBLEIC
namespace alglib_impl {
// Obsolete function, use MinLBFGSSetPrecDefault() instead.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minlbfgssetdefaultpreconditioner(const minlbfgsstate &state);
void minlbfgssetdefaultpreconditioner(minlbfgsstate *state) {
   minlbfgssetprecdefault(state);
}

// Obsolete function, use MinLBFGSSetCholeskyPreconditioner() instead.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minlbfgssetcholeskypreconditioner(const minlbfgsstate &state, const real_2d_array &p, const bool isupper);
void minlbfgssetcholeskypreconditioner(minlbfgsstate *state, RMatrix *p, bool isupper) {
   minlbfgssetpreccholesky(state, p, isupper);
}

// This is obsolete function which was used by previous version of the  BLEIC
// optimizer. It does nothing in the current version of BLEIC.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicsetbarrierwidth(const minbleicstate &state, const double mu);
void minbleicsetbarrierwidth(minbleicstate *state, double mu) {
}

// This is obsolete function which was used by previous version of the  BLEIC
// optimizer. It does nothing in the current version of BLEIC.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbleicsetbarrierdecay(const minbleicstate &state, const double mudecay);
void minbleicsetbarrierdecay(minbleicstate *state, double mudecay) {
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minasasetcond(const minasastate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits);
void minasasetcond(minasastate *state, double epsg, double epsf, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsg), "MinASASetCond: EpsG is not finite number!");
   ae_assert(epsg >= 0.0, "MinASASetCond: negative EpsG!");
   ae_assert(isfinite(epsf), "MinASASetCond: EpsF is not finite number!");
   ae_assert(epsf >= 0.0, "MinASASetCond: negative EpsF!");
   ae_assert(isfinite(epsx), "MinASASetCond: EpsX is not finite number!");
   ae_assert(epsx >= 0.0, "MinASASetCond: negative EpsX!");
   ae_assert(maxits >= 0, "MinASASetCond: negative MaxIts!");
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->epsg = epsg;
   state->epsf = epsf;
   state->epsx = epsx;
   state->maxits = maxits;
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minasasetxrep(const minasastate &state, const bool needxrep);
void minasasetxrep(minasastate *state, bool needxrep) {
   state->xrep = needxrep;
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minasasetalgorithm(const minasastate &state, const ae_int_t algotype);
void minasasetalgorithm(minasastate *state, ae_int_t algotype) {
   ae_assert(algotype >= -1 && algotype <= 1, "MinASASetAlgorithm: incorrect AlgoType!");
   if (algotype == -1) {
      algotype = 1;
   }
   state->cgtype = algotype;
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minasasetstpmax(const minasastate &state, const double stpmax);
void minasasetstpmax(minasastate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinASASetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinASASetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 30.07.2010 by Sergey Bochkanov
// API: void minasarestartfrom(const minasastate &state, const real_1d_array &x, const real_1d_array &bndl, const real_1d_array &bndu);
void minasarestartfrom(minasastate *state, RVector *x, RVector *bndl, RVector *bndu) {
   ae_assert(x->cnt >= state->n, "MinASARestartFrom: Length(X) < N!");
   ae_assert(isfinitevector(x, state->n), "MinASARestartFrom: X contains infinite or NaN values!");
   ae_assert(bndl->cnt >= state->n, "MinASARestartFrom: Length(BndL) < N!");
   ae_assert(isfinitevector(bndl, state->n), "MinASARestartFrom: BndL contains infinite or NaN values!");
   ae_assert(bndu->cnt >= state->n, "MinASARestartFrom: Length(BndU) < N!");
   ae_assert(isfinitevector(bndu, state->n), "MinASARestartFrom: BndU contains infinite or NaN values!");
   ae_v_move(state->x.xR, 1, x->xR, 1, state->n);
   ae_v_move(state->bndl.xR, 1, bndl->xR, 1, state->n);
   ae_v_move(state->bndu.xR, 1, bndu->xR, 1, state->n);
   state->laststep = 0.0;
   state->PQ = -1;
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 25.03.2010 by Sergey Bochkanov
// API: void minasacreate(const ae_int_t n, const real_1d_array &x, const real_1d_array &bndl, const real_1d_array &bndu, minasastate &state);
// API: void minasacreate(const real_1d_array &x, const real_1d_array &bndl, const real_1d_array &bndu, minasastate &state);
void minasacreate(ae_int_t n, RVector *x, RVector *bndl, RVector *bndu, minasastate *state) {
   ae_int_t i;
   SetObj(minasastate, state);
   ae_assert(n >= 1, "MinASA: N too small!");
   ae_assert(x->cnt >= n, "MinCGCreate: Length(X) < N!");
   ae_assert(isfinitevector(x, n), "MinCGCreate: X contains infinite or NaN values!");
   ae_assert(bndl->cnt >= n, "MinCGCreate: Length(BndL) < N!");
   ae_assert(isfinitevector(bndl, n), "MinCGCreate: BndL contains infinite or NaN values!");
   ae_assert(bndu->cnt >= n, "MinCGCreate: Length(BndU) < N!");
   ae_assert(isfinitevector(bndu, n), "MinCGCreate: BndU contains infinite or NaN values!");
   for (i = 0; i < n; i++) {
      ae_assert(bndl->xR[i] <= bndu->xR[i], "MinASA: inconsistent bounds!");
      ae_assert(bndl->xR[i] <= x->xR[i], "MinASA: infeasible X!");
      ae_assert(x->xR[i] <= bndu->xR[i], "MinASA: infeasible X!");
   }
// Initialize
   state->n = n;
   minasasetcond(state, 0.0, 0.0, 0.0, 0);
   minasasetxrep(state, false);
   minasasetstpmax(state, 0.0);
   minasasetalgorithm(state, -1);
   ae_vector_set_length(&state->bndl, n);
   ae_vector_set_length(&state->bndu, n);
   ae_vector_set_length(&state->ak, n);
   ae_vector_set_length(&state->xk, n);
   ae_vector_set_length(&state->dk, n);
   ae_vector_set_length(&state->an, n);
   ae_vector_set_length(&state->xn, n);
   ae_vector_set_length(&state->dn, n);
   ae_vector_set_length(&state->x, n);
   ae_vector_set_length(&state->d, n);
   ae_vector_set_length(&state->g, n);
   ae_vector_set_length(&state->gc, n);
   ae_vector_set_length(&state->work, n);
   ae_vector_set_length(&state->yk, n);
   minasarestartfrom(state, x, bndl, bndu);
}

// Returns norm of bounded anti-gradient.
//
// Bounded antigradient is a vector obtained from  anti-gradient  by  zeroing
// components which point outwards:
//     result = norm(v)
//     v[i] == 0     if -g[i] < 0 and x[i] == bndl[i] or
//                      -g[i] > 0 and x[i] == bndu[i]
//     v[i] == -g[i] otherwise
//
// This function may be used to check a stopping criterion.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
static double mincomp_asaboundedantigradnorm(minasastate *state) {
   ae_int_t i;
   double v;
   double result;
   result = 0.0;
   for (i = 0; i < state->n; i++) {
      v = -state->g.xR[i];
      if (state->x.xR[i] == state->bndl.xR[i] && -state->g.xR[i] < 0.0) {
         v = 0.0;
      }
      if (state->x.xR[i] == state->bndu.xR[i] && -state->g.xR[i] > 0.0) {
         v = 0.0;
      }
      result += sqr(v);
   }
   result = sqrt(result);
   return result;
}

// Returns norm of GI(x).
//
// GI(x) is  a  gradient  vector  whose  components  associated  with  active
// constraints are zeroed. It  differs  from  bounded  anti-gradient  because
// components  of   GI(x)   are   zeroed  independently  of  sign(g[i]),  and
// anti-gradient's components are zeroed with respect to both constraint  and
// sign.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
static double mincomp_asaginorm(minasastate *state) {
   ae_int_t i;
   double result;
   result = 0.0;
   for (i = 0; i < state->n; i++) {
      if (state->x.xR[i] != state->bndl.xR[i] && state->x.xR[i] != state->bndu.xR[i]) {
         result += sqr(state->g.xR[i]);
      }
   }
   result = sqrt(result);
   return result;
}

// Returns norm(D1(State.X))
//
// For a meaning of D1 see 'NEW ACTIVE SET ALGORITHM FOR BOX CONSTRAINED
// OPTIMIZATION' by WILLIAM W. HAGER AND HONGCHAO ZHANG.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
static double mincomp_asad1norm(minasastate *state) {
   ae_int_t i;
   double result;
   result = 0.0;
   for (i = 0; i < state->n; i++) {
      result += sqr(rboundval(state->x.xR[i] - state->g.xR[i], state->bndl.xR[i], state->bndu.xR[i]) - state->x.xR[i]);
   }
   result = sqrt(result);
   return result;
}

// Returns True, if U set is empty.
//
// * State.X is used as point,
// * State.G - as gradient,
// * D is calculated within function (because State.D may have different
//   meaning depending on current optimization algorithm)
//
// For a meaning of U see 'NEW ACTIVE SET ALGORITHM FOR BOX CONSTRAINED
// OPTIMIZATION' by WILLIAM W. HAGER AND HONGCHAO ZHANG.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
static bool mincomp_asauisempty(minasastate *state) {
   ae_int_t i;
   double d;
   double d2;
   double d32;
   bool result;
   d = mincomp_asad1norm(state);
   d2 = sqrt(d);
   d32 = d * d2;
   result = true;
   for (i = 0; i < state->n; i++) {
      if (!SmallR(state->g.xR[i], d2) && rmin2(state->x.xR[i] - state->bndl.xR[i], state->bndu.xR[i] - state->x.xR[i]) >= d32) {
         result = false;
         return result;
      }
   }
   return result;
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API function minasaoptimize() listed below.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
// API: bool minasaiteration(const minasastate &state);
// API: void minasaoptimize(minasastate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minasaiteration(minasastate *state) {
   const ae_int_t n1 = 2, n2 = 2;
   const double stpmin = 1.0E-300, gtol = 0.3, gpaftol = 0.0001, gpadecay = 0.5, asarho = 0.5;
   AutoS ae_int_t n;
   AutoS ae_int_t i;
   AutoS double betak;
   AutoS double v;
   AutoS double vv;
   AutoS ae_int_t mcinfo;
   AutoS bool b;
   AutoS bool stepfound;
   AutoS ae_int_t diffcnt;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14;
      default: goto Exit;
   }
Spawn:
// Prepare
   n = state->n;
   state->xupdated = state->needfg = false;
   state->repterminationtype = 0;
   state->repiterationscount = 0;
   state->repnfev = 0;
   state->debugrestartscount = 0;
   state->cgtype = 1;
   ae_v_move(state->xk.xR, 1, state->x.xR, 1, n);
   for (i = 0; i < n; i++) {
      if (state->xk.xR[i] == state->bndl.xR[i] || state->xk.xR[i] == state->bndu.xR[i]) {
         state->ak.xR[i] = 0.0;
      } else {
         state->ak.xR[i] = 1.0;
      }
   }
   state->mu = 0.1;
   state->curalgo = 0;
// Calculate F/G, initialize algorithm
   state->needfg = true, state->PQ = 0; goto Pause; Resume00: state->needfg = false;
   if (state->xrep) {
   // progress report
      state->xupdated = true, state->PQ = 1; goto Pause; Resume01: state->xupdated = false;
   }
   if (mincomp_asaboundedantigradnorm(state) <= state->epsg) {
      state->repterminationtype = 4;
      goto Exit;
   }
   state->repnfev++;
// Main cycle
//
// At the beginning of new iteration:
// * CurAlgo stores current algorithm selector
// * State.XK, State.F and State.G store current X/F/G
// * State.AK stores current set of active constraints
   while (true) {
      if (state->curalgo == 0) { // GPA algorithm
         state->k = 0;
         state->acount = 0;
         while (true) {
         // Determine Dk = proj(xk - gk)-xk
            for (i = 0; i < n; i++) {
               state->d.xR[i] = rboundval(state->xk.xR[i] - state->g.xR[i], state->bndl.xR[i], state->bndu.xR[i]) - state->xk.xR[i];
            }
         // Armijo line search.
         // * exact search with alpha == 1 is tried first,
         //   'exact' means that we evaluate f() EXACTLY at
         //   bound(x-g,bndl,bndu), without intermediate floating
         //   point operations.
         // * alpha < 1 are tried if explicit search wasn't successful
         // Result is placed into XN.
         //
         // Two types of search are needed because we can't
         // just use second type with alpha == 1 because in finite
         // precision arithmetics (x1-x0)+x0 may differ from x1.
         // So while x1 is correctly bounded (it lie EXACTLY on
         // boundary, if it is active), (x1-x0)+x0 may be
         // not bounded.
            v = ae_v_dotproduct(state->d.xR, 1, state->g.xR, 1, n);
            state->dginit = v;
            state->finit = state->f;
            if (mincomp_asad1norm(state) <= state->stpmax || state->stpmax == 0.0) {
            // Try alpha == 1 step first
               for (i = 0; i < n; i++) {
                  state->x.xR[i] = rboundval(state->xk.xR[i] - state->g.xR[i], state->bndl.xR[i], state->bndu.xR[i]);
               }
               state->needfg = true, state->PQ = 2; goto Pause; Resume02: state->needfg = false;
               state->repnfev++;
               stepfound = state->f <= state->finit + gpaftol * state->dginit;
            } else stepfound = false;
            if (stepfound) {
            // we are at the boundary(ies)
               ae_v_move(state->xn.xR, 1, state->x.xR, 1, n);
               state->stp = 1.0;
            } else {
            // alpha == 1 is too large, try smaller values
               state->stp = 1.0;
               linminnormalized(&state->d, &state->stp, n);
               state->dginit /= state->stp;
               state->stp *= gpadecay;
               if (state->stpmax > 0.0) {
                  state->stp = rmin2(state->stp, state->stpmax);
               }
               while (true) {
                  v = state->stp;
                  ae_v_move(state->x.xR, 1, state->xk.xR, 1, n);
                  ae_v_addd(state->x.xR, 1, state->d.xR, 1, n, v);
                  state->needfg = true, state->PQ = 3; goto Pause; Resume03: state->needfg = false;
                  state->repnfev++;
                  if (state->stp <= stpmin) {
                     break;
                  } else if (state->f <= state->finit + state->stp * gpaftol * state->dginit) {
                     break;
                  }
                  state->stp *= gpadecay;
               }
               ae_v_move(state->xn.xR, 1, state->x.xR, 1, n);
            }
            state->repiterationscount++;
            if (state->xrep) {
            // progress report
               state->xupdated = true, state->PQ = 4; goto Pause; Resume04: state->xupdated = false;
            }
         // Calculate new set of active constraints.
         // Reset counter if active set was changed.
         // Prepare for the new iteration
            for (i = 0; i < n; i++) {
               if (state->xn.xR[i] == state->bndl.xR[i] || state->xn.xR[i] == state->bndu.xR[i]) {
                  state->an.xR[i] = 0.0;
               } else {
                  state->an.xR[i] = 1.0;
               }
            }
            for (i = 0; i < n; i++) {
               if (state->ak.xR[i] != state->an.xR[i]) {
                  state->acount = -1;
                  break;
               }
            }
            state->acount++;
            ae_v_move(state->xk.xR, 1, state->xn.xR, 1, n);
            ae_v_move(state->ak.xR, 1, state->an.xR, 1, n);
         // Stopping conditions
            if (state->repiterationscount >= state->maxits && state->maxits > 0) {
            // Too many iterations
               state->repterminationtype = 5;
               if (state->xrep) {
                  state->xupdated = true, state->PQ = 5; goto Pause; Resume05: state->xupdated = false;
               }
               goto Exit;
            } else if (mincomp_asaboundedantigradnorm(state) <= state->epsg) {
            // Gradient is small enough
               state->repterminationtype = 4;
               if (state->xrep) {
                  state->xupdated = true, state->PQ = 6; goto Pause; Resume06: state->xupdated = false;
               }
               goto Exit;
            }
            v = ae_v_dotproduct(state->d.xR, 1, state->d.xR, 1, n);
            if (sqrt(v) * state->stp <= state->epsx) {
            // Step size is too small, no further improvement is
            // possible
               state->repterminationtype = 2;
               if (state->xrep) {
                  state->xupdated = true, state->PQ = 7; goto Pause; Resume07: state->xupdated = false;
               }
               goto Exit;
            } else if (state->finit - state->f <= state->epsf * rmax2(fabs(state->finit), rmax2(fabs(state->f), 1.0))) {
            // F(k+1)-F(k) is small enough
               state->repterminationtype = 1;
               if (state->xrep) {
                  state->xupdated = true, state->PQ = 8; goto Pause; Resume08: state->xupdated = false;
               }
               goto Exit;
            }
         // Decide - should we switch algorithm or not
            if (mincomp_asauisempty(state)) {
               if (mincomp_asaginorm(state) >= state->mu * mincomp_asad1norm(state)) {
                  state->curalgo = 1;
                  break;
               } else {
                  state->mu *= asarho;
               }
            } else {
               if (state->acount == n1) {
                  if (mincomp_asaginorm(state) >= state->mu * mincomp_asad1norm(state)) {
                     state->curalgo = 1;
                     break;
                  }
               }
            }
         // Next iteration
            state->k++;
         }
      } else if (state->curalgo == 1) { // CG algorithm
      // first, check that there are non-active constraints.
      // move to GPA algorithm, if all constraints are active
         b = true;
         for (i = 0; i < n; i++) {
            if (state->ak.xR[i] != 0.0) {
               b = false;
               break;
            }
         }
         if (b) {
            state->curalgo = 0;
            continue;
         }
      // CG iterations
         state->fold = state->f;
         ae_v_move(state->xk.xR, 1, state->x.xR, 1, n);
         for (i = 0; i < n; i++) {
            state->dk.xR[i] = -state->g.xR[i] * state->ak.xR[i];
            state->gc.xR[i] = state->g.xR[i] * state->ak.xR[i];
         }
         while (true) {
         // Store G[k] for later calculation of Y[k]
            for (i = 0; i < n; i++) {
               state->yk.xR[i] = -state->gc.xR[i];
            }
         // Make a CG step in direction given by DK[]:
         // * calculate step. Step projection into feasible set
         //   is used. It has several benefits: a) step may be
         //   found with usual line search, b) multiple constraints
         //   may be activated with one step, c) activated constraints
         //   are detected in a natural way - just compare x[i] with
         //   bounds
         // * update active set, set B to True, if there
         //   were changes in the set.
            ae_v_move(state->d.xR, 1, state->dk.xR, 1, n);
            ae_v_move(state->xn.xR, 1, state->xk.xR, 1, n);
            state->mcstage = 0;
            state->stp = 1.0;
            linminnormalized(&state->d, &state->stp, n);
            if (state->laststep != 0.0) {
               state->stp = state->laststep;
            }
            while (mcsrch(n, &state->xn, state->f, &state->gc, &state->d, &state->stp, state->stpmax, gtol, &mcinfo, &state->nfev, &state->work, &state->lstate, &state->mcstage)) {
            // preprocess data: bound State.XN so it belongs to the
            // feasible set and store it in the State.X
               for (i = 0; i < n; i++) {
                  state->x.xR[i] = rboundval(state->xn.xR[i], state->bndl.xR[i], state->bndu.xR[i]);
               }
            // RComm
               state->needfg = true, state->PQ = 9; goto Pause; Resume09: state->needfg = false;
            // postprocess data: zero components of G corresponding to
            // the active constraints
               for (i = 0; i < n; i++) {
                  if (state->x.xR[i] == state->bndl.xR[i] || state->x.xR[i] == state->bndu.xR[i]) {
                     state->gc.xR[i] = 0.0;
                  } else {
                     state->gc.xR[i] = state->g.xR[i];
                  }
               }
            }
            diffcnt = 0;
            for (i = 0; i < n; i++) {
            // XN contains unprojected result, project it,
            // save copy to X (will be used for progress reporting)
               state->xn.xR[i] = rboundval(state->xn.xR[i], state->bndl.xR[i], state->bndu.xR[i]);
            // update active set
               if (state->xn.xR[i] == state->bndl.xR[i] || state->xn.xR[i] == state->bndu.xR[i]) {
                  state->an.xR[i] = 0.0;
               } else {
                  state->an.xR[i] = 1.0;
               }
               if (state->an.xR[i] != state->ak.xR[i]) {
                  diffcnt++;
               }
               state->ak.xR[i] = state->an.xR[i];
            }
            ae_v_move(state->xk.xR, 1, state->xn.xR, 1, n);
            state->repnfev += state->nfev;
            state->repiterationscount++;
            if (state->xrep) {
            // progress report
               state->xupdated = true, state->PQ = 10; goto Pause; Resume10: state->xupdated = false;
            }
         // Update info about step length
            v = ae_v_dotproduct(state->d.xR, 1, state->d.xR, 1, n);
            state->laststep = sqrt(v) * state->stp;
         // Check stopping conditions.
            if (mincomp_asaboundedantigradnorm(state) <= state->epsg) {
            // Gradient is small enough
               state->repterminationtype = 4;
               if (state->xrep) {
                  state->xupdated = true, state->PQ = 11; goto Pause; Resume11: state->xupdated = false;
               }
               goto Exit;
            } else if (state->repiterationscount >= state->maxits && state->maxits > 0) {
            // Too many iterations
               state->repterminationtype = 5;
               if (state->xrep) {
                  state->xupdated = true, state->PQ = 12; goto Pause; Resume12: state->xupdated = false;
               }
               goto Exit;
            }
            if (mincomp_asaginorm(state) >= state->mu * mincomp_asad1norm(state) && diffcnt == 0) {
            // These conditions (EpsF/EpsX) are explicitly or implicitly
            // related to the current step size and influenced
            // by changes in the active constraints.
            //
            // For these reasons they are checked only when we don't
            // want to 'unstick' at the end of the iteration and there
            // were no changes in the active set.
            //
            // NOTE: consition |G| >= Mu*|D1| must be exactly opposite
            // to the condition used to switch back to GPA. At least
            // one inequality must be strict, otherwise infinite cycle
            // may occur when |G| == Mu*|D1| (we DON'T test stopping
            // conditions and we DON'T switch to GPA, so we cycle
            // indefinitely).
               if (state->fold - state->f <= state->epsf * rmax2(fabs(state->fold), rmax2(fabs(state->f), 1.0))) {
               // F(k+1)-F(k) is small enough
                  state->repterminationtype = 1;
                  if (state->xrep) {
                     state->xupdated = true, state->PQ = 13; goto Pause; Resume13: state->xupdated = false;
                  }
                  goto Exit;
               } else if (state->laststep <= state->epsx) {
               // X(k+1)-X(k) is small enough
                  state->repterminationtype = 2;
                  if (state->xrep) {
                     state->xupdated = true, state->PQ = 14; goto Pause; Resume14: state->xupdated = false;
                  }
                  goto Exit;
               }
            }
         // Check conditions for switching
            if (mincomp_asaginorm(state) < state->mu * mincomp_asad1norm(state)) {
               state->curalgo = 0;
               break;
            } else if (diffcnt > 0) {
               if (mincomp_asauisempty(state) || diffcnt >= n2) {
                  state->curalgo = 1;
               } else {
                  state->curalgo = 0;
               }
               break;
            }
         // Calculate D(k+1)
         //
         // Line search may result in:
         // * maximum feasible step being taken (already processed)
         // * point satisfying Wolfe conditions
         // * some kind of error (CG is restarted by assigning 0.0 to Beta)
            if (mcinfo == 1) {
            // Standard Wolfe conditions are satisfied:
            // * calculate Y[K] and BetaK
               ae_v_add(state->yk.xR, 1, state->gc.xR, 1, n);
               vv = ae_v_dotproduct(state->yk.xR, 1, state->dk.xR, 1, n);
               v = ae_v_dotproduct(state->gc.xR, 1, state->gc.xR, 1, n);
               state->betady = v / vv;
               v = ae_v_dotproduct(state->gc.xR, 1, state->yk.xR, 1, n);
               state->betahs = v / vv;
               if (state->cgtype == 0) {
                  betak = state->betady;
               }
               if (state->cgtype == 1) {
                  betak = rmax2(0.0, rmin2(state->betady, state->betahs));
               }
            } else {
            // Something is wrong (may be function is too wild or too flat).
            //
            // We'll set BetaK == 0, which will restart CG algorithm.
            // We can stop later (during normal checks) if stopping conditions are met.
               betak = 0.0;
               state->debugrestartscount++;
            }
            ae_v_moveneg(state->dn.xR, 1, state->gc.xR, 1, n);
            ae_v_addd(state->dn.xR, 1, state->dk.xR, 1, n, betak);
            ae_v_move(state->dk.xR, 1, state->dn.xR, 1, n);
         // update other information
            state->fold = state->f;
            state->k++;
         }
      }
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
// API: void minasaresultsbuf(const minasastate &state, real_1d_array &x, minasareport &rep);
void minasaresultsbuf(minasastate *state, RVector *x, minasareport *rep) {
   ae_int_t i;
   vectorsetlengthatleast(x, state->n);
   ae_v_move(x->xR, 1, state->x.xR, 1, state->n);
   rep->iterationscount = state->repiterationscount;
   rep->nfev = state->repnfev;
   rep->terminationtype = state->repterminationtype;
   rep->activeconstraints = 0;
   for (i = 0; i < state->n; i++) {
      if (state->ak.xR[i] == 0.0) {
         rep->activeconstraints++;
      }
   }
}

// Obsolete optimization algorithm.
// Was replaced by MinBLEIC subpackage.
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
// API: void minasaresults(const minasastate &state, real_1d_array &x, minasareport &rep);
void minasaresults(minasastate *state, RVector *x, minasareport *rep) {
   SetVector(x);
   SetObj(minasareport, rep);
   minasaresultsbuf(state, x, rep);
}

void minasastate_init(void *_p, bool make_automatic) {
   minasastate *p = (minasastate *)_p;
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ak, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->an, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->dn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->work, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->yk, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->gc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   linminstate_init(&p->lstate, make_automatic);
}

void minasastate_copy(void *_dst, const void *_src, bool make_automatic) {
   minasastate *dst = (minasastate *)_dst;
   const minasastate *src = (const minasastate *)_src;
   dst->n = src->n;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->xrep = src->xrep;
   dst->stpmax = src->stpmax;
   dst->cgtype = src->cgtype;
   dst->k = src->k;
   dst->nfev = src->nfev;
   dst->mcstage = src->mcstage;
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   dst->curalgo = src->curalgo;
   dst->acount = src->acount;
   dst->mu = src->mu;
   dst->finit = src->finit;
   dst->dginit = src->dginit;
   ae_vector_copy(&dst->ak, &src->ak, make_automatic);
   ae_vector_copy(&dst->xk, &src->xk, make_automatic);
   ae_vector_copy(&dst->dk, &src->dk, make_automatic);
   ae_vector_copy(&dst->an, &src->an, make_automatic);
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->dn, &src->dn, make_automatic);
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->fold = src->fold;
   dst->stp = src->stp;
   ae_vector_copy(&dst->work, &src->work, make_automatic);
   ae_vector_copy(&dst->yk, &src->yk, make_automatic);
   ae_vector_copy(&dst->gc, &src->gc, make_automatic);
   dst->laststep = src->laststep;
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->needfg = src->needfg;
   dst->xupdated = src->xupdated;
   dst->PQ = src->PQ;
   dst->repiterationscount = src->repiterationscount;
   dst->repnfev = src->repnfev;
   dst->repterminationtype = src->repterminationtype;
   dst->debugrestartscount = src->debugrestartscount;
   linminstate_copy(&dst->lstate, &src->lstate, make_automatic);
   dst->betahs = src->betahs;
   dst->betady = src->betady;
}

void minasastate_free(void *_p, bool make_automatic) {
   minasastate *p = (minasastate *)_p;
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->ak, make_automatic);
   ae_vector_free(&p->xk, make_automatic);
   ae_vector_free(&p->dk, make_automatic);
   ae_vector_free(&p->an, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->dn, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->work, make_automatic);
   ae_vector_free(&p->yk, make_automatic);
   ae_vector_free(&p->gc, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   linminstate_free(&p->lstate, make_automatic);
}

void minasareport_init(void *_p, bool make_automatic) {
}

void minasareport_copy(void *_dst, const void *_src, bool make_automatic) {
   minasareport *dst = (minasareport *)_dst;
   const minasareport *src = (const minasareport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->terminationtype = src->terminationtype;
   dst->activeconstraints = src->activeconstraints;
}

void minasareport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
DefClass(minasastate, DecVal(needfg) DecVal(xupdated) DecVal(f) DecVar(g) DecVar(x))
DefClass(minasareport, DecVal(iterationscount) DecVal(nfev) DecVal(terminationtype) DecVal(activeconstraints))

void minlbfgssetdefaultpreconditioner(const minlbfgsstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetdefaultpreconditioner(ConstT(minlbfgsstate, state));
   alglib_impl::ae_state_clear();
}

void minlbfgssetcholeskypreconditioner(const minlbfgsstate &state, const real_2d_array &p, const bool isupper) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minlbfgssetcholeskypreconditioner(ConstT(minlbfgsstate, state), ConstT(ae_matrix, p), isupper);
   alglib_impl::ae_state_clear();
}

void minbleicsetbarrierwidth(const minbleicstate &state, const double mu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetbarrierwidth(ConstT(minbleicstate, state), mu);
   alglib_impl::ae_state_clear();
}

void minbleicsetbarrierdecay(const minbleicstate &state, const double mudecay) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbleicsetbarrierdecay(ConstT(minbleicstate, state), mudecay);
   alglib_impl::ae_state_clear();
}

void minasasetcond(const minasastate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasasetcond(ConstT(minasastate, state), epsg, epsf, epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minasasetxrep(const minasastate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasasetxrep(ConstT(minasastate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minasasetalgorithm(const minasastate &state, const ae_int_t algotype) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasasetalgorithm(ConstT(minasastate, state), algotype);
   alglib_impl::ae_state_clear();
}

void minasasetstpmax(const minasastate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasasetstpmax(ConstT(minasastate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void minasarestartfrom(const minasastate &state, const real_1d_array &x, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasarestartfrom(ConstT(minasastate, state), ConstT(ae_vector, x), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minasacreate(const ae_int_t n, const real_1d_array &x, const real_1d_array &bndl, const real_1d_array &bndu, minasastate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasacreate(n, ConstT(ae_vector, x), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu), ConstT(minasastate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minasacreate(const real_1d_array &x, const real_1d_array &bndl, const real_1d_array &bndu, minasastate &state) {
   ae_int_t n = x.length();
   if (n != bndl.length() || n != bndu.length()) ThrowError("Error while calling 'minasacreate': looks like one of arguments has wrong size");
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasacreate(n, ConstT(ae_vector, x), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu), ConstT(minasastate, state));
   alglib_impl::ae_state_clear();
}
#endif

bool minasaiteration(const minasastate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minasaiteration(ConstT(minasastate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     grad    -   callback which calculates function (or merit function)
//                 value func and gradient grad at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
// ALGLIB: Copyright 20.03.2009 by Sergey Bochkanov
void minasaoptimize(minasastate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(grad != NULL, "minasaoptimize: grad is NULL");
   while (alglib_impl::minasaiteration(state.c_ptr()))
   BegPoll
      if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minasaoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minasaresultsbuf(const minasastate &state, real_1d_array &x, minasareport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasaresultsbuf(ConstT(minasastate, state), ConstT(ae_vector, x), ConstT(minasareport, rep));
   alglib_impl::ae_state_clear();
}

void minasaresults(const minasastate &state, real_1d_array &x, minasareport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minasaresults(ConstT(minasastate, state), ConstT(ae_vector, x), ConstT(minasareport, rep));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === MINBC Package ===
// Depends on: (AlgLibInternal) LINMIN
// Depends on: OPTSERV
namespace alglib_impl {
// This function sets boundary constraints for BC optimizer.
//
// Boundary constraints are inactive by default (after initial creation).
// They are preserved after algorithm restart with MinBCRestartFrom().
//
// Inputs:
//     State   -   structure stores algorithm state
//     BndL    -   lower bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very small number or -INF.
//     BndU    -   upper bounds, array[N].
//                 If some (all) variables are unbounded, you may specify
//                 very large number or +INF.
//
// NOTE 1: it is possible to specify BndL[i] == BndU[i]. In this case I-th
// variable will be "frozen" at X[i] == BndL[i] == BndU[i].
//
// NOTE 2: this solver has following useful properties:
// * bound constraints are always satisfied exactly
// * function is evaluated only INSIDE area specified by  bound  constraints,
//   even  when  numerical  differentiation is used (algorithm adjusts  nodes
//   according to boundary constraints)
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbcsetbc(const minbcstate &state, const real_1d_array &bndl, const real_1d_array &bndu);
void minbcsetbc(minbcstate *state, RVector *bndl, RVector *bndu) {
   ae_int_t i;
   ae_int_t n;
   n = state->nmain;
   ae_assert(bndl->cnt >= n, "MinBCSetBC: Length(BndL) < N");
   ae_assert(bndu->cnt >= n, "MinBCSetBC: Length(BndU) < N");
   for (i = 0; i < n; i++) {
      ae_assert(isfinite(bndl->xR[i]) || isneginf(bndl->xR[i]), "MinBCSetBC: BndL contains NAN or +INF");
      ae_assert(isfinite(bndu->xR[i]) || isposinf(bndu->xR[i]), "MinBCSetBC: BndL contains NAN or -INF");
      state->bndl.xR[i] = bndl->xR[i];
      state->hasbndl.xB[i] = isfinite(bndl->xR[i]);
      state->bndu.xR[i] = bndu->xR[i];
      state->hasbndu.xB[i] = isfinite(bndu->xR[i]);
   }
}

// This function sets stopping conditions for the optimizer.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     EpsG    -   >= 0
//                 The  subroutine  finishes  its  work   if   the  condition
//                 |v| < EpsG is satisfied, where:
//                 * |.| means Euclidian norm
//                 * v - scaled gradient vector, v[i] == g[i]*s[i]
//                 * g - gradient
//                 * s - scaling coefficients set by MinBCSetScale()
//     EpsF    -   >= 0
//                 The  subroutine  finishes  its work if on k+1-th iteration
//                 the  condition  |F(k+1)-F(k)| <= EpsF*max{|F(k)|,|F(k+1)|,1}
//                 is satisfied.
//     EpsX    -   >= 0
//                 The subroutine finishes its work if  on  k+1-th  iteration
//                 the condition |v| <= EpsX is fulfilled, where:
//                 * |.| means Euclidian norm
//                 * v - scaled step vector, v[i] == dx[i]/s[i]
//                 * dx - step vector, dx == X(k+1)-X(k)
//                 * s - scaling coefficients set by MinBCSetScale()
//     MaxIts  -   maximum number of iterations. If MaxIts == 0, the  number  of
//                 iterations is unlimited.
//
// Passing EpsG == 0, EpsF == 0 and EpsX == 0 and MaxIts == 0 (simultaneously) will lead
// to automatic stopping criterion selection.
//
// NOTE: when SetCond() called with non-zero MaxIts, BC solver may perform
//       slightly more than MaxIts iterations. I.e., MaxIts  sets  non-strict
//       limit on iterations count.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbcsetcond(const minbcstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits);
void minbcsetcond(minbcstate *state, double epsg, double epsf, double epsx, ae_int_t maxits) {
   ae_assert(isfinite(epsg), "MinBCSetCond: EpsG is not finite number");
   ae_assert(epsg >= 0.0, "MinBCSetCond: negative EpsG");
   ae_assert(isfinite(epsf), "MinBCSetCond: EpsF is not finite number");
   ae_assert(epsf >= 0.0, "MinBCSetCond: negative EpsF");
   ae_assert(isfinite(epsx), "MinBCSetCond: EpsX is not finite number");
   ae_assert(epsx >= 0.0, "MinBCSetCond: negative EpsX");
   ae_assert(maxits >= 0, "MinBCSetCond: negative MaxIts!");
   if (epsg == 0.0 && epsf == 0.0 && epsx == 0.0 && maxits == 0) {
      epsx = 0.000001;
   }
   state->epsg = epsg;
   state->epsf = epsf;
   state->epsx = epsx;
   state->maxits = maxits;
}

// This function sets scaling coefficients for BC optimizer.
//
// ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
// size and gradient are scaled before comparison with tolerances).  Scale of
// the I-th variable is a translation invariant measure of:
// a) "how large" the variable is
// b) how large the step should be to make significant changes in the function
//
// Scaling is also used by finite difference variant of the optimizer  - step
// along I-th axis is equal to DiffStep*S[I].
//
// In  most  optimizers  (and  in  the  BC  too)  scaling is NOT a form of
// preconditioning. It just  affects  stopping  conditions.  You  should  set
// preconditioner  by  separate  call  to  one  of  the  MinBCSetPrec...()
// functions.
//
// There is a special  preconditioning  mode, however,  which  uses   scaling
// coefficients to form diagonal preconditioning matrix. You  can  turn  this
// mode on, if you want.   But  you should understand that scaling is not the
// same thing as preconditioning - these are two different, although  related
// forms of tuning solver.
//
// Inputs:
//     State   -   structure stores algorithm state
//     S       -   array[N], non-zero scaling coefficients
//                 S[i] may be negative, sign doesn't matter.
// ALGLIB: Copyright 14.01.2011 by Sergey Bochkanov
// API: void minbcsetscale(const minbcstate &state, const real_1d_array &s);
void minbcsetscale(minbcstate *state, RVector *s) {
   ae_int_t i;
   ae_assert(s->cnt >= state->nmain, "MinBCSetScale: Length(S) < N");
   for (i = 0; i < state->nmain; i++) {
      ae_assert(isfinite(s->xR[i]), "MinBCSetScale: S contains infinite or NAN elements");
      ae_assert(s->xR[i] != 0.0, "MinBCSetScale: S contains zero elements");
      state->s.xR[i] = fabs(s->xR[i]);
   }
}

// Modification of the preconditioner: preconditioning is turned off.
//
// Inputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minbcsetprecdefault(const minbcstate &state);
void minbcsetprecdefault(minbcstate *state) {
   state->prectype = 0;
}

// Modification  of  the  preconditioner:  diagonal of approximate Hessian is
// used.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     D       -   diagonal of the approximate Hessian, array[0..N-1],
//                 (if larger, only leading N elements are used).
//
// NOTE 1: D[i] should be positive. Exception will be thrown otherwise.
//
// NOTE 2: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minbcsetprecdiag(const minbcstate &state, const real_1d_array &d);
void minbcsetprecdiag(minbcstate *state, RVector *d) {
   ae_int_t i;
   ae_assert(d->cnt >= state->nmain, "MinBCSetPrecDiag: D is too short");
   for (i = 0; i < state->nmain; i++) {
      ae_assert(isfinite(d->xR[i]), "MinBCSetPrecDiag: D contains infinite or NAN elements");
      ae_assert(d->xR[i] > 0.0, "MinBCSetPrecDiag: D contains non-positive elements");
   }
   vectorsetlengthatleast(&state->diagh, state->nmain);
   state->prectype = 2;
   for (i = 0; i < state->nmain; i++) {
      state->diagh.xR[i] = d->xR[i];
   }
}

// Modification of the preconditioner: scale-based diagonal preconditioning.
//
// This preconditioning mode can be useful when you  don't  have  approximate
// diagonal of Hessian, but you know that your  variables  are  badly  scaled
// (for  example,  one  variable is in [1,10], and another in [1000,100000]),
// and most part of the ill-conditioning comes from different scales of vars.
//
// In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
// can greatly improve convergence.
//
// IMPRTANT: you should set scale of your variables  with  MinBCSetScale()
// call  (before  or after MinBCSetPrecScale() call). Without knowledge of
// the scale of your variables scale-based preconditioner will be  just  unit
// matrix.
//
// Inputs:
//     State   -   structure which stores algorithm state
// ALGLIB: Copyright 13.10.2010 by Sergey Bochkanov
// API: void minbcsetprecscale(const minbcstate &state);
void minbcsetprecscale(minbcstate *state) {
   state->prectype = 3;
}

// This function turns on/off reporting.
//
// Inputs:
//     State   -   structure which stores algorithm state
//     NeedXRep-   whether iteration reports are needed or not
//
// If NeedXRep is True, algorithm will call rep() callback function if  it is
// provided to MinBCOptimize().
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbcsetxrep(const minbcstate &state, const bool needxrep);
void minbcsetxrep(minbcstate *state, bool needxrep) {
   state->xrep = needxrep;
}

// This function sets maximum step length
//
// Inputs:
//     State   -   structure which stores algorithm state
//     StpMax  -   maximum step length, >= 0. Set StpMax to 0.0,  if you don't
//                 want to limit step length.
//
// Use this subroutine when you optimize target function which contains exp()
// or  other  fast  growing  functions,  and optimization algorithm makes too
// large  steps  which  lead   to overflow. This function allows us to reject
// steps  that  are  too  large  (and  therefore  expose  us  to the possible
// overflow) without actually calculating function value at the x+stp*d.
// ALGLIB: Copyright 02.04.2010 by Sergey Bochkanov
// API: void minbcsetstpmax(const minbcstate &state, const double stpmax);
void minbcsetstpmax(minbcstate *state, double stpmax) {
   ae_assert(isfinite(stpmax), "MinBCSetStpMax: StpMax is not finite!");
   ae_assert(stpmax >= 0.0, "MinBCSetStpMax: StpMax < 0!");
   state->stpmax = stpmax;
}

// This subroutine restarts algorithm from new point.
// All optimization parameters (including constraints) are left unchanged.
//
// This  function  allows  to  solve multiple  optimization  problems  (which
// must have  same number of dimensions) without object reallocation penalty.
//
// Inputs:
//     State   -   structure previously allocated with MinBCCreate call.
//     X       -   new starting point.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbcrestartfrom(const minbcstate &state, const real_1d_array &x);
void minbcrestartfrom(minbcstate *state, RVector *x) {
   ae_int_t n;
   n = state->nmain;
// First, check for errors in the inputs
   ae_assert(x->cnt >= n, "MinBCRestartFrom: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinBCRestartFrom: X contains infinite or NaN values!");
// Set XC
   ae_v_move(state->xstart.xR, 1, x->xR, 1, n);
// prepare RComm facilities
   state->PQ = -1;
}

// Internal initialization subroutine.
static void minbc_minbcinitinternal(ae_int_t n, RVector *x, double diffstep, minbcstate *state) {
   ae_int_t i;
   EnFrame();
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
// Initialize
   state->teststep = 0.0;
   state->smoothnessguardlevel = 0;
   smoothnessmonitorinit(&state->smonitor, &state->s, 0, 0, false);
   state->nmain = n;
   state->diffstep = diffstep;
   vectorsetlengthatleast(&state->bndl, n);
   vectorsetlengthatleast(&state->hasbndl, n);
   vectorsetlengthatleast(&state->bndu, n);
   vectorsetlengthatleast(&state->hasbndu, n);
   vectorsetlengthatleast(&state->xstart, n);
   vectorsetlengthatleast(&state->xc, n);
   vectorsetlengthatleast(&state->cgc, n);
   vectorsetlengthatleast(&state->ugc, n);
   vectorsetlengthatleast(&state->xn, n);
   vectorsetlengthatleast(&state->cgn, n);
   vectorsetlengthatleast(&state->ugn, n);
   vectorsetlengthatleast(&state->xp, n);
   vectorsetlengthatleast(&state->d, n);
   vectorsetlengthatleast(&state->s, n);
   vectorsetlengthatleast(&state->invs, n);
   vectorsetlengthatleast(&state->lastscaleused, n);
   vectorsetlengthatleast(&state->x, n);
   vectorsetlengthatleast(&state->g, n);
   vectorsetlengthatleast(&state->work, n);
   for (i = 0; i < n; i++) {
      state->bndl.xR[i] = -INFINITY;
      state->hasbndl.xB[i] = false;
      state->bndu.xR[i] = +INFINITY;
      state->hasbndu.xB[i] = false;
      state->s.xR[i] = 1.0;
      state->invs.xR[i] = 1.0;
      state->lastscaleused.xR[i] = 1.0;
   }
   minbcsetcond(state, 0.0, 0.0, 0.0, 0);
   minbcsetxrep(state, false);
   minbcsetstpmax(state, 0.0);
   minbcsetprecdefault(state);
   minbcrestartfrom(state, x);
   DeFrame();
}

// BOX CONSTRAINED OPTIMIZATION
// WITH FAST ACTIVATION OF MULTIPLE BOX CONSTRAINTS
// The  subroutine  minimizes  function   F(x) of N arguments subject  to box
// constraints (with some of box constraints actually being equality ones).
//
// This optimizer uses algorithm similar to that of MinBLEIC (optimizer  with
// general linear constraints), but presence of box-only  constraints  allows
// us to use faster constraint activation strategies. On large-scale problems,
// with multiple constraints active at the solution, this  optimizer  can  be
// several times faster than BLEIC.
//
// REQUIREMENTS:
// * user must provide function value and gradient
// * starting point X0 must be feasible or
//   not too far away from the feasible set
// * grad(f) must be Lipschitz continuous on a level set:
//   L = { x : f(x) <= f(x0) }
// * function must be defined everywhere on the feasible set F
//
// USAGE:
//
// Constrained optimization if far more complex than the unconstrained one.
// Here we give very brief outline of the BC optimizer. We strongly recommend
// you to read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
// on optimization, which is available at http://www.alglib.net/optimization/
//
// 1. User initializes algorithm state with MinBCCreate() call
//
// 2. USer adds box constraints by calling MinBCSetBC() function.
//
// 3. User sets stopping conditions with MinBCSetCond().
//
// 4. User calls MinBCOptimize() function which takes algorithm  state and
//    pointer (delegate, etc.) to callback function which calculates F/G.
//
// 5. User calls MinBCResults() to get solution
//
// 6. Optionally user may call MinBCRestartFrom() to solve another problem
//    with same N but another starting point.
//    MinBCRestartFrom() allows to reuse already initialized structure.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size ofX
//     X       -   starting point, array[N]:
//                 * it is better to set X to a feasible point
//                 * but X can be infeasible, in which case algorithm will try
//                   to find feasible point first, using X as initial
//                   approximation.
//
// Outputs:
//     State   -   structure stores algorithm state
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbccreate(const ae_int_t n, const real_1d_array &x, minbcstate &state);
// API: void minbccreate(const real_1d_array &x, minbcstate &state);
void minbccreate(ae_int_t n, RVector *x, minbcstate *state) {
   EnFrame();
   SetObj(minbcstate, state);
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
   ae_assert(n >= 1, "MinBCCreate: N < 1");
   ae_assert(x->cnt >= n, "MinBCCreate: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinBCCreate: X contains infinite or NaN values!");
   minbc_minbcinitinternal(n, x, 0.0, state);
   DeFrame();
}

// The subroutine is finite difference variant of MinBCCreate().  It  uses
// finite differences in order to differentiate target function.
//
// Description below contains information which is specific to  this function
// only. We recommend to read comments on MinBCCreate() in  order  to  get
// more information about creation of BC optimizer.
//
// Inputs:
//     N       -   problem dimension, N > 0:
//                 * if given, only leading N elements of X are used
//                 * if not given, automatically determined from size of X
//     X       -   starting point, array[0..N-1].
//     DiffStep-   differentiation step, > 0
//
// Outputs:
//     State   -   structure which stores algorithm state
//
// NOTES:
// 1. algorithm uses 4-point central formula for differentiation.
// 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
//    S[] is scaling vector which can be set by MinBCSetScale() call.
// 3. we recommend you to use moderate values of  differentiation  step.  Too
//    large step will result in too large truncation  errors, while too small
//    step will result in too large numerical  errors.  0.000001  can be good
//    value to start with.
// 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
//    calculation needs 4*N function evaluations. This function will work for
//    any N - either small (1...10), moderate (10...100) or  large  (100...).
//    However, performance penalty will be too severe for any N's except  for
//    small ones.
//    We should also say that code which relies on numerical  differentiation
//    is  less  robust and precise. CG needs exact gradient values. Imprecise
//    gradient may slow  down  convergence, especially  on  highly  nonlinear
//    problems.
//    Thus  we  recommend to use this function for fast prototyping on small-
//    dimensional problems only, and to implement analytical gradient as soon
//    as possible.
// ALGLIB: Copyright 16.05.2011 by Sergey Bochkanov
// API: void minbccreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minbcstate &state);
// API: void minbccreatef(const real_1d_array &x, const double diffstep, minbcstate &state);
void minbccreatef(ae_int_t n, RVector *x, double diffstep, minbcstate *state) {
   EnFrame();
   SetObj(minbcstate, state);
   NewRMatrix(c, 0, 0);
   NewZVector(ct, 0);
   ae_assert(n >= 1, "MinBCCreateF: N < 1");
   ae_assert(x->cnt >= n, "MinBCCreateF: Length(X) < N");
   ae_assert(isfinitevector(x, n), "MinBCCreateF: X contains infinite or NaN values!");
   ae_assert(isfinite(diffstep), "MinBCCreateF: DiffStep is infinite or NaN!");
   ae_assert(diffstep > 0.0, "MinBCCreateF: DiffStep is non-positive!");
   minbc_minbcinitinternal(n, x, diffstep, state);
   DeFrame();
}

// This subroutine updates estimate of the good step length given:
// 1) previous estimate
// 2) new length of the good step
//
// It makes sure that estimate does not change too rapidly - ratio of new and
// old estimates will be at least 0.01, at most 100.0
//
// In case previous estimate of good step is zero (no estimate), new estimate
// is used unconditionally.
// ALGLIB: Copyright 16.01.2013 by Sergey Bochkanov
static void minbc_updateestimateofgoodstep(double *estimate, double newstep) {
   if (*estimate == 0.0) {
      *estimate = newstep;
      return;
   }
   if (newstep < *estimate * 0.01) {
      *estimate *= 0.01;
      return;
   }
   if (newstep > *estimate * 100.0) {
      *estimate *= 100.0;
      return;
   }
   *estimate = newstep;
}

// This function provides a reverse communication interface, which is not documented or recommended for use.
// Instead, it is recommended that you use the better-documented API functions minbcoptimize() listed below.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: bool minbciteration(const minbcstate &state);
// API: void minbcoptimize(minbcstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
// API: void minbcoptimize(minbcstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr) = NULL, void *ptr = NULL);
bool minbciteration(minbcstate *state) {
   const double gtol = 0.4, maxnonmonotoniclen = 0.00001, initialdecay = 0.5, mindecay = 0.1, decaycorrection = 0.8;
   AutoS ae_int_t freezeidx;
   AutoS double freezeval;
   AutoS double scaleddnorm;
   AutoS ae_int_t n;
   AutoS ae_int_t m;
   AutoS ae_int_t i;
   AutoS ae_int_t j;
   AutoS double v;
   AutoS double vv;
   AutoS double v0;
   AutoS bool b;
   AutoS ae_int_t mcinfo;
   AutoS ae_int_t itidx;
   AutoS double ginit;
   AutoS double gdecay;
   AutoS bool activationstatus;
   AutoS double activationstep;
// Manually threaded two-way signalling.
// Locals are zeroed out the first time around and are retained between pauses and subsequent resumes.
// A Spawn occurs when the routine is (re-)started.
// A Pause sends an event signal and waits for a response with data before carrying out the matching Resume.
// An Exit sends an exit signal indicating the end of the process.
   if (state->PQ >= 0) switch (state->PQ) {
      case 0: goto Resume00; case 1: goto Resume01; case 2: goto Resume02; case 3: goto Resume03;
      case 4: goto Resume04; case 5: goto Resume05; case 6: goto Resume06; case 7: goto Resume07;
      case 8: goto Resume08; case 9: goto Resume09; case 10: goto Resume10; case 11: goto Resume11;
      case 12: goto Resume12; case 13: goto Resume13; case 14: goto Resume14; case 15: goto Resume15;
      case 16: goto Resume16; case 17: goto Resume17; case 18: goto Resume18; case 19: goto Resume19;
      case 20: goto Resume20; case 21: goto Resume21; case 22: goto Resume22; case 23: goto Resume23;
      case 24: goto Resume24; case 25: goto Resume25; case 26: goto Resume26;
      case 27: goto Resume27; case 28: goto Resume28; case 29: goto Resume29;
      default: goto Exit;
   }
Spawn:
// Algorithm parameters:
// * M          number of L-BFGS corrections.
//              This coefficient remains fixed during iterations.
// * GDecay     desired decrease of constrained gradient during L-BFGS iterations.
//              This coefficient is decreased after each L-BFGS round until
//              it reaches minimum decay.
   m = imin2(5, state->nmain);
   gdecay = initialdecay;
// Init
   n = state->nmain;
   state->xupdated = state->needfg = state->needf = false;
   for (i = 0; i < n; i++) {
      state->xc.xR[i] = state->xstart.xR[i];
   }
   if (!enforceboundaryconstraints(&state->xc, &state->bndl, &state->hasbndl, &state->bndu, &state->hasbndu, n, 0)) {
   // Inconsistent constraints
      state->repterminationtype = -3;
      goto Exit;
   }
   state->userterminationneeded = false;
   state->repterminationtype = 0;
   state->repiterationscount = 0;
   state->repnfev = 0;
   state->repvaridx = -1;
   matrixsetlengthatleast(&state->bufyk, m + 1, n);
   matrixsetlengthatleast(&state->bufsk, m + 1, n);
   vectorsetlengthatleast(&state->bufrho, m);
   vectorsetlengthatleast(&state->buftheta, m);
   vectorsetlengthatleast(&state->tmp0, n);
   smoothnessmonitorinit(&state->smonitor, &state->s, n, 1, state->smoothnessguardlevel > 0);
   for (i = 0; i < n; i++) {
      state->lastscaleused.xR[i] = state->s.xR[i];
      state->invs.xR[i] = 1.0 / state->s.xR[i];
   }
// Fill TmpPrec with current preconditioner
   vectorsetlengthatleast(&state->tmpprec, n);
   for (i = 0; i < n; i++) {
      if (state->prectype == 2) {
         state->tmpprec.xR[i] = 1.0 / state->diagh.xR[i];
         continue;
      }
      if (state->prectype == 3) {
         state->tmpprec.xR[i] = sqr(state->s.xR[i]);
         continue;
      }
      state->tmpprec.xR[i] = 1.0;
   }
// Check correctness of user-supplied gradient
   if (state->diffstep == 0.0 && state->teststep > 0.0) {
      while (smoothnessmonitorcheckgradientatx0(&state->smonitor, &state->xc, &state->s, &state->bndl, &state->bndu, true, state->teststep)) {
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->smonitor.x.xR[i];
         }
         state->needfg = true, state->PQ = 0; goto Pause; Resume00: state->needfg = false;
         state->smonitor.fi.xR[0] = state->f;
         for (i = 0; i < n; i++) {
            state->smonitor.j.xyR[0][i] = state->g.xR[i];
         }
      }
   }
// Main cycle of BC-PG algorithm
   state->repterminationtype = 0;
   state->lastscaledgoodstep = 0.0;
   state->nonmonotoniccnt = iround(1.5 * n) + 5;
   ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
   if (state->diffstep == 0.0) {
      state->needfg = true, state->PQ = 1; goto Pause; Resume01: state->needfg = false;
   } else {
      state->needf = true, state->PQ = 2; goto Pause; Resume02: state->needf = false;
   }
   state->fc = state->f;
   trimprepare(state->f, &state->trimthreshold);
   state->repnfev++;
   if (state->xrep) {
   // Report current point
      ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
      state->f = state->fc;
      state->xupdated = true, state->PQ = 3; goto Pause; Resume03: state->xupdated = false;
   }
   if (state->userterminationneeded) {
   // User requested termination
      state->repterminationtype = 8;
      goto Exit;
   }
   while (true) {
   // Steepest descent phase
   //
   // (a) calculate unconstrained gradient
   // (b) check F/G for NAN/INF, abnormally terminate algorithm if needed
   // (c) perform one steepest descent step, activating only those constraints
   //     which prevent us from moving outside of box-constrained area
      ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
      if (state->diffstep == 0.0) {
      // Analytic gradient
         state->needfg = true, state->PQ = 4; goto Pause; Resume04: state->needfg = false;
      } else {
      // Numerical differentiation
         state->needf = true;
         state->PQ = 5; goto Pause; Resume05:
         state->fbase = state->f;
         for (i = 0; i < n; i++) {
            v = state->x.xR[i];
            b =
               state->hasbndl.xB[i] && v - state->diffstep * state->s.xR[i] < state->bndl.xR[i] ||
               state->hasbndu.xB[i] && v + state->diffstep * state->s.xR[i] > state->bndu.xR[i];
            if (!b) {
               state->x.xR[i] = v - state->diffstep * state->s.xR[i];
               state->PQ = 6; goto Pause; Resume06:
               state->fm2 = state->f;
               state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 7; goto Pause; Resume07:
               state->fm1 = state->f;
               state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
               state->PQ = 8; goto Pause; Resume08:
               state->fp1 = state->f;
               state->x.xR[i] = v + state->diffstep * state->s.xR[i];
               state->PQ = 9; goto Pause; Resume09:
               state->fp2 = state->f;
               state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
            } else {
               state->xm1 = v - state->diffstep * state->s.xR[i];
               state->xp1 = v + state->diffstep * state->s.xR[i];
               if (state->hasbndl.xB[i] && state->xm1 < state->bndl.xR[i]) {
                  state->xm1 = state->bndl.xR[i];
               }
               if (state->hasbndu.xB[i] && state->xp1 > state->bndu.xR[i]) {
                  state->xp1 = state->bndu.xR[i];
               }
               state->x.xR[i] = state->xm1;
               state->PQ = 10; goto Pause; Resume10:
               state->fm1 = state->f;
               state->x.xR[i] = state->xp1;
               state->PQ = 11; goto Pause; Resume11:
               state->fp1 = state->f;
               if (state->xm1 != state->xp1) {
                  state->g.xR[i] = (state->fp1 - state->fm1) / (state->xp1 - state->xm1);
               } else {
                  state->g.xR[i] = 0.0;
               }
            }
            state->x.xR[i] = v;
         }
         state->needf = false;
         state->f = state->fbase;
      }
      state->fc = state->f;
      ae_v_move(state->ugc.xR, 1, state->g.xR, 1, n);
      ae_v_move(state->cgc.xR, 1, state->g.xR, 1, n);
      projectgradientintobc(&state->xc, &state->cgc, &state->bndl, &state->hasbndl, &state->bndu, &state->hasbndu, n, 0);
      ginit = 0.0;
      for (i = 0; i < n; i++) {
         ginit += sqr(state->cgc.xR[i] * state->s.xR[i]);
      }
      ginit = sqrt(ginit);
      if (!isfinite(ginit) || !isfinite(state->fc)) {
      // Abnormal termination - infinities in function/gradient
         state->repterminationtype = -8;
         goto Exit;
      }
      if (state->userterminationneeded) {
      // User requested termination
         state->repterminationtype = 8;
         goto Exit;
      }
      if (ginit <= state->epsg) {
      // Gradient is small enough.
      // Optimization is terminated
         state->repterminationtype = 4;
         goto Exit;
      }
      for (i = 0; i < n; i++) {
         state->d.xR[i] = -state->tmpprec.xR[i] * state->cgc.xR[i];
      }
      scaleddnorm = 0.0;
      for (i = 0; i < n; i++) {
         scaleddnorm += sqr(state->d.xR[i] / state->s.xR[i]);
      }
      scaleddnorm = sqrt(scaleddnorm);
      ae_assert(scaleddnorm > 0.0, "MinBC: integrity check failed");
      if (state->lastscaledgoodstep > 0.0) {
         state->stp = state->lastscaledgoodstep / scaleddnorm;
      } else {
         state->stp = 1.0 / scaleddnorm;
      }
      calculatestepbound(&state->xc, &state->d, 1.0, &state->bndl, &state->hasbndl, &state->bndu, &state->hasbndu, n, 0, &freezeidx, &freezeval, &state->curstpmax);
      activationstep = state->curstpmax;
      if (freezeidx < 0 || state->curstpmax > 1.0E50) {
         state->curstpmax = 1.0E50;
      }
      if (state->stpmax > 0.0) {
         state->curstpmax = rmin2(state->curstpmax, state->stpmax / scaleddnorm);
      }
      ae_v_move(state->xn.xR, 1, state->xc.xR, 1, n);
      ae_v_move(state->cgn.xR, 1, state->cgc.xR, 1, n);
      ae_v_move(state->ugn.xR, 1, state->ugc.xR, 1, n);
      state->fn = state->fc;
      state->mcstage = 0;
      smoothnessmonitorstartlinesearch1u(&state->smonitor, &state->s, &state->invs, &state->xn, state->fn, &state->ugn, state->repiterationscount, -1);
      while (mcsrch(n, &state->xn, state->fn, &state->cgn, &state->d, &state->stp, state->curstpmax, gtol, &mcinfo, &state->nfev, &state->work, &state->lstate, &state->mcstage)) {
      // Copy XN to X, perform on-the-fly correction w.r.t box
      // constraints (projection onto feasible set).
         for (i = 0; i < n; i++) {
            state->x.xR[i] = state->xn.xR[i];
            if (state->hasbndl.xB[i] && state->xn.xR[i] < state->bndl.xR[i]) {
               state->x.xR[i] = state->bndl.xR[i];
            }
            if (state->hasbndu.xB[i] && state->xn.xR[i] > state->bndu.xR[i]) {
               state->x.xR[i] = state->bndu.xR[i];
            }
         }
      // Gradient, either user-provided or numerical differentiation
         if (state->diffstep == 0.0) {
         // Analytic gradient
            state->needfg = true, state->PQ = 12; goto Pause; Resume12: state->needfg = false;
            state->repnfev++;
         } else {
         // Numerical differentiation
            state->needf = true;
            state->PQ = 13; goto Pause; Resume13:
            state->fbase = state->f;
            for (i = 0; i < n; i++) {
               v = state->x.xR[i];
               b =
                  state->hasbndl.xB[i] && v - state->diffstep * state->s.xR[i] < state->bndl.xR[i] ||
                  state->hasbndu.xB[i] && v + state->diffstep * state->s.xR[i] > state->bndu.xR[i];
               if (!b) {
                  state->x.xR[i] = v - state->diffstep * state->s.xR[i];
                  state->PQ = 14; goto Pause; Resume14:
                  state->fm2 = state->f;
                  state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
                  state->PQ = 15; goto Pause; Resume15:
                  state->fm1 = state->f;
                  state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
                  state->PQ = 16; goto Pause; Resume16:
                  state->fp1 = state->f;
                  state->x.xR[i] = v + state->diffstep * state->s.xR[i];
                  state->PQ = 17; goto Pause; Resume17:
                  state->fp2 = state->f;
                  state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
                  state->repnfev += 4;
               } else {
                  state->xm1 = v - state->diffstep * state->s.xR[i];
                  state->xp1 = v + state->diffstep * state->s.xR[i];
                  if (state->hasbndl.xB[i] && state->xm1 < state->bndl.xR[i]) {
                     state->xm1 = state->bndl.xR[i];
                  }
                  if (state->hasbndu.xB[i] && state->xp1 > state->bndu.xR[i]) {
                     state->xp1 = state->bndu.xR[i];
                  }
                  state->x.xR[i] = state->xm1;
                  state->PQ = 18; goto Pause; Resume18:
                  state->fm1 = state->f;
                  state->x.xR[i] = state->xp1;
                  state->PQ = 19; goto Pause; Resume19:
                  state->fp1 = state->f;
                  if (state->xm1 != state->xp1) {
                     state->g.xR[i] = (state->fp1 - state->fm1) / (state->xp1 - state->xm1);
                  } else {
                     state->g.xR[i] = 0.0;
                  }
                  state->repnfev += 2;
               }
               state->x.xR[i] = v;
            }
            state->needf = false;
            state->f = state->fbase;
         }
      // Back to MCSRCH
         smoothnessmonitorenqueuepoint1u(&state->smonitor, &state->s, &state->invs, &state->d, state->stp, &state->x, state->f, &state->g);
         trimfunction(&state->f, &state->g, n, state->trimthreshold);
         state->fn = state->f;
         ae_v_move(state->cgn.xR, 1, state->g.xR, 1, n);
         ae_v_move(state->ugn.xR, 1, state->g.xR, 1, n);
         for (i = 0; i < n; i++) {
            if (state->d.xR[i] == 0.0) {
               state->cgn.xR[i] = 0.0;
            }
         }
      }
      smoothnessmonitorfinalizelinesearch(&state->smonitor);
      v = state->fn;
      for (i = 0; i < n; i++) {
         v = 0.1 * v + state->ugn.xR[i];
      }
      if (!isfinite(v)) {
      // Abnormal termination - infinities in function/gradient
         state->repterminationtype = -8;
         goto Exit;
      }
      if (mcinfo != 1 && mcinfo != 5) {
      // We can not find step which decreases function value. We have
      // two possibilities:
      // (a) numerical properties of the function do not allow us to
      //     find good step.
      // (b) we are close to activation of some constraint, and it is
      //     so close that step which activates it leads to change in
      //     target function which is smaller than numerical noise.
      //
      // Optimization algorithm must be able to handle case (b), because
      // inability to handle it will cause failure when algorithm
      // started very close to boundary of the feasible area.
      //
      // In order to correctly handle such cases we allow limited amount
      // of small steps which increase function value.
         if (freezeidx >= 0 && scaleddnorm * state->curstpmax <= maxnonmonotoniclen && state->nonmonotoniccnt > 0) {
         // We enforce non-monotonic step:
         // * Stp    = CurStpMax
         // * MCINFO = 5
         // * XN     = XC+CurStpMax*D
         // * non-monotonic counter is decreased
         //
         // NOTE: UGN/CGN are not updated because step is so short that we assume that
         //       GN is approximately equal to GC.
            state->stp = state->curstpmax;
            mcinfo = 5;
            v = state->curstpmax;
            ae_v_move(state->xn.xR, 1, state->xc.xR, 1, n);
            ae_v_addd(state->xn.xR, 1, state->d.xR, 1, n, v);
            state->nonmonotoniccnt--;
         } else {
         // Numerical properties of the function does not allow
         // us to solve problem. Algorithm is terminated
            state->repterminationtype = 7;
            goto Exit;
         }
      }
      if (state->userterminationneeded) {
      // User requested termination
         state->repterminationtype = 8;
         goto Exit;
      }
      ae_assert(mcinfo != 5 || state->stp == state->curstpmax, "MinBC: integrity check failed");
      postprocessboundedstep(&state->xn, &state->xc, &state->bndl, &state->hasbndl, &state->bndu, &state->hasbndu, n, 0, freezeidx, freezeval, state->stp, activationstep);
      state->fp = state->fc;
      state->fc = state->fn;
      ae_v_move(state->xp.xR, 1, state->xc.xR, 1, n);
      ae_v_move(state->xc.xR, 1, state->xn.xR, 1, n);
      ae_v_move(state->cgc.xR, 1, state->cgn.xR, 1, n);
      ae_v_move(state->ugc.xR, 1, state->ugn.xR, 1, n);
      if (state->xrep) {
         ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
         state->xupdated = true, state->PQ = 20; goto Pause; Resume20: state->xupdated = false;
      }
      state->repiterationscount++;
      if (mcinfo == 1) {
         v = 0.0;
         for (i = 0; i < n; i++) {
            v += sqr((state->xc.xR[i] - state->xp.xR[i]) / state->s.xR[i]);
         }
         v = sqrt(v);
         if (v <= state->epsx) {
         // Step is small enough
            state->repterminationtype = 2;
            goto Exit;
         }
         if (NearAtR(state->fp, state->fc, state->epsf * rmax2(fabs(state->fc), rmax2(fabs(state->fp), 1.0)))) {
         // Function change is small enough
            state->repterminationtype = 1;
            goto Exit;
         }
      }
      if (state->maxits > 0 && state->repiterationscount >= state->maxits) {
      // Iteration counter exceeded limit
         state->repterminationtype = 5;
         goto Exit;
      }
   // LBFGS stage:
   // * during LBFGS iterations we activate new constraints, but never
   //   deactivate already active ones.
   // * we perform at most N iterations of LBFGS before re-evaluating
   //   active set and restarting LBFGS.
   //
   // About termination:
   // * LBFGS iterations can be terminated because of two reasons:
   //   * "termination" - non-zero termination code in RepTerminationType,
   //     which means that optimization is done
   //   * "restart" - zero RepTerminationType, which means that we
   //     have to re-evaluate active set and resume LBFGS stage.
   // * one more option is "refresh" - to continue LBFGS iterations,
   //   but with all BFGS updates (Sk/Yk pairs) being dropped;
   //   it happens after changes in active set
      ginit = 0.0;
      for (i = 0; i < n; i++) {
         state->cgc.xR[i] = state->ugc.xR[i];
         if (state->hasbndl.xB[i] && state->xc.xR[i] == state->bndl.xR[i]) {
            state->cgc.xR[i] = 0.0;
         }
         if (state->hasbndu.xB[i] && state->xc.xR[i] == state->bndu.xR[i]) {
            state->cgc.xR[i] = 0.0;
         }
         ginit += sqr(state->cgc.xR[i] * state->s.xR[i]);
      }
      ginit = sqrt(ginit);
      state->bufsize = 0;
      for (itidx = 0; itidx < n; itidx++) {
      // At the beginning of each iteration:
      // * XC stores current point
      // * FC stores current function value
      // * UGC stores current unconstrained gradient
      // * CGC stores current constrained gradient
      // * D stores constrained step direction (calculated at this block)
      //
      // 1. Calculate search direction D according to L-BFGS algorithm
      //    using constrained preconditioner to perform inner multiplication.
      // 2. Evaluate scaled length of direction D; restart LBFGS if D is zero
      //    (it may be possible that we found minimum, but it is also possible
      //    that some constraints need deactivation)
      // 3. If D is non-zero, try to use previous scaled step length as initial estimate for new step.
      // 4. Calculate bound on step length.
         ae_v_move(state->work.xR, 1, state->cgc.xR, 1, n);
         for (i = state->bufsize - 1; i >= 0; i--) {
            v = ae_v_dotproduct(state->bufsk.xyR[i], 1, state->work.xR, 1, n);
            state->buftheta.xR[i] = v;
            vv = v * state->bufrho.xR[i];
            ae_v_subd(state->work.xR, 1, state->bufyk.xyR[i], 1, n, vv);
         }
         for (i = 0; i < n; i++) {
            state->work.xR[i] *= state->tmpprec.xR[i];
         }
         for (i = 0; i < state->bufsize; i++) {
            v = ae_v_dotproduct(state->bufyk.xyR[i], 1, state->work.xR, 1, n);
            vv = state->bufrho.xR[i] * (-v + state->buftheta.xR[i]);
            ae_v_addd(state->work.xR, 1, state->bufsk.xyR[i], 1, n, vv);
         }
         ae_v_moveneg(state->d.xR, 1, state->work.xR, 1, n);
         b = false;
         for (i = 0; i < n; i++)
            b = b ||
               state->hasbndl.xB[i] && state->xc.xR[i] == state->bndl.xR[i] && state->d.xR[i] != 0.0 ||
               state->hasbndu.xB[i] && state->xc.xR[i] == state->bndu.xR[i] && state->d.xR[i] != 0.0;
         ae_assert(!b, "MinBC: integrity check failed (q)");
         scaleddnorm = 0.0;
         for (i = 0; i < n; i++) {
            scaleddnorm += sqr(state->d.xR[i] / state->s.xR[i]);
         }
         scaleddnorm = sqrt(scaleddnorm);
         if (scaleddnorm == 0.0) {
         // Search direction is zero.
         // Skip back to steepest descent phase.
            break;
         }
         if (state->lastscaledgoodstep > 0.0) {
            state->stp = state->lastscaledgoodstep / scaleddnorm;
         } else {
            state->stp = 1.0 / scaleddnorm;
         }
         state->curstpmax = 1.0E50;
         if (state->stpmax > 0.0) {
            state->curstpmax = rmin2(state->curstpmax, state->stpmax / scaleddnorm);
         }
      // Minimize G(t) = F(CONSTRAIN(XC + t*D)), with t being scalar, XC and D being vectors.
         ae_v_move(state->xn.xR, 1, state->xc.xR, 1, n);
         ae_v_move(state->cgn.xR, 1, state->cgc.xR, 1, n);
         ae_v_move(state->ugn.xR, 1, state->ugc.xR, 1, n);
         state->fn = state->fc;
         state->mcstage = 0;
         smoothnessmonitorstartlinesearch1u(&state->smonitor, &state->s, &state->invs, &state->xn, state->fn, &state->ugn, state->repiterationscount, -1);
         while (mcsrch(n, &state->xn, state->fn, &state->cgn, &state->d, &state->stp, state->curstpmax, gtol, &mcinfo, &state->nfev, &state->work, &state->lstate, &state->mcstage)) {
         // Copy XN to X, perform on-the-fly correction w.r.t box
         // constraints (projection onto feasible set).
            for (i = 0; i < n; i++) {
               state->x.xR[i] = state->xn.xR[i];
               if (state->hasbndl.xB[i] && state->xn.xR[i] <= state->bndl.xR[i]) {
                  state->x.xR[i] = state->bndl.xR[i];
               }
               if (state->hasbndu.xB[i] && state->xn.xR[i] >= state->bndu.xR[i]) {
                  state->x.xR[i] = state->bndu.xR[i];
               }
            }
         // Gradient, either user-provided or numerical differentiation
            if (state->diffstep == 0.0) {
            // Analytic gradient
               state->needfg = true, state->PQ = 21; goto Pause; Resume21: state->needfg = false;
               state->repnfev++;
            } else {
            // Numerical differentiation
               state->needf = true;
               state->PQ = 22; goto Pause; Resume22:
               state->fbase = state->f;
               for (i = 0; i < n; i++) {
                  v = state->x.xR[i];
                  b =
                     state->hasbndl.xB[i] && v - state->diffstep * state->s.xR[i] < state->bndl.xR[i] ||
                     state->hasbndu.xB[i] && v + state->diffstep * state->s.xR[i] > state->bndu.xR[i];
                  if (!b) {
                     state->x.xR[i] = v - state->diffstep * state->s.xR[i];
                     state->PQ = 23; goto Pause; Resume23:
                     state->fm2 = state->f;
                     state->x.xR[i] = v - 0.5 * state->diffstep * state->s.xR[i];
                     state->PQ = 24; goto Pause; Resume24:
                     state->fm1 = state->f;
                     state->x.xR[i] = v + 0.5 * state->diffstep * state->s.xR[i];
                     state->PQ = 25; goto Pause; Resume25:
                     state->fp1 = state->f;
                     state->x.xR[i] = v + state->diffstep * state->s.xR[i];
                     state->PQ = 26; goto Pause; Resume26:
                     state->fp2 = state->f;
                     state->g.xR[i] = (8.0 * (state->fp1 - state->fm1) - (state->fp2 - state->fm2)) / (6.0 * state->diffstep * state->s.xR[i]);
                     state->repnfev += 4;
                  } else {
                     state->xm1 = v - state->diffstep * state->s.xR[i];
                     state->xp1 = v + state->diffstep * state->s.xR[i];
                     if (state->hasbndl.xB[i] && state->xm1 < state->bndl.xR[i]) {
                        state->xm1 = state->bndl.xR[i];
                     }
                     if (state->hasbndu.xB[i] && state->xp1 > state->bndu.xR[i]) {
                        state->xp1 = state->bndu.xR[i];
                     }
                     state->x.xR[i] = state->xm1;
                     state->PQ = 27; goto Pause; Resume27:
                     state->fm1 = state->f;
                     state->x.xR[i] = state->xp1;
                     state->PQ = 28; goto Pause; Resume28:
                     state->fp1 = state->f;
                     if (state->xm1 != state->xp1) {
                        state->g.xR[i] = (state->fp1 - state->fm1) / (state->xp1 - state->xm1);
                     } else {
                        state->g.xR[i] = 0.0;
                     }
                     state->repnfev += 2;
                  }
                  state->x.xR[i] = v;
               }
               state->needf = false;
               state->f = state->fbase;
            }
         // Back to MCSRCH
            smoothnessmonitorenqueuepoint1u(&state->smonitor, &state->s, &state->invs, &state->d, state->stp, &state->x, state->f, &state->g);
            trimfunction(&state->f, &state->g, n, state->trimthreshold);
            state->fn = state->f;
            for (i = 0; i < n; i++) {
               state->ugn.xR[i] = state->g.xR[i];
               state->cgn.xR[i] = state->g.xR[i];
               if (state->hasbndl.xB[i] && state->xn.xR[i] <= state->bndl.xR[i]) {
                  state->cgn.xR[i] = 0.0;
               }
               if (state->hasbndu.xB[i] && state->xn.xR[i] >= state->bndu.xR[i]) {
                  state->cgn.xR[i] = 0.0;
               }
            }
         }
         smoothnessmonitorfinalizelinesearch(&state->smonitor);
         for (i = 0; i < n; i++) {
            if (state->hasbndl.xB[i] && state->xn.xR[i] <= state->bndl.xR[i]) {
               state->xn.xR[i] = state->bndl.xR[i];
            }
            if (state->hasbndu.xB[i] && state->xn.xR[i] >= state->bndu.xR[i]) {
               state->xn.xR[i] = state->bndu.xR[i];
            }
         }
         ae_v_moveneg(state->bufsk.xyR[state->bufsize], 1, state->xc.xR, 1, n);
         ae_v_moveneg(state->bufyk.xyR[state->bufsize], 1, state->cgc.xR, 1, n);
         ae_v_add(state->bufsk.xyR[state->bufsize], 1, state->xn.xR, 1, n);
         ae_v_add(state->bufyk.xyR[state->bufsize], 1, state->cgn.xR, 1, n);
      // Handle special situations:
      // * check for presence of NAN/INF in function/gradient
      // * handle failure of line search
         v = state->fn;
         for (i = 0; i < n; i++) {
            v = 0.1 * v + state->ugn.xR[i];
         }
         if (!isfinite(v)) {
         // Abnormal termination - infinities in function/gradient
            state->repterminationtype = -8;
            goto Exit;
         }
         if (state->userterminationneeded) {
         // User requested termination
            state->repterminationtype = 8;
            goto Exit;
         }
         if (mcinfo != 1) {
         // Terminate LBFGS phase
            break;
         }
      // Current point is updated:
      // * move XC/FC/GC to XP/FP/GP
      // * move XN/FN/GN to XC/FC/GC
      // * report current point and update iterations counter
      // * push new pair SK/YK to LBFGS buffer
      // * update length of the good step
         activationstatus = false;
         for (i = 0; i < n; i++) {
            if (state->hasbndl.xB[i] && state->xn.xR[i] == state->bndl.xR[i] && state->xn.xR[i] != state->xc.xR[i]) {
               activationstatus = true;
            }
            if (state->hasbndu.xB[i] && state->xn.xR[i] == state->bndu.xR[i] && state->xn.xR[i] != state->xc.xR[i]) {
               activationstatus = true;
            }
         }
         state->fp = state->fc;
         state->fc = state->fn;
         ae_v_move(state->xp.xR, 1, state->xc.xR, 1, n);
         ae_v_move(state->xc.xR, 1, state->xn.xR, 1, n);
         ae_v_move(state->cgc.xR, 1, state->cgn.xR, 1, n);
         ae_v_move(state->ugc.xR, 1, state->ugn.xR, 1, n);
         if (state->xrep) {
            ae_v_move(state->x.xR, 1, state->xc.xR, 1, n);
            state->xupdated = true, state->PQ = 29; goto Pause; Resume29: state->xupdated = false;
         }
         state->repiterationscount++;
         if (state->bufsize == m) {
         // Buffer is full, shift contents by one row
            for (i = 0; i < state->bufsize; i++) {
               ae_v_move(state->bufsk.xyR[i], 1, state->bufsk.xyR[i + 1], 1, n);
               ae_v_move(state->bufyk.xyR[i], 1, state->bufyk.xyR[i + 1], 1, n);
            }
            for (i = 0; i < state->bufsize - 1; i++) {
               state->bufrho.xR[i] = state->bufrho.xR[i + 1];
               state->buftheta.xR[i] = state->buftheta.xR[i + 1];
            }
         } else {
         // Buffer is not full, increase buffer size by 1
            state->bufsize++;
         }
         v = ae_v_dotproduct(state->bufyk.xyR[state->bufsize - 1], 1, state->bufsk.xyR[state->bufsize - 1], 1, n);
         vv = ae_v_dotproduct(state->bufyk.xyR[state->bufsize - 1], 1, state->bufyk.xyR[state->bufsize - 1], 1, n);
         if (v == 0.0 || vv == 0.0) {
         // Strange internal error in LBFGS - either YK == 0
         // (which should not have been) or (SK,YK) == 0 (again,
         // unexpected). It should not take place because
         // MCINFO == 1, which signals "good" step. But just
         // to be sure we have special branch of code which
         // restarts LBFGS
            break;
         }
         state->bufrho.xR[state->bufsize - 1] = 1.0 / v;
         ae_assert(state->bufsize <= m, "MinBC: internal error");
         v = 0.0;
         vv = 0.0;
         for (i = 0; i < n; i++) {
            v += sqr((state->xc.xR[i] - state->xp.xR[i]) / state->s.xR[i]);
            vv += sqr(state->xc.xR[i] - state->xp.xR[i]);
         }
         minbc_updateestimateofgoodstep(&state->lastscaledgoodstep, sqrt(v));
      // Check MaxIts-based stopping condition.
         if (state->maxits > 0 && state->repiterationscount >= state->maxits) {
            state->repterminationtype = 5;
            goto Exit;
         }
      // Smooth reset (LBFGS memory model is refreshed) or hard restart:
      // * LBFGS model is refreshed, if line search was performed with activation of constraints
      // * algorithm is restarted if scaled gradient decreased below GDecay
         if (activationstatus) {
            state->bufsize = 0;
            continue;
         }
         v = 0.0;
         for (i = 0; i < n; i++) {
            v += sqr(state->cgc.xR[i] * state->s.xR[i]);
         }
         if (sqrt(v) < gdecay * ginit) {
            break;
         }
      }
   // Decrease decay coefficient. Subsequent L-BFGS stages will
   // have more stringent stopping criteria.
      gdecay = rmax2(gdecay * decaycorrection, mindecay);
   }
Exit:
   state->PQ = -1;
   return false;
Pause:
   return true;
}

// This  function  activates/deactivates verification  of  the  user-supplied
// analytic gradient.
//
// Upon  activation  of  this  option  OptGuard  integrity  checker  performs
// numerical differentiation of your target function  at  the  initial  point
// (note: future versions may also perform check  at  the  final  point)  and
// compares numerical gradient with analytic one provided by you.
//
// If difference is too large, an error flag is set and optimization  session
// continues. After optimization session is over, you can retrieve the report
// which  stores  both  gradients  and  specific  components  highlighted  as
// suspicious by the OptGuard.
//
// The primary OptGuard report can be retrieved with minbcoptguardresults().
//
// IMPORTANT: gradient check is a high-overhead option which  will  cost  you
//            about 3*N additional function evaluations. In many cases it may
//            cost as much as the rest of the optimization session.
//
//            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
//            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
//
// NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
//       does NOT interrupt optimization even if it discovers bad gradient.
//
// Inputs:
//     State       -   structure used to store algorithm state
//     TestStep    -   verification step used for numerical differentiation:
//                     * TestStep == 0 turns verification off
//                     * TestStep > 0 activates verification
//                     You should carefully choose TestStep. Value  which  is
//                     too large (so large that  function  behavior  is  non-
//                     cubic at this scale) will lead  to  false  alarms. Too
//                     short step will result in rounding  errors  dominating
//                     numerical derivative.
//
//                     You may use different step for different parameters by
//                     means of setting scale with minbcsetscale().
//
// ==== EXPLANATION ====
//
// In order to verify gradient algorithm performs following steps:
//   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
//     where X[i] is i-th component of the initial point and S[i] is a  scale
//     of i-th parameter
//   * F(X) is evaluated at these trial points
//   * we perform one more evaluation in the middle point of the interval
//   * we  build  cubic  model using function values and derivatives at trial
//     points and we compare its prediction with actual value in  the  middle
//     point
// ALGLIB: Copyright 15.06.2014 by Sergey Bochkanov
// API: void minbcoptguardgradient(const minbcstate &state, const double teststep);
void minbcoptguardgradient(minbcstate *state, double teststep) {
   ae_assert(isfinite(teststep), "MinBCOptGuardGradient: TestStep contains NaN or INF");
   ae_assert(teststep >= 0.0, "MinBCOptGuardGradient: invalid argument TestStep(TestStep < 0)");
   state->teststep = teststep;
}

// This  function  activates/deactivates nonsmoothness monitoring  option  of
// the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
// solution process and tries to detect ill-posed problems, i.e. ones with:
// a) discontinuous target function (non-C0)
// b) nonsmooth     target function (non-C1)
//
// Smoothness monitoring does NOT interrupt optimization  even if it suspects
// that your problem is nonsmooth. It just sets corresponding  flags  in  the
// OptGuard report which can be retrieved after optimization is over.
//
// Smoothness monitoring is a moderate overhead option which often adds  less
// than 1% to the optimizer running time. Thus, you can use it even for large
// scale problems.
//
// NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
//       continuity violations.
//
//       First, minor errors are hard to  catch - say, a 0.0001 difference in
//       the model values at two sides of the gap may be due to discontinuity
//       of the model - or simply because the model has changed.
//
//       Second, C1-violations  are  especially  difficult  to  detect  in  a
//       noninvasive way. The optimizer usually  performs  very  short  steps
//       near the nonsmoothness, and differentiation  usually   introduces  a
//       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
//       discontinuity in the slope is due to real nonsmoothness or just  due
//       to numerical noise alone.
//
//       Our top priority was to avoid false positives, so in some rare cases
//       minor errors may went unnoticed (however, in most cases they can  be
//       spotted with restart from different initial point).
//
// Inputs:
//     state   -   algorithm state
//     level   -   monitoring level:
//                 * 0 - monitoring is disabled
//                 * 1 - noninvasive low-overhead monitoring; function values
//                       and/or gradients are recorded, but OptGuard does not
//                       try to perform additional evaluations  in  order  to
//                       get more information about suspicious locations.
//
// ==== EXPLANATION ====
//
// One major source of headache during optimization  is  the  possibility  of
// the coding errors in the target function/constraints (or their gradients).
// Such  errors   most   often   manifest   themselves  as  discontinuity  or
// nonsmoothness of the target/constraints.
//
// Another frequent situation is when you try to optimize something involving
// lots of min() and max() operations, i.e. nonsmooth target. Although not  a
// coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
// stop right after encountering nonsmoothness, well before reaching solution.
//
// OptGuard integrity checker helps you to catch such situations: it monitors
// function values/gradients being passed  to  the  optimizer  and  tries  to
// errors. Upon discovering suspicious pair of points it  raises  appropriate
// flag (and allows you to continue optimization). When optimization is done,
// you can study OptGuard result.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbcoptguardsmoothness(const minbcstate &state, const ae_int_t level);
// API: void minbcoptguardsmoothness(const minbcstate &state);
void minbcoptguardsmoothness(minbcstate *state, ae_int_t level) {
   ae_assert(level == 0 || level == 1, "MinBCOptGuardSmoothness: unexpected value of level parameter");
   state->smoothnessguardlevel = level;
}

// Results of OptGuard integrity check, should be called  after  optimization
// session is over.
//
// ==== PRIMARY REPORT ====
//
// OptGuard performs several checks which are intended to catch common errors
// in the implementation of nonlinear function/gradient:
// * incorrect analytic gradient
// * discontinuous (non-C0) target functions (constraints)
// * nonsmooth     (non-C1) target functions (constraints)
//
// Each of these checks is activated with appropriate function:
// * minbcoptguardgradient() for gradient verification
// * minbcoptguardsmoothness() for C0/C1 checks
//
// Following flags are set when these errors are suspected:
// * rep.badgradsuspected, and additionally:
//   * rep.badgradvidx for specific variable (gradient element) suspected
//   * rep.badgradxbase, a point where gradient is tested
//   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
//     single row in order to make  report  structure  compatible  with  more
//     complex optimizers like MinNLC or MinLM)
//   * rep.badgradnum,   reference    gradient    obtained    via   numerical
//     differentiation (stored as  2D matrix with single row in order to make
//     report structure compatible with more complex optimizers  like  MinNLC
//     or MinLM)
// * rep.nonc0suspected
// * rep.nonc1suspected
//
// ==== ADDITIONAL REPORTS/LOGS ====
//
// Several different tests are performed to catch C0/C1 errors, you can  find
// out specific test signaled error by looking to:
// * rep.nonc0test0positive, for non-C0 test #0
// * rep.nonc1test0positive, for non-C1 test #0
// * rep.nonc1test1positive, for non-C1 test #1
//
// Additional information (including line search logs)  can  be  obtained  by
// means of:
// * minbcoptguardnonc1test0results()
// * minbcoptguardnonc1test1results()
// which return detailed error reports, specific points where discontinuities
// were found, and so on.
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     rep     -   generic OptGuard report;  more  detailed  reports  can  be
//                 retrieved with other functions.
//
// NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
//       ones) are possible although unlikely.
//
//       The reason  is  that  you  need  to  make several evaluations around
//       nonsmoothness  in  order  to  accumulate  enough  information  about
//       function curvature. Say, if you start right from the nonsmooth point,
//       optimizer simply won't get enough data to understand what  is  going
//       wrong before it terminates due to abrupt changes in the  derivative.
//       It is also  possible  that  "unlucky"  step  will  move  us  to  the
//       termination too quickly.
//
//       Our current approach is to have less than 0.1%  false  negatives  in
//       our test examples  (measured  with  multiple  restarts  from  random
//       points), and to have exactly 0% false positives.
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbcoptguardresults(const minbcstate &state, optguardreport &rep);
void minbcoptguardresults(minbcstate *state, optguardreport *rep) {
   SetObj(optguardreport, rep);
   smoothnessmonitorexportreport(&state->smonitor, rep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #0
//
// Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
// obtained during line searches and monitors  behavior  of  the  directional
// derivative estimate.
//
// This test is less powerful than test #1, but it does  not  depend  on  the
// gradient values and thus it is more robust against artifacts introduced by
// numerical differentiation.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], f[] - arrays of length CNT which store step lengths and  function
//   values at these points; f[i] is evaluated in x0+stp[i]*d.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #0 "strong" report
//     lngrep  -   C1 test #0 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbcoptguardnonc1test0results(const minbcstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep);
void minbcoptguardnonc1test0results(minbcstate *state, optguardnonc1test0report *strrep, optguardnonc1test0report *lngrep) {
   SetObj(optguardnonc1test0report, strrep);
   SetObj(optguardnonc1test0report, lngrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test0report(&state->smonitor.nonc1test0lngrep, &state->lastscaleused, lngrep);
}

// Detailed results of the OptGuard integrity check for nonsmoothness test #1
//
// Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
// gradient computed during line search.
//
// When precise analytic gradient is provided this test is more powerful than
// test #0  which  works  with  function  values  and  ignores  user-provided
// gradient.  However,  test  #0  becomes  more   powerful   when   numerical
// differentiation is employed (in such cases test #1 detects  higher  levels
// of numerical noise and becomes too conservative).
//
// This test also tells specific components of the gradient which violate  C1
// continuity, which makes it more informative than #0, which just tells that
// continuity is violated.
//
// Two reports are returned:
// * a "strongest" one, corresponding  to  line   search  which  had  highest
//   value of the nonsmoothness indicator
// * a "longest" one, corresponding to line search which  had  more  function
//   evaluations, and thus is more detailed
//
// In both cases following fields are returned:
//
// * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
//   did not notice anything (in the latter cases fields below are empty).
// * vidx - is an index of the variable in [0,N) with nonsmooth derivative
// * x0[], d[] - arrays of length N which store initial point  and  direction
//   for line search (d[] can be normalized, but does not have to)
// * stp[], g[] - arrays of length CNT which store step lengths and  gradient
//   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
//   vidx-th component of the gradient.
// * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
//   between steps #stpidxa and #stpidxb (usually we have  stpidxb == stpidxa+3,
//   with  most  likely  position  of  the  violation  between  stpidxa+1 and
//   stpidxa+2.
//
// ==== SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -   ====
// ====                   you will see where C1 continuity is violated. ====
//
// Inputs:
//     state   -   algorithm state
//
// Outputs:
//     strrep  -   C1 test #1 "strong" report
//     lngrep  -   C1 test #1 "long" report
// ALGLIB: Copyright 21.11.2018 by Sergey Bochkanov
// API: void minbcoptguardnonc1test1results(const minbcstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep);
void minbcoptguardnonc1test1results(minbcstate *state, optguardnonc1test1report *strrep, optguardnonc1test1report *lngrep) {
   SetObj(optguardnonc1test1report, strrep);
   SetObj(optguardnonc1test1report, lngrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1strrep, &state->lastscaleused, strrep);
   smoothnessmonitorexportc1test1report(&state->smonitor.nonc1test1lngrep, &state->lastscaleused, lngrep);
}

// BC results
//
// Buffered implementation of MinBCResults() which uses preallocated buffer
// to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
// intended to be used in the inner cycles of performance critical algorithms
// where array reallocation penalty is too large to be ignored.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbcresultsbuf(const minbcstate &state, real_1d_array &x, minbcreport &rep);
void minbcresultsbuf(minbcstate *state, RVector *x, minbcreport *rep) {
   ae_int_t i;
   vectorsetlengthatleast(x, state->nmain);
   rep->iterationscount = state->repiterationscount;
   rep->nfev = state->repnfev;
   rep->varidx = state->repvaridx;
   rep->terminationtype = state->repterminationtype;
   if (state->repterminationtype > 0) {
      ae_v_move(x->xR, 1, state->xc.xR, 1, state->nmain);
   } else {
      for (i = 0; i < state->nmain; i++) {
         x->xR[i] = NAN;
      }
   }
}

// BC results
//
// Inputs:
//     State   -   algorithm state
//
// Outputs:
//     X       -   array[0..N-1], solution
//     Rep     -   optimization report. You should check Rep.TerminationType
//                 in  order  to  distinguish  successful  termination  from
//                 unsuccessful one:
//                 * -8    internal integrity control  detected  infinite or
//                         NAN   values   in   function/gradient.   Abnormal
//                         termination signalled.
//                 * -3   inconsistent constraints.
//                 *  1   relative function improvement is no more than EpsF.
//                 *  2   scaled step is no more than EpsX.
//                 *  4   scaled gradient norm is no more than EpsG.
//                 *  5   MaxIts steps was taken
//                 *  8   terminated by user who called minbcrequesttermination().
//                        X contains point which was "current accepted"  when
//                        termination request was submitted.
//                 More information about fields of this  structure  can  be
//                 found in the comments on MinBCReport datatype.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
// API: void minbcresults(const minbcstate &state, real_1d_array &x, minbcreport &rep);
void minbcresults(minbcstate *state, RVector *x, minbcreport *rep) {
   SetVector(x);
   SetObj(minbcreport, rep);
   minbcresultsbuf(state, x, rep);
}

// This subroutine submits request for termination of running  optimizer.  It
// should be called from user-supplied callback when user decides that it  is
// time to "smoothly" terminate optimization process.  As  result,  optimizer
// stops at point which was "current accepted" when termination  request  was
// submitted and returns error code 8 (successful termination).
//
// Inputs:
//     State   -   optimizer structure
//
// NOTE: after  request  for  termination  optimizer  may   perform   several
//       additional calls to user-supplied callbacks. It does  NOT  guarantee
//       to stop immediately - it just guarantees that these additional calls
//       will be discarded later.
//
// NOTE: calling this function on optimizer which is NOT running will have no
//       effect.
//
// NOTE: multiple calls to this function are possible. First call is counted,
//       subsequent calls are silently ignored.
// ALGLIB: Copyright 08.10.2014 by Sergey Bochkanov
// API: void minbcrequesttermination(const minbcstate &state);
void minbcrequesttermination(minbcstate *state) {
   state->userterminationneeded = true;
}

void minbcstate_init(void *_p, bool make_automatic) {
   minbcstate *p = (minbcstate *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->diagh, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->x, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->g, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ugc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cgc, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->ugn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->cgn, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xp, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->d, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->hasbndl, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->hasbndu, 0, DT_BOOL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->xstart, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmpprec, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->tmp0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->work, 0, DT_REAL, make_automatic);
   linminstate_init(&p->lstate, make_automatic);
   ae_matrix_init(&p->bufyk, 0, 0, DT_REAL, make_automatic);
   ae_matrix_init(&p->bufsk, 0, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bufrho, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->buftheta, 0, DT_REAL, make_automatic);
   smoothnessmonitor_init(&p->smonitor, make_automatic);
   ae_vector_init(&p->lastscaleused, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->invs, 0, DT_REAL, make_automatic);
}

void minbcstate_copy(void *_dst, const void *_src, bool make_automatic) {
   minbcstate *dst = (minbcstate *)_dst;
   const minbcstate *src = (const minbcstate *)_src;
   dst->nmain = src->nmain;
   dst->epsg = src->epsg;
   dst->epsf = src->epsf;
   dst->epsx = src->epsx;
   dst->maxits = src->maxits;
   dst->xrep = src->xrep;
   dst->stpmax = src->stpmax;
   dst->diffstep = src->diffstep;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   dst->prectype = src->prectype;
   ae_vector_copy(&dst->diagh, &src->diagh, make_automatic);
   ae_vector_copy(&dst->x, &src->x, make_automatic);
   dst->f = src->f;
   ae_vector_copy(&dst->g, &src->g, make_automatic);
   dst->needf = src->needf;
   dst->needfg = src->needfg;
   dst->xupdated = src->xupdated;
   dst->userterminationneeded = src->userterminationneeded;
   dst->PQ = src->PQ;
   ae_vector_copy(&dst->xc, &src->xc, make_automatic);
   ae_vector_copy(&dst->ugc, &src->ugc, make_automatic);
   ae_vector_copy(&dst->cgc, &src->cgc, make_automatic);
   ae_vector_copy(&dst->xn, &src->xn, make_automatic);
   ae_vector_copy(&dst->ugn, &src->ugn, make_automatic);
   ae_vector_copy(&dst->cgn, &src->cgn, make_automatic);
   ae_vector_copy(&dst->xp, &src->xp, make_automatic);
   dst->fc = src->fc;
   dst->fn = src->fn;
   dst->fp = src->fp;
   ae_vector_copy(&dst->d, &src->d, make_automatic);
   dst->lastscaledgoodstep = src->lastscaledgoodstep;
   ae_vector_copy(&dst->hasbndl, &src->hasbndl, make_automatic);
   ae_vector_copy(&dst->hasbndu, &src->hasbndu, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   dst->repiterationscount = src->repiterationscount;
   dst->repnfev = src->repnfev;
   dst->repvaridx = src->repvaridx;
   dst->repterminationtype = src->repterminationtype;
   ae_vector_copy(&dst->xstart, &src->xstart, make_automatic);
   dst->fbase = src->fbase;
   dst->fm2 = src->fm2;
   dst->fm1 = src->fm1;
   dst->fp1 = src->fp1;
   dst->fp2 = src->fp2;
   dst->xm1 = src->xm1;
   dst->xp1 = src->xp1;
   dst->gm1 = src->gm1;
   dst->gp1 = src->gp1;
   ae_vector_copy(&dst->tmpprec, &src->tmpprec, make_automatic);
   ae_vector_copy(&dst->tmp0, &src->tmp0, make_automatic);
   dst->nfev = src->nfev;
   dst->mcstage = src->mcstage;
   dst->stp = src->stp;
   dst->curstpmax = src->curstpmax;
   ae_vector_copy(&dst->work, &src->work, make_automatic);
   linminstate_copy(&dst->lstate, &src->lstate, make_automatic);
   dst->trimthreshold = src->trimthreshold;
   dst->nonmonotoniccnt = src->nonmonotoniccnt;
   ae_matrix_copy(&dst->bufyk, &src->bufyk, make_automatic);
   ae_matrix_copy(&dst->bufsk, &src->bufsk, make_automatic);
   ae_vector_copy(&dst->bufrho, &src->bufrho, make_automatic);
   ae_vector_copy(&dst->buftheta, &src->buftheta, make_automatic);
   dst->bufsize = src->bufsize;
   dst->teststep = src->teststep;
   dst->smoothnessguardlevel = src->smoothnessguardlevel;
   smoothnessmonitor_copy(&dst->smonitor, &src->smonitor, make_automatic);
   ae_vector_copy(&dst->lastscaleused, &src->lastscaleused, make_automatic);
   ae_vector_copy(&dst->invs, &src->invs, make_automatic);
}

void minbcstate_free(void *_p, bool make_automatic) {
   minbcstate *p = (minbcstate *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->diagh, make_automatic);
   ae_vector_free(&p->x, make_automatic);
   ae_vector_free(&p->g, make_automatic);
   ae_vector_free(&p->xc, make_automatic);
   ae_vector_free(&p->ugc, make_automatic);
   ae_vector_free(&p->cgc, make_automatic);
   ae_vector_free(&p->xn, make_automatic);
   ae_vector_free(&p->ugn, make_automatic);
   ae_vector_free(&p->cgn, make_automatic);
   ae_vector_free(&p->xp, make_automatic);
   ae_vector_free(&p->d, make_automatic);
   ae_vector_free(&p->hasbndl, make_automatic);
   ae_vector_free(&p->hasbndu, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   ae_vector_free(&p->xstart, make_automatic);
   ae_vector_free(&p->tmpprec, make_automatic);
   ae_vector_free(&p->tmp0, make_automatic);
   ae_vector_free(&p->work, make_automatic);
   linminstate_free(&p->lstate, make_automatic);
   ae_matrix_free(&p->bufyk, make_automatic);
   ae_matrix_free(&p->bufsk, make_automatic);
   ae_vector_free(&p->bufrho, make_automatic);
   ae_vector_free(&p->buftheta, make_automatic);
   smoothnessmonitor_free(&p->smonitor, make_automatic);
   ae_vector_free(&p->lastscaleused, make_automatic);
   ae_vector_free(&p->invs, make_automatic);
}

void minbcreport_init(void *_p, bool make_automatic) {
}

void minbcreport_copy(void *_dst, const void *_src, bool make_automatic) {
   minbcreport *dst = (minbcreport *)_dst;
   const minbcreport *src = (const minbcreport *)_src;
   dst->iterationscount = src->iterationscount;
   dst->nfev = src->nfev;
   dst->varidx = src->varidx;
   dst->terminationtype = src->terminationtype;
}

void minbcreport_free(void *_p, bool make_automatic) {
}
} // end of namespace alglib_impl

namespace alglib {
// This object stores nonlinear optimizer state.
// You should use functions provided by MinBC subpackage to work with this
// object
DefClass(minbcstate, DecVal(needf) DecVal(needfg) DecVal(xupdated) DecVal(f) DecVar(g) DecVar(x))

// This structure stores optimization report:
// * iterationscount           number of iterations
// * nfev                      number of gradient evaluations
// * terminationtype           termination type (see below)
//
// TERMINATION CODES
//
// terminationtype field contains completion code, which can be:
//   -8    internal integrity control detected  infinite  or  NAN  values  in
//         function/gradient. Abnormal termination signalled.
//   -3    inconsistent constraints.
//    1    relative function improvement is no more than EpsF.
//    2    relative step is no more than EpsX.
//    4    gradient norm is no more than EpsG
//    5    MaxIts steps was taken
//    7    stopping conditions are too stringent,
//         further improvement is impossible,
//         X contains best point found so far.
//    8    terminated by user who called minbcrequesttermination(). X contains
//         point which was "current accepted" when  termination  request  was
//         submitted.
DefClass(minbcreport, DecVal(iterationscount) DecVal(nfev) DecVal(varidx) DecVal(terminationtype))

void minbcsetbc(const minbcstate &state, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetbc(ConstT(minbcstate, state), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void minbcsetcond(const minbcstate &state, const double epsg, const double epsf, const double epsx, const ae_int_t maxits) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetcond(ConstT(minbcstate, state), epsg, epsf, epsx, maxits);
   alglib_impl::ae_state_clear();
}

void minbcsetscale(const minbcstate &state, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetscale(ConstT(minbcstate, state), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void minbcsetprecdefault(const minbcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetprecdefault(ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}

void minbcsetprecdiag(const minbcstate &state, const real_1d_array &d) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetprecdiag(ConstT(minbcstate, state), ConstT(ae_vector, d));
   alglib_impl::ae_state_clear();
}

void minbcsetprecscale(const minbcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetprecscale(ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}

void minbcsetxrep(const minbcstate &state, const bool needxrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetxrep(ConstT(minbcstate, state), needxrep);
   alglib_impl::ae_state_clear();
}

void minbcsetstpmax(const minbcstate &state, const double stpmax) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcsetstpmax(ConstT(minbcstate, state), stpmax);
   alglib_impl::ae_state_clear();
}

void minbcrestartfrom(const minbcstate &state, const real_1d_array &x) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcrestartfrom(ConstT(minbcstate, state), ConstT(ae_vector, x));
   alglib_impl::ae_state_clear();
}

void minbccreate(const ae_int_t n, const real_1d_array &x, minbcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbccreate(n, ConstT(ae_vector, x), ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbccreate(const real_1d_array &x, minbcstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbccreate(n, ConstT(ae_vector, x), ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}
#endif

void minbccreatef(const ae_int_t n, const real_1d_array &x, const double diffstep, minbcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbccreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbccreatef(const real_1d_array &x, const double diffstep, minbcstate &state) {
   ae_int_t n = x.length();
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbccreatef(n, ConstT(ae_vector, x), diffstep, ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}
#endif

bool minbciteration(const minbcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::minbciteration(ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
   return Ok;
}

// This family of functions is used to launch iterations of nonlinear optimizer
//
// These functions accept following parameters:
//     state   -   algorithm state
//     func    -   callback which calculates function (or merit function)
//                 value func at given point x
//     grad    -   callback which calculates function (or merit function)
//                 value func and gradient grad at given point x
//     rep     -   optional callback which is called after each iteration
//                 can be NULL
//     ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
//                 can be NULL
//
// NOTES:
//
// 1. This function has two different implementations: one which  uses  exact
//    (analytical) user-supplied gradient,  and one which uses function value
//    only  and  numerically  differentiates  function  in  order  to  obtain
//    gradient.
//
//    Depending  on  the  specific  function  used to create optimizer object
//    (either  MinBCCreate() for analytical gradient or  MinBCCreateF()
//    for numerical differentiation) you should choose appropriate variant of
//    MinBCOptimize() - one  which  accepts  function  AND gradient or one
//    which accepts function ONLY.
//
//    Be careful to choose variant of MinBCOptimize() which corresponds to
//    your optimization scheme! Table below lists different  combinations  of
//    callback (function/gradient) passed to MinBCOptimize()  and specific
//    function used to create optimizer.
//
//                      |         USER PASSED TO MinBCOptimize()
//    CREATED WITH      |  function only   |  function and gradient
//    ------------------------------------------------------------
//    MinBCCreateF()    |     works               FAILS
//    MinBCCreate()     |     FAILS               works
//
//    Here "FAIL" denotes inappropriate combinations  of  optimizer  creation
//    function  and  MinBCOptimize()  version.   Attemps   to   use   such
//    combination (for  example,  to  create optimizer with MinBCCreateF()
//    and  to  pass  gradient  information  to  MinCGOptimize()) will lead to
//    exception being thrown. Either  you  did  not pass gradient when it WAS
//    needed or you passed gradient when it was NOT needed.
// ALGLIB: Copyright 28.11.2010 by Sergey Bochkanov
void minbcoptimize(minbcstate &state, void (*func)(const real_1d_array &x, double &func, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(func != NULL, "minbcoptimize: func is NULL");
   while (alglib_impl::minbciteration(state.c_ptr()))
   BegPoll
      if (state.needf) func(state.x, state.f, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minbcoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}
void minbcoptimize(minbcstate &state, void (*grad)(const real_1d_array &x, double &func, real_1d_array &grad, void *ptr), void (*rep)(const real_1d_array &x, double func, void *ptr)/* = NULL*/, void *ptr/* = NULL*/) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::ae_assert(grad != NULL, "minbcoptimize: grad is NULL");
   while (alglib_impl::minbciteration(state.c_ptr()))
   BegPoll
      if (state.needfg) grad(state.x, state.f, state.g, ptr);
      else if (state.xupdated) { if (rep != NULL) rep(state.x, state.f, ptr); }
      else alglib_impl::ae_assert(false, "minbcoptimize: some derivatives were not provided?");
   EndPoll
   alglib_impl::ae_state_clear();
}

void minbcoptguardgradient(const minbcstate &state, const double teststep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcoptguardgradient(ConstT(minbcstate, state), teststep);
   alglib_impl::ae_state_clear();
}

void minbcoptguardsmoothness(const minbcstate &state, const ae_int_t level) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcoptguardsmoothness(ConstT(minbcstate, state), level);
   alglib_impl::ae_state_clear();
}
#if !defined AE_NO_EXCEPTIONS
void minbcoptguardsmoothness(const minbcstate &state) {
   ae_int_t level = 1;
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcoptguardsmoothness(ConstT(minbcstate, state), level);
   alglib_impl::ae_state_clear();
}
#endif

void minbcoptguardresults(const minbcstate &state, optguardreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcoptguardresults(ConstT(minbcstate, state), ConstT(optguardreport, rep));
   alglib_impl::ae_state_clear();
}

void minbcoptguardnonc1test0results(const minbcstate &state, optguardnonc1test0report &strrep, optguardnonc1test0report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcoptguardnonc1test0results(ConstT(minbcstate, state), ConstT(optguardnonc1test0report, strrep), ConstT(optguardnonc1test0report, lngrep));
   alglib_impl::ae_state_clear();
}

void minbcoptguardnonc1test1results(const minbcstate &state, optguardnonc1test1report &strrep, optguardnonc1test1report &lngrep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcoptguardnonc1test1results(ConstT(minbcstate, state), ConstT(optguardnonc1test1report, strrep), ConstT(optguardnonc1test1report, lngrep));
   alglib_impl::ae_state_clear();
}

void minbcresultsbuf(const minbcstate &state, real_1d_array &x, minbcreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcresultsbuf(ConstT(minbcstate, state), ConstT(ae_vector, x), ConstT(minbcreport, rep));
   alglib_impl::ae_state_clear();
}

void minbcresults(const minbcstate &state, real_1d_array &x, minbcreport &rep) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcresults(ConstT(minbcstate, state), ConstT(ae_vector, x), ConstT(minbcreport, rep));
   alglib_impl::ae_state_clear();
}

void minbcrequesttermination(const minbcstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::minbcrequesttermination(ConstT(minbcstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib

// === OPTS Package ===
// Depends on: MINLP
namespace alglib_impl {
// Initialize test LP problem.
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemcreate(const ae_int_t n, const bool hasknowntarget, const double targetf, lptestproblem &p);
void lptestproblemcreate(ae_int_t n, bool hasknowntarget, double targetf, lptestproblem *p) {
   SetObj(lptestproblem, p);
   ae_assert(n >= 1, "LPTestProblemCreate: N < 1");
   p->n = n;
   p->hasknowntarget = hasknowntarget;
   if (hasknowntarget) {
      p->targetf = targetf;
   } else {
      p->targetf = NAN;
   }
   ae_vector_set_length(&p->s, n);
   rsetv(n, 1.0, &p->s);
   ae_vector_set_length(&p->c, n);
   rsetv(n, 0.0, &p->c);
   ae_vector_set_length(&p->bndl, n);
   rsetv(n, 0.0, &p->bndl);
   ae_vector_set_length(&p->bndu, n);
   rsetv(n, 0.0, &p->bndu);
   p->m = 0;
   ae_vector_set_length(&p->al, 0);
   ae_vector_set_length(&p->au, 0);
}

// Query test problem info
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: bool lptestproblemhasknowntarget(const lptestproblem &p);
bool lptestproblemhasknowntarget(lptestproblem *p) {
   bool result;
   result = p->hasknowntarget;
   return result;
}

// Query test problem info
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: double lptestproblemgettargetf(const lptestproblem &p);
double lptestproblemgettargetf(lptestproblem *p) {
   double result;
   result = p->targetf;
   return result;
}

// Query test problem info
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: ae_int_t lptestproblemgetn(const lptestproblem &p);
ae_int_t lptestproblemgetn(lptestproblem *p) {
   ae_int_t result;
   result = p->n;
   return result;
}

// Query test problem info
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: ae_int_t lptestproblemgetm(const lptestproblem &p);
ae_int_t lptestproblemgetm(lptestproblem *p) {
   ae_int_t result;
   result = p->m;
   return result;
}

// Set scale for test LP problem
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemsetscale(const lptestproblem &p, const real_1d_array &s);
void lptestproblemsetscale(lptestproblem *p, RVector *s) {
   rcopyv(p->n, s, &p->s);
}

// Set cost for test LP problem
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemsetcost(const lptestproblem &p, const real_1d_array &c);
void lptestproblemsetcost(lptestproblem *p, RVector *c) {
   rcopyv(p->n, c, &p->c);
}

// Set box constraints for test LP problem
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemsetbc(const lptestproblem &p, const real_1d_array &bndl, const real_1d_array &bndu);
void lptestproblemsetbc(lptestproblem *p, RVector *bndl, RVector *bndu) {
   rcopyv(p->n, bndl, &p->bndl);
   rcopyv(p->n, bndu, &p->bndu);
}

// Set box constraints for test LP problem
//
// This function is intended for internal use by ALGLIB.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemsetlc2(const lptestproblem &p, const sparsematrix &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t m);
void lptestproblemsetlc2(lptestproblem *p, sparsematrix *a, RVector *al, RVector *au, ae_int_t m) {
   if (m <= 0) {
      p->m = 0;
      return;
   }
   ae_assert(sparsegetnrows(a) == m, "LPTestProblemSetLC2: rows(A) != M");
   p->m = m;
   sparsecopytocrs(a, &p->a);
   ae_vector_set_length(&p->al, m);
   ae_vector_set_length(&p->au, m);
   rcopyv(m, al, &p->al);
   rcopyv(m, au, &p->au);
}

// This is internal function intended to  be  used  only  by  ALGLIB  itself.
// Although for technical reasons it is made publicly available (and has  its
// own manual entry), you should never call it.
// ALGLIB: Copyright 11.01.2011 by Sergey Bochkanov
// API: void xdbgminlpcreatefromtestproblem(const lptestproblem &p, minlpstate &state);
void xdbgminlpcreatefromtestproblem(lptestproblem *p, minlpstate *state) {
   SetObj(minlpstate, state);
   minlpcreate(p->n, state);
   minlpsetscale(state, &p->s);
   minlpsetcost(state, &p->c);
   minlpsetbc(state, &p->bndl, &p->bndu);
   minlpsetlc2(state, &p->a, &p->al, &p->au, p->m);
}

// Serializer: allocation
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
void lptestproblemalloc(ae_serializer *s, lptestproblem *p) {
   ae_serializer_alloc_entry(s);
   ae_serializer_alloc_entry(s);
   ae_serializer_alloc_entry(s);
   ae_serializer_alloc_entry(s);
   ae_serializer_alloc_entry(s);
   allocrealarray(s, &p->s, p->n);
   allocrealarray(s, &p->c, p->n);
   allocrealarray(s, &p->bndl, p->n);
   allocrealarray(s, &p->bndu, p->n);
   ae_serializer_alloc_entry(s);
   if (p->m > 0) {
      sparsealloc(s, &p->a);
      allocrealarray(s, &p->al, p->m);
      allocrealarray(s, &p->au, p->m);
   }
   ae_serializer_alloc_entry(s);
}

// Serializer: serialization
// These functions serialize a data structure to a C++ string or stream.
// * serialization can be freely moved across 32-bit and 64-bit systems,
//   and different byte orders. For example, you can serialize a string
//   on a SPARC and unserialize it on an x86.
// * ALGLIB++ serialization is compatible with serialization in ALGLIB,
//   in both directions.
// Important properties of s_out:
// * it contains alphanumeric characters, dots, underscores, minus signs
// * these symbols are grouped into words, which are separated by spaces
//   and Windows-style (CR+LF) newlines
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemserialize(lptestproblem &obj, std::string &s_out);
// API: void lptestproblemserialize(lptestproblem &obj, std::ostream &s_out);
void lptestproblemserialize(ae_serializer *s, lptestproblem *p) {
   ae_serializer_serialize_int(s, getlptestserializationcode());
   ae_serializer_serialize_int(s, 0);
   ae_serializer_serialize_int(s, p->n);
   ae_serializer_serialize_bool(s, p->hasknowntarget);
   ae_serializer_serialize_double(s, p->targetf);
   serializerealarray(s, &p->s, p->n);
   serializerealarray(s, &p->c, p->n);
   serializerealarray(s, &p->bndl, p->n);
   serializerealarray(s, &p->bndu, p->n);
   ae_serializer_serialize_int(s, p->m);
   if (p->m > 0) {
      sparseserialize(s, &p->a);
      serializerealarray(s, &p->al, p->m);
      serializerealarray(s, &p->au, p->m);
   }
   ae_serializer_serialize_int(s, 872);
}

// Serializer: unserialization
// These functions unserialize a data structure from a C++ string or stream.
// Important properties of s_in:
// * any combination of spaces, tabs, Windows or Unix stype newlines can
//   be used as separators, so as to allow flexible reformatting of the
//   stream or string from text or XML files.
// * But you should not insert separators into the middle of the "words"
//   nor you should change case of letters.
// ALGLIB: Copyright 20.07.2021 by Sergey Bochkanov
// API: void lptestproblemunserialize(const std::string &s_in, lptestproblem &obj);
// API: void lptestproblemunserialize(const std::istream &s_in, lptestproblem &obj);
void lptestproblemunserialize(ae_serializer *s, lptestproblem *p) {
   SetObj(lptestproblem, p);
   ae_assert(ae_serializer_unserialize_int(s) == getlptestserializationcode(), "lptestproblemunserialize: stream header corrupted");
   ae_assert(ae_serializer_unserialize_int(s) == 0, "lptestproblemunserialize: stream header corrupted");
   p->n = ae_serializer_unserialize_int(s);
   p->hasknowntarget = ae_serializer_unserialize_bool(s);
   p->targetf = ae_serializer_unserialize_double(s);
   unserializerealarray(s, &p->s);
   unserializerealarray(s, &p->c);
   unserializerealarray(s, &p->bndl);
   unserializerealarray(s, &p->bndu);
   p->m = ae_serializer_unserialize_int(s);
   if (p->m > 0) {
      sparseunserialize(s, &p->a);
      unserializerealarray(s, &p->al);
      unserializerealarray(s, &p->au);
   }
   ae_assert(ae_serializer_unserialize_int(s) == 872, "lptestproblemunserialize: end-of-stream marker not found");
}

void lptestproblem_init(void *_p, bool make_automatic) {
   lptestproblem *p = (lptestproblem *)_p;
   ae_vector_init(&p->s, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->c, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndl, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->bndu, 0, DT_REAL, make_automatic);
   sparsematrix_init(&p->a, make_automatic);
   ae_vector_init(&p->al, 0, DT_REAL, make_automatic);
   ae_vector_init(&p->au, 0, DT_REAL, make_automatic);
}

void lptestproblem_copy(void *_dst, const void *_src, bool make_automatic) {
   lptestproblem *dst = (lptestproblem *)_dst;
   const lptestproblem *src = (const lptestproblem *)_src;
   dst->n = src->n;
   dst->hasknowntarget = src->hasknowntarget;
   dst->targetf = src->targetf;
   ae_vector_copy(&dst->s, &src->s, make_automatic);
   ae_vector_copy(&dst->c, &src->c, make_automatic);
   ae_vector_copy(&dst->bndl, &src->bndl, make_automatic);
   ae_vector_copy(&dst->bndu, &src->bndu, make_automatic);
   dst->m = src->m;
   sparsematrix_copy(&dst->a, &src->a, make_automatic);
   ae_vector_copy(&dst->al, &src->al, make_automatic);
   ae_vector_copy(&dst->au, &src->au, make_automatic);
}

void lptestproblem_free(void *_p, bool make_automatic) {
   lptestproblem *p = (lptestproblem *)_p;
   ae_vector_free(&p->s, make_automatic);
   ae_vector_free(&p->c, make_automatic);
   ae_vector_free(&p->bndl, make_automatic);
   ae_vector_free(&p->bndu, make_automatic);
   sparsematrix_free(&p->a, make_automatic);
   ae_vector_free(&p->al, make_automatic);
   ae_vector_free(&p->au, make_automatic);
}
} // end of namespace alglib_impl

namespace alglib {
// This is a test problem class  intended  for  internal  performance  tests.
// Never use it directly in your projects.
DefClass(lptestproblem, )

void lptestproblemserialize(lptestproblem &obj, std::string &s_out) {
   alglib_impl::ae_state_init();
   TryCatch()
   NewSerializer(serializer);
   alglib_impl::ae_serializer_alloc_start(&serializer);
   alglib_impl::lptestproblemalloc(&serializer, obj.c_ptr());
   size_t ssize = alglib_impl::ae_serializer_get_alloc_size(&serializer);
   s_out.clear();
   s_out.reserve(ssize + 1);
   alglib_impl::ae_serializer_sstart_str(&serializer, &s_out);
   alglib_impl::lptestproblemserialize(&serializer, obj.c_ptr());
   alglib_impl::ae_serializer_stop(&serializer);
   alglib_impl::ae_assert(s_out.length() <= (size_t)ssize, "lptestproblemserialize: serialization integrity error");
   alglib_impl::ae_state_clear();
}
void lptestproblemserialize(lptestproblem &obj, std::ostream &s_out) {
   alglib_impl::ae_state_init();
   TryCatch()
   NewSerializer(serializer);
   alglib_impl::ae_serializer_alloc_start(&serializer);
   alglib_impl::lptestproblemalloc(&serializer, obj.c_ptr());
   alglib_impl::ae_serializer_get_alloc_size(&serializer); // not actually needed, but we have to ask
   alglib_impl::ae_serializer_sstart_stream(&serializer, &s_out);
   alglib_impl::lptestproblemserialize(&serializer, obj.c_ptr());
   alglib_impl::ae_serializer_stop(&serializer);
   alglib_impl::ae_state_clear();
}

void lptestproblemunserialize(const std::string &s_in, lptestproblem &obj) {
   alglib_impl::ae_state_init();
   TryCatch()
   NewSerializer(serializer);
   alglib_impl::ae_serializer_ustart_str(&serializer, &s_in);
   alglib_impl::lptestproblemunserialize(&serializer, obj.c_ptr());
   alglib_impl::ae_serializer_stop(&serializer);
   alglib_impl::ae_state_clear();
}
void lptestproblemunserialize(const std::istream &s_in, lptestproblem &obj) {
   alglib_impl::ae_state_init();
   TryCatch()
   NewSerializer(serializer);
   alglib_impl::ae_serializer_ustart_stream(&serializer, &s_in);
   alglib_impl::lptestproblemunserialize(&serializer, obj.c_ptr());
   alglib_impl::ae_serializer_stop(&serializer);
   alglib_impl::ae_state_clear();
}

void lptestproblemcreate(const ae_int_t n, const bool hasknowntarget, const double targetf, lptestproblem &p) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::lptestproblemcreate(n, hasknowntarget, targetf, ConstT(lptestproblem, p));
   alglib_impl::ae_state_clear();
}

bool lptestproblemhasknowntarget(const lptestproblem &p) {
   alglib_impl::ae_state_init();
   TryCatch(false)
   bool Ok = alglib_impl::lptestproblemhasknowntarget(ConstT(lptestproblem, p));
   alglib_impl::ae_state_clear();
   return Ok;
}

double lptestproblemgettargetf(const lptestproblem &p) {
   alglib_impl::ae_state_init();
   TryCatch(0.0)
   double D = alglib_impl::lptestproblemgettargetf(ConstT(lptestproblem, p));
   alglib_impl::ae_state_clear();
   return D;
}

ae_int_t lptestproblemgetn(const lptestproblem &p) {
   alglib_impl::ae_state_init();
   TryCatch(0)
   ae_int_t Z = alglib_impl::lptestproblemgetn(ConstT(lptestproblem, p));
   alglib_impl::ae_state_clear();
   return Z;
}

ae_int_t lptestproblemgetm(const lptestproblem &p) {
   alglib_impl::ae_state_init();
   TryCatch(0)
   ae_int_t Z = alglib_impl::lptestproblemgetm(ConstT(lptestproblem, p));
   alglib_impl::ae_state_clear();
   return Z;
}

void lptestproblemsetscale(const lptestproblem &p, const real_1d_array &s) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::lptestproblemsetscale(ConstT(lptestproblem, p), ConstT(ae_vector, s));
   alglib_impl::ae_state_clear();
}

void lptestproblemsetcost(const lptestproblem &p, const real_1d_array &c) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::lptestproblemsetcost(ConstT(lptestproblem, p), ConstT(ae_vector, c));
   alglib_impl::ae_state_clear();
}

void lptestproblemsetbc(const lptestproblem &p, const real_1d_array &bndl, const real_1d_array &bndu) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::lptestproblemsetbc(ConstT(lptestproblem, p), ConstT(ae_vector, bndl), ConstT(ae_vector, bndu));
   alglib_impl::ae_state_clear();
}

void lptestproblemsetlc2(const lptestproblem &p, const sparsematrix &a, const real_1d_array &al, const real_1d_array &au, const ae_int_t m) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::lptestproblemsetlc2(ConstT(lptestproblem, p), ConstT(sparsematrix, a), ConstT(ae_vector, al), ConstT(ae_vector, au), m);
   alglib_impl::ae_state_clear();
}

void xdbgminlpcreatefromtestproblem(const lptestproblem &p, minlpstate &state) {
   alglib_impl::ae_state_init();
   TryCatch()
   alglib_impl::xdbgminlpcreatefromtestproblem(ConstT(lptestproblem, p), ConstT(minlpstate, state));
   alglib_impl::ae_state_clear();
}
} // end of namespace alglib
